{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d17a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import(\n",
    "    RandomForestRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    StackingRegressor,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce1950",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3af2a7",
   "metadata": {},
   "source": [
    "<b>Data Preparation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9b8242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>ROM</th>\n",
       "      <th>RAM</th>\n",
       "      <th>OS</th>\n",
       "      <th>Screen size</th>\n",
       "      <th>Dual Sim</th>\n",
       "      <th>Expandable Memory</th>\n",
       "      <th>5G</th>\n",
       "      <th>Fingerprint Sensor</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Y5 Prime</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Android</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Y5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Android</td>\n",
       "      <td>5.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone 4S</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>iOS</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Y5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Android</td>\n",
       "      <td>5.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Y5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Android</td>\n",
       "      <td>5.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand      Model   ROM  RAM       OS  Screen size  Dual Sim  \\\n",
       "0  Huawei   Y5 Prime  16.0  2.0  Android         5.45         1   \n",
       "1  Huawei         Y5  16.0  2.0  Android         5.71         1   \n",
       "2   Apple  iPhone 4S  16.0  0.5      iOS         3.50         0   \n",
       "3  Huawei         Y5  16.0  2.0  Android         5.71         0   \n",
       "4  Huawei         Y5  16.0  2.0  Android         5.71         1   \n",
       "\n",
       "   Expandable Memory  5G  Fingerprint Sensor  Price  \n",
       "0                  1   0                   1   5000  \n",
       "1                  1   0                   1   5000  \n",
       "2                  0   0                   0   5000  \n",
       "3                  0   0                   0   5000  \n",
       "4                  0   0                   0   5000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MobilePhonedata_new2.csv')\n",
    "df = df.iloc[: , 1:]\n",
    "X=df.drop(\"Price\", axis=1)\n",
    "y=np.log(df[\"Price\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4331ef76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROM</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Screen size</th>\n",
       "      <th>Dual Sim</th>\n",
       "      <th>Expandable Memory</th>\n",
       "      <th>5G</th>\n",
       "      <th>Fingerprint Sensor</th>\n",
       "      <th>Brand_Asus</th>\n",
       "      <th>Brand_BlackBerry</th>\n",
       "      <th>Brand_Google</th>\n",
       "      <th>...</th>\n",
       "      <th>Model_iPhone XR</th>\n",
       "      <th>Model_iPhone XS</th>\n",
       "      <th>Model_iPhone XS Max</th>\n",
       "      <th>Model_style</th>\n",
       "      <th>Model_style 2</th>\n",
       "      <th>Model_style2</th>\n",
       "      <th>OS_BlackBerry OS</th>\n",
       "      <th>OS_Other</th>\n",
       "      <th>OS_Symbian OS</th>\n",
       "      <th>OS_iOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROM  RAM  Screen size  Dual Sim  Expandable Memory  5G  \\\n",
       "0  16.0  2.0         5.45         1                  1   0   \n",
       "1  16.0  2.0         5.71         1                  1   0   \n",
       "2  16.0  0.5         3.50         0                  0   0   \n",
       "3  16.0  2.0         5.71         0                  0   0   \n",
       "4  16.0  2.0         5.71         1                  0   0   \n",
       "\n",
       "   Fingerprint Sensor  Brand_Asus  Brand_BlackBerry  Brand_Google  ...  \\\n",
       "0                   1           0                 0             0  ...   \n",
       "1                   1           0                 0             0  ...   \n",
       "2                   0           0                 0             0  ...   \n",
       "3                   0           0                 0             0  ...   \n",
       "4                   0           0                 0             0  ...   \n",
       "\n",
       "   Model_iPhone XR  Model_iPhone XS  Model_iPhone XS Max  Model_style  \\\n",
       "0                0                0                    0            0   \n",
       "1                0                0                    0            0   \n",
       "2                0                0                    0            0   \n",
       "3                0                0                    0            0   \n",
       "4                0                0                    0            0   \n",
       "\n",
       "   Model_style 2  Model_style2  OS_BlackBerry OS  OS_Other  OS_Symbian OS  \\\n",
       "0              0             0                 0         0              0   \n",
       "1              0             0                 0         0              0   \n",
       "2              0             0                 0         0              0   \n",
       "3              0             0                 0         0              0   \n",
       "4              0             0                 0         0              0   \n",
       "\n",
       "   OS_iOS  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 626 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, columns=[\"Brand\", \"Model\", \"OS\"], drop_first=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7539e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377fde37",
   "metadata": {},
   "source": [
    "<b>Choose Model, Train and Evaluate</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e4a4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearregression = LinearRegression()\n",
    "linearregression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "560c0ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Coefficients for each of the independent attributes\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, col_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m----> 5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe coefficients for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(col_name, \u001b[43mlinearregression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      6\u001b[0m     )\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "#Coefficients for each of the independent attributes\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\n",
    "        \"The coefficients for {} is {}\".format(col_name, linearregression.coef_[0][idx])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd23bd9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe intercept for our model is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mlinearregression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "print(\"The intercept for our model is {}\".format(linearregression.intercept_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d59df018",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = linearregression.predict(X_train)\n",
    "pred_test = linearregression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bb8e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9453991907376229\n",
      "-199870930315925.38\n"
     ]
    }
   ],
   "source": [
    "#R2 Squared\n",
    "lrscore_train = linearregression.score(X_train, y_train)\n",
    "lrscore_test = linearregression.score(X_test, y_test)\n",
    "print(lrscore_train)\n",
    "print(lrscore_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7f7b7fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18675248915675133\n",
      "11419290.601834722\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_lr_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_lr_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print(rmse_lr_train)\n",
    "print(rmse_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5411c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bb54045",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mdata\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual\u001b[39m\u001b[38;5;124m\"\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Price vs Residual\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Price\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(data[\"pred\"], data[\"residual\"], color=\"red\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0dc22fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, pred_test, color=\"red\")\n",
    "plt.plot( y_test, color=\"blue\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a0fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d144a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b91df0b4",
   "metadata": {},
   "source": [
    "<b>Comparing the actual output values for X_test with the predicted values.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a32b6518",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      2\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pred_test\n\u001b[1;32m----> 3\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Price'"
     ]
    }
   ],
   "source": [
    "data = y_test.copy()\n",
    "data[\"pred\"] = pred_test\n",
    "data[\"residual\"] = data[\"Price\"] - data[\"pred\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d1563d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'residual'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'residual'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresidual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Price vs Residual\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Price\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'residual'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(data[\"pred\"], data[\"residual\"], color=\"red\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d971b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9766       637.84375\n",
      "22672      128.18750\n",
      "2300      1440.50000\n",
      "15956   -18832.43750\n",
      "27170     6377.21875\n",
      "            ...     \n",
      "11469      462.15625\n",
      "6713      3887.34375\n",
      "39206     5554.90625\n",
      "14223     1987.00000\n",
      "3475     -5347.34375\n",
      "Name: residual, Length: 12007, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2488e0712b0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data.residual)\n",
    "import seaborn as sns\n",
    "d = pd.DataFrame(data.residual)\n",
    "\n",
    "sns.displot(data=d, x = \"residual\",kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6311d6",
   "metadata": {},
   "source": [
    "Because of the complexity in the data, Linear Regression is not a good choice for this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e723da0c",
   "metadata": {},
   "source": [
    "### Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b686431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=80, min_samples_split=10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfregressor =RandomForestRegressor(max_depth=80, min_samples_split=10,criterion=\"squared_error\")\n",
    "rfregressor.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12d4e444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37368</th>\n",
       "      <td>147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>17500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>17000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40017</th>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24554</th>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>17500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>29500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28016 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Price\n",
       "37368  147000\n",
       "6280    17500\n",
       "5953    17000\n",
       "40017  480000\n",
       "24554   42000\n",
       "...       ...\n",
       "6265    17500\n",
       "11284   24000\n",
       "38158  177000\n",
       "860      7800\n",
       "15795   29500\n",
       "\n",
       "[28016 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76665a22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfregressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_train \u001b[38;5;241m=\u001b[39m \u001b[43mrfregressor\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m      2\u001b[0m pred_test \u001b[38;5;241m=\u001b[39m rfregressor\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rfregressor' is not defined"
     ]
    }
   ],
   "source": [
    "pred_train = rfregressor.predict(X_train)\n",
    "pred_test = rfregressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c27cc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9752085698350669\n",
      "0.9605708146775603\n"
     ]
    }
   ],
   "source": [
    "rfscore_train = rfregressor.score(X_train, y_train)\n",
    "rfscore_test = rfregressor.score(X_test, y_test)\n",
    "print(rfscore_train)\n",
    "print(rfscore_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a9d5d",
   "metadata": {},
   "source": [
    "The R-squared values are around 94% and 93% which is very high compared to Linear Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbc4d334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8219.138668319478\n",
      "10320.391159606683\n"
     ]
    }
   ],
   "source": [
    "rmse_rf_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_rf_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print(rmse_rf_train)\n",
    "print(rmse_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1455cf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>pred</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22000</td>\n",
       "      <td>22325.936244</td>\n",
       "      <td>-325.936244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22672</th>\n",
       "      <td>39000</td>\n",
       "      <td>39500.159657</td>\n",
       "      <td>-500.159657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>11000</td>\n",
       "      <td>9980.575483</td>\n",
       "      <td>1019.424517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15956</th>\n",
       "      <td>29500</td>\n",
       "      <td>46009.483211</td>\n",
       "      <td>-16509.483211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27170</th>\n",
       "      <td>49000</td>\n",
       "      <td>49435.690277</td>\n",
       "      <td>-435.690277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price          pred      residual\n",
       "9766   22000  22325.936244   -325.936244\n",
       "22672  39000  39500.159657   -500.159657\n",
       "2300   11000   9980.575483   1019.424517\n",
       "15956  29500  46009.483211 -16509.483211\n",
       "27170  49000  49435.690277   -435.690277"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = y_test.copy()\n",
    "data[\"pred\"] = pred_test\n",
    "data[\"residual\"] = data[\"Price\"] - data[\"pred\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c0af842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(data[\"pred\"], data[\"residual\"], color=\"red\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7707263e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAM</th>\n",
       "      <td>0.355145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROM</th>\n",
       "      <td>0.320751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OS_iOS</th>\n",
       "      <td>0.093523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_iPhone 12 Pro Max</th>\n",
       "      <td>0.075398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Screen size</th>\n",
       "      <td>0.034195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_Redmi Note 3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_Nova 2 Lite</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_Safari</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_Safari 2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_Magna</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "RAM                      0.355145\n",
       "ROM                      0.320751\n",
       "OS_iOS                   0.093523\n",
       "Model_iPhone 12 Pro Max  0.075398\n",
       "Screen size              0.034195\n",
       "...                           ...\n",
       "Model_Redmi Note 3       0.000000\n",
       "Model_Nova 2 Lite        0.000000\n",
       "Model_Safari             0.000000\n",
       "Model_Safari 2           0.000000\n",
       "Model_Magna              0.000000\n",
       "\n",
       "[626 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rfregressor.feature_importances_, index=X_test.columns).sort_values(\n",
    "    0, ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5559798",
   "metadata": {},
   "source": [
    "### Adaboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91625458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=10,\n",
       "                                                       min_samples_split=100,\n",
       "                                                       random_state=42),\n",
       "                  random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "adaboost = AdaBoostRegressor(\n",
    "    base_estimator = DecisionTreeRegressor(\n",
    "        max_depth=10, min_samples_split=100, random_state=42\n",
    "    ),\n",
    "    random_state=42,\n",
    ")\n",
    "adaboost.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4409445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = adaboost.predict(X_train)\n",
    "pred_test = adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0dcad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9506333594260149\n",
      "0.9375204646263878\n"
     ]
    }
   ],
   "source": [
    "adascore_train = adaboost.score(X_train, y_train)\n",
    "adascore_test = adaboost.score(X_test, y_test)\n",
    "print(adascore_train)\n",
    "print(adascore_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e40e3ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11598.245688635523\n",
      "12991.405894271455\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "rmse_ada_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_ada_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print(rmse_ada_train)\n",
    "print(rmse_ada_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c6a3a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>pred</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22000</td>\n",
       "      <td>22735.733945</td>\n",
       "      <td>-735.733945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22672</th>\n",
       "      <td>39000</td>\n",
       "      <td>39370.818182</td>\n",
       "      <td>-370.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>11000</td>\n",
       "      <td>10692.612245</td>\n",
       "      <td>307.387755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15956</th>\n",
       "      <td>29500</td>\n",
       "      <td>34534.449608</td>\n",
       "      <td>-5034.449608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27170</th>\n",
       "      <td>49000</td>\n",
       "      <td>44833.763566</td>\n",
       "      <td>4166.236434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price          pred     residual\n",
       "9766   22000  22735.733945  -735.733945\n",
       "22672  39000  39370.818182  -370.818182\n",
       "2300   11000  10692.612245   307.387755\n",
       "15956  29500  34534.449608 -5034.449608\n",
       "27170  49000  44833.763566  4166.236434"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = y_test.copy()\n",
    "data[\"pred\"] = pred_test\n",
    "data[\"residual\"] = data[\"Price\"] - data[\"pred\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d764b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(data[\"pred\"], data[\"residual\"], color=\"red\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b51ee1",
   "metadata": {},
   "source": [
    "### Gradient Boost Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "708b34fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=10,\n",
       "                          min_samples_split=100, random_state=30)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gradientboost = GradientBoostingRegressor(\n",
    "    max_depth=10, min_samples_split=100, learning_rate=0.01, random_state=30\n",
    ")\n",
    "gradientboost.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b4bdeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = gradientboost.predict(X_train)\n",
    "pred_test = gradientboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8e00933",
   "metadata": {},
   "source": [
    "gradientscore_train = gradientboost.score(X_train, y_train)\n",
    "gradientscore_test = gradientboost.score(X_train, y_train)\n",
    "print(gradientscore_train)\n",
    "print(gradientscore_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa5a3f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21788.241280245515\n",
      "22151.94969718857\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "rmse_gradient_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_gradient_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print(rmse_gradient_train)\n",
    "print(rmse_gradient_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4e429f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>pred</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22000</td>\n",
       "      <td>33339.427366</td>\n",
       "      <td>-11339.427366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22672</th>\n",
       "      <td>39000</td>\n",
       "      <td>44313.693948</td>\n",
       "      <td>-5313.693948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>11000</td>\n",
       "      <td>25564.371392</td>\n",
       "      <td>-14564.371392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15956</th>\n",
       "      <td>29500</td>\n",
       "      <td>44345.351416</td>\n",
       "      <td>-14845.351416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27170</th>\n",
       "      <td>49000</td>\n",
       "      <td>47406.074275</td>\n",
       "      <td>1593.925725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price          pred      residual\n",
       "9766   22000  33339.427366 -11339.427366\n",
       "22672  39000  44313.693948  -5313.693948\n",
       "2300   11000  25564.371392 -14564.371392\n",
       "15956  29500  44345.351416 -14845.351416\n",
       "27170  49000  47406.074275   1593.925725"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = y_test.copy()\n",
    "data[\"pred\"] = pred_test\n",
    "data[\"residual\"] = data[\"Price\"] - data[\"pred\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e4d9409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(data[\"pred\"], data[\"residual\"], color=\"red\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b7369",
   "metadata": {},
   "source": [
    "### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9106d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2749467231.66211987\n",
      "Iteration 2, loss = 2744657295.46700430\n",
      "Iteration 3, loss = 2734354440.27566957\n",
      "Iteration 4, loss = 2720411918.80964947\n",
      "Iteration 5, loss = 2702725320.95245695\n",
      "Iteration 6, loss = 2681605134.53726339\n",
      "Iteration 7, loss = 2657195864.29869699\n",
      "Iteration 8, loss = 2629657013.48597717\n",
      "Iteration 9, loss = 2599318789.10924816\n",
      "Iteration 10, loss = 2566365797.23986149\n",
      "Iteration 11, loss = 2531299844.29710960\n",
      "Iteration 12, loss = 2494088583.58781910\n",
      "Iteration 13, loss = 2454963489.27360106\n",
      "Iteration 14, loss = 2414229477.18143892\n",
      "Iteration 15, loss = 2371922416.95725536\n",
      "Iteration 16, loss = 2328216781.14284992\n",
      "Iteration 17, loss = 2283346628.39066362\n",
      "Iteration 18, loss = 2237508730.41149330\n",
      "Iteration 19, loss = 2190785312.62856960\n",
      "Iteration 20, loss = 2143471578.20528650\n",
      "Iteration 21, loss = 2095657385.51934719\n",
      "Iteration 22, loss = 2047434510.36943150\n",
      "Iteration 23, loss = 1999008900.05104828\n",
      "Iteration 24, loss = 1950450491.44357991\n",
      "Iteration 25, loss = 1902076601.85518861\n",
      "Iteration 26, loss = 1853831452.61029601\n",
      "Iteration 27, loss = 1805554260.77770090\n",
      "Iteration 28, loss = 1757924288.45609426\n",
      "Iteration 29, loss = 1710711103.07565379\n",
      "Iteration 30, loss = 1663929165.21918845\n",
      "Iteration 31, loss = 1618586905.12643838\n",
      "Iteration 32, loss = 1573615149.68374944\n",
      "Iteration 33, loss = 1529640660.16798615\n",
      "Iteration 34, loss = 1486680726.21148157\n",
      "Iteration 35, loss = 1444860675.53436875\n",
      "Iteration 36, loss = 1404201187.75878263\n",
      "Iteration 37, loss = 1364764113.19403934\n",
      "Iteration 38, loss = 1326554524.45190310\n",
      "Iteration 39, loss = 1289729791.97020316\n",
      "Iteration 40, loss = 1253928105.45759702\n",
      "Iteration 41, loss = 1220079543.22662592\n",
      "Iteration 42, loss = 1187790815.43352461\n",
      "Iteration 43, loss = 1157273265.88038397\n",
      "Iteration 44, loss = 1128331354.54565501\n",
      "Iteration 45, loss = 1100911183.30416846\n",
      "Iteration 46, loss = 1075304283.61485791\n",
      "Iteration 47, loss = 1051159662.51835060\n",
      "Iteration 48, loss = 1028928548.88513041\n",
      "Iteration 49, loss = 1008500136.14766979\n",
      "Iteration 50, loss = 989844102.12909710\n",
      "Iteration 51, loss = 972689529.24236357\n",
      "Iteration 52, loss = 957136318.87265265\n",
      "Iteration 53, loss = 943198492.12481499\n",
      "Iteration 54, loss = 930810211.40183663\n",
      "Iteration 55, loss = 919868040.38434041\n",
      "Iteration 56, loss = 910188694.90390885\n",
      "Iteration 57, loss = 902096460.70086396\n",
      "Iteration 58, loss = 894784724.17521143\n",
      "Iteration 59, loss = 888658385.31767356\n",
      "Iteration 60, loss = 883757776.10637486\n",
      "Iteration 61, loss = 879730560.58525836\n",
      "Iteration 62, loss = 876343456.82482672\n",
      "Iteration 63, loss = 873685338.57815516\n",
      "Iteration 64, loss = 871482674.50283015\n",
      "Iteration 65, loss = 869863858.30793858\n",
      "Iteration 66, loss = 868412396.97230840\n",
      "Iteration 67, loss = 867268333.33119690\n",
      "Iteration 68, loss = 866312191.63698590\n",
      "Iteration 69, loss = 865544688.39754081\n",
      "Iteration 70, loss = 864912322.46164012\n",
      "Iteration 71, loss = 864361617.56204784\n",
      "Iteration 72, loss = 863870659.88331425\n",
      "Iteration 73, loss = 863398316.76856136\n",
      "Iteration 74, loss = 862955029.12986672\n",
      "Iteration 75, loss = 862544937.08575773\n",
      "Iteration 76, loss = 862097867.25920773\n",
      "Iteration 77, loss = 861667231.57901537\n",
      "Iteration 78, loss = 861225094.07176661\n",
      "Iteration 79, loss = 860807034.91640365\n",
      "Iteration 80, loss = 860379796.80919468\n",
      "Iteration 81, loss = 859918915.41980481\n",
      "Iteration 82, loss = 859478520.57877171\n",
      "Iteration 83, loss = 859025574.61983597\n",
      "Iteration 84, loss = 858589154.28056705\n",
      "Iteration 85, loss = 858121936.72810042\n",
      "Iteration 86, loss = 857665944.11151552\n",
      "Iteration 87, loss = 857214965.63124132\n",
      "Iteration 88, loss = 856755078.21745801\n",
      "Iteration 89, loss = 856317227.73690486\n",
      "Iteration 90, loss = 855846396.60334289\n",
      "Iteration 91, loss = 855396706.79015923\n",
      "Iteration 92, loss = 854916681.66553330\n",
      "Iteration 93, loss = 854470453.18601441\n",
      "Iteration 94, loss = 853995821.39786816\n",
      "Iteration 95, loss = 853533875.08241379\n",
      "Iteration 96, loss = 853018692.50736046\n",
      "Iteration 97, loss = 852610305.19822216\n",
      "Iteration 98, loss = 852141658.47125065\n",
      "Iteration 99, loss = 851677027.65475035\n",
      "Iteration 100, loss = 851213235.48476732\n",
      "Iteration 101, loss = 850743927.59403312\n",
      "Iteration 102, loss = 850283125.34962559\n",
      "Iteration 103, loss = 849816118.25167799\n",
      "Iteration 104, loss = 849343336.74873972\n",
      "Iteration 105, loss = 848876547.47889149\n",
      "Iteration 106, loss = 848402895.66920578\n",
      "Iteration 107, loss = 847941376.64242625\n",
      "Iteration 108, loss = 847477701.27260184\n",
      "Iteration 109, loss = 846997520.87492764\n",
      "Iteration 110, loss = 846541753.64315224\n",
      "Iteration 111, loss = 846069603.73378575\n",
      "Iteration 112, loss = 845595519.42111802\n",
      "Iteration 113, loss = 845109597.12782609\n",
      "Iteration 114, loss = 844636595.40550911\n",
      "Iteration 115, loss = 844189571.36159337\n",
      "Iteration 116, loss = 843700705.38853300\n",
      "Iteration 117, loss = 843212219.15268314\n",
      "Iteration 118, loss = 842739823.47458291\n",
      "Iteration 119, loss = 842268939.63486314\n",
      "Iteration 120, loss = 841797787.69240391\n",
      "Iteration 121, loss = 841321586.58863282\n",
      "Iteration 122, loss = 840862387.54419303\n",
      "Iteration 123, loss = 840363502.32139051\n",
      "Iteration 124, loss = 839899586.67719674\n",
      "Iteration 125, loss = 839413014.89978480\n",
      "Iteration 126, loss = 838940978.28640079\n",
      "Iteration 127, loss = 838458487.07547939\n",
      "Iteration 128, loss = 838006653.18285489\n",
      "Iteration 129, loss = 837528164.43425655\n",
      "Iteration 130, loss = 837032212.64903939\n",
      "Iteration 131, loss = 836566629.86042488\n",
      "Iteration 132, loss = 836077197.74107397\n",
      "Iteration 133, loss = 835599605.35893989\n",
      "Iteration 134, loss = 835116076.35704148\n",
      "Iteration 135, loss = 834646340.01975513\n",
      "Iteration 136, loss = 834144536.71881354\n",
      "Iteration 137, loss = 833675688.80962229\n",
      "Iteration 138, loss = 833198635.75501072\n",
      "Iteration 139, loss = 832728979.31952202\n",
      "Iteration 140, loss = 832251439.57184231\n",
      "Iteration 141, loss = 831777838.80489957\n",
      "Iteration 142, loss = 831296756.54018617\n",
      "Iteration 143, loss = 830827190.40253580\n",
      "Iteration 144, loss = 830373932.32445538\n",
      "Iteration 145, loss = 829844304.16335940\n",
      "Iteration 146, loss = 829372940.54548109\n",
      "Iteration 147, loss = 828877719.21182263\n",
      "Iteration 148, loss = 828405565.39291239\n",
      "Iteration 149, loss = 827905468.45565331\n",
      "Iteration 150, loss = 827439174.32894683\n",
      "Iteration 151, loss = 826943359.12964451\n",
      "Iteration 152, loss = 826483601.09181190\n",
      "Iteration 153, loss = 825971208.56723869\n",
      "Iteration 154, loss = 825482923.00857043\n",
      "Iteration 155, loss = 824995870.99238384\n",
      "Iteration 156, loss = 824501308.16886365\n",
      "Iteration 157, loss = 824024705.47733128\n",
      "Iteration 158, loss = 823550941.77538788\n",
      "Iteration 159, loss = 823038331.85174119\n",
      "Iteration 160, loss = 822577138.76845717\n",
      "Iteration 161, loss = 822065858.55078781\n",
      "Iteration 162, loss = 821585572.94606042\n",
      "Iteration 163, loss = 821142840.78731668\n",
      "Iteration 164, loss = 820632572.69162643\n",
      "Iteration 165, loss = 820134268.93623412\n",
      "Iteration 166, loss = 819650522.41357517\n",
      "Iteration 167, loss = 819160086.73041356\n",
      "Iteration 168, loss = 818671296.05863965\n",
      "Iteration 169, loss = 818171070.20336854\n",
      "Iteration 170, loss = 817677000.74199510\n",
      "Iteration 171, loss = 817185316.65203357\n",
      "Iteration 172, loss = 816678795.49108005\n",
      "Iteration 173, loss = 816193581.15444517\n",
      "Iteration 174, loss = 815686212.53180206\n",
      "Iteration 175, loss = 815187903.02367651\n",
      "Iteration 176, loss = 814686137.73781037\n",
      "Iteration 177, loss = 814189411.98068750\n",
      "Iteration 178, loss = 813670686.22277701\n",
      "Iteration 179, loss = 813173325.60362256\n",
      "Iteration 180, loss = 812660953.43071067\n",
      "Iteration 181, loss = 812157761.50069964\n",
      "Iteration 182, loss = 811647752.77362955\n",
      "Iteration 183, loss = 811128561.60986662\n",
      "Iteration 184, loss = 810627289.05315149\n",
      "Iteration 185, loss = 810128970.61082864\n",
      "Iteration 186, loss = 809610260.90874982\n",
      "Iteration 187, loss = 809081232.09041977\n",
      "Iteration 188, loss = 808587346.77174354\n",
      "Iteration 189, loss = 808050107.93608129\n",
      "Iteration 190, loss = 807540709.71070397\n",
      "Iteration 191, loss = 807057474.67720497\n",
      "Iteration 192, loss = 806507725.74363363\n",
      "Iteration 193, loss = 805998710.72623682\n",
      "Iteration 194, loss = 805470857.49320841\n",
      "Iteration 195, loss = 804935968.68120348\n",
      "Iteration 196, loss = 804419142.05088866\n",
      "Iteration 197, loss = 803917533.56440413\n",
      "Iteration 198, loss = 803379650.14933050\n",
      "Iteration 199, loss = 802854534.28745401\n",
      "Iteration 200, loss = 802323554.53789377\n",
      "Iteration 201, loss = 801793143.52753830\n",
      "Iteration 202, loss = 801274214.82906866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 203, loss = 800751677.39184952\n",
      "Iteration 204, loss = 800201366.59876013\n",
      "Iteration 205, loss = 799680177.63827300\n",
      "Iteration 206, loss = 799145085.58642471\n",
      "Iteration 207, loss = 798608493.18847597\n",
      "Iteration 208, loss = 798080078.55243170\n",
      "Iteration 209, loss = 797555510.71966028\n",
      "Iteration 210, loss = 797015435.69442201\n",
      "Iteration 211, loss = 796463629.79718566\n",
      "Iteration 212, loss = 795938016.15630925\n",
      "Iteration 213, loss = 795408552.72230172\n",
      "Iteration 214, loss = 794880177.06257284\n",
      "Iteration 215, loss = 794352465.15181875\n",
      "Iteration 216, loss = 793856289.29270494\n",
      "Iteration 217, loss = 793284725.75761020\n",
      "Iteration 218, loss = 792757399.51982486\n",
      "Iteration 219, loss = 792220397.11379647\n",
      "Iteration 220, loss = 791693527.19663680\n",
      "Iteration 221, loss = 791160982.38018894\n",
      "Iteration 222, loss = 790629903.39405334\n",
      "Iteration 223, loss = 790066956.92685068\n",
      "Iteration 224, loss = 789542271.14253128\n",
      "Iteration 225, loss = 788982898.38703406\n",
      "Iteration 226, loss = 788451202.15210390\n",
      "Iteration 227, loss = 787880371.80230951\n",
      "Iteration 228, loss = 787338251.13511848\n",
      "Iteration 229, loss = 786776609.53295898\n",
      "Iteration 230, loss = 786241893.73852181\n",
      "Iteration 231, loss = 785690308.46578383\n",
      "Iteration 232, loss = 785123278.70994258\n",
      "Iteration 233, loss = 784563390.76193404\n",
      "Iteration 234, loss = 783989836.00043011\n",
      "Iteration 235, loss = 783422613.54694355\n",
      "Iteration 236, loss = 782872271.78089058\n",
      "Iteration 237, loss = 782294353.20242691\n",
      "Iteration 238, loss = 781729270.44989717\n",
      "Iteration 239, loss = 781153200.54669237\n",
      "Iteration 240, loss = 780607191.30202723\n",
      "Iteration 241, loss = 780011494.53425467\n",
      "Iteration 242, loss = 779423557.59630013\n",
      "Iteration 243, loss = 778862301.16944969\n",
      "Iteration 244, loss = 778290342.20512116\n",
      "Iteration 245, loss = 777700210.47122455\n",
      "Iteration 246, loss = 777128449.84687471\n",
      "Iteration 247, loss = 776552986.13843930\n",
      "Iteration 248, loss = 775980762.44277894\n",
      "Iteration 249, loss = 775397258.09906769\n",
      "Iteration 250, loss = 774825117.14076638\n",
      "Iteration 251, loss = 774231045.96387625\n",
      "Iteration 252, loss = 773640215.94751251\n",
      "Iteration 253, loss = 773084771.12264717\n",
      "Iteration 254, loss = 772511407.72572041\n",
      "Iteration 255, loss = 771952636.10167778\n",
      "Iteration 256, loss = 771378474.13040745\n",
      "Iteration 257, loss = 770794532.67331553\n",
      "Iteration 258, loss = 770218371.99658120\n",
      "Iteration 259, loss = 769629893.02933729\n",
      "Iteration 260, loss = 769058816.72814417\n",
      "Iteration 261, loss = 768455064.55372548\n",
      "Iteration 262, loss = 767850130.87280452\n",
      "Iteration 263, loss = 767259473.04149413\n",
      "Iteration 264, loss = 766654217.98762167\n",
      "Iteration 265, loss = 766065846.94134164\n",
      "Iteration 266, loss = 765452757.35943353\n",
      "Iteration 267, loss = 764853469.98355675\n",
      "Iteration 268, loss = 764242073.79625320\n",
      "Iteration 269, loss = 763628363.36832047\n",
      "Iteration 270, loss = 763026063.05031109\n",
      "Iteration 271, loss = 762404873.50686300\n",
      "Iteration 272, loss = 761773126.99183619\n",
      "Iteration 273, loss = 761188122.09192562\n",
      "Iteration 274, loss = 760581348.73321211\n",
      "Iteration 275, loss = 759959931.96497726\n",
      "Iteration 276, loss = 759331116.53055120\n",
      "Iteration 277, loss = 758736215.73434651\n",
      "Iteration 278, loss = 758090074.16065323\n",
      "Iteration 279, loss = 757461605.88659286\n",
      "Iteration 280, loss = 756844584.05759037\n",
      "Iteration 281, loss = 756229582.00371277\n",
      "Iteration 282, loss = 755588811.15356827\n",
      "Iteration 283, loss = 754948278.19464421\n",
      "Iteration 284, loss = 754306842.04845417\n",
      "Iteration 285, loss = 753681323.35513163\n",
      "Iteration 286, loss = 753041212.16675639\n",
      "Iteration 287, loss = 752392261.25655210\n",
      "Iteration 288, loss = 751759985.08067501\n",
      "Iteration 289, loss = 751118001.70040917\n",
      "Iteration 290, loss = 750486481.51587141\n",
      "Iteration 291, loss = 749823288.15993297\n",
      "Iteration 292, loss = 749164300.54573977\n",
      "Iteration 293, loss = 748527738.25821519\n",
      "Iteration 294, loss = 747879412.09760046\n",
      "Iteration 295, loss = 747208686.45502162\n",
      "Iteration 296, loss = 746562584.59618652\n",
      "Iteration 297, loss = 745906527.16063726\n",
      "Iteration 298, loss = 745216917.52612567\n",
      "Iteration 299, loss = 744569970.47141123\n",
      "Iteration 300, loss = 743886007.51530874\n",
      "Iteration 301, loss = 743212473.02294028\n",
      "Iteration 302, loss = 742537664.54510903\n",
      "Iteration 303, loss = 741846185.83091486\n",
      "Iteration 304, loss = 741160561.69684422\n",
      "Iteration 305, loss = 740471181.40186894\n",
      "Iteration 306, loss = 739785209.70214927\n",
      "Iteration 307, loss = 739086714.52575994\n",
      "Iteration 308, loss = 738362592.80804229\n",
      "Iteration 309, loss = 737664190.16267955\n",
      "Iteration 310, loss = 736980559.47074032\n",
      "Iteration 311, loss = 736261563.92386782\n",
      "Iteration 312, loss = 735549312.17397022\n",
      "Iteration 313, loss = 734841543.50117862\n",
      "Iteration 314, loss = 734143012.89394951\n",
      "Iteration 315, loss = 733415974.71056986\n",
      "Iteration 316, loss = 732708181.71060598\n",
      "Iteration 317, loss = 731956419.33708489\n",
      "Iteration 318, loss = 731229405.01452768\n",
      "Iteration 319, loss = 730517143.89451480\n",
      "Iteration 320, loss = 729770258.70377326\n",
      "Iteration 321, loss = 729053783.52965200\n",
      "Iteration 322, loss = 728311632.01699114\n",
      "Iteration 323, loss = 727581009.24367607\n",
      "Iteration 324, loss = 726832249.77483034\n",
      "Iteration 325, loss = 726112337.50761771\n",
      "Iteration 326, loss = 725368970.10222924\n",
      "Iteration 327, loss = 724612244.48207581\n",
      "Iteration 328, loss = 723857379.35227406\n",
      "Iteration 329, loss = 723121365.53895926\n",
      "Iteration 330, loss = 722383839.45514214\n",
      "Iteration 331, loss = 721677592.22713947\n",
      "Iteration 332, loss = 720922665.26620317\n",
      "Iteration 333, loss = 720174993.91938984\n",
      "Iteration 334, loss = 719451350.60871959\n",
      "Iteration 335, loss = 718703485.89061940\n",
      "Iteration 336, loss = 717949368.06006634\n",
      "Iteration 337, loss = 717203606.65315592\n",
      "Iteration 338, loss = 716465526.81265211\n",
      "Iteration 339, loss = 715683603.69698024\n",
      "Iteration 340, loss = 714925347.32726634\n",
      "Iteration 341, loss = 714168654.61256969\n",
      "Iteration 342, loss = 713393324.55305731\n",
      "Iteration 343, loss = 712626173.46308815\n",
      "Iteration 344, loss = 711864107.53035927\n",
      "Iteration 345, loss = 711077868.02404964\n",
      "Iteration 346, loss = 710312088.70315099\n",
      "Iteration 347, loss = 709531543.53267920\n",
      "Iteration 348, loss = 708742602.32048154\n",
      "Iteration 349, loss = 707954483.58624411\n",
      "Iteration 350, loss = 707163636.14960420\n",
      "Iteration 351, loss = 706368494.50391448\n",
      "Iteration 352, loss = 705567364.69099462\n",
      "Iteration 353, loss = 704770244.30242920\n",
      "Iteration 354, loss = 703971356.57806098\n",
      "Iteration 355, loss = 703170567.98263991\n",
      "Iteration 356, loss = 702357988.79041088\n",
      "Iteration 357, loss = 701548594.00416386\n",
      "Iteration 358, loss = 700714332.87671423\n",
      "Iteration 359, loss = 699893325.60810006\n",
      "Iteration 360, loss = 699084609.98378956\n",
      "Iteration 361, loss = 698284735.50466204\n",
      "Iteration 362, loss = 697452093.68104279\n",
      "Iteration 363, loss = 696628010.33602238\n",
      "Iteration 364, loss = 695795781.71104264\n",
      "Iteration 365, loss = 694985458.30159080\n",
      "Iteration 366, loss = 694126179.43834436\n",
      "Iteration 367, loss = 693302968.68519282\n",
      "Iteration 368, loss = 692458161.62878156\n",
      "Iteration 369, loss = 691632466.78200233\n",
      "Iteration 370, loss = 690790841.74388587\n",
      "Iteration 371, loss = 689942121.13507140\n",
      "Iteration 372, loss = 689095457.90282929\n",
      "Iteration 373, loss = 688262309.09990525\n",
      "Iteration 374, loss = 687413828.35787308\n",
      "Iteration 375, loss = 686548744.16023934\n",
      "Iteration 376, loss = 685699814.96614921\n",
      "Iteration 377, loss = 684820242.86761689\n",
      "Iteration 378, loss = 683951302.97492468\n",
      "Iteration 379, loss = 683074633.61185229\n",
      "Iteration 380, loss = 682181153.28075540\n",
      "Iteration 381, loss = 681297457.27361441\n",
      "Iteration 382, loss = 680420744.61376131\n",
      "Iteration 383, loss = 679539454.74404120\n",
      "Iteration 384, loss = 678669637.70671010\n",
      "Iteration 385, loss = 677750287.43286514\n",
      "Iteration 386, loss = 676874852.53175247\n",
      "Iteration 387, loss = 675971929.85325360\n",
      "Iteration 388, loss = 675085129.11530483\n",
      "Iteration 389, loss = 674211434.20706820\n",
      "Iteration 390, loss = 673318478.75936425\n",
      "Iteration 391, loss = 672413185.28948486\n",
      "Iteration 392, loss = 671526985.25892043\n",
      "Iteration 393, loss = 670634398.96842194\n",
      "Iteration 394, loss = 669778098.71598208\n",
      "Iteration 395, loss = 668827643.39412844\n",
      "Iteration 396, loss = 667928495.49407756\n",
      "Iteration 397, loss = 667008473.51901770\n",
      "Iteration 398, loss = 666113291.60526681\n",
      "Iteration 399, loss = 665202230.25082064\n",
      "Iteration 400, loss = 664288976.24255514\n",
      "Iteration 401, loss = 663385758.19398236\n",
      "Iteration 402, loss = 662479753.14852524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 403, loss = 661596842.08166277\n",
      "Iteration 404, loss = 660660700.21654153\n",
      "Iteration 405, loss = 659725794.59909213\n",
      "Iteration 406, loss = 658789086.91463888\n",
      "Iteration 407, loss = 657859492.91035748\n",
      "Iteration 408, loss = 656921834.43652344\n",
      "Iteration 409, loss = 655990790.79862535\n",
      "Iteration 410, loss = 655071034.13675010\n",
      "Iteration 411, loss = 654111105.47958994\n",
      "Iteration 412, loss = 653162927.73335421\n",
      "Iteration 413, loss = 652242708.11842525\n",
      "Iteration 414, loss = 651291792.08331251\n",
      "Iteration 415, loss = 650359879.02607751\n",
      "Iteration 416, loss = 649417801.62491965\n",
      "Iteration 417, loss = 648447815.01327753\n",
      "Iteration 418, loss = 647509203.16642475\n",
      "Iteration 419, loss = 646536891.40833104\n",
      "Iteration 420, loss = 645592486.95112669\n",
      "Iteration 421, loss = 644612459.81293893\n",
      "Iteration 422, loss = 643685636.58256376\n",
      "Iteration 423, loss = 642718940.78807640\n",
      "Iteration 424, loss = 641732137.35581756\n",
      "Iteration 425, loss = 640773113.29809046\n",
      "Iteration 426, loss = 639800297.81188178\n",
      "Iteration 427, loss = 638819745.77342451\n",
      "Iteration 428, loss = 637829843.50679135\n",
      "Iteration 429, loss = 636841068.68997478\n",
      "Iteration 430, loss = 635867423.19070578\n",
      "Iteration 431, loss = 634886217.21037614\n",
      "Iteration 432, loss = 633895847.16319311\n",
      "Iteration 433, loss = 632933029.96829796\n",
      "Iteration 434, loss = 631944841.00046253\n",
      "Iteration 435, loss = 630957961.90974772\n",
      "Iteration 436, loss = 629982453.91126466\n",
      "Iteration 437, loss = 628979450.08786821\n",
      "Iteration 438, loss = 627958900.83795655\n",
      "Iteration 439, loss = 626968314.83305347\n",
      "Iteration 440, loss = 625982753.31957245\n",
      "Iteration 441, loss = 624987203.72362268\n",
      "Iteration 442, loss = 623996326.07088161\n",
      "Iteration 443, loss = 623007593.43200207\n",
      "Iteration 444, loss = 621990334.15561199\n",
      "Iteration 445, loss = 621005585.25362396\n",
      "Iteration 446, loss = 620005236.22669268\n",
      "Iteration 447, loss = 618982729.25034630\n",
      "Iteration 448, loss = 617987224.35740161\n",
      "Iteration 449, loss = 616988305.14545047\n",
      "Iteration 450, loss = 615994247.31195927\n",
      "Iteration 451, loss = 614972593.67274177\n",
      "Iteration 452, loss = 613962858.30113435\n",
      "Iteration 453, loss = 612999970.46332920\n",
      "Iteration 454, loss = 612009966.06037951\n",
      "Iteration 455, loss = 610987763.95411050\n",
      "Iteration 456, loss = 609968374.74012566\n",
      "Iteration 457, loss = 608971326.36833680\n",
      "Iteration 458, loss = 607979273.76472723\n",
      "Iteration 459, loss = 606990539.25801623\n",
      "Iteration 460, loss = 605953241.84820497\n",
      "Iteration 461, loss = 604952045.92242932\n",
      "Iteration 462, loss = 603967535.10793555\n",
      "Iteration 463, loss = 602936061.98114073\n",
      "Iteration 464, loss = 601932982.59320211\n",
      "Iteration 465, loss = 600910577.55556035\n",
      "Iteration 466, loss = 599927559.60499883\n",
      "Iteration 467, loss = 598905296.59847093\n",
      "Iteration 468, loss = 597902867.12366080\n",
      "Iteration 469, loss = 596884167.81325054\n",
      "Iteration 470, loss = 595856370.48416233\n",
      "Iteration 471, loss = 594819933.60987496\n",
      "Iteration 472, loss = 593838656.38889921\n",
      "Iteration 473, loss = 592823254.24886620\n",
      "Iteration 474, loss = 591791651.07619441\n",
      "Iteration 475, loss = 590792508.57143998\n",
      "Iteration 476, loss = 589811641.67702699\n",
      "Iteration 477, loss = 588761296.66436923\n",
      "Iteration 478, loss = 587746326.87623894\n",
      "Iteration 479, loss = 586742611.23666131\n",
      "Iteration 480, loss = 585737048.92530906\n",
      "Iteration 481, loss = 584708365.77803719\n",
      "Iteration 482, loss = 583685280.26221228\n",
      "Iteration 483, loss = 582664103.90038776\n",
      "Iteration 484, loss = 581656451.65615344\n",
      "Iteration 485, loss = 580649741.78985679\n",
      "Iteration 486, loss = 579632383.11021245\n",
      "Iteration 487, loss = 578586999.13356924\n",
      "Iteration 488, loss = 577568443.62351966\n",
      "Iteration 489, loss = 576562230.02345037\n",
      "Iteration 490, loss = 575543929.95220506\n",
      "Iteration 491, loss = 574535898.20948279\n",
      "Iteration 492, loss = 573531741.04640543\n",
      "Iteration 493, loss = 572495070.89786065\n",
      "Iteration 494, loss = 571497279.74317312\n",
      "Iteration 495, loss = 570484114.67142475\n",
      "Iteration 496, loss = 569469997.20993829\n",
      "Iteration 497, loss = 568452514.28934383\n",
      "Iteration 498, loss = 567454278.80182874\n",
      "Iteration 499, loss = 566464835.03235424\n",
      "Iteration 500, loss = 565460727.97853220\n",
      "Iteration 501, loss = 564483773.84260237\n",
      "Iteration 502, loss = 563482823.09866917\n",
      "Iteration 503, loss = 562493092.23805225\n",
      "Iteration 504, loss = 561484498.79516864\n",
      "Iteration 505, loss = 560472306.45357013\n",
      "Iteration 506, loss = 559490720.87175417\n",
      "Iteration 507, loss = 558528608.63846874\n",
      "Iteration 508, loss = 557522513.31306696\n",
      "Iteration 509, loss = 556529108.65568101\n",
      "Iteration 510, loss = 555556154.90574229\n",
      "Iteration 511, loss = 554563465.23772156\n",
      "Iteration 512, loss = 553588801.10658324\n",
      "Iteration 513, loss = 552570970.75625217\n",
      "Iteration 514, loss = 551584494.01578379\n",
      "Iteration 515, loss = 550590982.71813071\n",
      "Iteration 516, loss = 549601396.32293975\n",
      "Iteration 517, loss = 548627180.25208032\n",
      "Iteration 518, loss = 547644024.66528320\n",
      "Iteration 519, loss = 546647292.58436894\n",
      "Iteration 520, loss = 545676478.56082773\n",
      "Iteration 521, loss = 544703083.26525235\n",
      "Iteration 522, loss = 543723793.38047409\n",
      "Iteration 523, loss = 542741843.65837014\n",
      "Iteration 524, loss = 541773029.36984563\n",
      "Iteration 525, loss = 540785033.31727123\n",
      "Iteration 526, loss = 539818368.83457863\n",
      "Iteration 527, loss = 538844606.67566180\n",
      "Iteration 528, loss = 537898779.93312204\n",
      "Iteration 529, loss = 536912608.57900202\n",
      "Iteration 530, loss = 535951968.89624399\n",
      "Iteration 531, loss = 534969053.72596562\n",
      "Iteration 532, loss = 534015263.92030364\n",
      "Iteration 533, loss = 533014934.07126069\n",
      "Iteration 534, loss = 532082354.25668329\n",
      "Iteration 535, loss = 531124440.40515435\n",
      "Iteration 536, loss = 530177583.07919461\n",
      "Iteration 537, loss = 529265562.13845694\n",
      "Iteration 538, loss = 528320452.67907852\n",
      "Iteration 539, loss = 527395918.11119777\n",
      "Iteration 540, loss = 526481995.84630239\n",
      "Iteration 541, loss = 525567692.31700182\n",
      "Iteration 542, loss = 524650213.11176640\n",
      "Iteration 543, loss = 523735090.60957491\n",
      "Iteration 544, loss = 522835020.50365669\n",
      "Iteration 545, loss = 521899743.64683086\n",
      "Iteration 546, loss = 520984737.61232150\n",
      "Iteration 547, loss = 520053138.16548949\n",
      "Iteration 548, loss = 519130583.66897768\n",
      "Iteration 549, loss = 518216516.32775402\n",
      "Iteration 550, loss = 517330353.45921510\n",
      "Iteration 551, loss = 516397363.09964854\n",
      "Iteration 552, loss = 515489828.98731315\n",
      "Iteration 553, loss = 514588092.88560325\n",
      "Iteration 554, loss = 513675078.72056836\n",
      "Iteration 555, loss = 512762352.62491214\n",
      "Iteration 556, loss = 511828833.58868587\n",
      "Iteration 557, loss = 510913391.44773006\n",
      "Iteration 558, loss = 509990850.94012713\n",
      "Iteration 559, loss = 509064352.10367846\n",
      "Iteration 560, loss = 508151160.46244049\n",
      "Iteration 561, loss = 507217427.03015202\n",
      "Iteration 562, loss = 506272026.42559969\n",
      "Iteration 563, loss = 505359887.07030183\n",
      "Iteration 564, loss = 504447362.79072827\n",
      "Iteration 565, loss = 503511335.89373857\n",
      "Iteration 566, loss = 502601843.68662643\n",
      "Iteration 567, loss = 501667351.09763455\n",
      "Iteration 568, loss = 500762310.99022317\n",
      "Iteration 569, loss = 499837121.75108743\n",
      "Iteration 570, loss = 498922701.13833129\n",
      "Iteration 571, loss = 498009556.94875753\n",
      "Iteration 572, loss = 497106280.50717270\n",
      "Iteration 573, loss = 496191978.25318003\n",
      "Iteration 574, loss = 495316628.41541147\n",
      "Iteration 575, loss = 494429650.30028105\n",
      "Iteration 576, loss = 493579122.20604223\n",
      "Iteration 577, loss = 492656237.27181756\n",
      "Iteration 578, loss = 491783151.63355851\n",
      "Iteration 579, loss = 490892944.15499526\n",
      "Iteration 580, loss = 490017888.31062162\n",
      "Iteration 581, loss = 489119557.52896643\n",
      "Iteration 582, loss = 488256783.58142620\n",
      "Iteration 583, loss = 487377633.48427522\n",
      "Iteration 584, loss = 486476820.87975430\n",
      "Iteration 585, loss = 485587166.69790131\n",
      "Iteration 586, loss = 484671982.09281939\n",
      "Iteration 587, loss = 483798880.91928881\n",
      "Iteration 588, loss = 482918464.69510978\n",
      "Iteration 589, loss = 482064911.95041311\n",
      "Iteration 590, loss = 481153110.25731879\n",
      "Iteration 591, loss = 480304411.29578167\n",
      "Iteration 592, loss = 479435533.44245690\n",
      "Iteration 593, loss = 478556027.36752570\n",
      "Iteration 594, loss = 477680556.40054893\n",
      "Iteration 595, loss = 476818521.25232047\n",
      "Iteration 596, loss = 475973636.13487667\n",
      "Iteration 597, loss = 475092750.68540812\n",
      "Iteration 598, loss = 474232354.22260809\n",
      "Iteration 599, loss = 473357654.48021668\n",
      "Iteration 600, loss = 472521629.77223897\n",
      "Iteration 601, loss = 471664784.11614388\n",
      "Iteration 602, loss = 470786985.22614157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 603, loss = 469959112.93413132\n",
      "Iteration 604, loss = 469055782.62710238\n",
      "Iteration 605, loss = 468205570.76024890\n",
      "Iteration 606, loss = 467349103.24167615\n",
      "Iteration 607, loss = 466506121.40951252\n",
      "Iteration 608, loss = 465632267.08590835\n",
      "Iteration 609, loss = 464772399.21043468\n",
      "Iteration 610, loss = 463952266.64225930\n",
      "Iteration 611, loss = 463130756.28432691\n",
      "Iteration 612, loss = 462236286.78119385\n",
      "Iteration 613, loss = 461431434.28341562\n",
      "Iteration 614, loss = 460593264.02619499\n",
      "Iteration 615, loss = 459731071.63014150\n",
      "Iteration 616, loss = 458921322.73137474\n",
      "Iteration 617, loss = 458050968.48349679\n",
      "Iteration 618, loss = 457203013.88715458\n",
      "Iteration 619, loss = 456383268.52280766\n",
      "Iteration 620, loss = 455573611.39383507\n",
      "Iteration 621, loss = 454725726.67742479\n",
      "Iteration 622, loss = 453881737.69871962\n",
      "Iteration 623, loss = 453062943.18926185\n",
      "Iteration 624, loss = 452242785.59381300\n",
      "Iteration 625, loss = 451417803.48461914\n",
      "Iteration 626, loss = 450580122.97314423\n",
      "Iteration 627, loss = 449749198.42758024\n",
      "Iteration 628, loss = 448946029.08576101\n",
      "Iteration 629, loss = 448138952.92636240\n",
      "Iteration 630, loss = 447285994.44222581\n",
      "Iteration 631, loss = 446450916.50298887\n",
      "Iteration 632, loss = 445639200.77695221\n",
      "Iteration 633, loss = 444823163.38480836\n",
      "Iteration 634, loss = 443993072.46418667\n",
      "Iteration 635, loss = 443162415.21395189\n",
      "Iteration 636, loss = 442339671.86377895\n",
      "Iteration 637, loss = 441527092.70156598\n",
      "Iteration 638, loss = 440737459.73321146\n",
      "Iteration 639, loss = 439904223.32138878\n",
      "Iteration 640, loss = 439093324.84827083\n",
      "Iteration 641, loss = 438291020.45242751\n",
      "Iteration 642, loss = 437503282.17959601\n",
      "Iteration 643, loss = 436698056.70162928\n",
      "Iteration 644, loss = 435906602.41224247\n",
      "Iteration 645, loss = 435114055.01252472\n",
      "Iteration 646, loss = 434296259.91556829\n",
      "Iteration 647, loss = 433491459.83493268\n",
      "Iteration 648, loss = 432682287.80430871\n",
      "Iteration 649, loss = 431895488.56828463\n",
      "Iteration 650, loss = 431095266.42573345\n",
      "Iteration 651, loss = 430273799.75389010\n",
      "Iteration 652, loss = 429490027.21962786\n",
      "Iteration 653, loss = 428689059.02240169\n",
      "Iteration 654, loss = 427899771.79306418\n",
      "Iteration 655, loss = 427105705.69012707\n",
      "Iteration 656, loss = 426330613.99253732\n",
      "Iteration 657, loss = 425520110.13116568\n",
      "Iteration 658, loss = 424734941.30241901\n",
      "Iteration 659, loss = 423972145.30581993\n",
      "Iteration 660, loss = 423205370.18302351\n",
      "Iteration 661, loss = 422401897.13723576\n",
      "Iteration 662, loss = 421614000.91950566\n",
      "Iteration 663, loss = 420860049.09708261\n",
      "Iteration 664, loss = 420081931.48979926\n",
      "Iteration 665, loss = 419297356.13973063\n",
      "Iteration 666, loss = 418534214.09368420\n",
      "Iteration 667, loss = 417776100.86503345\n",
      "Iteration 668, loss = 416974951.21389925\n",
      "Iteration 669, loss = 416217555.35216999\n",
      "Iteration 670, loss = 415437586.11468571\n",
      "Iteration 671, loss = 414663966.05852199\n",
      "Iteration 672, loss = 413893528.39472431\n",
      "Iteration 673, loss = 413129469.22161430\n",
      "Iteration 674, loss = 412352236.90660685\n",
      "Iteration 675, loss = 411608200.17455924\n",
      "Iteration 676, loss = 410853514.59910512\n",
      "Iteration 677, loss = 410098921.43107277\n",
      "Iteration 678, loss = 409356288.93982428\n",
      "Iteration 679, loss = 408585663.93754780\n",
      "Iteration 680, loss = 407869075.82140839\n",
      "Iteration 681, loss = 407098036.71125436\n",
      "Iteration 682, loss = 406308592.26263213\n",
      "Iteration 683, loss = 405532407.31587762\n",
      "Iteration 684, loss = 404822994.19694096\n",
      "Iteration 685, loss = 404015908.41291648\n",
      "Iteration 686, loss = 403268711.62080514\n",
      "Iteration 687, loss = 402508763.19759047\n",
      "Iteration 688, loss = 401760161.09765184\n",
      "Iteration 689, loss = 401013188.80577511\n",
      "Iteration 690, loss = 400267580.47978193\n",
      "Iteration 691, loss = 399508875.89365810\n",
      "Iteration 692, loss = 398764677.02766490\n",
      "Iteration 693, loss = 398009706.46183747\n",
      "Iteration 694, loss = 397260346.87732846\n",
      "Iteration 695, loss = 396534215.55775940\n",
      "Iteration 696, loss = 395740999.83026433\n",
      "Iteration 697, loss = 394991651.42254263\n",
      "Iteration 698, loss = 394243766.87343240\n",
      "Iteration 699, loss = 393487918.18410385\n",
      "Iteration 700, loss = 392746420.52757722\n",
      "Iteration 701, loss = 391997565.68636358\n",
      "Iteration 702, loss = 391273371.29792559\n",
      "Iteration 703, loss = 390517630.90586287\n",
      "Iteration 704, loss = 389745622.26896775\n",
      "Iteration 705, loss = 389003668.54269940\n",
      "Iteration 706, loss = 388261500.09327471\n",
      "Iteration 707, loss = 387530335.04301196\n",
      "Iteration 708, loss = 386768787.56512141\n",
      "Iteration 709, loss = 386039112.44689965\n",
      "Iteration 710, loss = 385272565.12680066\n",
      "Iteration 711, loss = 384528248.60449886\n",
      "Iteration 712, loss = 383819818.00763893\n",
      "Iteration 713, loss = 383092959.92637080\n",
      "Iteration 714, loss = 382324747.09067714\n",
      "Iteration 715, loss = 381616497.41032350\n",
      "Iteration 716, loss = 380895500.47441399\n",
      "Iteration 717, loss = 380133974.16598469\n",
      "Iteration 718, loss = 379392367.53210860\n",
      "Iteration 719, loss = 378666080.51234478\n",
      "Iteration 720, loss = 377931558.23482305\n",
      "Iteration 721, loss = 377198159.05086303\n",
      "Iteration 722, loss = 376448734.36915874\n",
      "Iteration 723, loss = 375713330.78960389\n",
      "Iteration 724, loss = 375022281.97687727\n",
      "Iteration 725, loss = 374264116.30301332\n",
      "Iteration 726, loss = 373557364.34413743\n",
      "Iteration 727, loss = 372844542.66211772\n",
      "Iteration 728, loss = 372139788.76966894\n",
      "Iteration 729, loss = 371390283.53030235\n",
      "Iteration 730, loss = 370699483.62602746\n",
      "Iteration 731, loss = 369962583.41477174\n",
      "Iteration 732, loss = 369275398.15359420\n",
      "Iteration 733, loss = 368558208.70799333\n",
      "Iteration 734, loss = 367821262.56978887\n",
      "Iteration 735, loss = 367123032.98189813\n",
      "Iteration 736, loss = 366424380.30531794\n",
      "Iteration 737, loss = 365719110.77865702\n",
      "Iteration 738, loss = 365019888.18981957\n",
      "Iteration 739, loss = 364305526.26301384\n",
      "Iteration 740, loss = 363635390.63563919\n",
      "Iteration 741, loss = 362893880.84964693\n",
      "Iteration 742, loss = 362189362.12729716\n",
      "Iteration 743, loss = 361509867.00090510\n",
      "Iteration 744, loss = 360785505.54708183\n",
      "Iteration 745, loss = 360055137.40329325\n",
      "Iteration 746, loss = 359368841.92172831\n",
      "Iteration 747, loss = 358658566.40054154\n",
      "Iteration 748, loss = 357949820.20400625\n",
      "Iteration 749, loss = 357217559.90311444\n",
      "Iteration 750, loss = 356527625.46641028\n",
      "Iteration 751, loss = 355805848.42727298\n",
      "Iteration 752, loss = 355104876.37546515\n",
      "Iteration 753, loss = 354399114.49172866\n",
      "Iteration 754, loss = 353673589.14080304\n",
      "Iteration 755, loss = 352995351.50611299\n",
      "Iteration 756, loss = 352253461.85332340\n",
      "Iteration 757, loss = 351570490.04255450\n",
      "Iteration 758, loss = 350856034.13470590\n",
      "Iteration 759, loss = 350136791.32047737\n",
      "Iteration 760, loss = 349439588.99834734\n",
      "Iteration 761, loss = 348740716.27339423\n",
      "Iteration 762, loss = 348036498.33921623\n",
      "Iteration 763, loss = 347329151.02149540\n",
      "Iteration 764, loss = 346632435.87589830\n",
      "Iteration 765, loss = 345926138.14042968\n",
      "Iteration 766, loss = 345228113.46111703\n",
      "Iteration 767, loss = 344523986.92294431\n",
      "Iteration 768, loss = 343847329.67287344\n",
      "Iteration 769, loss = 343141478.14732724\n",
      "Iteration 770, loss = 342452311.83457321\n",
      "Iteration 771, loss = 341717590.65090305\n",
      "Iteration 772, loss = 341048058.57513767\n",
      "Iteration 773, loss = 340340780.78224468\n",
      "Iteration 774, loss = 339627897.88532978\n",
      "Iteration 775, loss = 338970948.12743562\n",
      "Iteration 776, loss = 338244328.42024547\n",
      "Iteration 777, loss = 337540114.19587326\n",
      "Iteration 778, loss = 336850820.92419058\n",
      "Iteration 779, loss = 336160694.34788078\n",
      "Iteration 780, loss = 335453849.33485824\n",
      "Iteration 781, loss = 334774193.53067786\n",
      "Iteration 782, loss = 334043952.34100235\n",
      "Iteration 783, loss = 333354239.64735788\n",
      "Iteration 784, loss = 332657077.10111779\n",
      "Iteration 785, loss = 331962893.05666566\n",
      "Iteration 786, loss = 331255193.79827160\n",
      "Iteration 787, loss = 330600634.83051163\n",
      "Iteration 788, loss = 329891113.36345232\n",
      "Iteration 789, loss = 329185185.77895671\n",
      "Iteration 790, loss = 328488501.22484320\n",
      "Iteration 791, loss = 327764056.63925546\n",
      "Iteration 792, loss = 327050557.49287486\n",
      "Iteration 793, loss = 326363621.00942349\n",
      "Iteration 794, loss = 325630808.56864375\n",
      "Iteration 795, loss = 324859219.28811783\n",
      "Iteration 796, loss = 324174535.60280228\n",
      "Iteration 797, loss = 323422926.27131313\n",
      "Iteration 798, loss = 322686817.94589913\n",
      "Iteration 799, loss = 321976489.61084735\n",
      "Iteration 800, loss = 321210642.82250148\n",
      "Iteration 801, loss = 320501949.27486360\n",
      "Iteration 802, loss = 319804978.49343699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 803, loss = 318987214.87603295\n",
      "Iteration 804, loss = 318209570.78884667\n",
      "Iteration 805, loss = 317449815.89186335\n",
      "Iteration 806, loss = 316652674.48017871\n",
      "Iteration 807, loss = 315873393.19861186\n",
      "Iteration 808, loss = 315062494.18211675\n",
      "Iteration 809, loss = 314263160.75792259\n",
      "Iteration 810, loss = 313418830.12045705\n",
      "Iteration 811, loss = 312643884.49092215\n",
      "Iteration 812, loss = 311791793.31265056\n",
      "Iteration 813, loss = 310982037.16400421\n",
      "Iteration 814, loss = 310172604.26903909\n",
      "Iteration 815, loss = 309352019.28934920\n",
      "Iteration 816, loss = 308522053.93439436\n",
      "Iteration 817, loss = 307620187.91466951\n",
      "Iteration 818, loss = 306729485.82355624\n",
      "Iteration 819, loss = 305851811.24127358\n",
      "Iteration 820, loss = 305051803.27636045\n",
      "Iteration 821, loss = 304218097.85065639\n",
      "Iteration 822, loss = 303471384.93979234\n",
      "Iteration 823, loss = 302647439.71018261\n",
      "Iteration 824, loss = 301926989.44014859\n",
      "Iteration 825, loss = 301137536.44866312\n",
      "Iteration 826, loss = 300393475.80119723\n",
      "Iteration 827, loss = 299681413.70141059\n",
      "Iteration 828, loss = 298960214.43169934\n",
      "Iteration 829, loss = 298245660.09088939\n",
      "Iteration 830, loss = 297516862.38965052\n",
      "Iteration 831, loss = 296830314.69100022\n",
      "Iteration 832, loss = 296134759.23486674\n",
      "Iteration 833, loss = 295396399.48859769\n",
      "Iteration 834, loss = 294710934.21127629\n",
      "Iteration 835, loss = 293998208.24610150\n",
      "Iteration 836, loss = 293333514.91499162\n",
      "Iteration 837, loss = 292622768.10693210\n",
      "Iteration 838, loss = 291916690.20829588\n",
      "Iteration 839, loss = 291210903.98368114\n",
      "Iteration 840, loss = 290526659.12848371\n",
      "Iteration 841, loss = 289837504.13859814\n",
      "Iteration 842, loss = 289147086.27105856\n",
      "Iteration 843, loss = 288423296.16131026\n",
      "Iteration 844, loss = 287729266.57351285\n",
      "Iteration 845, loss = 287045928.53234214\n",
      "Iteration 846, loss = 286362411.98442286\n",
      "Iteration 847, loss = 285669867.00210989\n",
      "Iteration 848, loss = 284976530.77414191\n",
      "Iteration 849, loss = 284280379.49508262\n",
      "Iteration 850, loss = 283605763.41478080\n",
      "Iteration 851, loss = 282930497.71618271\n",
      "Iteration 852, loss = 282236826.85576576\n",
      "Iteration 853, loss = 281565763.43877381\n",
      "Iteration 854, loss = 280868925.42293870\n",
      "Iteration 855, loss = 280181829.79838628\n",
      "Iteration 856, loss = 279472692.94848728\n",
      "Iteration 857, loss = 278801849.98019272\n",
      "Iteration 858, loss = 278096440.70435548\n",
      "Iteration 859, loss = 277375807.57521361\n",
      "Iteration 860, loss = 276697748.88967997\n",
      "Iteration 861, loss = 275967670.84795171\n",
      "Iteration 862, loss = 275289433.36644059\n",
      "Iteration 863, loss = 274576936.94114822\n",
      "Iteration 864, loss = 273914898.02224177\n",
      "Iteration 865, loss = 273192098.72213155\n",
      "Iteration 866, loss = 272473196.19179529\n",
      "Iteration 867, loss = 271778002.99894738\n",
      "Iteration 868, loss = 271081326.66998160\n",
      "Iteration 869, loss = 270317814.71330398\n",
      "Iteration 870, loss = 269590993.97144616\n",
      "Iteration 871, loss = 268864052.45647466\n",
      "Iteration 872, loss = 268134084.79940665\n",
      "Iteration 873, loss = 267459966.56298903\n",
      "Iteration 874, loss = 266696393.48025173\n",
      "Iteration 875, loss = 265963245.98163006\n",
      "Iteration 876, loss = 265236279.50388268\n",
      "Iteration 877, loss = 264486662.78085893\n",
      "Iteration 878, loss = 263750623.17299217\n",
      "Iteration 879, loss = 263030188.30570441\n",
      "Iteration 880, loss = 262316945.68103087\n",
      "Iteration 881, loss = 261565217.27580723\n",
      "Iteration 882, loss = 260870337.62483445\n",
      "Iteration 883, loss = 260180223.25322095\n",
      "Iteration 884, loss = 259418479.28796226\n",
      "Iteration 885, loss = 258711143.68721932\n",
      "Iteration 886, loss = 257941222.56108490\n",
      "Iteration 887, loss = 257187016.91123170\n",
      "Iteration 888, loss = 256433969.71790636\n",
      "Iteration 889, loss = 255740846.11617830\n",
      "Iteration 890, loss = 255025755.96884811\n",
      "Iteration 891, loss = 254321931.86077929\n",
      "Iteration 892, loss = 253645881.99481899\n",
      "Iteration 893, loss = 252957105.92404991\n",
      "Iteration 894, loss = 252281526.91456336\n",
      "Iteration 895, loss = 251622196.72116473\n",
      "Iteration 896, loss = 251022344.08989272\n",
      "Iteration 897, loss = 250349414.99568671\n",
      "Iteration 898, loss = 249732356.05709231\n",
      "Iteration 899, loss = 249080209.78262624\n",
      "Iteration 900, loss = 248454415.83227170\n",
      "Iteration 901, loss = 247855073.10254353\n",
      "Iteration 902, loss = 247215256.86564314\n",
      "Iteration 903, loss = 246623897.23672113\n",
      "Iteration 904, loss = 245976559.52037460\n",
      "Iteration 905, loss = 245371297.87324676\n",
      "Iteration 906, loss = 244765329.23861200\n",
      "Iteration 907, loss = 244159531.61021328\n",
      "Iteration 908, loss = 243557160.23067835\n",
      "Iteration 909, loss = 242935707.47906590\n",
      "Iteration 910, loss = 242334290.74816275\n",
      "Iteration 911, loss = 241716269.03646517\n",
      "Iteration 912, loss = 241112811.59015819\n",
      "Iteration 913, loss = 240505313.13130149\n",
      "Iteration 914, loss = 239896994.28253937\n",
      "Iteration 915, loss = 239284855.70857114\n",
      "Iteration 916, loss = 238691145.33381322\n",
      "Iteration 917, loss = 238126705.61580855\n",
      "Iteration 918, loss = 237501850.39973140\n",
      "Iteration 919, loss = 236893984.04761213\n",
      "Iteration 920, loss = 236319111.19898939\n",
      "Iteration 921, loss = 235705721.10604176\n",
      "Iteration 922, loss = 235113304.67676640\n",
      "Iteration 923, loss = 234521780.11302513\n",
      "Iteration 924, loss = 233917287.90810156\n",
      "Iteration 925, loss = 233326069.18488431\n",
      "Iteration 926, loss = 232759258.96650675\n",
      "Iteration 927, loss = 232169206.91192314\n",
      "Iteration 928, loss = 231570009.26405263\n",
      "Iteration 929, loss = 230996321.17601219\n",
      "Iteration 930, loss = 230386156.46532497\n",
      "Iteration 931, loss = 229812633.31330770\n",
      "Iteration 932, loss = 229235824.42825389\n",
      "Iteration 933, loss = 228667418.39853773\n",
      "Iteration 934, loss = 228071707.51344144\n",
      "Iteration 935, loss = 227475110.71863657\n",
      "Iteration 936, loss = 226899708.42019767\n",
      "Iteration 937, loss = 226346771.65404448\n",
      "Iteration 938, loss = 225732738.01868480\n",
      "Iteration 939, loss = 225188440.76979586\n",
      "Iteration 940, loss = 224601627.27098474\n",
      "Iteration 941, loss = 224020875.85653400\n",
      "Iteration 942, loss = 223461046.23195747\n",
      "Iteration 943, loss = 222891067.11428317\n",
      "Iteration 944, loss = 222319812.66124439\n",
      "Iteration 945, loss = 221754234.91763741\n",
      "Iteration 946, loss = 221199348.78007618\n",
      "Iteration 947, loss = 220619721.73216462\n",
      "Iteration 948, loss = 220053351.98856363\n",
      "Iteration 949, loss = 219486108.71668112\n",
      "Iteration 950, loss = 218935402.53922123\n",
      "Iteration 951, loss = 218382937.77691075\n",
      "Iteration 952, loss = 217811349.90914872\n",
      "Iteration 953, loss = 217268846.92908892\n",
      "Iteration 954, loss = 216730344.84558746\n",
      "Iteration 955, loss = 216168862.40585747\n",
      "Iteration 956, loss = 215622608.82087037\n",
      "Iteration 957, loss = 215079643.04194638\n",
      "Iteration 958, loss = 214502283.58333203\n",
      "Iteration 959, loss = 214007520.84255999\n",
      "Iteration 960, loss = 213423355.22344807\n",
      "Iteration 961, loss = 212901968.50748169\n",
      "Iteration 962, loss = 212358867.77860856\n",
      "Iteration 963, loss = 211828979.14600584\n",
      "Iteration 964, loss = 211272403.36726108\n",
      "Iteration 965, loss = 210736198.16822201\n",
      "Iteration 966, loss = 210202050.24035498\n",
      "Iteration 967, loss = 209726072.95118529\n",
      "Iteration 968, loss = 209171939.52489036\n",
      "Iteration 969, loss = 208647565.67488790\n",
      "Iteration 970, loss = 208132810.16779393\n",
      "Iteration 971, loss = 207593852.17090869\n",
      "Iteration 972, loss = 207094123.78117537\n",
      "Iteration 973, loss = 206591402.21647924\n",
      "Iteration 974, loss = 206070367.91023812\n",
      "Iteration 975, loss = 205543564.73963448\n",
      "Iteration 976, loss = 205059416.00418675\n",
      "Iteration 977, loss = 204536303.57637334\n",
      "Iteration 978, loss = 204046769.83063322\n",
      "Iteration 979, loss = 203538015.29346970\n",
      "Iteration 980, loss = 203056413.45096108\n",
      "Iteration 981, loss = 202555365.78426638\n",
      "Iteration 982, loss = 202041602.61699533\n",
      "Iteration 983, loss = 201539152.62185961\n",
      "Iteration 984, loss = 201058129.39546487\n",
      "Iteration 985, loss = 200545350.93501234\n",
      "Iteration 986, loss = 200074887.46202651\n",
      "Iteration 987, loss = 199570753.91288674\n",
      "Iteration 988, loss = 199108705.01604378\n",
      "Iteration 989, loss = 198594825.33089653\n",
      "Iteration 990, loss = 198092317.17795506\n",
      "Iteration 991, loss = 197604118.67900911\n",
      "Iteration 992, loss = 197128334.38415590\n",
      "Iteration 993, loss = 196632065.67263985\n",
      "Iteration 994, loss = 196151315.13542143\n",
      "Iteration 995, loss = 195685098.83412543\n",
      "Iteration 996, loss = 195184916.83175942\n",
      "Iteration 997, loss = 194701929.34118223\n",
      "Iteration 998, loss = 194243459.44700113\n",
      "Iteration 999, loss = 193756623.17070508\n",
      "Iteration 1000, loss = 193281957.46254802\n",
      "Iteration 1001, loss = 192823667.01004243\n",
      "Iteration 1002, loss = 192336142.28730145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1003, loss = 191872914.93679878\n",
      "Iteration 1004, loss = 191404153.68748623\n",
      "Iteration 1005, loss = 190945710.31267181\n",
      "Iteration 1006, loss = 190470130.50270125\n",
      "Iteration 1007, loss = 190023722.69691566\n",
      "Iteration 1008, loss = 189544298.45894742\n",
      "Iteration 1009, loss = 189082566.74603686\n",
      "Iteration 1010, loss = 188634113.81878209\n",
      "Iteration 1011, loss = 188168448.54077455\n",
      "Iteration 1012, loss = 187716742.85046342\n",
      "Iteration 1013, loss = 187270072.85626492\n",
      "Iteration 1014, loss = 186827278.54421285\n",
      "Iteration 1015, loss = 186394273.33930942\n",
      "Iteration 1016, loss = 185957010.29081815\n",
      "Iteration 1017, loss = 185540096.42258865\n",
      "Iteration 1018, loss = 185066372.96751800\n",
      "Iteration 1019, loss = 184604548.60775384\n",
      "Iteration 1020, loss = 184212302.91861039\n",
      "Iteration 1021, loss = 183731659.57711136\n",
      "Iteration 1022, loss = 183311656.08153248\n",
      "Iteration 1023, loss = 182869064.42591915\n",
      "Iteration 1024, loss = 182410965.83231610\n",
      "Iteration 1025, loss = 182028284.02028409\n",
      "Iteration 1026, loss = 181542638.96663594\n",
      "Iteration 1027, loss = 181145287.94470912\n",
      "Iteration 1028, loss = 180702224.32847688\n",
      "Iteration 1029, loss = 180285170.57700896\n",
      "Iteration 1030, loss = 179825351.18309107\n",
      "Iteration 1031, loss = 179408074.82679951\n",
      "Iteration 1032, loss = 178986763.93727300\n",
      "Iteration 1033, loss = 178553377.37486300\n",
      "Iteration 1034, loss = 178133605.36092752\n",
      "Iteration 1035, loss = 177723912.91786224\n",
      "Iteration 1036, loss = 177285155.47221312\n",
      "Iteration 1037, loss = 176846813.30982551\n",
      "Iteration 1038, loss = 176453787.63140661\n",
      "Iteration 1039, loss = 176147072.45713443\n",
      "Iteration 1040, loss = 175642180.16722217\n",
      "Iteration 1041, loss = 175235353.26354083\n",
      "Iteration 1042, loss = 174816304.09336337\n",
      "Iteration 1043, loss = 174405507.75949264\n",
      "Iteration 1044, loss = 174001863.90060994\n",
      "Iteration 1045, loss = 173606312.85539296\n",
      "Iteration 1046, loss = 173208990.97024509\n",
      "Iteration 1047, loss = 172804603.77341318\n",
      "Iteration 1048, loss = 172400926.36002263\n",
      "Iteration 1049, loss = 172003723.56669852\n",
      "Iteration 1050, loss = 171625069.76901814\n",
      "Iteration 1051, loss = 171223051.15538585\n",
      "Iteration 1052, loss = 170834898.56822804\n",
      "Iteration 1053, loss = 170443519.83526915\n",
      "Iteration 1054, loss = 170044842.89063951\n",
      "Iteration 1055, loss = 169668374.76448709\n",
      "Iteration 1056, loss = 169277467.24464822\n",
      "Iteration 1057, loss = 168906113.99058902\n",
      "Iteration 1058, loss = 168497857.50145432\n",
      "Iteration 1059, loss = 168118232.78197908\n",
      "Iteration 1060, loss = 167748145.99225453\n",
      "Iteration 1061, loss = 167337397.22005099\n",
      "Iteration 1062, loss = 166964229.58011100\n",
      "Iteration 1063, loss = 166593404.87765861\n",
      "Iteration 1064, loss = 166200495.07238171\n",
      "Iteration 1065, loss = 165860814.22473821\n",
      "Iteration 1066, loss = 165452627.55987516\n",
      "Iteration 1067, loss = 165098205.58299235\n",
      "Iteration 1068, loss = 164729890.65778637\n",
      "Iteration 1069, loss = 164458905.69023317\n",
      "Iteration 1070, loss = 164018251.91974223\n",
      "Iteration 1071, loss = 163660990.62629738\n",
      "Iteration 1072, loss = 163287642.28908780\n",
      "Iteration 1073, loss = 162939434.22729325\n",
      "Iteration 1074, loss = 162578933.46925801\n",
      "Iteration 1075, loss = 162222366.83281100\n",
      "Iteration 1076, loss = 161857771.44003013\n",
      "Iteration 1077, loss = 161504008.84455699\n",
      "Iteration 1078, loss = 161160602.67603606\n",
      "Iteration 1079, loss = 160804603.08091721\n",
      "Iteration 1080, loss = 160444115.88792884\n",
      "Iteration 1081, loss = 160110651.16882265\n",
      "Iteration 1082, loss = 159776688.24087530\n",
      "Iteration 1083, loss = 159423198.23030889\n",
      "Iteration 1084, loss = 159063066.69312257\n",
      "Iteration 1085, loss = 158727740.34389043\n",
      "Iteration 1086, loss = 158387166.35340255\n",
      "Iteration 1087, loss = 158040738.02209431\n",
      "Iteration 1088, loss = 157693428.24539912\n",
      "Iteration 1089, loss = 157366929.66904494\n",
      "Iteration 1090, loss = 157050159.42037970\n",
      "Iteration 1091, loss = 156683372.73243347\n",
      "Iteration 1092, loss = 156346371.89063618\n",
      "Iteration 1093, loss = 156042455.91232479\n",
      "Iteration 1094, loss = 155678617.81800413\n",
      "Iteration 1095, loss = 155371773.61212963\n",
      "Iteration 1096, loss = 155046177.87410575\n",
      "Iteration 1097, loss = 154718223.79464355\n",
      "Iteration 1098, loss = 154413349.95489767\n",
      "Iteration 1099, loss = 154076979.13947317\n",
      "Iteration 1100, loss = 153752745.50818905\n",
      "Iteration 1101, loss = 153426718.52590486\n",
      "Iteration 1102, loss = 153116448.30847800\n",
      "Iteration 1103, loss = 152814059.08684674\n",
      "Iteration 1104, loss = 152491827.77383903\n",
      "Iteration 1105, loss = 152176185.16956657\n",
      "Iteration 1106, loss = 151882985.06449580\n",
      "Iteration 1107, loss = 151560130.32478437\n",
      "Iteration 1108, loss = 151269943.44329375\n",
      "Iteration 1109, loss = 150931748.27509633\n",
      "Iteration 1110, loss = 150650792.21573263\n",
      "Iteration 1111, loss = 150338809.87422302\n",
      "Iteration 1112, loss = 150014988.47570774\n",
      "Iteration 1113, loss = 149751857.21854910\n",
      "Iteration 1114, loss = 149426414.50678051\n",
      "Iteration 1115, loss = 149118642.57431370\n",
      "Iteration 1116, loss = 148814528.58639970\n",
      "Iteration 1117, loss = 148536369.76436308\n",
      "Iteration 1118, loss = 148273558.89827678\n",
      "Iteration 1119, loss = 147924159.99391961\n",
      "Iteration 1120, loss = 147643654.11642048\n",
      "Iteration 1121, loss = 147346274.76332843\n",
      "Iteration 1122, loss = 147090893.89606979\n",
      "Iteration 1123, loss = 146817513.01890329\n",
      "Iteration 1124, loss = 146490225.13861069\n",
      "Iteration 1125, loss = 146178067.73001647\n",
      "Iteration 1126, loss = 145908060.47725680\n",
      "Iteration 1127, loss = 145611126.04445583\n",
      "Iteration 1128, loss = 145340987.84115982\n",
      "Iteration 1129, loss = 145049317.44167009\n",
      "Iteration 1130, loss = 144750527.51648551\n",
      "Iteration 1131, loss = 144477337.87972194\n",
      "Iteration 1132, loss = 144207473.67596978\n",
      "Iteration 1133, loss = 143936771.17219403\n",
      "Iteration 1134, loss = 143653707.50935352\n",
      "Iteration 1135, loss = 143373661.33109146\n",
      "Iteration 1136, loss = 143104243.58742437\n",
      "Iteration 1137, loss = 142854748.74238703\n",
      "Iteration 1138, loss = 142575040.73095676\n",
      "Iteration 1139, loss = 142269474.16491857\n",
      "Iteration 1140, loss = 142001822.94163573\n",
      "Iteration 1141, loss = 141755045.59773520\n",
      "Iteration 1142, loss = 141472387.01248580\n",
      "Iteration 1143, loss = 141223541.00436142\n",
      "Iteration 1144, loss = 140954903.41159803\n",
      "Iteration 1145, loss = 140663156.21928719\n",
      "Iteration 1146, loss = 140444974.73685670\n",
      "Iteration 1147, loss = 140159908.00153694\n",
      "Iteration 1148, loss = 139915338.09059265\n",
      "Iteration 1149, loss = 139641724.69260249\n",
      "Iteration 1150, loss = 139398517.10842732\n",
      "Iteration 1151, loss = 139127476.40133372\n",
      "Iteration 1152, loss = 138884295.85231078\n",
      "Iteration 1153, loss = 138624102.09153566\n",
      "Iteration 1154, loss = 138372791.71205515\n",
      "Iteration 1155, loss = 138115041.82846996\n",
      "Iteration 1156, loss = 137867097.09564736\n",
      "Iteration 1157, loss = 137614692.23850590\n",
      "Iteration 1158, loss = 137391376.58333641\n",
      "Iteration 1159, loss = 137111796.10051891\n",
      "Iteration 1160, loss = 136883711.10605037\n",
      "Iteration 1161, loss = 136623909.84812239\n",
      "Iteration 1162, loss = 136398131.58644187\n",
      "Iteration 1163, loss = 136154102.33486325\n",
      "Iteration 1164, loss = 135900378.57339865\n",
      "Iteration 1165, loss = 135636607.20381612\n",
      "Iteration 1166, loss = 135407133.83702663\n",
      "Iteration 1167, loss = 135149301.88526616\n",
      "Iteration 1168, loss = 134923889.29088897\n",
      "Iteration 1169, loss = 134690428.85244814\n",
      "Iteration 1170, loss = 134440722.81023714\n",
      "Iteration 1171, loss = 134219808.90090522\n",
      "Iteration 1172, loss = 133971600.52426891\n",
      "Iteration 1173, loss = 133736252.12709223\n",
      "Iteration 1174, loss = 133497779.49324821\n",
      "Iteration 1175, loss = 133269450.72048724\n",
      "Iteration 1176, loss = 133057888.76837170\n",
      "Iteration 1177, loss = 132805022.42178875\n",
      "Iteration 1178, loss = 132583086.80808444\n",
      "Iteration 1179, loss = 132334158.13187221\n",
      "Iteration 1180, loss = 132105143.97053289\n",
      "Iteration 1181, loss = 131890312.71187688\n",
      "Iteration 1182, loss = 131639615.87461661\n",
      "Iteration 1183, loss = 131422475.03710873\n",
      "Iteration 1184, loss = 131190927.62049602\n",
      "Iteration 1185, loss = 130995790.55281402\n",
      "Iteration 1186, loss = 130780364.08774933\n",
      "Iteration 1187, loss = 130530624.61691862\n",
      "Iteration 1188, loss = 130312749.53593884\n",
      "Iteration 1189, loss = 130088785.93628336\n",
      "Iteration 1190, loss = 129878495.70077658\n",
      "Iteration 1191, loss = 129631654.26315010\n",
      "Iteration 1192, loss = 129421016.13385433\n",
      "Iteration 1193, loss = 129210851.44228807\n",
      "Iteration 1194, loss = 128980498.74815960\n",
      "Iteration 1195, loss = 128771396.08549984\n",
      "Iteration 1196, loss = 128543346.25913846\n",
      "Iteration 1197, loss = 128323541.68376511\n",
      "Iteration 1198, loss = 128102625.95684169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1199, loss = 127904706.07621758\n",
      "Iteration 1200, loss = 127700361.14129391\n",
      "Iteration 1201, loss = 127474879.79046047\n",
      "Iteration 1202, loss = 127299809.79695299\n",
      "Iteration 1203, loss = 127050713.30309230\n",
      "Iteration 1204, loss = 126844325.61300519\n",
      "Iteration 1205, loss = 126641483.39332749\n",
      "Iteration 1206, loss = 126428355.25877272\n",
      "Iteration 1207, loss = 126230664.86944871\n",
      "Iteration 1208, loss = 126014061.98095477\n",
      "Iteration 1209, loss = 125826739.86469464\n",
      "Iteration 1210, loss = 125626571.51576674\n",
      "Iteration 1211, loss = 125419916.36901815\n",
      "Iteration 1212, loss = 125213759.77749564\n",
      "Iteration 1213, loss = 125040511.97609454\n",
      "Iteration 1214, loss = 124813045.77627216\n",
      "Iteration 1215, loss = 124624689.83334133\n",
      "Iteration 1216, loss = 124434094.41394024\n",
      "Iteration 1217, loss = 124229174.54766709\n",
      "Iteration 1218, loss = 124033875.84699987\n",
      "Iteration 1219, loss = 123863484.81745245\n",
      "Iteration 1220, loss = 123697161.15148814\n",
      "Iteration 1221, loss = 123452672.43170804\n",
      "Iteration 1222, loss = 123271883.02128972\n",
      "Iteration 1223, loss = 123100864.32046744\n",
      "Iteration 1224, loss = 122912161.45119968\n",
      "Iteration 1225, loss = 122698218.77210210\n",
      "Iteration 1226, loss = 122521050.29644364\n",
      "Iteration 1227, loss = 122313060.64773649\n",
      "Iteration 1228, loss = 122135596.68781187\n",
      "Iteration 1229, loss = 121958640.71958192\n",
      "Iteration 1230, loss = 121730069.89482218\n",
      "Iteration 1231, loss = 121617834.99901544\n",
      "Iteration 1232, loss = 121377356.01352049\n",
      "Iteration 1233, loss = 121205355.47276294\n",
      "Iteration 1234, loss = 121016520.58272696\n",
      "Iteration 1235, loss = 120860177.46395943\n",
      "Iteration 1236, loss = 120658914.09868574\n",
      "Iteration 1237, loss = 120474612.00867279\n",
      "Iteration 1238, loss = 120290786.80157673\n",
      "Iteration 1239, loss = 120118166.49545935\n",
      "Iteration 1240, loss = 119930785.45081136\n",
      "Iteration 1241, loss = 119757790.28607903\n",
      "Iteration 1242, loss = 119593597.04378274\n",
      "Iteration 1243, loss = 119384491.74486890\n",
      "Iteration 1244, loss = 119254941.05975181\n",
      "Iteration 1245, loss = 119060046.78942730\n",
      "Iteration 1246, loss = 118878875.52482422\n",
      "Iteration 1247, loss = 118710266.26591422\n",
      "Iteration 1248, loss = 118573167.63872451\n",
      "Iteration 1249, loss = 118378709.41140568\n",
      "Iteration 1250, loss = 118183584.18564011\n",
      "Iteration 1251, loss = 118022517.43846324\n",
      "Iteration 1252, loss = 117858882.48420054\n",
      "Iteration 1253, loss = 117681852.18929382\n",
      "Iteration 1254, loss = 117509763.79807323\n",
      "Iteration 1255, loss = 117342578.53375416\n",
      "Iteration 1256, loss = 117188274.37745850\n",
      "Iteration 1257, loss = 117006741.92405976\n",
      "Iteration 1258, loss = 116860438.32175925\n",
      "Iteration 1259, loss = 116664203.32270283\n",
      "Iteration 1260, loss = 116503400.69199288\n",
      "Iteration 1261, loss = 116361002.06905164\n",
      "Iteration 1262, loss = 116215803.36244118\n",
      "Iteration 1263, loss = 116033971.27151868\n",
      "Iteration 1264, loss = 115864123.01242930\n",
      "Iteration 1265, loss = 115718993.03298749\n",
      "Iteration 1266, loss = 115565111.12139829\n",
      "Iteration 1267, loss = 115421056.95856978\n",
      "Iteration 1268, loss = 115227930.93215904\n",
      "Iteration 1269, loss = 115046471.26839991\n",
      "Iteration 1270, loss = 114895868.75043640\n",
      "Iteration 1271, loss = 114736780.35976399\n",
      "Iteration 1272, loss = 114596523.95333445\n",
      "Iteration 1273, loss = 114440594.12074560\n",
      "Iteration 1274, loss = 114262537.50018400\n",
      "Iteration 1275, loss = 114104936.40296845\n",
      "Iteration 1276, loss = 113947602.84308317\n",
      "Iteration 1277, loss = 113803647.58565697\n",
      "Iteration 1278, loss = 113669232.42102681\n",
      "Iteration 1279, loss = 113506446.85054174\n",
      "Iteration 1280, loss = 113346390.97308536\n",
      "Iteration 1281, loss = 113221528.93336985\n",
      "Iteration 1282, loss = 113084525.54460602\n",
      "Iteration 1283, loss = 112940271.63889454\n",
      "Iteration 1284, loss = 112772619.39843942\n",
      "Iteration 1285, loss = 112618206.52671430\n",
      "Iteration 1286, loss = 112501124.87451056\n",
      "Iteration 1287, loss = 112348220.16106300\n",
      "Iteration 1288, loss = 112201034.19666521\n",
      "Iteration 1289, loss = 112054440.48317495\n",
      "Iteration 1290, loss = 111890281.73754376\n",
      "Iteration 1291, loss = 111761111.19164060\n",
      "Iteration 1292, loss = 111606165.37750697\n",
      "Iteration 1293, loss = 111475733.99698031\n",
      "Iteration 1294, loss = 111330566.56475180\n",
      "Iteration 1295, loss = 111192457.48191528\n",
      "Iteration 1296, loss = 111048198.18202932\n",
      "Iteration 1297, loss = 110905161.60329367\n",
      "Iteration 1298, loss = 110760278.48266900\n",
      "Iteration 1299, loss = 110642921.11631945\n",
      "Iteration 1300, loss = 110496165.26979220\n",
      "Iteration 1301, loss = 110368768.83424142\n",
      "Iteration 1302, loss = 110202263.69036366\n",
      "Iteration 1303, loss = 110097878.65695399\n",
      "Iteration 1304, loss = 109917762.36123557\n",
      "Iteration 1305, loss = 109829015.91045105\n",
      "Iteration 1306, loss = 109706605.01478389\n",
      "Iteration 1307, loss = 109543399.94788955\n",
      "Iteration 1308, loss = 109430474.63309197\n",
      "Iteration 1309, loss = 109288143.89067140\n",
      "Iteration 1310, loss = 109147831.78073445\n",
      "Iteration 1311, loss = 109021720.76895601\n",
      "Iteration 1312, loss = 108885632.43463324\n",
      "Iteration 1313, loss = 108749605.04781039\n",
      "Iteration 1314, loss = 108626382.96240452\n",
      "Iteration 1315, loss = 108477635.09653059\n",
      "Iteration 1316, loss = 108360933.15993834\n",
      "Iteration 1317, loss = 108266177.12605968\n",
      "Iteration 1318, loss = 108120165.16305862\n",
      "Iteration 1319, loss = 108012985.43882722\n",
      "Iteration 1320, loss = 107875325.23963946\n",
      "Iteration 1321, loss = 107747004.33795796\n",
      "Iteration 1322, loss = 107632881.67523125\n",
      "Iteration 1323, loss = 107515585.21247855\n",
      "Iteration 1324, loss = 107392127.87864168\n",
      "Iteration 1325, loss = 107254355.66983071\n",
      "Iteration 1326, loss = 107130392.50223126\n",
      "Iteration 1327, loss = 107005149.35196453\n",
      "Iteration 1328, loss = 106886466.05616233\n",
      "Iteration 1329, loss = 106773464.93214497\n",
      "Iteration 1330, loss = 106658036.47010550\n",
      "Iteration 1331, loss = 106538752.15295944\n",
      "Iteration 1332, loss = 106457092.61382473\n",
      "Iteration 1333, loss = 106290009.85930258\n",
      "Iteration 1334, loss = 106180927.72143030\n",
      "Iteration 1335, loss = 106079759.75359946\n",
      "Iteration 1336, loss = 105943460.98141010\n",
      "Iteration 1337, loss = 105842162.27952352\n",
      "Iteration 1338, loss = 105748117.61226177\n",
      "Iteration 1339, loss = 105799026.15600204\n",
      "Iteration 1340, loss = 105518898.50182344\n",
      "Iteration 1341, loss = 105395452.38504092\n",
      "Iteration 1342, loss = 105294405.46504149\n",
      "Iteration 1343, loss = 105188020.09143588\n",
      "Iteration 1344, loss = 105085368.29188427\n",
      "Iteration 1345, loss = 104966315.44710495\n",
      "Iteration 1346, loss = 104866694.60102901\n",
      "Iteration 1347, loss = 104752445.63676189\n",
      "Iteration 1348, loss = 104643285.70600607\n",
      "Iteration 1349, loss = 104525822.70005505\n",
      "Iteration 1350, loss = 104418308.91292080\n",
      "Iteration 1351, loss = 104357351.35362853\n",
      "Iteration 1352, loss = 104208691.28568329\n",
      "Iteration 1353, loss = 104103046.69783652\n",
      "Iteration 1354, loss = 103997003.19150096\n",
      "Iteration 1355, loss = 103886222.15873581\n",
      "Iteration 1356, loss = 103801157.94803116\n",
      "Iteration 1357, loss = 103688215.51506130\n",
      "Iteration 1358, loss = 103592766.14587308\n",
      "Iteration 1359, loss = 103484704.79023829\n",
      "Iteration 1360, loss = 103385725.51706278\n",
      "Iteration 1361, loss = 103284937.97968578\n",
      "Iteration 1362, loss = 103166488.69397901\n",
      "Iteration 1363, loss = 103060787.43491112\n",
      "Iteration 1364, loss = 102959497.19956362\n",
      "Iteration 1365, loss = 102859226.33409815\n",
      "Iteration 1366, loss = 102761388.75472538\n",
      "Iteration 1367, loss = 102661485.94736029\n",
      "Iteration 1368, loss = 102559236.99326414\n",
      "Iteration 1369, loss = 102455663.60587700\n",
      "Iteration 1370, loss = 102353421.53345771\n",
      "Iteration 1371, loss = 102284490.69830735\n",
      "Iteration 1372, loss = 102163946.76020975\n",
      "Iteration 1373, loss = 102071831.80789976\n",
      "Iteration 1374, loss = 101959770.60250816\n",
      "Iteration 1375, loss = 101869332.05308363\n",
      "Iteration 1376, loss = 101780331.84353866\n",
      "Iteration 1377, loss = 101673326.80131210\n",
      "Iteration 1378, loss = 101571741.50103331\n",
      "Iteration 1379, loss = 101480418.10853674\n",
      "Iteration 1380, loss = 101379396.20101090\n",
      "Iteration 1381, loss = 101293049.85048440\n",
      "Iteration 1382, loss = 101188322.45923522\n",
      "Iteration 1383, loss = 101094167.26470400\n",
      "Iteration 1384, loss = 101001024.00277425\n",
      "Iteration 1385, loss = 100914327.98593722\n",
      "Iteration 1386, loss = 100820173.73835485\n",
      "Iteration 1387, loss = 100746898.05710877\n",
      "Iteration 1388, loss = 100637831.37777969\n",
      "Iteration 1389, loss = 100560405.17607224\n",
      "Iteration 1390, loss = 100477063.93799585\n",
      "Iteration 1391, loss = 100362984.12315549\n",
      "Iteration 1392, loss = 100293353.11411621\n",
      "Iteration 1393, loss = 100197409.46518026\n",
      "Iteration 1394, loss = 100138653.22690117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1395, loss = 99987288.57115705\n",
      "Iteration 1396, loss = 99916897.39251770\n",
      "Iteration 1397, loss = 99810291.53506614\n",
      "Iteration 1398, loss = 99769168.97328281\n",
      "Iteration 1399, loss = 99653796.01416932\n",
      "Iteration 1400, loss = 99585281.67502755\n",
      "Iteration 1401, loss = 99523721.12194479\n",
      "Iteration 1402, loss = 99404539.34479970\n",
      "Iteration 1403, loss = 99356005.62864999\n",
      "Iteration 1404, loss = 99236728.81497073\n",
      "Iteration 1405, loss = 99144233.43051544\n",
      "Iteration 1406, loss = 99062323.65456972\n",
      "Iteration 1407, loss = 98980112.72840685\n",
      "Iteration 1408, loss = 98905577.13240780\n",
      "Iteration 1409, loss = 98819060.78307156\n",
      "Iteration 1410, loss = 98737242.67524129\n",
      "Iteration 1411, loss = 98652601.43144865\n",
      "Iteration 1412, loss = 98579569.12986307\n",
      "Iteration 1413, loss = 98510365.78066386\n",
      "Iteration 1414, loss = 98416320.93644014\n",
      "Iteration 1415, loss = 98339466.90524323\n",
      "Iteration 1416, loss = 98251457.13493507\n",
      "Iteration 1417, loss = 98184104.28851451\n",
      "Iteration 1418, loss = 98043132.40798569\n",
      "Iteration 1419, loss = 98037195.48718223\n",
      "Iteration 1420, loss = 97904339.01980467\n",
      "Iteration 1421, loss = 97859699.47762112\n",
      "Iteration 1422, loss = 97801819.37670474\n",
      "Iteration 1423, loss = 97699873.57035844\n",
      "Iteration 1424, loss = 97611537.74102557\n",
      "Iteration 1425, loss = 97558293.91547771\n",
      "Iteration 1426, loss = 97482870.57424070\n",
      "Iteration 1427, loss = 97391966.76289733\n",
      "Iteration 1428, loss = 97305200.83877911\n",
      "Iteration 1429, loss = 97243235.59062505\n",
      "Iteration 1430, loss = 97126547.32808521\n",
      "Iteration 1431, loss = 97101062.15096831\n",
      "Iteration 1432, loss = 97014428.18143652\n",
      "Iteration 1433, loss = 96945179.09403378\n",
      "Iteration 1434, loss = 96871929.27815332\n",
      "Iteration 1435, loss = 96821204.87030166\n",
      "Iteration 1436, loss = 96711048.89660969\n",
      "Iteration 1437, loss = 96654981.24701913\n",
      "Iteration 1438, loss = 96576554.20732464\n",
      "Iteration 1439, loss = 96522585.61857876\n",
      "Iteration 1440, loss = 96465906.12683722\n",
      "Iteration 1441, loss = 96377224.40992303\n",
      "Iteration 1442, loss = 96288511.30581775\n",
      "Iteration 1443, loss = 96207853.16660316\n",
      "Iteration 1444, loss = 96139645.98251289\n",
      "Iteration 1445, loss = 96110269.66918422\n",
      "Iteration 1446, loss = 95999289.62944569\n",
      "Iteration 1447, loss = 95947279.48428780\n",
      "Iteration 1448, loss = 95868391.55201857\n",
      "Iteration 1449, loss = 95782035.49657799\n",
      "Iteration 1450, loss = 95756224.74590163\n",
      "Iteration 1451, loss = 95695112.15877536\n",
      "Iteration 1452, loss = 95612040.50972924\n",
      "Iteration 1453, loss = 95556111.51452447\n",
      "Iteration 1454, loss = 95483223.29652916\n",
      "Iteration 1455, loss = 95377546.23343275\n",
      "Iteration 1456, loss = 95354542.17045681\n",
      "Iteration 1457, loss = 95262517.41740410\n",
      "Iteration 1458, loss = 95205036.16723667\n",
      "Iteration 1459, loss = 95151282.75887379\n",
      "Iteration 1460, loss = 95068496.43997759\n",
      "Iteration 1461, loss = 95003856.51507032\n",
      "Iteration 1462, loss = 94971008.28430898\n",
      "Iteration 1463, loss = 94856431.29094052\n",
      "Iteration 1464, loss = 94806631.66771445\n",
      "Iteration 1465, loss = 94721573.86031015\n",
      "Iteration 1466, loss = 94668463.33497758\n",
      "Iteration 1467, loss = 94602845.68367425\n",
      "Iteration 1468, loss = 94549639.82544808\n",
      "Iteration 1469, loss = 94490484.17764302\n",
      "Iteration 1470, loss = 94433939.23802885\n",
      "Iteration 1471, loss = 94326245.55252145\n",
      "Iteration 1472, loss = 94281533.23471232\n",
      "Iteration 1473, loss = 94233880.32106557\n",
      "Iteration 1474, loss = 94161322.54158130\n",
      "Iteration 1475, loss = 94103794.00774790\n",
      "Iteration 1476, loss = 94026525.94789359\n",
      "Iteration 1477, loss = 93989748.66470391\n",
      "Iteration 1478, loss = 93916585.17989430\n",
      "Iteration 1479, loss = 93856375.99462882\n",
      "Iteration 1480, loss = 93793315.59011115\n",
      "Iteration 1481, loss = 93723758.09189810\n",
      "Iteration 1482, loss = 93670155.29962385\n",
      "Iteration 1483, loss = 93615361.95836182\n",
      "Iteration 1484, loss = 93555867.88692571\n",
      "Iteration 1485, loss = 93480229.46925727\n",
      "Iteration 1486, loss = 93417257.91322444\n",
      "Iteration 1487, loss = 93368607.76044126\n",
      "Iteration 1488, loss = 93309331.27439877\n",
      "Iteration 1489, loss = 93261986.85547704\n",
      "Iteration 1490, loss = 93182041.79030940\n",
      "Iteration 1491, loss = 93129114.53300515\n",
      "Iteration 1492, loss = 93083995.97954291\n",
      "Iteration 1493, loss = 93012030.17098622\n",
      "Iteration 1494, loss = 92967190.68641599\n",
      "Iteration 1495, loss = 92910548.53854740\n",
      "Iteration 1496, loss = 92838285.69814567\n",
      "Iteration 1497, loss = 92777324.21566190\n",
      "Iteration 1498, loss = 92747457.15401615\n",
      "Iteration 1499, loss = 92645092.56764738\n",
      "Iteration 1500, loss = 92607611.02661267\n",
      "Iteration 1501, loss = 92540590.05143896\n",
      "Iteration 1502, loss = 92495399.25667542\n",
      "Iteration 1503, loss = 92442318.33850101\n",
      "Iteration 1504, loss = 92395243.47147304\n",
      "Iteration 1505, loss = 92328289.43517914\n",
      "Iteration 1506, loss = 92279742.20069230\n",
      "Iteration 1507, loss = 92234643.93797982\n",
      "Iteration 1508, loss = 92179940.01605688\n",
      "Iteration 1509, loss = 92121069.38312362\n",
      "Iteration 1510, loss = 92062100.72054985\n",
      "Iteration 1511, loss = 92002886.55198234\n",
      "Iteration 1512, loss = 91960083.81032935\n",
      "Iteration 1513, loss = 91908175.54740760\n",
      "Iteration 1514, loss = 91854016.70014033\n",
      "Iteration 1515, loss = 91812680.63658422\n",
      "Iteration 1516, loss = 91734389.09929289\n",
      "Iteration 1517, loss = 91690934.84999344\n",
      "Iteration 1518, loss = 91657396.09340282\n",
      "Iteration 1519, loss = 91585137.79032883\n",
      "Iteration 1520, loss = 91549870.46689448\n",
      "Iteration 1521, loss = 91479847.06326774\n",
      "Iteration 1522, loss = 91424355.88589251\n",
      "Iteration 1523, loss = 91397045.19437207\n",
      "Iteration 1524, loss = 91334967.13158521\n",
      "Iteration 1525, loss = 91297994.05294530\n",
      "Iteration 1526, loss = 91223023.50756817\n",
      "Iteration 1527, loss = 91198786.49224213\n",
      "Iteration 1528, loss = 91136627.46518269\n",
      "Iteration 1529, loss = 91057770.06235364\n",
      "Iteration 1530, loss = 91099092.07577224\n",
      "Iteration 1531, loss = 90969772.11743525\n",
      "Iteration 1532, loss = 90939451.84394211\n",
      "Iteration 1533, loss = 90897240.25641939\n",
      "Iteration 1534, loss = 90841781.64698809\n",
      "Iteration 1535, loss = 90787639.00445998\n",
      "Iteration 1536, loss = 90749212.40571007\n",
      "Iteration 1537, loss = 90678242.46012615\n",
      "Iteration 1538, loss = 90624852.55745517\n",
      "Iteration 1539, loss = 90611708.30690308\n",
      "Iteration 1540, loss = 90540917.19368948\n",
      "Iteration 1541, loss = 90513771.90346348\n",
      "Iteration 1542, loss = 90447617.95021690\n",
      "Iteration 1543, loss = 90407619.34931427\n",
      "Iteration 1544, loss = 90404255.51078507\n",
      "Iteration 1545, loss = 90314547.15184379\n",
      "Iteration 1546, loss = 90253159.67055765\n",
      "Iteration 1547, loss = 90244158.93207204\n",
      "Iteration 1548, loss = 90154280.76777892\n",
      "Iteration 1549, loss = 90116487.89990762\n",
      "Iteration 1550, loss = 90119141.53713505\n",
      "Iteration 1551, loss = 90038784.01754840\n",
      "Iteration 1552, loss = 89982598.75413394\n",
      "Iteration 1553, loss = 89929182.58201149\n",
      "Iteration 1554, loss = 89890182.13616429\n",
      "Iteration 1555, loss = 89941360.95677666\n",
      "Iteration 1556, loss = 89805285.20680900\n",
      "Iteration 1557, loss = 89750406.55561548\n",
      "Iteration 1558, loss = 89699582.37079559\n",
      "Iteration 1559, loss = 89655497.24705435\n",
      "Iteration 1560, loss = 89602555.37421921\n",
      "Iteration 1561, loss = 89559040.62941402\n",
      "Iteration 1562, loss = 89513969.76239668\n",
      "Iteration 1563, loss = 89477404.28550634\n",
      "Iteration 1564, loss = 89430613.89253588\n",
      "Iteration 1565, loss = 89409214.28871816\n",
      "Iteration 1566, loss = 89341649.38508151\n",
      "Iteration 1567, loss = 89292235.21553695\n",
      "Iteration 1568, loss = 89245502.06187390\n",
      "Iteration 1569, loss = 89216311.01306036\n",
      "Iteration 1570, loss = 89135734.90759943\n",
      "Iteration 1571, loss = 89134550.20656565\n",
      "Iteration 1572, loss = 89095785.78906035\n",
      "Iteration 1573, loss = 89037167.00818060\n",
      "Iteration 1574, loss = 88976031.30538322\n",
      "Iteration 1575, loss = 88936746.62709212\n",
      "Iteration 1576, loss = 88891818.13037984\n",
      "Iteration 1577, loss = 88878017.05784738\n",
      "Iteration 1578, loss = 88812291.34873655\n",
      "Iteration 1579, loss = 88763526.08442476\n",
      "Iteration 1580, loss = 88737899.55840537\n",
      "Iteration 1581, loss = 88706541.83769928\n",
      "Iteration 1582, loss = 88639327.71785058\n",
      "Iteration 1583, loss = 88584146.75267874\n",
      "Iteration 1584, loss = 88562224.17366700\n",
      "Iteration 1585, loss = 88524949.55064163\n",
      "Iteration 1586, loss = 88478022.79817574\n",
      "Iteration 1587, loss = 88433994.18996331\n",
      "Iteration 1588, loss = 88389221.27476585\n",
      "Iteration 1589, loss = 88363235.02709478\n",
      "Iteration 1590, loss = 88286570.50508060\n",
      "Iteration 1591, loss = 88281839.13970548\n",
      "Iteration 1592, loss = 88225206.34345663\n",
      "Iteration 1593, loss = 88164868.89741069\n",
      "Iteration 1594, loss = 88125534.55265990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1595, loss = 88104732.98575030\n",
      "Iteration 1596, loss = 88046940.10538869\n",
      "Iteration 1597, loss = 88021336.14366098\n",
      "Iteration 1598, loss = 87947169.34909520\n",
      "Iteration 1599, loss = 87938190.17996939\n",
      "Iteration 1600, loss = 87912718.56222391\n",
      "Iteration 1601, loss = 87835574.16390775\n",
      "Iteration 1602, loss = 87808899.83207944\n",
      "Iteration 1603, loss = 87767575.43828264\n",
      "Iteration 1604, loss = 87729312.51249136\n",
      "Iteration 1605, loss = 87670108.37771210\n",
      "Iteration 1606, loss = 87636721.99160349\n",
      "Iteration 1607, loss = 87604166.41862504\n",
      "Iteration 1608, loss = 87565788.93129833\n",
      "Iteration 1609, loss = 87502069.61641134\n",
      "Iteration 1610, loss = 87465472.48956975\n",
      "Iteration 1611, loss = 87429923.84511209\n",
      "Iteration 1612, loss = 87391216.49044870\n",
      "Iteration 1613, loss = 87348860.63831303\n",
      "Iteration 1614, loss = 87297183.85842514\n",
      "Iteration 1615, loss = 87276500.86246477\n",
      "Iteration 1616, loss = 87238304.47232525\n",
      "Iteration 1617, loss = 87215840.77776782\n",
      "Iteration 1618, loss = 87159176.12512153\n",
      "Iteration 1619, loss = 87112180.64111561\n",
      "Iteration 1620, loss = 87069621.03226526\n",
      "Iteration 1621, loss = 87048504.42387295\n",
      "Iteration 1622, loss = 86983004.72482917\n",
      "Iteration 1623, loss = 86949081.89649743\n",
      "Iteration 1624, loss = 86923817.20992805\n",
      "Iteration 1625, loss = 86887499.26222703\n",
      "Iteration 1626, loss = 86838342.45904621\n",
      "Iteration 1627, loss = 86808390.34382977\n",
      "Iteration 1628, loss = 86763703.60618861\n",
      "Iteration 1629, loss = 86718324.31623740\n",
      "Iteration 1630, loss = 86704293.29727082\n",
      "Iteration 1631, loss = 86637667.15798636\n",
      "Iteration 1632, loss = 86628236.85029486\n",
      "Iteration 1633, loss = 86567982.92856835\n",
      "Iteration 1634, loss = 86536831.12332524\n",
      "Iteration 1635, loss = 86506090.00913647\n",
      "Iteration 1636, loss = 86442118.62263305\n",
      "Iteration 1637, loss = 86445000.31960851\n",
      "Iteration 1638, loss = 86346314.55012672\n",
      "Iteration 1639, loss = 86354387.81118546\n",
      "Iteration 1640, loss = 86297747.31394741\n",
      "Iteration 1641, loss = 86329890.37719324\n",
      "Iteration 1642, loss = 86230371.78996849\n",
      "Iteration 1643, loss = 86208135.54727015\n",
      "Iteration 1644, loss = 86207166.64588946\n",
      "Iteration 1645, loss = 86119138.75839159\n",
      "Iteration 1646, loss = 86114698.05417472\n",
      "Iteration 1647, loss = 86056485.55318406\n",
      "Iteration 1648, loss = 86024428.68981181\n",
      "Iteration 1649, loss = 85975091.59302445\n",
      "Iteration 1650, loss = 85944648.09923768\n",
      "Iteration 1651, loss = 85926415.71423846\n",
      "Iteration 1652, loss = 85848466.87394758\n",
      "Iteration 1653, loss = 85822537.63255076\n",
      "Iteration 1654, loss = 85790138.18748389\n",
      "Iteration 1655, loss = 85755729.46449505\n",
      "Iteration 1656, loss = 85718355.48938060\n",
      "Iteration 1657, loss = 85689705.61878996\n",
      "Iteration 1658, loss = 85653161.14254721\n",
      "Iteration 1659, loss = 85603020.03509110\n",
      "Iteration 1660, loss = 85576462.30239984\n",
      "Iteration 1661, loss = 85545261.32485580\n",
      "Iteration 1662, loss = 85514100.48156008\n",
      "Iteration 1663, loss = 85464252.86872303\n",
      "Iteration 1664, loss = 85430697.87881559\n",
      "Iteration 1665, loss = 85420825.39970616\n",
      "Iteration 1666, loss = 85374902.85754144\n",
      "Iteration 1667, loss = 85340811.27701361\n",
      "Iteration 1668, loss = 85293762.49128406\n",
      "Iteration 1669, loss = 85271373.17886198\n",
      "Iteration 1670, loss = 85209796.61460643\n",
      "Iteration 1671, loss = 85204880.74588165\n",
      "Iteration 1672, loss = 85158823.98071693\n",
      "Iteration 1673, loss = 85104831.69892180\n",
      "Iteration 1674, loss = 85101226.93784276\n",
      "Iteration 1675, loss = 85055298.18955955\n",
      "Iteration 1676, loss = 85033331.29580729\n",
      "Iteration 1677, loss = 84964186.92485212\n",
      "Iteration 1678, loss = 84942292.11806819\n",
      "Iteration 1679, loss = 84914111.98328632\n",
      "Iteration 1680, loss = 84888852.97278801\n",
      "Iteration 1681, loss = 84840316.57367642\n",
      "Iteration 1682, loss = 84799070.97179684\n",
      "Iteration 1683, loss = 84805570.56421088\n",
      "Iteration 1684, loss = 84751474.96432859\n",
      "Iteration 1685, loss = 84719024.57313251\n",
      "Iteration 1686, loss = 84677592.87436841\n",
      "Iteration 1687, loss = 84666459.84427558\n",
      "Iteration 1688, loss = 84609102.29028019\n",
      "Iteration 1689, loss = 84577172.41496782\n",
      "Iteration 1690, loss = 84534635.03542496\n",
      "Iteration 1691, loss = 84494523.68289451\n",
      "Iteration 1692, loss = 84465593.00031765\n",
      "Iteration 1693, loss = 84433463.40128246\n",
      "Iteration 1694, loss = 84409285.21462913\n",
      "Iteration 1695, loss = 84358979.15305062\n",
      "Iteration 1696, loss = 84363340.10227723\n",
      "Iteration 1697, loss = 84309128.54486817\n",
      "Iteration 1698, loss = 84263915.16542286\n",
      "Iteration 1699, loss = 84243522.32949492\n",
      "Iteration 1700, loss = 84193215.12014946\n",
      "Iteration 1701, loss = 84192605.04276022\n",
      "Iteration 1702, loss = 84135559.62601399\n",
      "Iteration 1703, loss = 84105524.53672336\n",
      "Iteration 1704, loss = 84072022.04765025\n",
      "Iteration 1705, loss = 84017252.87376820\n",
      "Iteration 1706, loss = 84014657.19189894\n",
      "Iteration 1707, loss = 83968316.68451387\n",
      "Iteration 1708, loss = 83937986.22843939\n",
      "Iteration 1709, loss = 83918534.33783790\n",
      "Iteration 1710, loss = 83884225.69871196\n",
      "Iteration 1711, loss = 83837902.65170513\n",
      "Iteration 1712, loss = 83814111.94674253\n",
      "Iteration 1713, loss = 83783458.97974414\n",
      "Iteration 1714, loss = 83748488.66856399\n",
      "Iteration 1715, loss = 83733981.69173780\n",
      "Iteration 1716, loss = 83694042.81297573\n",
      "Iteration 1717, loss = 83655025.43883251\n",
      "Iteration 1718, loss = 83637584.23606947\n",
      "Iteration 1719, loss = 83599491.78528070\n",
      "Iteration 1720, loss = 83558543.10720560\n",
      "Iteration 1721, loss = 83533687.20731577\n",
      "Iteration 1722, loss = 83503290.50505152\n",
      "Iteration 1723, loss = 83469043.95755270\n",
      "Iteration 1724, loss = 83453099.01727013\n",
      "Iteration 1725, loss = 83406981.24929440\n",
      "Iteration 1726, loss = 83369604.05093177\n",
      "Iteration 1727, loss = 83339382.61144011\n",
      "Iteration 1728, loss = 83297796.47063725\n",
      "Iteration 1729, loss = 83289872.97912873\n",
      "Iteration 1730, loss = 83277365.83207105\n",
      "Iteration 1731, loss = 83204114.45377642\n",
      "Iteration 1732, loss = 83187291.74645963\n",
      "Iteration 1733, loss = 83134555.38467582\n",
      "Iteration 1734, loss = 83115159.70867968\n",
      "Iteration 1735, loss = 83079118.35002784\n",
      "Iteration 1736, loss = 83063095.44830552\n",
      "Iteration 1737, loss = 83030340.51237957\n",
      "Iteration 1738, loss = 82971027.54370399\n",
      "Iteration 1739, loss = 82953479.20375079\n",
      "Iteration 1740, loss = 82921892.73813336\n",
      "Iteration 1741, loss = 82897454.55981165\n",
      "Iteration 1742, loss = 82867473.02807234\n",
      "Iteration 1743, loss = 82844063.87540759\n",
      "Iteration 1744, loss = 82816238.64963792\n",
      "Iteration 1745, loss = 82814619.66394646\n",
      "Iteration 1746, loss = 82724505.18122838\n",
      "Iteration 1747, loss = 82710658.30288886\n",
      "Iteration 1748, loss = 82678758.95883839\n",
      "Iteration 1749, loss = 82675090.18914218\n",
      "Iteration 1750, loss = 82614302.02684996\n",
      "Iteration 1751, loss = 82586449.59424411\n",
      "Iteration 1752, loss = 82556570.10586177\n",
      "Iteration 1753, loss = 82533188.17129852\n",
      "Iteration 1754, loss = 82490199.37290707\n",
      "Iteration 1755, loss = 82469264.18958682\n",
      "Iteration 1756, loss = 82423809.13375214\n",
      "Iteration 1757, loss = 82415906.03428498\n",
      "Iteration 1758, loss = 82360576.45574224\n",
      "Iteration 1759, loss = 82343468.72159930\n",
      "Iteration 1760, loss = 82333660.48974621\n",
      "Iteration 1761, loss = 82282950.36699745\n",
      "Iteration 1762, loss = 82259591.58456089\n",
      "Iteration 1763, loss = 82191365.69588053\n",
      "Iteration 1764, loss = 82212629.59443793\n",
      "Iteration 1765, loss = 82143984.03412864\n",
      "Iteration 1766, loss = 82171463.71377155\n",
      "Iteration 1767, loss = 82124899.62909885\n",
      "Iteration 1768, loss = 82062247.49490933\n",
      "Iteration 1769, loss = 82058230.05867885\n",
      "Iteration 1770, loss = 82004308.78301273\n",
      "Iteration 1771, loss = 82000536.48738296\n",
      "Iteration 1772, loss = 81977863.94974066\n",
      "Iteration 1773, loss = 81904038.17908402\n",
      "Iteration 1774, loss = 81938936.39231808\n",
      "Iteration 1775, loss = 81857013.92193875\n",
      "Iteration 1776, loss = 81818719.98605622\n",
      "Iteration 1777, loss = 81792814.86303288\n",
      "Iteration 1778, loss = 81778173.60486588\n",
      "Iteration 1779, loss = 81736537.59030682\n",
      "Iteration 1780, loss = 81706951.68298373\n",
      "Iteration 1781, loss = 81711095.67548615\n",
      "Iteration 1782, loss = 81682991.80813071\n",
      "Iteration 1783, loss = 81632528.32454577\n",
      "Iteration 1784, loss = 81609255.21790580\n",
      "Iteration 1785, loss = 81578861.39378965\n",
      "Iteration 1786, loss = 81572123.61694553\n",
      "Iteration 1787, loss = 81550610.36666706\n",
      "Iteration 1788, loss = 81491939.96155272\n",
      "Iteration 1789, loss = 81453696.27676369\n",
      "Iteration 1790, loss = 81434073.58662419\n",
      "Iteration 1791, loss = 81405221.13201554\n",
      "Iteration 1792, loss = 81402511.80392866\n",
      "Iteration 1793, loss = 81341850.67195894\n",
      "Iteration 1794, loss = 81333664.90662213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1795, loss = 81284545.77594233\n",
      "Iteration 1796, loss = 81273947.34589295\n",
      "Iteration 1797, loss = 81237862.10209580\n",
      "Iteration 1798, loss = 81209530.43704662\n",
      "Iteration 1799, loss = 81177491.51421930\n",
      "Iteration 1800, loss = 81142625.73204167\n",
      "Iteration 1801, loss = 81102533.47622246\n",
      "Iteration 1802, loss = 81090840.23225637\n",
      "Iteration 1803, loss = 81074368.11011858\n",
      "Iteration 1804, loss = 81020893.41505064\n",
      "Iteration 1805, loss = 81003447.58481646\n",
      "Iteration 1806, loss = 80955834.76304251\n",
      "Iteration 1807, loss = 80962785.47621314\n",
      "Iteration 1808, loss = 80930276.92389059\n",
      "Iteration 1809, loss = 80891397.75288779\n",
      "Iteration 1810, loss = 80873354.98331511\n",
      "Iteration 1811, loss = 80851085.75973044\n",
      "Iteration 1812, loss = 80811353.89307842\n",
      "Iteration 1813, loss = 80798449.31104124\n",
      "Iteration 1814, loss = 80765225.28149568\n",
      "Iteration 1815, loss = 80718133.78213869\n",
      "Iteration 1816, loss = 80705841.54967967\n",
      "Iteration 1817, loss = 80670293.69116184\n",
      "Iteration 1818, loss = 80646396.54809949\n",
      "Iteration 1819, loss = 80617907.93762606\n",
      "Iteration 1820, loss = 80572162.06232502\n",
      "Iteration 1821, loss = 80580696.79248133\n",
      "Iteration 1822, loss = 80535645.97071566\n",
      "Iteration 1823, loss = 80522202.03310943\n",
      "Iteration 1824, loss = 80466309.44590653\n",
      "Iteration 1825, loss = 80490547.35941896\n",
      "Iteration 1826, loss = 80416681.00141124\n",
      "Iteration 1827, loss = 80399493.34834333\n",
      "Iteration 1828, loss = 80373825.72176504\n",
      "Iteration 1829, loss = 80333060.53587359\n",
      "Iteration 1830, loss = 80315782.08098146\n",
      "Iteration 1831, loss = 80288929.62086906\n",
      "Iteration 1832, loss = 80256177.05683114\n",
      "Iteration 1833, loss = 80233151.86172482\n",
      "Iteration 1834, loss = 80218029.61634952\n",
      "Iteration 1835, loss = 80177999.69670083\n",
      "Iteration 1836, loss = 80135904.61470050\n",
      "Iteration 1837, loss = 80124141.02796109\n",
      "Iteration 1838, loss = 80063975.81574507\n",
      "Iteration 1839, loss = 80065910.19672944\n",
      "Iteration 1840, loss = 80054012.56689830\n",
      "Iteration 1841, loss = 80024580.91253532\n",
      "Iteration 1842, loss = 79996532.37568986\n",
      "Iteration 1843, loss = 79973269.71210220\n",
      "Iteration 1844, loss = 79949278.54796155\n",
      "Iteration 1845, loss = 79902355.16813621\n",
      "Iteration 1846, loss = 79877508.14586891\n",
      "Iteration 1847, loss = 79851434.03640251\n",
      "Iteration 1848, loss = 79831561.88180952\n",
      "Iteration 1849, loss = 79817192.52499811\n",
      "Iteration 1850, loss = 79797057.23160797\n",
      "Iteration 1851, loss = 79778544.29010996\n",
      "Iteration 1852, loss = 79735310.82508731\n",
      "Iteration 1853, loss = 79695322.97227089\n",
      "Iteration 1854, loss = 79694556.17725343\n",
      "Iteration 1855, loss = 79644040.04653920\n",
      "Iteration 1856, loss = 79611596.54443818\n",
      "Iteration 1857, loss = 79575134.47471333\n",
      "Iteration 1858, loss = 79556045.09891097\n",
      "Iteration 1859, loss = 79543449.32422078\n",
      "Iteration 1860, loss = 79512376.01720430\n",
      "Iteration 1861, loss = 79484669.64886789\n",
      "Iteration 1862, loss = 79452472.98880126\n",
      "Iteration 1863, loss = 79454733.50566457\n",
      "Iteration 1864, loss = 79402815.86988890\n",
      "Iteration 1865, loss = 79412118.49065395\n",
      "Iteration 1866, loss = 79365949.36998950\n",
      "Iteration 1867, loss = 79327591.69741337\n",
      "Iteration 1868, loss = 79306967.91667174\n",
      "Iteration 1869, loss = 79289964.99402465\n",
      "Iteration 1870, loss = 79265014.78506128\n",
      "Iteration 1871, loss = 79248084.12751289\n",
      "Iteration 1872, loss = 79212333.69320470\n",
      "Iteration 1873, loss = 79189734.26778047\n",
      "Iteration 1874, loss = 79164626.10852982\n",
      "Iteration 1875, loss = 79127245.63833854\n",
      "Iteration 1876, loss = 79107457.35498738\n",
      "Iteration 1877, loss = 79070528.60849185\n",
      "Iteration 1878, loss = 79040413.46056502\n",
      "Iteration 1879, loss = 78999822.53015052\n",
      "Iteration 1880, loss = 79038350.51758863\n",
      "Iteration 1881, loss = 79041404.24897908\n",
      "Iteration 1882, loss = 78962262.34565870\n",
      "Iteration 1883, loss = 78910829.17824036\n",
      "Iteration 1884, loss = 78872482.82659045\n",
      "Iteration 1885, loss = 78866716.75234079\n",
      "Iteration 1886, loss = 78839038.08628221\n",
      "Iteration 1887, loss = 78802748.55030365\n",
      "Iteration 1888, loss = 78793018.26321845\n",
      "Iteration 1889, loss = 78763119.54871616\n",
      "Iteration 1890, loss = 78739421.47033228\n",
      "Iteration 1891, loss = 78698204.17154042\n",
      "Iteration 1892, loss = 78688441.54862058\n",
      "Iteration 1893, loss = 78681444.44273843\n",
      "Iteration 1894, loss = 78624668.62652457\n",
      "Iteration 1895, loss = 78631785.64576592\n",
      "Iteration 1896, loss = 78600875.43166097\n",
      "Iteration 1897, loss = 78559954.96107510\n",
      "Iteration 1898, loss = 78535168.24006476\n",
      "Iteration 1899, loss = 78526705.86919779\n",
      "Iteration 1900, loss = 78523414.28704388\n",
      "Iteration 1901, loss = 78480822.63941361\n",
      "Iteration 1902, loss = 78437812.59476636\n",
      "Iteration 1903, loss = 78409642.61960937\n",
      "Iteration 1904, loss = 78405435.37504624\n",
      "Iteration 1905, loss = 78364888.57115155\n",
      "Iteration 1906, loss = 78339622.73481095\n",
      "Iteration 1907, loss = 78337260.25114463\n",
      "Iteration 1908, loss = 78304174.34254123\n",
      "Iteration 1909, loss = 78294704.97709537\n",
      "Iteration 1910, loss = 78246730.72457270\n",
      "Iteration 1911, loss = 78222930.21487527\n",
      "Iteration 1912, loss = 78207221.23356789\n",
      "Iteration 1913, loss = 78181354.40382932\n",
      "Iteration 1914, loss = 78138284.72082758\n",
      "Iteration 1915, loss = 78132248.08068137\n",
      "Iteration 1916, loss = 78101659.09401768\n",
      "Iteration 1917, loss = 78111391.92004962\n",
      "Iteration 1918, loss = 78040347.09401353\n",
      "Iteration 1919, loss = 78013989.51798911\n",
      "Iteration 1920, loss = 78009999.77095969\n",
      "Iteration 1921, loss = 77977446.07163747\n",
      "Iteration 1922, loss = 77946374.32453746\n",
      "Iteration 1923, loss = 77929910.41123180\n",
      "Iteration 1924, loss = 77910080.27866386\n",
      "Iteration 1925, loss = 77889801.49519351\n",
      "Iteration 1926, loss = 77859455.51916443\n",
      "Iteration 1927, loss = 77842884.72422640\n",
      "Iteration 1928, loss = 77814511.87278615\n",
      "Iteration 1929, loss = 77796402.75899236\n",
      "Iteration 1930, loss = 77769706.04888563\n",
      "Iteration 1931, loss = 77744820.80856253\n",
      "Iteration 1932, loss = 77703801.45008835\n",
      "Iteration 1933, loss = 77711056.44495562\n",
      "Iteration 1934, loss = 77688957.80354166\n",
      "Iteration 1935, loss = 77632642.77052678\n",
      "Iteration 1936, loss = 77622174.28732416\n",
      "Iteration 1937, loss = 77569603.95758097\n",
      "Iteration 1938, loss = 77564834.62049304\n",
      "Iteration 1939, loss = 77530333.98605268\n",
      "Iteration 1940, loss = 77517041.56818764\n",
      "Iteration 1941, loss = 77488197.09131637\n",
      "Iteration 1942, loss = 77492864.57140718\n",
      "Iteration 1943, loss = 77442354.07297096\n",
      "Iteration 1944, loss = 77427849.58776669\n",
      "Iteration 1945, loss = 77407316.04977214\n",
      "Iteration 1946, loss = 77382089.21958362\n",
      "Iteration 1947, loss = 77344712.55040915\n",
      "Iteration 1948, loss = 77314077.96058214\n",
      "Iteration 1949, loss = 77314433.60853498\n",
      "Iteration 1950, loss = 77269240.16187370\n",
      "Iteration 1951, loss = 77249603.93477216\n",
      "Iteration 1952, loss = 77225020.18472199\n",
      "Iteration 1953, loss = 77221970.74400698\n",
      "Iteration 1954, loss = 77178922.47613347\n",
      "Iteration 1955, loss = 77162825.32780313\n",
      "Iteration 1956, loss = 77170616.38760108\n",
      "Iteration 1957, loss = 77110272.89471044\n",
      "Iteration 1958, loss = 77069656.30156267\n",
      "Iteration 1959, loss = 77070706.57897086\n",
      "Iteration 1960, loss = 77045668.48017962\n",
      "Iteration 1961, loss = 77008657.09737775\n",
      "Iteration 1962, loss = 76982225.42709111\n",
      "Iteration 1963, loss = 76984091.66672158\n",
      "Iteration 1964, loss = 76964346.61325768\n",
      "Iteration 1965, loss = 76918307.68266921\n",
      "Iteration 1966, loss = 76893759.53509641\n",
      "Iteration 1967, loss = 76889662.83468685\n",
      "Iteration 1968, loss = 76844355.63670065\n",
      "Iteration 1969, loss = 76852109.85202698\n",
      "Iteration 1970, loss = 76814182.45484056\n",
      "Iteration 1971, loss = 76781320.92276242\n",
      "Iteration 1972, loss = 76768489.81443585\n",
      "Iteration 1973, loss = 76757752.54400046\n",
      "Iteration 1974, loss = 76718128.96550442\n",
      "Iteration 1975, loss = 76689011.15189815\n",
      "Iteration 1976, loss = 76677883.19024803\n",
      "Iteration 1977, loss = 76657940.13077027\n",
      "Iteration 1978, loss = 76632391.25649022\n",
      "Iteration 1979, loss = 76605885.63678998\n",
      "Iteration 1980, loss = 76614780.33736524\n",
      "Iteration 1981, loss = 76546248.83233233\n",
      "Iteration 1982, loss = 76517601.29763694\n",
      "Iteration 1983, loss = 76502854.90468347\n",
      "Iteration 1984, loss = 76496313.30389936\n",
      "Iteration 1985, loss = 76463217.23431487\n",
      "Iteration 1986, loss = 76442090.63712963\n",
      "Iteration 1987, loss = 76425990.68611275\n",
      "Iteration 1988, loss = 76451478.04837997\n",
      "Iteration 1989, loss = 76372495.68690127\n",
      "Iteration 1990, loss = 76356647.69570579\n",
      "Iteration 1991, loss = 76345243.29342023\n",
      "Iteration 1992, loss = 76306051.18762924\n",
      "Iteration 1993, loss = 76295124.39787096\n",
      "Iteration 1994, loss = 76258848.91969454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1995, loss = 76239533.30125427\n",
      "Iteration 1996, loss = 76218397.54604635\n",
      "Iteration 1997, loss = 76201663.14556535\n",
      "Iteration 1998, loss = 76160799.66130686\n",
      "Iteration 1999, loss = 76143789.52817802\n",
      "Iteration 2000, loss = 76135198.60352844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=8, max_iter=2000, n_iter_no_change=1000,\n",
       "             random_state=42, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlpregressor = MLPRegressor(\n",
    "    hidden_layer_sizes=8,\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    verbose=True,\n",
    "    n_iter_no_change=1000,\n",
    "    max_iter=2000,\n",
    "    tol=0.001,\n",
    "    random_state=42,\n",
    ")\n",
    "mlpregressor.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e89d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = mlpregressor.predict(X_train)\n",
    "pred_test = mlpregressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38fef3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9441503238523707\n",
      "0.9441503238523707\n"
     ]
    }
   ],
   "source": [
    "mlpscore_train = mlpregressor.score(X_train, y_train)\n",
    "mlpscore_test = mlpregressor.score(X_train, y_train)\n",
    "print(mlpscore_train)\n",
    "print(mlpscore_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c861173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12336.326261066291\n",
      "12055.471833142914\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "rmse_mlp_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_mlp_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print(rmse_mlp_train)\n",
    "print(rmse_mlp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4869d2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>pred</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22000</td>\n",
       "      <td>22025.303934</td>\n",
       "      <td>-25.303934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22672</th>\n",
       "      <td>39000</td>\n",
       "      <td>39302.751011</td>\n",
       "      <td>-302.751011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>11000</td>\n",
       "      <td>16339.916261</td>\n",
       "      <td>-5339.916261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15956</th>\n",
       "      <td>29500</td>\n",
       "      <td>48821.231786</td>\n",
       "      <td>-19321.231786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27170</th>\n",
       "      <td>49000</td>\n",
       "      <td>43597.967632</td>\n",
       "      <td>5402.032368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price          pred      residual\n",
       "9766   22000  22025.303934    -25.303934\n",
       "22672  39000  39302.751011   -302.751011\n",
       "2300   11000  16339.916261  -5339.916261\n",
       "15956  29500  48821.231786 -19321.231786\n",
       "27170  49000  43597.967632   5402.032368"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = y_test.copy()\n",
    "data[\"pred\"] = pred_test\n",
    "data[\"residual\"] = data[\"Price\"] - data[\"pred\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b99a6505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(data[\"pred\"], data[\"residual\"], color=\"red\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e436fa5",
   "metadata": {},
   "source": [
    "### XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ec1c529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=10, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=1, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgbregressor = XGBRegressor(\n",
    "    max_depth=10, learning_rate=0.1, reg_alpha=1, random_state=42\n",
    ")\n",
    "xgbregressor.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01c11025",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = xgbregressor.predict(X_train)\n",
    "pred_test = xgbregressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d1d2e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9771665893798432\n",
      "0.9506573144660839\n"
     ]
    }
   ],
   "source": [
    "xgbscore_train = xgbregressor.score(X_train, y_train)\n",
    "xgbscore_test = xgbregressor.score(X_test, y_test)\n",
    "print(xgbscore_train)\n",
    "print(xgbscore_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ebdbf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7887.8911804078025\n",
      "11545.125215630496\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "rmse_xgb_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_xgb_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print(rmse_xgb_train)\n",
    "print(rmse_xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7409c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>pred</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22000</td>\n",
       "      <td>22465.250000</td>\n",
       "      <td>-465.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22672</th>\n",
       "      <td>39000</td>\n",
       "      <td>39461.273438</td>\n",
       "      <td>-461.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>11000</td>\n",
       "      <td>10187.328125</td>\n",
       "      <td>812.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15956</th>\n",
       "      <td>29500</td>\n",
       "      <td>43730.449219</td>\n",
       "      <td>-14230.449219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27170</th>\n",
       "      <td>49000</td>\n",
       "      <td>45002.765625</td>\n",
       "      <td>3997.234375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price          pred      residual\n",
       "9766   22000  22465.250000   -465.250000\n",
       "22672  39000  39461.273438   -461.273438\n",
       "2300   11000  10187.328125    812.671875\n",
       "15956  29500  43730.449219 -14230.449219\n",
       "27170  49000  45002.765625   3997.234375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = y_test.copy()\n",
    "data[\"pred\"] = pred_test\n",
    "data[\"residual\"] = data[\"Price\"] - data[\"pred\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca595b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(data[\"pred\"], data[\"residual\"], color=\"red\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba44828",
   "metadata": {},
   "source": [
    "### Stacking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09597b80",
   "metadata": {},
   "source": [
    "<p>Stacking model will be built using the tuned models- decision tree, random forest and gradient boosting, then use XGBoost to get the final prediction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7102472",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"Gradient Boost\", gradientboost),\n",
    "    (\"MLP\", mlpregressor),\n",
    "    (\"Ada Boost\", adaboost),\n",
    "    (\"Random Forest\", rfregressor),\n",
    "]\n",
    "final_estimator = XGBRegressor(\n",
    "    max_depth = 10, learning_rate=0.1, reg_alpha=10, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f46840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2749467231.66211987\n",
      "Iteration 2, loss = 2744657295.46700430\n",
      "Iteration 3, loss = 2734354440.27566957\n",
      "Iteration 4, loss = 2720411918.80964947\n",
      "Iteration 5, loss = 2702725320.95245695\n",
      "Iteration 6, loss = 2681605134.53726339\n",
      "Iteration 7, loss = 2657195864.29869699\n",
      "Iteration 8, loss = 2629657013.48597717\n",
      "Iteration 9, loss = 2599318789.10924816\n",
      "Iteration 10, loss = 2566365797.23986149\n",
      "Iteration 11, loss = 2531299844.29710960\n",
      "Iteration 12, loss = 2494088583.58781910\n",
      "Iteration 13, loss = 2454963489.27360106\n",
      "Iteration 14, loss = 2414229477.18143892\n",
      "Iteration 15, loss = 2371922416.95725536\n",
      "Iteration 16, loss = 2328216781.14284992\n",
      "Iteration 17, loss = 2283346628.39066362\n",
      "Iteration 18, loss = 2237508730.41149330\n",
      "Iteration 19, loss = 2190785312.62856960\n",
      "Iteration 20, loss = 2143471578.20528650\n",
      "Iteration 21, loss = 2095657385.51934719\n",
      "Iteration 22, loss = 2047434510.36943150\n",
      "Iteration 23, loss = 1999008900.05104828\n",
      "Iteration 24, loss = 1950450491.44357991\n",
      "Iteration 25, loss = 1902076601.85518861\n",
      "Iteration 26, loss = 1853831452.61029601\n",
      "Iteration 27, loss = 1805554260.77770090\n",
      "Iteration 28, loss = 1757924288.45609426\n",
      "Iteration 29, loss = 1710711103.07565379\n",
      "Iteration 30, loss = 1663929165.21918845\n",
      "Iteration 31, loss = 1618586905.12643838\n",
      "Iteration 32, loss = 1573615149.68374944\n",
      "Iteration 33, loss = 1529640660.16798615\n",
      "Iteration 34, loss = 1486680726.21148157\n",
      "Iteration 35, loss = 1444860675.53436875\n",
      "Iteration 36, loss = 1404201187.75878263\n",
      "Iteration 37, loss = 1364764113.19403934\n",
      "Iteration 38, loss = 1326554524.45190310\n",
      "Iteration 39, loss = 1289729791.97020316\n",
      "Iteration 40, loss = 1253928105.45759702\n",
      "Iteration 41, loss = 1220079543.22662592\n",
      "Iteration 42, loss = 1187790815.43352461\n",
      "Iteration 43, loss = 1157273265.88038397\n",
      "Iteration 44, loss = 1128331354.54565501\n",
      "Iteration 45, loss = 1100911183.30416846\n",
      "Iteration 46, loss = 1075304283.61485791\n",
      "Iteration 47, loss = 1051159662.51835060\n",
      "Iteration 48, loss = 1028928548.88513041\n",
      "Iteration 49, loss = 1008500136.14766979\n",
      "Iteration 50, loss = 989844102.12909710\n",
      "Iteration 51, loss = 972689529.24236357\n",
      "Iteration 52, loss = 957136318.87265265\n",
      "Iteration 53, loss = 943198492.12481499\n",
      "Iteration 54, loss = 930810211.40183663\n",
      "Iteration 55, loss = 919868040.38434041\n",
      "Iteration 56, loss = 910188694.90390885\n",
      "Iteration 57, loss = 902096460.70086396\n",
      "Iteration 58, loss = 894784724.17521143\n",
      "Iteration 59, loss = 888658385.31767356\n",
      "Iteration 60, loss = 883757776.10637486\n",
      "Iteration 61, loss = 879730560.58525836\n",
      "Iteration 62, loss = 876343456.82482672\n",
      "Iteration 63, loss = 873685338.57815516\n",
      "Iteration 64, loss = 871482674.50283015\n",
      "Iteration 65, loss = 869863858.30793858\n",
      "Iteration 66, loss = 868412396.97230840\n",
      "Iteration 67, loss = 867268333.33119690\n",
      "Iteration 68, loss = 866312191.63698590\n",
      "Iteration 69, loss = 865544688.39754081\n",
      "Iteration 70, loss = 864912322.46164012\n",
      "Iteration 71, loss = 864361617.56204784\n",
      "Iteration 72, loss = 863870659.88331425\n",
      "Iteration 73, loss = 863398316.76856136\n",
      "Iteration 74, loss = 862955029.12986672\n",
      "Iteration 75, loss = 862544937.08575773\n",
      "Iteration 76, loss = 862097867.25920773\n",
      "Iteration 77, loss = 861667231.57901537\n",
      "Iteration 78, loss = 861225094.07176661\n",
      "Iteration 79, loss = 860807034.91640365\n",
      "Iteration 80, loss = 860379796.80919468\n",
      "Iteration 81, loss = 859918915.41980481\n",
      "Iteration 82, loss = 859478520.57877171\n",
      "Iteration 83, loss = 859025574.61983597\n",
      "Iteration 84, loss = 858589154.28056705\n",
      "Iteration 85, loss = 858121936.72810042\n",
      "Iteration 86, loss = 857665944.11151552\n",
      "Iteration 87, loss = 857214965.63124132\n",
      "Iteration 88, loss = 856755078.21745801\n",
      "Iteration 89, loss = 856317227.73690486\n",
      "Iteration 90, loss = 855846396.60334289\n",
      "Iteration 91, loss = 855396706.79015923\n",
      "Iteration 92, loss = 854916681.66553330\n",
      "Iteration 93, loss = 854470453.18601441\n",
      "Iteration 94, loss = 853995821.39786816\n",
      "Iteration 95, loss = 853533875.08241379\n",
      "Iteration 96, loss = 853018692.50736046\n",
      "Iteration 97, loss = 852610305.19822216\n",
      "Iteration 98, loss = 852141658.47125065\n",
      "Iteration 99, loss = 851677027.65475035\n",
      "Iteration 100, loss = 851213235.48476732\n",
      "Iteration 101, loss = 850743927.59403312\n",
      "Iteration 102, loss = 850283125.34962559\n",
      "Iteration 103, loss = 849816118.25167799\n",
      "Iteration 104, loss = 849343336.74873972\n",
      "Iteration 105, loss = 848876547.47889149\n",
      "Iteration 106, loss = 848402895.66920578\n",
      "Iteration 107, loss = 847941376.64242625\n",
      "Iteration 108, loss = 847477701.27260184\n",
      "Iteration 109, loss = 846997520.87492764\n",
      "Iteration 110, loss = 846541753.64315224\n",
      "Iteration 111, loss = 846069603.73378575\n",
      "Iteration 112, loss = 845595519.42111802\n",
      "Iteration 113, loss = 845109597.12782609\n",
      "Iteration 114, loss = 844636595.40550911\n",
      "Iteration 115, loss = 844189571.36159337\n",
      "Iteration 116, loss = 843700705.38853300\n",
      "Iteration 117, loss = 843212219.15268314\n",
      "Iteration 118, loss = 842739823.47458291\n",
      "Iteration 119, loss = 842268939.63486314\n",
      "Iteration 120, loss = 841797787.69240391\n",
      "Iteration 121, loss = 841321586.58863282\n",
      "Iteration 122, loss = 840862387.54419303\n",
      "Iteration 123, loss = 840363502.32139051\n",
      "Iteration 124, loss = 839899586.67719674\n",
      "Iteration 125, loss = 839413014.89978480\n",
      "Iteration 126, loss = 838940978.28640079\n",
      "Iteration 127, loss = 838458487.07547939\n",
      "Iteration 128, loss = 838006653.18285489\n",
      "Iteration 129, loss = 837528164.43425655\n",
      "Iteration 130, loss = 837032212.64903939\n",
      "Iteration 131, loss = 836566629.86042488\n",
      "Iteration 132, loss = 836077197.74107397\n",
      "Iteration 133, loss = 835599605.35893989\n",
      "Iteration 134, loss = 835116076.35704148\n",
      "Iteration 135, loss = 834646340.01975513\n",
      "Iteration 136, loss = 834144536.71881354\n",
      "Iteration 137, loss = 833675688.80962229\n",
      "Iteration 138, loss = 833198635.75501072\n",
      "Iteration 139, loss = 832728979.31952202\n",
      "Iteration 140, loss = 832251439.57184231\n",
      "Iteration 141, loss = 831777838.80489957\n",
      "Iteration 142, loss = 831296756.54018617\n",
      "Iteration 143, loss = 830827190.40253580\n",
      "Iteration 144, loss = 830373932.32445538\n",
      "Iteration 145, loss = 829844304.16335940\n",
      "Iteration 146, loss = 829372940.54548109\n",
      "Iteration 147, loss = 828877719.21182263\n",
      "Iteration 148, loss = 828405565.39291239\n",
      "Iteration 149, loss = 827905468.45565331\n",
      "Iteration 150, loss = 827439174.32894683\n",
      "Iteration 151, loss = 826943359.12964451\n",
      "Iteration 152, loss = 826483601.09181190\n",
      "Iteration 153, loss = 825971208.56723869\n",
      "Iteration 154, loss = 825482923.00857043\n",
      "Iteration 155, loss = 824995870.99238384\n",
      "Iteration 156, loss = 824501308.16886365\n",
      "Iteration 157, loss = 824024705.47733128\n",
      "Iteration 158, loss = 823550941.77538788\n",
      "Iteration 159, loss = 823038331.85174119\n",
      "Iteration 160, loss = 822577138.76845717\n",
      "Iteration 161, loss = 822065858.55078781\n",
      "Iteration 162, loss = 821585572.94606042\n",
      "Iteration 163, loss = 821142840.78731668\n",
      "Iteration 164, loss = 820632572.69162643\n",
      "Iteration 165, loss = 820134268.93623412\n",
      "Iteration 166, loss = 819650522.41357517\n",
      "Iteration 167, loss = 819160086.73041356\n",
      "Iteration 168, loss = 818671296.05863965\n",
      "Iteration 169, loss = 818171070.20336854\n",
      "Iteration 170, loss = 817677000.74199510\n",
      "Iteration 171, loss = 817185316.65203357\n",
      "Iteration 172, loss = 816678795.49108005\n",
      "Iteration 173, loss = 816193581.15444517\n",
      "Iteration 174, loss = 815686212.53180206\n",
      "Iteration 175, loss = 815187903.02367651\n",
      "Iteration 176, loss = 814686137.73781037\n",
      "Iteration 177, loss = 814189411.98068750\n",
      "Iteration 178, loss = 813670686.22277701\n",
      "Iteration 179, loss = 813173325.60362256\n",
      "Iteration 180, loss = 812660953.43071067\n",
      "Iteration 181, loss = 812157761.50069964\n",
      "Iteration 182, loss = 811647752.77362955\n",
      "Iteration 183, loss = 811128561.60986662\n",
      "Iteration 184, loss = 810627289.05315149\n",
      "Iteration 185, loss = 810128970.61082864\n",
      "Iteration 186, loss = 809610260.90874982\n",
      "Iteration 187, loss = 809081232.09041977\n",
      "Iteration 188, loss = 808587346.77174354\n",
      "Iteration 189, loss = 808050107.93608129\n",
      "Iteration 190, loss = 807540709.71070397\n",
      "Iteration 191, loss = 807057474.67720497\n",
      "Iteration 192, loss = 806507725.74363363\n",
      "Iteration 193, loss = 805998710.72623682\n",
      "Iteration 194, loss = 805470857.49320841\n",
      "Iteration 195, loss = 804935968.68120348\n",
      "Iteration 196, loss = 804419142.05088866\n",
      "Iteration 197, loss = 803917533.56440413\n",
      "Iteration 198, loss = 803379650.14933050\n",
      "Iteration 199, loss = 802854534.28745401\n",
      "Iteration 200, loss = 802323554.53789377\n",
      "Iteration 201, loss = 801793143.52753830\n",
      "Iteration 202, loss = 801274214.82906866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 203, loss = 800751677.39184952\n",
      "Iteration 204, loss = 800201366.59876013\n",
      "Iteration 205, loss = 799680177.63827300\n",
      "Iteration 206, loss = 799145085.58642471\n",
      "Iteration 207, loss = 798608493.18847597\n",
      "Iteration 208, loss = 798080078.55243170\n",
      "Iteration 209, loss = 797555510.71966028\n",
      "Iteration 210, loss = 797015435.69442201\n",
      "Iteration 211, loss = 796463629.79718566\n",
      "Iteration 212, loss = 795938016.15630925\n",
      "Iteration 213, loss = 795408552.72230172\n",
      "Iteration 214, loss = 794880177.06257284\n",
      "Iteration 215, loss = 794352465.15181875\n",
      "Iteration 216, loss = 793856289.29270494\n",
      "Iteration 217, loss = 793284725.75761020\n",
      "Iteration 218, loss = 792757399.51982486\n",
      "Iteration 219, loss = 792220397.11379647\n",
      "Iteration 220, loss = 791693527.19663680\n",
      "Iteration 221, loss = 791160982.38018894\n",
      "Iteration 222, loss = 790629903.39405334\n",
      "Iteration 223, loss = 790066956.92685068\n",
      "Iteration 224, loss = 789542271.14253128\n",
      "Iteration 225, loss = 788982898.38703406\n",
      "Iteration 226, loss = 788451202.15210390\n",
      "Iteration 227, loss = 787880371.80230951\n",
      "Iteration 228, loss = 787338251.13511848\n",
      "Iteration 229, loss = 786776609.53295898\n",
      "Iteration 230, loss = 786241893.73852181\n",
      "Iteration 231, loss = 785690308.46578383\n",
      "Iteration 232, loss = 785123278.70994258\n",
      "Iteration 233, loss = 784563390.76193404\n",
      "Iteration 234, loss = 783989836.00043011\n",
      "Iteration 235, loss = 783422613.54694355\n",
      "Iteration 236, loss = 782872271.78089058\n",
      "Iteration 237, loss = 782294353.20242691\n",
      "Iteration 238, loss = 781729270.44989717\n",
      "Iteration 239, loss = 781153200.54669237\n",
      "Iteration 240, loss = 780607191.30202723\n",
      "Iteration 241, loss = 780011494.53425467\n",
      "Iteration 242, loss = 779423557.59630013\n",
      "Iteration 243, loss = 778862301.16944969\n",
      "Iteration 244, loss = 778290342.20512116\n",
      "Iteration 245, loss = 777700210.47122455\n",
      "Iteration 246, loss = 777128449.84687471\n",
      "Iteration 247, loss = 776552986.13843930\n",
      "Iteration 248, loss = 775980762.44277894\n",
      "Iteration 249, loss = 775397258.09906769\n",
      "Iteration 250, loss = 774825117.14076638\n",
      "Iteration 251, loss = 774231045.96387625\n",
      "Iteration 252, loss = 773640215.94751251\n",
      "Iteration 253, loss = 773084771.12264717\n",
      "Iteration 254, loss = 772511407.72572041\n",
      "Iteration 255, loss = 771952636.10167778\n",
      "Iteration 256, loss = 771378474.13040745\n",
      "Iteration 257, loss = 770794532.67331553\n",
      "Iteration 258, loss = 770218371.99658120\n",
      "Iteration 259, loss = 769629893.02933729\n",
      "Iteration 260, loss = 769058816.72814417\n",
      "Iteration 261, loss = 768455064.55372548\n",
      "Iteration 262, loss = 767850130.87280452\n",
      "Iteration 263, loss = 767259473.04149413\n",
      "Iteration 264, loss = 766654217.98762167\n",
      "Iteration 265, loss = 766065846.94134164\n",
      "Iteration 266, loss = 765452757.35943353\n",
      "Iteration 267, loss = 764853469.98355675\n",
      "Iteration 268, loss = 764242073.79625320\n",
      "Iteration 269, loss = 763628363.36832047\n",
      "Iteration 270, loss = 763026063.05031109\n",
      "Iteration 271, loss = 762404873.50686300\n",
      "Iteration 272, loss = 761773126.99183619\n",
      "Iteration 273, loss = 761188122.09192562\n",
      "Iteration 274, loss = 760581348.73321211\n",
      "Iteration 275, loss = 759959931.96497726\n",
      "Iteration 276, loss = 759331116.53055120\n",
      "Iteration 277, loss = 758736215.73434651\n",
      "Iteration 278, loss = 758090074.16065323\n",
      "Iteration 279, loss = 757461605.88659286\n",
      "Iteration 280, loss = 756844584.05759037\n",
      "Iteration 281, loss = 756229582.00371277\n",
      "Iteration 282, loss = 755588811.15356827\n",
      "Iteration 283, loss = 754948278.19464421\n",
      "Iteration 284, loss = 754306842.04845417\n",
      "Iteration 285, loss = 753681323.35513163\n",
      "Iteration 286, loss = 753041212.16675639\n",
      "Iteration 287, loss = 752392261.25655210\n",
      "Iteration 288, loss = 751759985.08067501\n",
      "Iteration 289, loss = 751118001.70040917\n",
      "Iteration 290, loss = 750486481.51587141\n",
      "Iteration 291, loss = 749823288.15993297\n",
      "Iteration 292, loss = 749164300.54573977\n",
      "Iteration 293, loss = 748527738.25821519\n",
      "Iteration 294, loss = 747879412.09760046\n",
      "Iteration 295, loss = 747208686.45502162\n",
      "Iteration 296, loss = 746562584.59618652\n",
      "Iteration 297, loss = 745906527.16063726\n",
      "Iteration 298, loss = 745216917.52612567\n",
      "Iteration 299, loss = 744569970.47141123\n",
      "Iteration 300, loss = 743886007.51530874\n",
      "Iteration 301, loss = 743212473.02294028\n",
      "Iteration 302, loss = 742537664.54510903\n",
      "Iteration 303, loss = 741846185.83091486\n",
      "Iteration 304, loss = 741160561.69684422\n",
      "Iteration 305, loss = 740471181.40186894\n",
      "Iteration 306, loss = 739785209.70214927\n",
      "Iteration 307, loss = 739086714.52575994\n",
      "Iteration 308, loss = 738362592.80804229\n",
      "Iteration 309, loss = 737664190.16267955\n",
      "Iteration 310, loss = 736980559.47074032\n",
      "Iteration 311, loss = 736261563.92386782\n",
      "Iteration 312, loss = 735549312.17397022\n",
      "Iteration 313, loss = 734841543.50117862\n",
      "Iteration 314, loss = 734143012.89394951\n",
      "Iteration 315, loss = 733415974.71056986\n",
      "Iteration 316, loss = 732708181.71060598\n",
      "Iteration 317, loss = 731956419.33708489\n",
      "Iteration 318, loss = 731229405.01452768\n",
      "Iteration 319, loss = 730517143.89451480\n",
      "Iteration 320, loss = 729770258.70377326\n",
      "Iteration 321, loss = 729053783.52965200\n",
      "Iteration 322, loss = 728311632.01699114\n",
      "Iteration 323, loss = 727581009.24367607\n",
      "Iteration 324, loss = 726832249.77483034\n",
      "Iteration 325, loss = 726112337.50761771\n",
      "Iteration 326, loss = 725368970.10222924\n",
      "Iteration 327, loss = 724612244.48207581\n",
      "Iteration 328, loss = 723857379.35227406\n",
      "Iteration 329, loss = 723121365.53895926\n",
      "Iteration 330, loss = 722383839.45514214\n",
      "Iteration 331, loss = 721677592.22713947\n",
      "Iteration 332, loss = 720922665.26620317\n",
      "Iteration 333, loss = 720174993.91938984\n",
      "Iteration 334, loss = 719451350.60871959\n",
      "Iteration 335, loss = 718703485.89061940\n",
      "Iteration 336, loss = 717949368.06006634\n",
      "Iteration 337, loss = 717203606.65315592\n",
      "Iteration 338, loss = 716465526.81265211\n",
      "Iteration 339, loss = 715683603.69698024\n",
      "Iteration 340, loss = 714925347.32726634\n",
      "Iteration 341, loss = 714168654.61256969\n",
      "Iteration 342, loss = 713393324.55305731\n",
      "Iteration 343, loss = 712626173.46308815\n",
      "Iteration 344, loss = 711864107.53035927\n",
      "Iteration 345, loss = 711077868.02404964\n",
      "Iteration 346, loss = 710312088.70315099\n",
      "Iteration 347, loss = 709531543.53267920\n",
      "Iteration 348, loss = 708742602.32048154\n",
      "Iteration 349, loss = 707954483.58624411\n",
      "Iteration 350, loss = 707163636.14960420\n",
      "Iteration 351, loss = 706368494.50391448\n",
      "Iteration 352, loss = 705567364.69099462\n",
      "Iteration 353, loss = 704770244.30242920\n",
      "Iteration 354, loss = 703971356.57806098\n",
      "Iteration 355, loss = 703170567.98263991\n",
      "Iteration 356, loss = 702357988.79041088\n",
      "Iteration 357, loss = 701548594.00416386\n",
      "Iteration 358, loss = 700714332.87671423\n",
      "Iteration 359, loss = 699893325.60810006\n",
      "Iteration 360, loss = 699084609.98378956\n",
      "Iteration 361, loss = 698284735.50466204\n",
      "Iteration 362, loss = 697452093.68104279\n",
      "Iteration 363, loss = 696628010.33602238\n",
      "Iteration 364, loss = 695795781.71104264\n",
      "Iteration 365, loss = 694985458.30159080\n",
      "Iteration 366, loss = 694126179.43834436\n",
      "Iteration 367, loss = 693302968.68519282\n",
      "Iteration 368, loss = 692458161.62878156\n",
      "Iteration 369, loss = 691632466.78200233\n",
      "Iteration 370, loss = 690790841.74388587\n",
      "Iteration 371, loss = 689942121.13507140\n",
      "Iteration 372, loss = 689095457.90282929\n",
      "Iteration 373, loss = 688262309.09990525\n",
      "Iteration 374, loss = 687413828.35787308\n",
      "Iteration 375, loss = 686548744.16023934\n",
      "Iteration 376, loss = 685699814.96614921\n",
      "Iteration 377, loss = 684820242.86761689\n",
      "Iteration 378, loss = 683951302.97492468\n",
      "Iteration 379, loss = 683074633.61185229\n",
      "Iteration 380, loss = 682181153.28075540\n",
      "Iteration 381, loss = 681297457.27361441\n",
      "Iteration 382, loss = 680420744.61376131\n",
      "Iteration 383, loss = 679539454.74404120\n",
      "Iteration 384, loss = 678669637.70671010\n",
      "Iteration 385, loss = 677750287.43286514\n",
      "Iteration 386, loss = 676874852.53175247\n",
      "Iteration 387, loss = 675971929.85325360\n",
      "Iteration 388, loss = 675085129.11530483\n",
      "Iteration 389, loss = 674211434.20706820\n",
      "Iteration 390, loss = 673318478.75936425\n",
      "Iteration 391, loss = 672413185.28948486\n",
      "Iteration 392, loss = 671526985.25892043\n",
      "Iteration 393, loss = 670634398.96842194\n",
      "Iteration 394, loss = 669778098.71598208\n",
      "Iteration 395, loss = 668827643.39412844\n",
      "Iteration 396, loss = 667928495.49407756\n",
      "Iteration 397, loss = 667008473.51901770\n",
      "Iteration 398, loss = 666113291.60526681\n",
      "Iteration 399, loss = 665202230.25082064\n",
      "Iteration 400, loss = 664288976.24255514\n",
      "Iteration 401, loss = 663385758.19398236\n",
      "Iteration 402, loss = 662479753.14852524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 403, loss = 661596842.08166277\n",
      "Iteration 404, loss = 660660700.21654153\n",
      "Iteration 405, loss = 659725794.59909213\n",
      "Iteration 406, loss = 658789086.91463888\n",
      "Iteration 407, loss = 657859492.91035748\n",
      "Iteration 408, loss = 656921834.43652344\n",
      "Iteration 409, loss = 655990790.79862535\n",
      "Iteration 410, loss = 655071034.13675010\n",
      "Iteration 411, loss = 654111105.47958994\n",
      "Iteration 412, loss = 653162927.73335421\n",
      "Iteration 413, loss = 652242708.11842525\n",
      "Iteration 414, loss = 651291792.08331251\n",
      "Iteration 415, loss = 650359879.02607751\n",
      "Iteration 416, loss = 649417801.62491965\n",
      "Iteration 417, loss = 648447815.01327753\n",
      "Iteration 418, loss = 647509203.16642475\n",
      "Iteration 419, loss = 646536891.40833104\n",
      "Iteration 420, loss = 645592486.95112669\n",
      "Iteration 421, loss = 644612459.81293893\n",
      "Iteration 422, loss = 643685636.58256376\n",
      "Iteration 423, loss = 642718940.78807640\n",
      "Iteration 424, loss = 641732137.35581756\n",
      "Iteration 425, loss = 640773113.29809046\n",
      "Iteration 426, loss = 639800297.81188178\n",
      "Iteration 427, loss = 638819745.77342451\n",
      "Iteration 428, loss = 637829843.50679135\n",
      "Iteration 429, loss = 636841068.68997478\n",
      "Iteration 430, loss = 635867423.19070578\n",
      "Iteration 431, loss = 634886217.21037614\n",
      "Iteration 432, loss = 633895847.16319311\n",
      "Iteration 433, loss = 632933029.96829796\n",
      "Iteration 434, loss = 631944841.00046253\n",
      "Iteration 435, loss = 630957961.90974772\n",
      "Iteration 436, loss = 629982453.91126466\n",
      "Iteration 437, loss = 628979450.08786821\n",
      "Iteration 438, loss = 627958900.83795655\n",
      "Iteration 439, loss = 626968314.83305347\n",
      "Iteration 440, loss = 625982753.31957245\n",
      "Iteration 441, loss = 624987203.72362268\n",
      "Iteration 442, loss = 623996326.07088161\n",
      "Iteration 443, loss = 623007593.43200207\n",
      "Iteration 444, loss = 621990334.15561199\n",
      "Iteration 445, loss = 621005585.25362396\n",
      "Iteration 446, loss = 620005236.22669268\n",
      "Iteration 447, loss = 618982729.25034630\n",
      "Iteration 448, loss = 617987224.35740161\n",
      "Iteration 449, loss = 616988305.14545047\n",
      "Iteration 450, loss = 615994247.31195927\n",
      "Iteration 451, loss = 614972593.67274177\n",
      "Iteration 452, loss = 613962858.30113435\n",
      "Iteration 453, loss = 612999970.46332920\n",
      "Iteration 454, loss = 612009966.06037951\n",
      "Iteration 455, loss = 610987763.95411050\n",
      "Iteration 456, loss = 609968374.74012566\n",
      "Iteration 457, loss = 608971326.36833680\n",
      "Iteration 458, loss = 607979273.76472723\n",
      "Iteration 459, loss = 606990539.25801623\n",
      "Iteration 460, loss = 605953241.84820497\n",
      "Iteration 461, loss = 604952045.92242932\n",
      "Iteration 462, loss = 603967535.10793555\n",
      "Iteration 463, loss = 602936061.98114073\n",
      "Iteration 464, loss = 601932982.59320211\n",
      "Iteration 465, loss = 600910577.55556035\n",
      "Iteration 466, loss = 599927559.60499883\n",
      "Iteration 467, loss = 598905296.59847093\n",
      "Iteration 468, loss = 597902867.12366080\n",
      "Iteration 469, loss = 596884167.81325054\n",
      "Iteration 470, loss = 595856370.48416233\n",
      "Iteration 471, loss = 594819933.60987496\n",
      "Iteration 472, loss = 593838656.38889921\n",
      "Iteration 473, loss = 592823254.24886620\n",
      "Iteration 474, loss = 591791651.07619441\n",
      "Iteration 475, loss = 590792508.57143998\n",
      "Iteration 476, loss = 589811641.67702699\n",
      "Iteration 477, loss = 588761296.66436923\n",
      "Iteration 478, loss = 587746326.87623894\n",
      "Iteration 479, loss = 586742611.23666131\n",
      "Iteration 480, loss = 585737048.92530906\n",
      "Iteration 481, loss = 584708365.77803719\n",
      "Iteration 482, loss = 583685280.26221228\n",
      "Iteration 483, loss = 582664103.90038776\n",
      "Iteration 484, loss = 581656451.65615344\n",
      "Iteration 485, loss = 580649741.78985679\n",
      "Iteration 486, loss = 579632383.11021245\n",
      "Iteration 487, loss = 578586999.13356924\n",
      "Iteration 488, loss = 577568443.62351966\n",
      "Iteration 489, loss = 576562230.02345037\n",
      "Iteration 490, loss = 575543929.95220506\n",
      "Iteration 491, loss = 574535898.20948279\n",
      "Iteration 492, loss = 573531741.04640543\n",
      "Iteration 493, loss = 572495070.89786065\n",
      "Iteration 494, loss = 571497279.74317312\n",
      "Iteration 495, loss = 570484114.67142475\n",
      "Iteration 496, loss = 569469997.20993829\n",
      "Iteration 497, loss = 568452514.28934383\n",
      "Iteration 498, loss = 567454278.80182874\n",
      "Iteration 499, loss = 566464835.03235424\n",
      "Iteration 500, loss = 565460727.97853220\n",
      "Iteration 501, loss = 564483773.84260237\n",
      "Iteration 502, loss = 563482823.09866917\n",
      "Iteration 503, loss = 562493092.23805225\n",
      "Iteration 504, loss = 561484498.79516864\n",
      "Iteration 505, loss = 560472306.45357013\n",
      "Iteration 506, loss = 559490720.87175417\n",
      "Iteration 507, loss = 558528608.63846874\n",
      "Iteration 508, loss = 557522513.31306696\n",
      "Iteration 509, loss = 556529108.65568101\n",
      "Iteration 510, loss = 555556154.90574229\n",
      "Iteration 511, loss = 554563465.23772156\n",
      "Iteration 512, loss = 553588801.10658324\n",
      "Iteration 513, loss = 552570970.75625217\n",
      "Iteration 514, loss = 551584494.01578379\n",
      "Iteration 515, loss = 550590982.71813071\n",
      "Iteration 516, loss = 549601396.32293975\n",
      "Iteration 517, loss = 548627180.25208032\n",
      "Iteration 518, loss = 547644024.66528320\n",
      "Iteration 519, loss = 546647292.58436894\n",
      "Iteration 520, loss = 545676478.56082773\n",
      "Iteration 521, loss = 544703083.26525235\n",
      "Iteration 522, loss = 543723793.38047409\n",
      "Iteration 523, loss = 542741843.65837014\n",
      "Iteration 524, loss = 541773029.36984563\n",
      "Iteration 525, loss = 540785033.31727123\n",
      "Iteration 526, loss = 539818368.83457863\n",
      "Iteration 527, loss = 538844606.67566180\n",
      "Iteration 528, loss = 537898779.93312204\n",
      "Iteration 529, loss = 536912608.57900202\n",
      "Iteration 530, loss = 535951968.89624399\n",
      "Iteration 531, loss = 534969053.72596562\n",
      "Iteration 532, loss = 534015263.92030364\n",
      "Iteration 533, loss = 533014934.07126069\n",
      "Iteration 534, loss = 532082354.25668329\n",
      "Iteration 535, loss = 531124440.40515435\n",
      "Iteration 536, loss = 530177583.07919461\n",
      "Iteration 537, loss = 529265562.13845694\n",
      "Iteration 538, loss = 528320452.67907852\n",
      "Iteration 539, loss = 527395918.11119777\n",
      "Iteration 540, loss = 526481995.84630239\n",
      "Iteration 541, loss = 525567692.31700182\n",
      "Iteration 542, loss = 524650213.11176640\n",
      "Iteration 543, loss = 523735090.60957491\n",
      "Iteration 544, loss = 522835020.50365669\n",
      "Iteration 545, loss = 521899743.64683086\n",
      "Iteration 546, loss = 520984737.61232150\n",
      "Iteration 547, loss = 520053138.16548949\n",
      "Iteration 548, loss = 519130583.66897768\n",
      "Iteration 549, loss = 518216516.32775402\n",
      "Iteration 550, loss = 517330353.45921510\n",
      "Iteration 551, loss = 516397363.09964854\n",
      "Iteration 552, loss = 515489828.98731315\n",
      "Iteration 553, loss = 514588092.88560325\n",
      "Iteration 554, loss = 513675078.72056836\n",
      "Iteration 555, loss = 512762352.62491214\n",
      "Iteration 556, loss = 511828833.58868587\n",
      "Iteration 557, loss = 510913391.44773006\n",
      "Iteration 558, loss = 509990850.94012713\n",
      "Iteration 559, loss = 509064352.10367846\n",
      "Iteration 560, loss = 508151160.46244049\n",
      "Iteration 561, loss = 507217427.03015202\n",
      "Iteration 562, loss = 506272026.42559969\n",
      "Iteration 563, loss = 505359887.07030183\n",
      "Iteration 564, loss = 504447362.79072827\n",
      "Iteration 565, loss = 503511335.89373857\n",
      "Iteration 566, loss = 502601843.68662643\n",
      "Iteration 567, loss = 501667351.09763455\n",
      "Iteration 568, loss = 500762310.99022317\n",
      "Iteration 569, loss = 499837121.75108743\n",
      "Iteration 570, loss = 498922701.13833129\n",
      "Iteration 571, loss = 498009556.94875753\n",
      "Iteration 572, loss = 497106280.50717270\n",
      "Iteration 573, loss = 496191978.25318003\n",
      "Iteration 574, loss = 495316628.41541147\n",
      "Iteration 575, loss = 494429650.30028105\n",
      "Iteration 576, loss = 493579122.20604223\n",
      "Iteration 577, loss = 492656237.27181756\n",
      "Iteration 578, loss = 491783151.63355851\n",
      "Iteration 579, loss = 490892944.15499526\n",
      "Iteration 580, loss = 490017888.31062162\n",
      "Iteration 581, loss = 489119557.52896643\n",
      "Iteration 582, loss = 488256783.58142620\n",
      "Iteration 583, loss = 487377633.48427522\n",
      "Iteration 584, loss = 486476820.87975430\n",
      "Iteration 585, loss = 485587166.69790131\n",
      "Iteration 586, loss = 484671982.09281939\n",
      "Iteration 587, loss = 483798880.91928881\n",
      "Iteration 588, loss = 482918464.69510978\n",
      "Iteration 589, loss = 482064911.95041311\n",
      "Iteration 590, loss = 481153110.25731879\n",
      "Iteration 591, loss = 480304411.29578167\n",
      "Iteration 592, loss = 479435533.44245690\n",
      "Iteration 593, loss = 478556027.36752570\n",
      "Iteration 594, loss = 477680556.40054893\n",
      "Iteration 595, loss = 476818521.25232047\n",
      "Iteration 596, loss = 475973636.13487667\n",
      "Iteration 597, loss = 475092750.68540812\n",
      "Iteration 598, loss = 474232354.22260809\n",
      "Iteration 599, loss = 473357654.48021668\n",
      "Iteration 600, loss = 472521629.77223897\n",
      "Iteration 601, loss = 471664784.11614388\n",
      "Iteration 602, loss = 470786985.22614157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 603, loss = 469959112.93413132\n",
      "Iteration 604, loss = 469055782.62710238\n",
      "Iteration 605, loss = 468205570.76024890\n",
      "Iteration 606, loss = 467349103.24167615\n",
      "Iteration 607, loss = 466506121.40951252\n",
      "Iteration 608, loss = 465632267.08590835\n",
      "Iteration 609, loss = 464772399.21043468\n",
      "Iteration 610, loss = 463952266.64225930\n",
      "Iteration 611, loss = 463130756.28432691\n",
      "Iteration 612, loss = 462236286.78119385\n",
      "Iteration 613, loss = 461431434.28341562\n",
      "Iteration 614, loss = 460593264.02619499\n",
      "Iteration 615, loss = 459731071.63014150\n",
      "Iteration 616, loss = 458921322.73137474\n",
      "Iteration 617, loss = 458050968.48349679\n",
      "Iteration 618, loss = 457203013.88715458\n",
      "Iteration 619, loss = 456383268.52280766\n",
      "Iteration 620, loss = 455573611.39383507\n",
      "Iteration 621, loss = 454725726.67742479\n",
      "Iteration 622, loss = 453881737.69871962\n",
      "Iteration 623, loss = 453062943.18926185\n",
      "Iteration 624, loss = 452242785.59381300\n",
      "Iteration 625, loss = 451417803.48461914\n",
      "Iteration 626, loss = 450580122.97314423\n",
      "Iteration 627, loss = 449749198.42758024\n",
      "Iteration 628, loss = 448946029.08576101\n",
      "Iteration 629, loss = 448138952.92636240\n",
      "Iteration 630, loss = 447285994.44222581\n",
      "Iteration 631, loss = 446450916.50298887\n",
      "Iteration 632, loss = 445639200.77695221\n",
      "Iteration 633, loss = 444823163.38480836\n",
      "Iteration 634, loss = 443993072.46418667\n",
      "Iteration 635, loss = 443162415.21395189\n",
      "Iteration 636, loss = 442339671.86377895\n",
      "Iteration 637, loss = 441527092.70156598\n",
      "Iteration 638, loss = 440737459.73321146\n",
      "Iteration 639, loss = 439904223.32138878\n",
      "Iteration 640, loss = 439093324.84827083\n",
      "Iteration 641, loss = 438291020.45242751\n",
      "Iteration 642, loss = 437503282.17959601\n",
      "Iteration 643, loss = 436698056.70162928\n",
      "Iteration 644, loss = 435906602.41224247\n",
      "Iteration 645, loss = 435114055.01252472\n",
      "Iteration 646, loss = 434296259.91556829\n",
      "Iteration 647, loss = 433491459.83493268\n",
      "Iteration 648, loss = 432682287.80430871\n",
      "Iteration 649, loss = 431895488.56828463\n",
      "Iteration 650, loss = 431095266.42573345\n",
      "Iteration 651, loss = 430273799.75389010\n",
      "Iteration 652, loss = 429490027.21962786\n",
      "Iteration 653, loss = 428689059.02240169\n",
      "Iteration 654, loss = 427899771.79306418\n",
      "Iteration 655, loss = 427105705.69012707\n",
      "Iteration 656, loss = 426330613.99253732\n",
      "Iteration 657, loss = 425520110.13116568\n",
      "Iteration 658, loss = 424734941.30241901\n",
      "Iteration 659, loss = 423972145.30581993\n",
      "Iteration 660, loss = 423205370.18302351\n",
      "Iteration 661, loss = 422401897.13723576\n",
      "Iteration 662, loss = 421614000.91950566\n",
      "Iteration 663, loss = 420860049.09708261\n",
      "Iteration 664, loss = 420081931.48979926\n",
      "Iteration 665, loss = 419297356.13973063\n",
      "Iteration 666, loss = 418534214.09368420\n",
      "Iteration 667, loss = 417776100.86503345\n",
      "Iteration 668, loss = 416974951.21389925\n",
      "Iteration 669, loss = 416217555.35216999\n",
      "Iteration 670, loss = 415437586.11468571\n",
      "Iteration 671, loss = 414663966.05852199\n",
      "Iteration 672, loss = 413893528.39472431\n",
      "Iteration 673, loss = 413129469.22161430\n",
      "Iteration 674, loss = 412352236.90660685\n",
      "Iteration 675, loss = 411608200.17455924\n",
      "Iteration 676, loss = 410853514.59910512\n",
      "Iteration 677, loss = 410098921.43107277\n",
      "Iteration 678, loss = 409356288.93982428\n",
      "Iteration 679, loss = 408585663.93754780\n",
      "Iteration 680, loss = 407869075.82140839\n",
      "Iteration 681, loss = 407098036.71125436\n",
      "Iteration 682, loss = 406308592.26263213\n",
      "Iteration 683, loss = 405532407.31587762\n",
      "Iteration 684, loss = 404822994.19694096\n",
      "Iteration 685, loss = 404015908.41291648\n",
      "Iteration 686, loss = 403268711.62080514\n",
      "Iteration 687, loss = 402508763.19759047\n",
      "Iteration 688, loss = 401760161.09765184\n",
      "Iteration 689, loss = 401013188.80577511\n",
      "Iteration 690, loss = 400267580.47978193\n",
      "Iteration 691, loss = 399508875.89365810\n",
      "Iteration 692, loss = 398764677.02766490\n",
      "Iteration 693, loss = 398009706.46183747\n",
      "Iteration 694, loss = 397260346.87732846\n",
      "Iteration 695, loss = 396534215.55775940\n",
      "Iteration 696, loss = 395740999.83026433\n",
      "Iteration 697, loss = 394991651.42254263\n",
      "Iteration 698, loss = 394243766.87343240\n",
      "Iteration 699, loss = 393487918.18410385\n",
      "Iteration 700, loss = 392746420.52757722\n",
      "Iteration 701, loss = 391997565.68636358\n",
      "Iteration 702, loss = 391273371.29792559\n",
      "Iteration 703, loss = 390517630.90586287\n",
      "Iteration 704, loss = 389745622.26896775\n",
      "Iteration 705, loss = 389003668.54269940\n",
      "Iteration 706, loss = 388261500.09327471\n",
      "Iteration 707, loss = 387530335.04301196\n",
      "Iteration 708, loss = 386768787.56512141\n",
      "Iteration 709, loss = 386039112.44689965\n",
      "Iteration 710, loss = 385272565.12680066\n",
      "Iteration 711, loss = 384528248.60449886\n",
      "Iteration 712, loss = 383819818.00763893\n",
      "Iteration 713, loss = 383092959.92637080\n",
      "Iteration 714, loss = 382324747.09067714\n",
      "Iteration 715, loss = 381616497.41032350\n",
      "Iteration 716, loss = 380895500.47441399\n",
      "Iteration 717, loss = 380133974.16598469\n",
      "Iteration 718, loss = 379392367.53210860\n",
      "Iteration 719, loss = 378666080.51234478\n",
      "Iteration 720, loss = 377931558.23482305\n",
      "Iteration 721, loss = 377198159.05086303\n",
      "Iteration 722, loss = 376448734.36915874\n",
      "Iteration 723, loss = 375713330.78960389\n",
      "Iteration 724, loss = 375022281.97687727\n",
      "Iteration 725, loss = 374264116.30301332\n",
      "Iteration 726, loss = 373557364.34413743\n",
      "Iteration 727, loss = 372844542.66211772\n",
      "Iteration 728, loss = 372139788.76966894\n",
      "Iteration 729, loss = 371390283.53030235\n",
      "Iteration 730, loss = 370699483.62602746\n",
      "Iteration 731, loss = 369962583.41477174\n",
      "Iteration 732, loss = 369275398.15359420\n",
      "Iteration 733, loss = 368558208.70799333\n",
      "Iteration 734, loss = 367821262.56978887\n",
      "Iteration 735, loss = 367123032.98189813\n",
      "Iteration 736, loss = 366424380.30531794\n",
      "Iteration 737, loss = 365719110.77865702\n",
      "Iteration 738, loss = 365019888.18981957\n",
      "Iteration 739, loss = 364305526.26301384\n",
      "Iteration 740, loss = 363635390.63563919\n",
      "Iteration 741, loss = 362893880.84964693\n",
      "Iteration 742, loss = 362189362.12729716\n",
      "Iteration 743, loss = 361509867.00090510\n",
      "Iteration 744, loss = 360785505.54708183\n",
      "Iteration 745, loss = 360055137.40329325\n",
      "Iteration 746, loss = 359368841.92172831\n",
      "Iteration 747, loss = 358658566.40054154\n",
      "Iteration 748, loss = 357949820.20400625\n",
      "Iteration 749, loss = 357217559.90311444\n",
      "Iteration 750, loss = 356527625.46641028\n",
      "Iteration 751, loss = 355805848.42727298\n",
      "Iteration 752, loss = 355104876.37546515\n",
      "Iteration 753, loss = 354399114.49172866\n",
      "Iteration 754, loss = 353673589.14080304\n",
      "Iteration 755, loss = 352995351.50611299\n",
      "Iteration 756, loss = 352253461.85332340\n",
      "Iteration 757, loss = 351570490.04255450\n",
      "Iteration 758, loss = 350856034.13470590\n",
      "Iteration 759, loss = 350136791.32047737\n",
      "Iteration 760, loss = 349439588.99834734\n",
      "Iteration 761, loss = 348740716.27339423\n",
      "Iteration 762, loss = 348036498.33921623\n",
      "Iteration 763, loss = 347329151.02149540\n",
      "Iteration 764, loss = 346632435.87589830\n",
      "Iteration 765, loss = 345926138.14042968\n",
      "Iteration 766, loss = 345228113.46111703\n",
      "Iteration 767, loss = 344523986.92294431\n",
      "Iteration 768, loss = 343847329.67287344\n",
      "Iteration 769, loss = 343141478.14732724\n",
      "Iteration 770, loss = 342452311.83457321\n",
      "Iteration 771, loss = 341717590.65090305\n",
      "Iteration 772, loss = 341048058.57513767\n",
      "Iteration 773, loss = 340340780.78224468\n",
      "Iteration 774, loss = 339627897.88532978\n",
      "Iteration 775, loss = 338970948.12743562\n",
      "Iteration 776, loss = 338244328.42024547\n",
      "Iteration 777, loss = 337540114.19587326\n",
      "Iteration 778, loss = 336850820.92419058\n",
      "Iteration 779, loss = 336160694.34788078\n",
      "Iteration 780, loss = 335453849.33485824\n",
      "Iteration 781, loss = 334774193.53067786\n",
      "Iteration 782, loss = 334043952.34100235\n",
      "Iteration 783, loss = 333354239.64735788\n",
      "Iteration 784, loss = 332657077.10111779\n",
      "Iteration 785, loss = 331962893.05666566\n",
      "Iteration 786, loss = 331255193.79827160\n",
      "Iteration 787, loss = 330600634.83051163\n",
      "Iteration 788, loss = 329891113.36345232\n",
      "Iteration 789, loss = 329185185.77895671\n",
      "Iteration 790, loss = 328488501.22484320\n",
      "Iteration 791, loss = 327764056.63925546\n",
      "Iteration 792, loss = 327050557.49287486\n",
      "Iteration 793, loss = 326363621.00942349\n",
      "Iteration 794, loss = 325630808.56864375\n",
      "Iteration 795, loss = 324859219.28811783\n",
      "Iteration 796, loss = 324174535.60280228\n",
      "Iteration 797, loss = 323422926.27131313\n",
      "Iteration 798, loss = 322686817.94589913\n",
      "Iteration 799, loss = 321976489.61084735\n",
      "Iteration 800, loss = 321210642.82250148\n",
      "Iteration 801, loss = 320501949.27486360\n",
      "Iteration 802, loss = 319804978.49343699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 803, loss = 318987214.87603295\n",
      "Iteration 804, loss = 318209570.78884667\n",
      "Iteration 805, loss = 317449815.89186335\n",
      "Iteration 806, loss = 316652674.48017871\n",
      "Iteration 807, loss = 315873393.19861186\n",
      "Iteration 808, loss = 315062494.18211675\n",
      "Iteration 809, loss = 314263160.75792259\n",
      "Iteration 810, loss = 313418830.12045705\n",
      "Iteration 811, loss = 312643884.49092215\n",
      "Iteration 812, loss = 311791793.31265056\n",
      "Iteration 813, loss = 310982037.16400421\n",
      "Iteration 814, loss = 310172604.26903909\n",
      "Iteration 815, loss = 309352019.28934920\n",
      "Iteration 816, loss = 308522053.93439436\n",
      "Iteration 817, loss = 307620187.91466951\n",
      "Iteration 818, loss = 306729485.82355624\n",
      "Iteration 819, loss = 305851811.24127358\n",
      "Iteration 820, loss = 305051803.27636045\n",
      "Iteration 821, loss = 304218097.85065639\n",
      "Iteration 822, loss = 303471384.93979234\n",
      "Iteration 823, loss = 302647439.71018261\n",
      "Iteration 824, loss = 301926989.44014859\n",
      "Iteration 825, loss = 301137536.44866312\n",
      "Iteration 826, loss = 300393475.80119723\n",
      "Iteration 827, loss = 299681413.70141059\n",
      "Iteration 828, loss = 298960214.43169934\n",
      "Iteration 829, loss = 298245660.09088939\n",
      "Iteration 830, loss = 297516862.38965052\n",
      "Iteration 831, loss = 296830314.69100022\n",
      "Iteration 832, loss = 296134759.23486674\n",
      "Iteration 833, loss = 295396399.48859769\n",
      "Iteration 834, loss = 294710934.21127629\n",
      "Iteration 835, loss = 293998208.24610150\n",
      "Iteration 836, loss = 293333514.91499162\n",
      "Iteration 837, loss = 292622768.10693210\n",
      "Iteration 838, loss = 291916690.20829588\n",
      "Iteration 839, loss = 291210903.98368114\n",
      "Iteration 840, loss = 290526659.12848371\n",
      "Iteration 841, loss = 289837504.13859814\n",
      "Iteration 842, loss = 289147086.27105856\n",
      "Iteration 843, loss = 288423296.16131026\n",
      "Iteration 844, loss = 287729266.57351285\n",
      "Iteration 845, loss = 287045928.53234214\n",
      "Iteration 846, loss = 286362411.98442286\n",
      "Iteration 847, loss = 285669867.00210989\n",
      "Iteration 848, loss = 284976530.77414191\n",
      "Iteration 849, loss = 284280379.49508262\n",
      "Iteration 850, loss = 283605763.41478080\n",
      "Iteration 851, loss = 282930497.71618271\n",
      "Iteration 852, loss = 282236826.85576576\n",
      "Iteration 853, loss = 281565763.43877381\n",
      "Iteration 854, loss = 280868925.42293870\n",
      "Iteration 855, loss = 280181829.79838628\n",
      "Iteration 856, loss = 279472692.94848728\n",
      "Iteration 857, loss = 278801849.98019272\n",
      "Iteration 858, loss = 278096440.70435548\n",
      "Iteration 859, loss = 277375807.57521361\n",
      "Iteration 860, loss = 276697748.88967997\n",
      "Iteration 861, loss = 275967670.84795171\n",
      "Iteration 862, loss = 275289433.36644059\n",
      "Iteration 863, loss = 274576936.94114822\n",
      "Iteration 864, loss = 273914898.02224177\n",
      "Iteration 865, loss = 273192098.72213155\n",
      "Iteration 866, loss = 272473196.19179529\n",
      "Iteration 867, loss = 271778002.99894738\n",
      "Iteration 868, loss = 271081326.66998160\n",
      "Iteration 869, loss = 270317814.71330398\n",
      "Iteration 870, loss = 269590993.97144616\n",
      "Iteration 871, loss = 268864052.45647466\n",
      "Iteration 872, loss = 268134084.79940665\n",
      "Iteration 873, loss = 267459966.56298903\n",
      "Iteration 874, loss = 266696393.48025173\n",
      "Iteration 875, loss = 265963245.98163006\n",
      "Iteration 876, loss = 265236279.50388268\n",
      "Iteration 877, loss = 264486662.78085893\n",
      "Iteration 878, loss = 263750623.17299217\n",
      "Iteration 879, loss = 263030188.30570441\n",
      "Iteration 880, loss = 262316945.68103087\n",
      "Iteration 881, loss = 261565217.27580723\n",
      "Iteration 882, loss = 260870337.62483445\n",
      "Iteration 883, loss = 260180223.25322095\n",
      "Iteration 884, loss = 259418479.28796226\n",
      "Iteration 885, loss = 258711143.68721932\n",
      "Iteration 886, loss = 257941222.56108490\n",
      "Iteration 887, loss = 257187016.91123170\n",
      "Iteration 888, loss = 256433969.71790636\n",
      "Iteration 889, loss = 255740846.11617830\n",
      "Iteration 890, loss = 255025755.96884811\n",
      "Iteration 891, loss = 254321931.86077929\n",
      "Iteration 892, loss = 253645881.99481899\n",
      "Iteration 893, loss = 252957105.92404991\n",
      "Iteration 894, loss = 252281526.91456336\n",
      "Iteration 895, loss = 251622196.72116473\n",
      "Iteration 896, loss = 251022344.08989272\n",
      "Iteration 897, loss = 250349414.99568671\n",
      "Iteration 898, loss = 249732356.05709231\n",
      "Iteration 899, loss = 249080209.78262624\n",
      "Iteration 900, loss = 248454415.83227170\n",
      "Iteration 901, loss = 247855073.10254353\n",
      "Iteration 902, loss = 247215256.86564314\n",
      "Iteration 903, loss = 246623897.23672113\n",
      "Iteration 904, loss = 245976559.52037460\n",
      "Iteration 905, loss = 245371297.87324676\n",
      "Iteration 906, loss = 244765329.23861200\n",
      "Iteration 907, loss = 244159531.61021328\n",
      "Iteration 908, loss = 243557160.23067835\n",
      "Iteration 909, loss = 242935707.47906590\n",
      "Iteration 910, loss = 242334290.74816275\n",
      "Iteration 911, loss = 241716269.03646517\n",
      "Iteration 912, loss = 241112811.59015819\n",
      "Iteration 913, loss = 240505313.13130149\n",
      "Iteration 914, loss = 239896994.28253937\n",
      "Iteration 915, loss = 239284855.70857114\n",
      "Iteration 916, loss = 238691145.33381322\n",
      "Iteration 917, loss = 238126705.61580855\n",
      "Iteration 918, loss = 237501850.39973140\n",
      "Iteration 919, loss = 236893984.04761213\n",
      "Iteration 920, loss = 236319111.19898939\n",
      "Iteration 921, loss = 235705721.10604176\n",
      "Iteration 922, loss = 235113304.67676640\n",
      "Iteration 923, loss = 234521780.11302513\n",
      "Iteration 924, loss = 233917287.90810156\n",
      "Iteration 925, loss = 233326069.18488431\n",
      "Iteration 926, loss = 232759258.96650675\n",
      "Iteration 927, loss = 232169206.91192314\n",
      "Iteration 928, loss = 231570009.26405263\n",
      "Iteration 929, loss = 230996321.17601219\n",
      "Iteration 930, loss = 230386156.46532497\n",
      "Iteration 931, loss = 229812633.31330770\n",
      "Iteration 932, loss = 229235824.42825389\n",
      "Iteration 933, loss = 228667418.39853773\n",
      "Iteration 934, loss = 228071707.51344144\n",
      "Iteration 935, loss = 227475110.71863657\n",
      "Iteration 936, loss = 226899708.42019767\n",
      "Iteration 937, loss = 226346771.65404448\n",
      "Iteration 938, loss = 225732738.01868480\n",
      "Iteration 939, loss = 225188440.76979586\n",
      "Iteration 940, loss = 224601627.27098474\n",
      "Iteration 941, loss = 224020875.85653400\n",
      "Iteration 942, loss = 223461046.23195747\n",
      "Iteration 943, loss = 222891067.11428317\n",
      "Iteration 944, loss = 222319812.66124439\n",
      "Iteration 945, loss = 221754234.91763741\n",
      "Iteration 946, loss = 221199348.78007618\n",
      "Iteration 947, loss = 220619721.73216462\n",
      "Iteration 948, loss = 220053351.98856363\n",
      "Iteration 949, loss = 219486108.71668112\n",
      "Iteration 950, loss = 218935402.53922123\n",
      "Iteration 951, loss = 218382937.77691075\n",
      "Iteration 952, loss = 217811349.90914872\n",
      "Iteration 953, loss = 217268846.92908892\n",
      "Iteration 954, loss = 216730344.84558746\n",
      "Iteration 955, loss = 216168862.40585747\n",
      "Iteration 956, loss = 215622608.82087037\n",
      "Iteration 957, loss = 215079643.04194638\n",
      "Iteration 958, loss = 214502283.58333203\n",
      "Iteration 959, loss = 214007520.84255999\n",
      "Iteration 960, loss = 213423355.22344807\n",
      "Iteration 961, loss = 212901968.50748169\n",
      "Iteration 962, loss = 212358867.77860856\n",
      "Iteration 963, loss = 211828979.14600584\n",
      "Iteration 964, loss = 211272403.36726108\n",
      "Iteration 965, loss = 210736198.16822201\n",
      "Iteration 966, loss = 210202050.24035498\n",
      "Iteration 967, loss = 209726072.95118529\n",
      "Iteration 968, loss = 209171939.52489036\n",
      "Iteration 969, loss = 208647565.67488790\n",
      "Iteration 970, loss = 208132810.16779393\n",
      "Iteration 971, loss = 207593852.17090869\n",
      "Iteration 972, loss = 207094123.78117537\n",
      "Iteration 973, loss = 206591402.21647924\n",
      "Iteration 974, loss = 206070367.91023812\n",
      "Iteration 975, loss = 205543564.73963448\n",
      "Iteration 976, loss = 205059416.00418675\n",
      "Iteration 977, loss = 204536303.57637334\n",
      "Iteration 978, loss = 204046769.83063322\n",
      "Iteration 979, loss = 203538015.29346970\n",
      "Iteration 980, loss = 203056413.45096108\n",
      "Iteration 981, loss = 202555365.78426638\n",
      "Iteration 982, loss = 202041602.61699533\n",
      "Iteration 983, loss = 201539152.62185961\n",
      "Iteration 984, loss = 201058129.39546487\n",
      "Iteration 985, loss = 200545350.93501234\n",
      "Iteration 986, loss = 200074887.46202651\n",
      "Iteration 987, loss = 199570753.91288674\n",
      "Iteration 988, loss = 199108705.01604378\n",
      "Iteration 989, loss = 198594825.33089653\n",
      "Iteration 990, loss = 198092317.17795506\n",
      "Iteration 991, loss = 197604118.67900911\n",
      "Iteration 992, loss = 197128334.38415590\n",
      "Iteration 993, loss = 196632065.67263985\n",
      "Iteration 994, loss = 196151315.13542143\n",
      "Iteration 995, loss = 195685098.83412543\n",
      "Iteration 996, loss = 195184916.83175942\n",
      "Iteration 997, loss = 194701929.34118223\n",
      "Iteration 998, loss = 194243459.44700113\n",
      "Iteration 999, loss = 193756623.17070508\n",
      "Iteration 1000, loss = 193281957.46254802\n",
      "Iteration 1001, loss = 192823667.01004243\n",
      "Iteration 1002, loss = 192336142.28730145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1003, loss = 191872914.93679878\n",
      "Iteration 1004, loss = 191404153.68748623\n",
      "Iteration 1005, loss = 190945710.31267181\n",
      "Iteration 1006, loss = 190470130.50270125\n",
      "Iteration 1007, loss = 190023722.69691566\n",
      "Iteration 1008, loss = 189544298.45894742\n",
      "Iteration 1009, loss = 189082566.74603686\n",
      "Iteration 1010, loss = 188634113.81878209\n",
      "Iteration 1011, loss = 188168448.54077455\n",
      "Iteration 1012, loss = 187716742.85046342\n",
      "Iteration 1013, loss = 187270072.85626492\n",
      "Iteration 1014, loss = 186827278.54421285\n",
      "Iteration 1015, loss = 186394273.33930942\n",
      "Iteration 1016, loss = 185957010.29081815\n",
      "Iteration 1017, loss = 185540096.42258865\n",
      "Iteration 1018, loss = 185066372.96751800\n",
      "Iteration 1019, loss = 184604548.60775384\n",
      "Iteration 1020, loss = 184212302.91861039\n",
      "Iteration 1021, loss = 183731659.57711136\n",
      "Iteration 1022, loss = 183311656.08153248\n",
      "Iteration 1023, loss = 182869064.42591915\n",
      "Iteration 1024, loss = 182410965.83231610\n",
      "Iteration 1025, loss = 182028284.02028409\n",
      "Iteration 1026, loss = 181542638.96663594\n",
      "Iteration 1027, loss = 181145287.94470912\n",
      "Iteration 1028, loss = 180702224.32847688\n",
      "Iteration 1029, loss = 180285170.57700896\n",
      "Iteration 1030, loss = 179825351.18309107\n",
      "Iteration 1031, loss = 179408074.82679951\n",
      "Iteration 1032, loss = 178986763.93727300\n",
      "Iteration 1033, loss = 178553377.37486300\n",
      "Iteration 1034, loss = 178133605.36092752\n",
      "Iteration 1035, loss = 177723912.91786224\n",
      "Iteration 1036, loss = 177285155.47221312\n",
      "Iteration 1037, loss = 176846813.30982551\n",
      "Iteration 1038, loss = 176453787.63140661\n",
      "Iteration 1039, loss = 176147072.45713443\n",
      "Iteration 1040, loss = 175642180.16722217\n",
      "Iteration 1041, loss = 175235353.26354083\n",
      "Iteration 1042, loss = 174816304.09336337\n",
      "Iteration 1043, loss = 174405507.75949264\n",
      "Iteration 1044, loss = 174001863.90060994\n",
      "Iteration 1045, loss = 173606312.85539296\n",
      "Iteration 1046, loss = 173208990.97024509\n",
      "Iteration 1047, loss = 172804603.77341318\n",
      "Iteration 1048, loss = 172400926.36002263\n",
      "Iteration 1049, loss = 172003723.56669852\n",
      "Iteration 1050, loss = 171625069.76901814\n",
      "Iteration 1051, loss = 171223051.15538585\n",
      "Iteration 1052, loss = 170834898.56822804\n",
      "Iteration 1053, loss = 170443519.83526915\n",
      "Iteration 1054, loss = 170044842.89063951\n",
      "Iteration 1055, loss = 169668374.76448709\n",
      "Iteration 1056, loss = 169277467.24464822\n",
      "Iteration 1057, loss = 168906113.99058902\n",
      "Iteration 1058, loss = 168497857.50145432\n",
      "Iteration 1059, loss = 168118232.78197908\n",
      "Iteration 1060, loss = 167748145.99225453\n",
      "Iteration 1061, loss = 167337397.22005099\n",
      "Iteration 1062, loss = 166964229.58011100\n",
      "Iteration 1063, loss = 166593404.87765861\n",
      "Iteration 1064, loss = 166200495.07238171\n",
      "Iteration 1065, loss = 165860814.22473821\n",
      "Iteration 1066, loss = 165452627.55987516\n",
      "Iteration 1067, loss = 165098205.58299235\n",
      "Iteration 1068, loss = 164729890.65778637\n",
      "Iteration 1069, loss = 164458905.69023317\n",
      "Iteration 1070, loss = 164018251.91974223\n",
      "Iteration 1071, loss = 163660990.62629738\n",
      "Iteration 1072, loss = 163287642.28908780\n",
      "Iteration 1073, loss = 162939434.22729325\n",
      "Iteration 1074, loss = 162578933.46925801\n",
      "Iteration 1075, loss = 162222366.83281100\n",
      "Iteration 1076, loss = 161857771.44003013\n",
      "Iteration 1077, loss = 161504008.84455699\n",
      "Iteration 1078, loss = 161160602.67603606\n",
      "Iteration 1079, loss = 160804603.08091721\n",
      "Iteration 1080, loss = 160444115.88792884\n",
      "Iteration 1081, loss = 160110651.16882265\n",
      "Iteration 1082, loss = 159776688.24087530\n",
      "Iteration 1083, loss = 159423198.23030889\n",
      "Iteration 1084, loss = 159063066.69312257\n",
      "Iteration 1085, loss = 158727740.34389043\n",
      "Iteration 1086, loss = 158387166.35340255\n",
      "Iteration 1087, loss = 158040738.02209431\n",
      "Iteration 1088, loss = 157693428.24539912\n",
      "Iteration 1089, loss = 157366929.66904494\n",
      "Iteration 1090, loss = 157050159.42037970\n",
      "Iteration 1091, loss = 156683372.73243347\n",
      "Iteration 1092, loss = 156346371.89063618\n",
      "Iteration 1093, loss = 156042455.91232479\n",
      "Iteration 1094, loss = 155678617.81800413\n",
      "Iteration 1095, loss = 155371773.61212963\n",
      "Iteration 1096, loss = 155046177.87410575\n",
      "Iteration 1097, loss = 154718223.79464355\n",
      "Iteration 1098, loss = 154413349.95489767\n",
      "Iteration 1099, loss = 154076979.13947317\n",
      "Iteration 1100, loss = 153752745.50818905\n",
      "Iteration 1101, loss = 153426718.52590486\n",
      "Iteration 1102, loss = 153116448.30847800\n",
      "Iteration 1103, loss = 152814059.08684674\n",
      "Iteration 1104, loss = 152491827.77383903\n",
      "Iteration 1105, loss = 152176185.16956657\n",
      "Iteration 1106, loss = 151882985.06449580\n",
      "Iteration 1107, loss = 151560130.32478437\n",
      "Iteration 1108, loss = 151269943.44329375\n",
      "Iteration 1109, loss = 150931748.27509633\n",
      "Iteration 1110, loss = 150650792.21573263\n",
      "Iteration 1111, loss = 150338809.87422302\n",
      "Iteration 1112, loss = 150014988.47570774\n",
      "Iteration 1113, loss = 149751857.21854910\n",
      "Iteration 1114, loss = 149426414.50678051\n",
      "Iteration 1115, loss = 149118642.57431370\n",
      "Iteration 1116, loss = 148814528.58639970\n",
      "Iteration 1117, loss = 148536369.76436308\n",
      "Iteration 1118, loss = 148273558.89827678\n",
      "Iteration 1119, loss = 147924159.99391961\n",
      "Iteration 1120, loss = 147643654.11642048\n",
      "Iteration 1121, loss = 147346274.76332843\n",
      "Iteration 1122, loss = 147090893.89606979\n",
      "Iteration 1123, loss = 146817513.01890329\n",
      "Iteration 1124, loss = 146490225.13861069\n",
      "Iteration 1125, loss = 146178067.73001647\n",
      "Iteration 1126, loss = 145908060.47725680\n",
      "Iteration 1127, loss = 145611126.04445583\n",
      "Iteration 1128, loss = 145340987.84115982\n",
      "Iteration 1129, loss = 145049317.44167009\n",
      "Iteration 1130, loss = 144750527.51648551\n",
      "Iteration 1131, loss = 144477337.87972194\n",
      "Iteration 1132, loss = 144207473.67596978\n",
      "Iteration 1133, loss = 143936771.17219403\n",
      "Iteration 1134, loss = 143653707.50935352\n",
      "Iteration 1135, loss = 143373661.33109146\n",
      "Iteration 1136, loss = 143104243.58742437\n",
      "Iteration 1137, loss = 142854748.74238703\n",
      "Iteration 1138, loss = 142575040.73095676\n",
      "Iteration 1139, loss = 142269474.16491857\n",
      "Iteration 1140, loss = 142001822.94163573\n",
      "Iteration 1141, loss = 141755045.59773520\n",
      "Iteration 1142, loss = 141472387.01248580\n",
      "Iteration 1143, loss = 141223541.00436142\n",
      "Iteration 1144, loss = 140954903.41159803\n",
      "Iteration 1145, loss = 140663156.21928719\n",
      "Iteration 1146, loss = 140444974.73685670\n",
      "Iteration 1147, loss = 140159908.00153694\n",
      "Iteration 1148, loss = 139915338.09059265\n",
      "Iteration 1149, loss = 139641724.69260249\n",
      "Iteration 1150, loss = 139398517.10842732\n",
      "Iteration 1151, loss = 139127476.40133372\n",
      "Iteration 1152, loss = 138884295.85231078\n",
      "Iteration 1153, loss = 138624102.09153566\n",
      "Iteration 1154, loss = 138372791.71205515\n",
      "Iteration 1155, loss = 138115041.82846996\n",
      "Iteration 1156, loss = 137867097.09564736\n",
      "Iteration 1157, loss = 137614692.23850590\n",
      "Iteration 1158, loss = 137391376.58333641\n",
      "Iteration 1159, loss = 137111796.10051891\n",
      "Iteration 1160, loss = 136883711.10605037\n",
      "Iteration 1161, loss = 136623909.84812239\n",
      "Iteration 1162, loss = 136398131.58644187\n",
      "Iteration 1163, loss = 136154102.33486325\n",
      "Iteration 1164, loss = 135900378.57339865\n",
      "Iteration 1165, loss = 135636607.20381612\n",
      "Iteration 1166, loss = 135407133.83702663\n",
      "Iteration 1167, loss = 135149301.88526616\n",
      "Iteration 1168, loss = 134923889.29088897\n",
      "Iteration 1169, loss = 134690428.85244814\n",
      "Iteration 1170, loss = 134440722.81023714\n",
      "Iteration 1171, loss = 134219808.90090522\n",
      "Iteration 1172, loss = 133971600.52426891\n",
      "Iteration 1173, loss = 133736252.12709223\n",
      "Iteration 1174, loss = 133497779.49324821\n",
      "Iteration 1175, loss = 133269450.72048724\n",
      "Iteration 1176, loss = 133057888.76837170\n",
      "Iteration 1177, loss = 132805022.42178875\n",
      "Iteration 1178, loss = 132583086.80808444\n",
      "Iteration 1179, loss = 132334158.13187221\n",
      "Iteration 1180, loss = 132105143.97053289\n",
      "Iteration 1181, loss = 131890312.71187688\n",
      "Iteration 1182, loss = 131639615.87461661\n",
      "Iteration 1183, loss = 131422475.03710873\n",
      "Iteration 1184, loss = 131190927.62049602\n",
      "Iteration 1185, loss = 130995790.55281402\n",
      "Iteration 1186, loss = 130780364.08774933\n",
      "Iteration 1187, loss = 130530624.61691862\n",
      "Iteration 1188, loss = 130312749.53593884\n",
      "Iteration 1189, loss = 130088785.93628336\n",
      "Iteration 1190, loss = 129878495.70077658\n",
      "Iteration 1191, loss = 129631654.26315010\n",
      "Iteration 1192, loss = 129421016.13385433\n",
      "Iteration 1193, loss = 129210851.44228807\n",
      "Iteration 1194, loss = 128980498.74815960\n",
      "Iteration 1195, loss = 128771396.08549984\n",
      "Iteration 1196, loss = 128543346.25913846\n",
      "Iteration 1197, loss = 128323541.68376511\n",
      "Iteration 1198, loss = 128102625.95684169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1199, loss = 127904706.07621758\n",
      "Iteration 1200, loss = 127700361.14129391\n",
      "Iteration 1201, loss = 127474879.79046047\n",
      "Iteration 1202, loss = 127299809.79695299\n",
      "Iteration 1203, loss = 127050713.30309230\n",
      "Iteration 1204, loss = 126844325.61300519\n",
      "Iteration 1205, loss = 126641483.39332749\n",
      "Iteration 1206, loss = 126428355.25877272\n",
      "Iteration 1207, loss = 126230664.86944871\n",
      "Iteration 1208, loss = 126014061.98095477\n",
      "Iteration 1209, loss = 125826739.86469464\n",
      "Iteration 1210, loss = 125626571.51576674\n",
      "Iteration 1211, loss = 125419916.36901815\n",
      "Iteration 1212, loss = 125213759.77749564\n",
      "Iteration 1213, loss = 125040511.97609454\n",
      "Iteration 1214, loss = 124813045.77627216\n",
      "Iteration 1215, loss = 124624689.83334133\n",
      "Iteration 1216, loss = 124434094.41394024\n",
      "Iteration 1217, loss = 124229174.54766709\n",
      "Iteration 1218, loss = 124033875.84699987\n",
      "Iteration 1219, loss = 123863484.81745245\n",
      "Iteration 1220, loss = 123697161.15148814\n",
      "Iteration 1221, loss = 123452672.43170804\n",
      "Iteration 1222, loss = 123271883.02128972\n",
      "Iteration 1223, loss = 123100864.32046744\n",
      "Iteration 1224, loss = 122912161.45119968\n",
      "Iteration 1225, loss = 122698218.77210210\n",
      "Iteration 1226, loss = 122521050.29644364\n",
      "Iteration 1227, loss = 122313060.64773649\n",
      "Iteration 1228, loss = 122135596.68781187\n",
      "Iteration 1229, loss = 121958640.71958192\n",
      "Iteration 1230, loss = 121730069.89482218\n",
      "Iteration 1231, loss = 121617834.99901544\n",
      "Iteration 1232, loss = 121377356.01352049\n",
      "Iteration 1233, loss = 121205355.47276294\n",
      "Iteration 1234, loss = 121016520.58272696\n",
      "Iteration 1235, loss = 120860177.46395943\n",
      "Iteration 1236, loss = 120658914.09868574\n",
      "Iteration 1237, loss = 120474612.00867279\n",
      "Iteration 1238, loss = 120290786.80157673\n",
      "Iteration 1239, loss = 120118166.49545935\n",
      "Iteration 1240, loss = 119930785.45081136\n",
      "Iteration 1241, loss = 119757790.28607903\n",
      "Iteration 1242, loss = 119593597.04378274\n",
      "Iteration 1243, loss = 119384491.74486890\n",
      "Iteration 1244, loss = 119254941.05975181\n",
      "Iteration 1245, loss = 119060046.78942730\n",
      "Iteration 1246, loss = 118878875.52482422\n",
      "Iteration 1247, loss = 118710266.26591422\n",
      "Iteration 1248, loss = 118573167.63872451\n",
      "Iteration 1249, loss = 118378709.41140568\n",
      "Iteration 1250, loss = 118183584.18564011\n",
      "Iteration 1251, loss = 118022517.43846324\n",
      "Iteration 1252, loss = 117858882.48420054\n",
      "Iteration 1253, loss = 117681852.18929382\n",
      "Iteration 1254, loss = 117509763.79807323\n",
      "Iteration 1255, loss = 117342578.53375416\n",
      "Iteration 1256, loss = 117188274.37745850\n",
      "Iteration 1257, loss = 117006741.92405976\n",
      "Iteration 1258, loss = 116860438.32175925\n",
      "Iteration 1259, loss = 116664203.32270283\n",
      "Iteration 1260, loss = 116503400.69199288\n",
      "Iteration 1261, loss = 116361002.06905164\n",
      "Iteration 1262, loss = 116215803.36244118\n",
      "Iteration 1263, loss = 116033971.27151868\n",
      "Iteration 1264, loss = 115864123.01242930\n",
      "Iteration 1265, loss = 115718993.03298749\n",
      "Iteration 1266, loss = 115565111.12139829\n",
      "Iteration 1267, loss = 115421056.95856978\n",
      "Iteration 1268, loss = 115227930.93215904\n",
      "Iteration 1269, loss = 115046471.26839991\n",
      "Iteration 1270, loss = 114895868.75043640\n",
      "Iteration 1271, loss = 114736780.35976399\n",
      "Iteration 1272, loss = 114596523.95333445\n",
      "Iteration 1273, loss = 114440594.12074560\n",
      "Iteration 1274, loss = 114262537.50018400\n",
      "Iteration 1275, loss = 114104936.40296845\n",
      "Iteration 1276, loss = 113947602.84308317\n",
      "Iteration 1277, loss = 113803647.58565697\n",
      "Iteration 1278, loss = 113669232.42102681\n",
      "Iteration 1279, loss = 113506446.85054174\n",
      "Iteration 1280, loss = 113346390.97308536\n",
      "Iteration 1281, loss = 113221528.93336985\n",
      "Iteration 1282, loss = 113084525.54460602\n",
      "Iteration 1283, loss = 112940271.63889454\n",
      "Iteration 1284, loss = 112772619.39843942\n",
      "Iteration 1285, loss = 112618206.52671430\n",
      "Iteration 1286, loss = 112501124.87451056\n",
      "Iteration 1287, loss = 112348220.16106300\n",
      "Iteration 1288, loss = 112201034.19666521\n",
      "Iteration 1289, loss = 112054440.48317495\n",
      "Iteration 1290, loss = 111890281.73754376\n",
      "Iteration 1291, loss = 111761111.19164060\n",
      "Iteration 1292, loss = 111606165.37750697\n",
      "Iteration 1293, loss = 111475733.99698031\n",
      "Iteration 1294, loss = 111330566.56475180\n",
      "Iteration 1295, loss = 111192457.48191528\n",
      "Iteration 1296, loss = 111048198.18202932\n",
      "Iteration 1297, loss = 110905161.60329367\n",
      "Iteration 1298, loss = 110760278.48266900\n",
      "Iteration 1299, loss = 110642921.11631945\n",
      "Iteration 1300, loss = 110496165.26979220\n",
      "Iteration 1301, loss = 110368768.83424142\n",
      "Iteration 1302, loss = 110202263.69036366\n",
      "Iteration 1303, loss = 110097878.65695399\n",
      "Iteration 1304, loss = 109917762.36123557\n",
      "Iteration 1305, loss = 109829015.91045105\n",
      "Iteration 1306, loss = 109706605.01478389\n",
      "Iteration 1307, loss = 109543399.94788955\n",
      "Iteration 1308, loss = 109430474.63309197\n",
      "Iteration 1309, loss = 109288143.89067140\n",
      "Iteration 1310, loss = 109147831.78073445\n",
      "Iteration 1311, loss = 109021720.76895601\n",
      "Iteration 1312, loss = 108885632.43463324\n",
      "Iteration 1313, loss = 108749605.04781039\n",
      "Iteration 1314, loss = 108626382.96240452\n",
      "Iteration 1315, loss = 108477635.09653059\n",
      "Iteration 1316, loss = 108360933.15993834\n",
      "Iteration 1317, loss = 108266177.12605968\n",
      "Iteration 1318, loss = 108120165.16305862\n",
      "Iteration 1319, loss = 108012985.43882722\n",
      "Iteration 1320, loss = 107875325.23963946\n",
      "Iteration 1321, loss = 107747004.33795796\n",
      "Iteration 1322, loss = 107632881.67523125\n",
      "Iteration 1323, loss = 107515585.21247855\n",
      "Iteration 1324, loss = 107392127.87864168\n",
      "Iteration 1325, loss = 107254355.66983071\n",
      "Iteration 1326, loss = 107130392.50223126\n",
      "Iteration 1327, loss = 107005149.35196453\n",
      "Iteration 1328, loss = 106886466.05616233\n",
      "Iteration 1329, loss = 106773464.93214497\n",
      "Iteration 1330, loss = 106658036.47010550\n",
      "Iteration 1331, loss = 106538752.15295944\n",
      "Iteration 1332, loss = 106457092.61382473\n",
      "Iteration 1333, loss = 106290009.85930258\n",
      "Iteration 1334, loss = 106180927.72143030\n",
      "Iteration 1335, loss = 106079759.75359946\n",
      "Iteration 1336, loss = 105943460.98141010\n",
      "Iteration 1337, loss = 105842162.27952352\n",
      "Iteration 1338, loss = 105748117.61226177\n",
      "Iteration 1339, loss = 105799026.15600204\n",
      "Iteration 1340, loss = 105518898.50182344\n",
      "Iteration 1341, loss = 105395452.38504092\n",
      "Iteration 1342, loss = 105294405.46504149\n",
      "Iteration 1343, loss = 105188020.09143588\n",
      "Iteration 1344, loss = 105085368.29188427\n",
      "Iteration 1345, loss = 104966315.44710495\n",
      "Iteration 1346, loss = 104866694.60102901\n",
      "Iteration 1347, loss = 104752445.63676189\n",
      "Iteration 1348, loss = 104643285.70600607\n",
      "Iteration 1349, loss = 104525822.70005505\n",
      "Iteration 1350, loss = 104418308.91292080\n",
      "Iteration 1351, loss = 104357351.35362853\n",
      "Iteration 1352, loss = 104208691.28568329\n",
      "Iteration 1353, loss = 104103046.69783652\n",
      "Iteration 1354, loss = 103997003.19150096\n",
      "Iteration 1355, loss = 103886222.15873581\n",
      "Iteration 1356, loss = 103801157.94803116\n",
      "Iteration 1357, loss = 103688215.51506130\n",
      "Iteration 1358, loss = 103592766.14587308\n",
      "Iteration 1359, loss = 103484704.79023829\n",
      "Iteration 1360, loss = 103385725.51706278\n",
      "Iteration 1361, loss = 103284937.97968578\n",
      "Iteration 1362, loss = 103166488.69397901\n",
      "Iteration 1363, loss = 103060787.43491112\n",
      "Iteration 1364, loss = 102959497.19956362\n",
      "Iteration 1365, loss = 102859226.33409815\n",
      "Iteration 1366, loss = 102761388.75472538\n",
      "Iteration 1367, loss = 102661485.94736029\n",
      "Iteration 1368, loss = 102559236.99326414\n",
      "Iteration 1369, loss = 102455663.60587700\n",
      "Iteration 1370, loss = 102353421.53345771\n",
      "Iteration 1371, loss = 102284490.69830735\n",
      "Iteration 1372, loss = 102163946.76020975\n",
      "Iteration 1373, loss = 102071831.80789976\n",
      "Iteration 1374, loss = 101959770.60250816\n",
      "Iteration 1375, loss = 101869332.05308363\n",
      "Iteration 1376, loss = 101780331.84353866\n",
      "Iteration 1377, loss = 101673326.80131210\n",
      "Iteration 1378, loss = 101571741.50103331\n",
      "Iteration 1379, loss = 101480418.10853674\n",
      "Iteration 1380, loss = 101379396.20101090\n",
      "Iteration 1381, loss = 101293049.85048440\n",
      "Iteration 1382, loss = 101188322.45923522\n",
      "Iteration 1383, loss = 101094167.26470400\n",
      "Iteration 1384, loss = 101001024.00277425\n",
      "Iteration 1385, loss = 100914327.98593722\n",
      "Iteration 1386, loss = 100820173.73835485\n",
      "Iteration 1387, loss = 100746898.05710877\n",
      "Iteration 1388, loss = 100637831.37777969\n",
      "Iteration 1389, loss = 100560405.17607224\n",
      "Iteration 1390, loss = 100477063.93799585\n",
      "Iteration 1391, loss = 100362984.12315549\n",
      "Iteration 1392, loss = 100293353.11411621\n",
      "Iteration 1393, loss = 100197409.46518026\n",
      "Iteration 1394, loss = 100138653.22690117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1395, loss = 99987288.57115705\n",
      "Iteration 1396, loss = 99916897.39251770\n",
      "Iteration 1397, loss = 99810291.53506614\n",
      "Iteration 1398, loss = 99769168.97328281\n",
      "Iteration 1399, loss = 99653796.01416932\n",
      "Iteration 1400, loss = 99585281.67502755\n",
      "Iteration 1401, loss = 99523721.12194479\n",
      "Iteration 1402, loss = 99404539.34479970\n",
      "Iteration 1403, loss = 99356005.62864999\n",
      "Iteration 1404, loss = 99236728.81497073\n",
      "Iteration 1405, loss = 99144233.43051544\n",
      "Iteration 1406, loss = 99062323.65456972\n",
      "Iteration 1407, loss = 98980112.72840685\n",
      "Iteration 1408, loss = 98905577.13240780\n",
      "Iteration 1409, loss = 98819060.78307156\n",
      "Iteration 1410, loss = 98737242.67524129\n",
      "Iteration 1411, loss = 98652601.43144865\n",
      "Iteration 1412, loss = 98579569.12986307\n",
      "Iteration 1413, loss = 98510365.78066386\n",
      "Iteration 1414, loss = 98416320.93644014\n",
      "Iteration 1415, loss = 98339466.90524323\n",
      "Iteration 1416, loss = 98251457.13493507\n",
      "Iteration 1417, loss = 98184104.28851451\n",
      "Iteration 1418, loss = 98043132.40798569\n",
      "Iteration 1419, loss = 98037195.48718223\n",
      "Iteration 1420, loss = 97904339.01980467\n",
      "Iteration 1421, loss = 97859699.47762112\n",
      "Iteration 1422, loss = 97801819.37670474\n",
      "Iteration 1423, loss = 97699873.57035844\n",
      "Iteration 1424, loss = 97611537.74102557\n",
      "Iteration 1425, loss = 97558293.91547771\n",
      "Iteration 1426, loss = 97482870.57424070\n",
      "Iteration 1427, loss = 97391966.76289733\n",
      "Iteration 1428, loss = 97305200.83877911\n",
      "Iteration 1429, loss = 97243235.59062505\n",
      "Iteration 1430, loss = 97126547.32808521\n",
      "Iteration 1431, loss = 97101062.15096831\n",
      "Iteration 1432, loss = 97014428.18143652\n",
      "Iteration 1433, loss = 96945179.09403378\n",
      "Iteration 1434, loss = 96871929.27815332\n",
      "Iteration 1435, loss = 96821204.87030166\n",
      "Iteration 1436, loss = 96711048.89660969\n",
      "Iteration 1437, loss = 96654981.24701913\n",
      "Iteration 1438, loss = 96576554.20732464\n",
      "Iteration 1439, loss = 96522585.61857876\n",
      "Iteration 1440, loss = 96465906.12683722\n",
      "Iteration 1441, loss = 96377224.40992303\n",
      "Iteration 1442, loss = 96288511.30581775\n",
      "Iteration 1443, loss = 96207853.16660316\n",
      "Iteration 1444, loss = 96139645.98251289\n",
      "Iteration 1445, loss = 96110269.66918422\n",
      "Iteration 1446, loss = 95999289.62944569\n",
      "Iteration 1447, loss = 95947279.48428780\n",
      "Iteration 1448, loss = 95868391.55201857\n",
      "Iteration 1449, loss = 95782035.49657799\n",
      "Iteration 1450, loss = 95756224.74590163\n",
      "Iteration 1451, loss = 95695112.15877536\n",
      "Iteration 1452, loss = 95612040.50972924\n",
      "Iteration 1453, loss = 95556111.51452447\n",
      "Iteration 1454, loss = 95483223.29652916\n",
      "Iteration 1455, loss = 95377546.23343275\n",
      "Iteration 1456, loss = 95354542.17045681\n",
      "Iteration 1457, loss = 95262517.41740410\n",
      "Iteration 1458, loss = 95205036.16723667\n",
      "Iteration 1459, loss = 95151282.75887379\n",
      "Iteration 1460, loss = 95068496.43997759\n",
      "Iteration 1461, loss = 95003856.51507032\n",
      "Iteration 1462, loss = 94971008.28430898\n",
      "Iteration 1463, loss = 94856431.29094052\n",
      "Iteration 1464, loss = 94806631.66771445\n",
      "Iteration 1465, loss = 94721573.86031015\n",
      "Iteration 1466, loss = 94668463.33497758\n",
      "Iteration 1467, loss = 94602845.68367425\n",
      "Iteration 1468, loss = 94549639.82544808\n",
      "Iteration 1469, loss = 94490484.17764302\n",
      "Iteration 1470, loss = 94433939.23802885\n",
      "Iteration 1471, loss = 94326245.55252145\n",
      "Iteration 1472, loss = 94281533.23471232\n",
      "Iteration 1473, loss = 94233880.32106557\n",
      "Iteration 1474, loss = 94161322.54158130\n",
      "Iteration 1475, loss = 94103794.00774790\n",
      "Iteration 1476, loss = 94026525.94789359\n",
      "Iteration 1477, loss = 93989748.66470391\n",
      "Iteration 1478, loss = 93916585.17989430\n",
      "Iteration 1479, loss = 93856375.99462882\n",
      "Iteration 1480, loss = 93793315.59011115\n",
      "Iteration 1481, loss = 93723758.09189810\n",
      "Iteration 1482, loss = 93670155.29962385\n",
      "Iteration 1483, loss = 93615361.95836182\n",
      "Iteration 1484, loss = 93555867.88692571\n",
      "Iteration 1485, loss = 93480229.46925727\n",
      "Iteration 1486, loss = 93417257.91322444\n",
      "Iteration 1487, loss = 93368607.76044126\n",
      "Iteration 1488, loss = 93309331.27439877\n",
      "Iteration 1489, loss = 93261986.85547704\n",
      "Iteration 1490, loss = 93182041.79030940\n",
      "Iteration 1491, loss = 93129114.53300515\n",
      "Iteration 1492, loss = 93083995.97954291\n",
      "Iteration 1493, loss = 93012030.17098622\n",
      "Iteration 1494, loss = 92967190.68641599\n",
      "Iteration 1495, loss = 92910548.53854740\n",
      "Iteration 1496, loss = 92838285.69814567\n",
      "Iteration 1497, loss = 92777324.21566190\n",
      "Iteration 1498, loss = 92747457.15401615\n",
      "Iteration 1499, loss = 92645092.56764738\n",
      "Iteration 1500, loss = 92607611.02661267\n",
      "Iteration 1501, loss = 92540590.05143896\n",
      "Iteration 1502, loss = 92495399.25667542\n",
      "Iteration 1503, loss = 92442318.33850101\n",
      "Iteration 1504, loss = 92395243.47147304\n",
      "Iteration 1505, loss = 92328289.43517914\n",
      "Iteration 1506, loss = 92279742.20069230\n",
      "Iteration 1507, loss = 92234643.93797982\n",
      "Iteration 1508, loss = 92179940.01605688\n",
      "Iteration 1509, loss = 92121069.38312362\n",
      "Iteration 1510, loss = 92062100.72054985\n",
      "Iteration 1511, loss = 92002886.55198234\n",
      "Iteration 1512, loss = 91960083.81032935\n",
      "Iteration 1513, loss = 91908175.54740760\n",
      "Iteration 1514, loss = 91854016.70014033\n",
      "Iteration 1515, loss = 91812680.63658422\n",
      "Iteration 1516, loss = 91734389.09929289\n",
      "Iteration 1517, loss = 91690934.84999344\n",
      "Iteration 1518, loss = 91657396.09340282\n",
      "Iteration 1519, loss = 91585137.79032883\n",
      "Iteration 1520, loss = 91549870.46689448\n",
      "Iteration 1521, loss = 91479847.06326774\n",
      "Iteration 1522, loss = 91424355.88589251\n",
      "Iteration 1523, loss = 91397045.19437207\n",
      "Iteration 1524, loss = 91334967.13158521\n",
      "Iteration 1525, loss = 91297994.05294530\n",
      "Iteration 1526, loss = 91223023.50756817\n",
      "Iteration 1527, loss = 91198786.49224213\n",
      "Iteration 1528, loss = 91136627.46518269\n",
      "Iteration 1529, loss = 91057770.06235364\n",
      "Iteration 1530, loss = 91099092.07577224\n",
      "Iteration 1531, loss = 90969772.11743525\n",
      "Iteration 1532, loss = 90939451.84394211\n",
      "Iteration 1533, loss = 90897240.25641939\n",
      "Iteration 1534, loss = 90841781.64698809\n",
      "Iteration 1535, loss = 90787639.00445998\n",
      "Iteration 1536, loss = 90749212.40571007\n",
      "Iteration 1537, loss = 90678242.46012615\n",
      "Iteration 1538, loss = 90624852.55745517\n",
      "Iteration 1539, loss = 90611708.30690308\n",
      "Iteration 1540, loss = 90540917.19368948\n",
      "Iteration 1541, loss = 90513771.90346348\n",
      "Iteration 1542, loss = 90447617.95021690\n",
      "Iteration 1543, loss = 90407619.34931427\n",
      "Iteration 1544, loss = 90404255.51078507\n",
      "Iteration 1545, loss = 90314547.15184379\n",
      "Iteration 1546, loss = 90253159.67055765\n",
      "Iteration 1547, loss = 90244158.93207204\n",
      "Iteration 1548, loss = 90154280.76777892\n",
      "Iteration 1549, loss = 90116487.89990762\n",
      "Iteration 1550, loss = 90119141.53713505\n",
      "Iteration 1551, loss = 90038784.01754840\n",
      "Iteration 1552, loss = 89982598.75413394\n",
      "Iteration 1553, loss = 89929182.58201149\n",
      "Iteration 1554, loss = 89890182.13616429\n",
      "Iteration 1555, loss = 89941360.95677666\n",
      "Iteration 1556, loss = 89805285.20680900\n",
      "Iteration 1557, loss = 89750406.55561548\n",
      "Iteration 1558, loss = 89699582.37079559\n",
      "Iteration 1559, loss = 89655497.24705435\n",
      "Iteration 1560, loss = 89602555.37421921\n",
      "Iteration 1561, loss = 89559040.62941402\n",
      "Iteration 1562, loss = 89513969.76239668\n",
      "Iteration 1563, loss = 89477404.28550634\n",
      "Iteration 1564, loss = 89430613.89253588\n",
      "Iteration 1565, loss = 89409214.28871816\n",
      "Iteration 1566, loss = 89341649.38508151\n",
      "Iteration 1567, loss = 89292235.21553695\n",
      "Iteration 1568, loss = 89245502.06187390\n",
      "Iteration 1569, loss = 89216311.01306036\n",
      "Iteration 1570, loss = 89135734.90759943\n",
      "Iteration 1571, loss = 89134550.20656565\n",
      "Iteration 1572, loss = 89095785.78906035\n",
      "Iteration 1573, loss = 89037167.00818060\n",
      "Iteration 1574, loss = 88976031.30538322\n",
      "Iteration 1575, loss = 88936746.62709212\n",
      "Iteration 1576, loss = 88891818.13037984\n",
      "Iteration 1577, loss = 88878017.05784738\n",
      "Iteration 1578, loss = 88812291.34873655\n",
      "Iteration 1579, loss = 88763526.08442476\n",
      "Iteration 1580, loss = 88737899.55840537\n",
      "Iteration 1581, loss = 88706541.83769928\n",
      "Iteration 1582, loss = 88639327.71785058\n",
      "Iteration 1583, loss = 88584146.75267874\n",
      "Iteration 1584, loss = 88562224.17366700\n",
      "Iteration 1585, loss = 88524949.55064163\n",
      "Iteration 1586, loss = 88478022.79817574\n",
      "Iteration 1587, loss = 88433994.18996331\n",
      "Iteration 1588, loss = 88389221.27476585\n",
      "Iteration 1589, loss = 88363235.02709478\n",
      "Iteration 1590, loss = 88286570.50508060\n",
      "Iteration 1591, loss = 88281839.13970548\n",
      "Iteration 1592, loss = 88225206.34345663\n",
      "Iteration 1593, loss = 88164868.89741069\n",
      "Iteration 1594, loss = 88125534.55265990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1595, loss = 88104732.98575030\n",
      "Iteration 1596, loss = 88046940.10538869\n",
      "Iteration 1597, loss = 88021336.14366098\n",
      "Iteration 1598, loss = 87947169.34909520\n",
      "Iteration 1599, loss = 87938190.17996939\n",
      "Iteration 1600, loss = 87912718.56222391\n",
      "Iteration 1601, loss = 87835574.16390775\n",
      "Iteration 1602, loss = 87808899.83207944\n",
      "Iteration 1603, loss = 87767575.43828264\n",
      "Iteration 1604, loss = 87729312.51249136\n",
      "Iteration 1605, loss = 87670108.37771210\n",
      "Iteration 1606, loss = 87636721.99160349\n",
      "Iteration 1607, loss = 87604166.41862504\n",
      "Iteration 1608, loss = 87565788.93129833\n",
      "Iteration 1609, loss = 87502069.61641134\n",
      "Iteration 1610, loss = 87465472.48956975\n",
      "Iteration 1611, loss = 87429923.84511209\n",
      "Iteration 1612, loss = 87391216.49044870\n",
      "Iteration 1613, loss = 87348860.63831303\n",
      "Iteration 1614, loss = 87297183.85842514\n",
      "Iteration 1615, loss = 87276500.86246477\n",
      "Iteration 1616, loss = 87238304.47232525\n",
      "Iteration 1617, loss = 87215840.77776782\n",
      "Iteration 1618, loss = 87159176.12512153\n",
      "Iteration 1619, loss = 87112180.64111561\n",
      "Iteration 1620, loss = 87069621.03226526\n",
      "Iteration 1621, loss = 87048504.42387295\n",
      "Iteration 1622, loss = 86983004.72482917\n",
      "Iteration 1623, loss = 86949081.89649743\n",
      "Iteration 1624, loss = 86923817.20992805\n",
      "Iteration 1625, loss = 86887499.26222703\n",
      "Iteration 1626, loss = 86838342.45904621\n",
      "Iteration 1627, loss = 86808390.34382977\n",
      "Iteration 1628, loss = 86763703.60618861\n",
      "Iteration 1629, loss = 86718324.31623740\n",
      "Iteration 1630, loss = 86704293.29727082\n",
      "Iteration 1631, loss = 86637667.15798636\n",
      "Iteration 1632, loss = 86628236.85029486\n",
      "Iteration 1633, loss = 86567982.92856835\n",
      "Iteration 1634, loss = 86536831.12332524\n",
      "Iteration 1635, loss = 86506090.00913647\n",
      "Iteration 1636, loss = 86442118.62263305\n",
      "Iteration 1637, loss = 86445000.31960851\n",
      "Iteration 1638, loss = 86346314.55012672\n",
      "Iteration 1639, loss = 86354387.81118546\n",
      "Iteration 1640, loss = 86297747.31394741\n",
      "Iteration 1641, loss = 86329890.37719324\n",
      "Iteration 1642, loss = 86230371.78996849\n",
      "Iteration 1643, loss = 86208135.54727015\n",
      "Iteration 1644, loss = 86207166.64588946\n",
      "Iteration 1645, loss = 86119138.75839159\n",
      "Iteration 1646, loss = 86114698.05417472\n",
      "Iteration 1647, loss = 86056485.55318406\n",
      "Iteration 1648, loss = 86024428.68981181\n",
      "Iteration 1649, loss = 85975091.59302445\n",
      "Iteration 1650, loss = 85944648.09923768\n",
      "Iteration 1651, loss = 85926415.71423846\n",
      "Iteration 1652, loss = 85848466.87394758\n",
      "Iteration 1653, loss = 85822537.63255076\n",
      "Iteration 1654, loss = 85790138.18748389\n",
      "Iteration 1655, loss = 85755729.46449505\n",
      "Iteration 1656, loss = 85718355.48938060\n",
      "Iteration 1657, loss = 85689705.61878996\n",
      "Iteration 1658, loss = 85653161.14254721\n",
      "Iteration 1659, loss = 85603020.03509110\n",
      "Iteration 1660, loss = 85576462.30239984\n",
      "Iteration 1661, loss = 85545261.32485580\n",
      "Iteration 1662, loss = 85514100.48156008\n",
      "Iteration 1663, loss = 85464252.86872303\n",
      "Iteration 1664, loss = 85430697.87881559\n",
      "Iteration 1665, loss = 85420825.39970616\n",
      "Iteration 1666, loss = 85374902.85754144\n",
      "Iteration 1667, loss = 85340811.27701361\n",
      "Iteration 1668, loss = 85293762.49128406\n",
      "Iteration 1669, loss = 85271373.17886198\n",
      "Iteration 1670, loss = 85209796.61460643\n",
      "Iteration 1671, loss = 85204880.74588165\n",
      "Iteration 1672, loss = 85158823.98071693\n",
      "Iteration 1673, loss = 85104831.69892180\n",
      "Iteration 1674, loss = 85101226.93784276\n",
      "Iteration 1675, loss = 85055298.18955955\n",
      "Iteration 1676, loss = 85033331.29580729\n",
      "Iteration 1677, loss = 84964186.92485212\n",
      "Iteration 1678, loss = 84942292.11806819\n",
      "Iteration 1679, loss = 84914111.98328632\n",
      "Iteration 1680, loss = 84888852.97278801\n",
      "Iteration 1681, loss = 84840316.57367642\n",
      "Iteration 1682, loss = 84799070.97179684\n",
      "Iteration 1683, loss = 84805570.56421088\n",
      "Iteration 1684, loss = 84751474.96432859\n",
      "Iteration 1685, loss = 84719024.57313251\n",
      "Iteration 1686, loss = 84677592.87436841\n",
      "Iteration 1687, loss = 84666459.84427558\n",
      "Iteration 1688, loss = 84609102.29028019\n",
      "Iteration 1689, loss = 84577172.41496782\n",
      "Iteration 1690, loss = 84534635.03542496\n",
      "Iteration 1691, loss = 84494523.68289451\n",
      "Iteration 1692, loss = 84465593.00031765\n",
      "Iteration 1693, loss = 84433463.40128246\n",
      "Iteration 1694, loss = 84409285.21462913\n",
      "Iteration 1695, loss = 84358979.15305062\n",
      "Iteration 1696, loss = 84363340.10227723\n",
      "Iteration 1697, loss = 84309128.54486817\n",
      "Iteration 1698, loss = 84263915.16542286\n",
      "Iteration 1699, loss = 84243522.32949492\n",
      "Iteration 1700, loss = 84193215.12014946\n",
      "Iteration 1701, loss = 84192605.04276022\n",
      "Iteration 1702, loss = 84135559.62601399\n",
      "Iteration 1703, loss = 84105524.53672336\n",
      "Iteration 1704, loss = 84072022.04765025\n",
      "Iteration 1705, loss = 84017252.87376820\n",
      "Iteration 1706, loss = 84014657.19189894\n",
      "Iteration 1707, loss = 83968316.68451387\n",
      "Iteration 1708, loss = 83937986.22843939\n",
      "Iteration 1709, loss = 83918534.33783790\n",
      "Iteration 1710, loss = 83884225.69871196\n",
      "Iteration 1711, loss = 83837902.65170513\n",
      "Iteration 1712, loss = 83814111.94674253\n",
      "Iteration 1713, loss = 83783458.97974414\n",
      "Iteration 1714, loss = 83748488.66856399\n",
      "Iteration 1715, loss = 83733981.69173780\n",
      "Iteration 1716, loss = 83694042.81297573\n",
      "Iteration 1717, loss = 83655025.43883251\n",
      "Iteration 1718, loss = 83637584.23606947\n",
      "Iteration 1719, loss = 83599491.78528070\n",
      "Iteration 1720, loss = 83558543.10720560\n",
      "Iteration 1721, loss = 83533687.20731577\n",
      "Iteration 1722, loss = 83503290.50505152\n",
      "Iteration 1723, loss = 83469043.95755270\n",
      "Iteration 1724, loss = 83453099.01727013\n",
      "Iteration 1725, loss = 83406981.24929440\n",
      "Iteration 1726, loss = 83369604.05093177\n",
      "Iteration 1727, loss = 83339382.61144011\n",
      "Iteration 1728, loss = 83297796.47063725\n",
      "Iteration 1729, loss = 83289872.97912873\n",
      "Iteration 1730, loss = 83277365.83207105\n",
      "Iteration 1731, loss = 83204114.45377642\n",
      "Iteration 1732, loss = 83187291.74645963\n",
      "Iteration 1733, loss = 83134555.38467582\n",
      "Iteration 1734, loss = 83115159.70867968\n",
      "Iteration 1735, loss = 83079118.35002784\n",
      "Iteration 1736, loss = 83063095.44830552\n",
      "Iteration 1737, loss = 83030340.51237957\n",
      "Iteration 1738, loss = 82971027.54370399\n",
      "Iteration 1739, loss = 82953479.20375079\n",
      "Iteration 1740, loss = 82921892.73813336\n",
      "Iteration 1741, loss = 82897454.55981165\n",
      "Iteration 1742, loss = 82867473.02807234\n",
      "Iteration 1743, loss = 82844063.87540759\n",
      "Iteration 1744, loss = 82816238.64963792\n",
      "Iteration 1745, loss = 82814619.66394646\n",
      "Iteration 1746, loss = 82724505.18122838\n",
      "Iteration 1747, loss = 82710658.30288886\n",
      "Iteration 1748, loss = 82678758.95883839\n",
      "Iteration 1749, loss = 82675090.18914218\n",
      "Iteration 1750, loss = 82614302.02684996\n",
      "Iteration 1751, loss = 82586449.59424411\n",
      "Iteration 1752, loss = 82556570.10586177\n",
      "Iteration 1753, loss = 82533188.17129852\n",
      "Iteration 1754, loss = 82490199.37290707\n",
      "Iteration 1755, loss = 82469264.18958682\n",
      "Iteration 1756, loss = 82423809.13375214\n",
      "Iteration 1757, loss = 82415906.03428498\n",
      "Iteration 1758, loss = 82360576.45574224\n",
      "Iteration 1759, loss = 82343468.72159930\n",
      "Iteration 1760, loss = 82333660.48974621\n",
      "Iteration 1761, loss = 82282950.36699745\n",
      "Iteration 1762, loss = 82259591.58456089\n",
      "Iteration 1763, loss = 82191365.69588053\n",
      "Iteration 1764, loss = 82212629.59443793\n",
      "Iteration 1765, loss = 82143984.03412864\n",
      "Iteration 1766, loss = 82171463.71377155\n",
      "Iteration 1767, loss = 82124899.62909885\n",
      "Iteration 1768, loss = 82062247.49490933\n",
      "Iteration 1769, loss = 82058230.05867885\n",
      "Iteration 1770, loss = 82004308.78301273\n",
      "Iteration 1771, loss = 82000536.48738296\n",
      "Iteration 1772, loss = 81977863.94974066\n",
      "Iteration 1773, loss = 81904038.17908402\n",
      "Iteration 1774, loss = 81938936.39231808\n",
      "Iteration 1775, loss = 81857013.92193875\n",
      "Iteration 1776, loss = 81818719.98605622\n",
      "Iteration 1777, loss = 81792814.86303288\n",
      "Iteration 1778, loss = 81778173.60486588\n",
      "Iteration 1779, loss = 81736537.59030682\n",
      "Iteration 1780, loss = 81706951.68298373\n",
      "Iteration 1781, loss = 81711095.67548615\n",
      "Iteration 1782, loss = 81682991.80813071\n",
      "Iteration 1783, loss = 81632528.32454577\n",
      "Iteration 1784, loss = 81609255.21790580\n",
      "Iteration 1785, loss = 81578861.39378965\n",
      "Iteration 1786, loss = 81572123.61694553\n",
      "Iteration 1787, loss = 81550610.36666706\n",
      "Iteration 1788, loss = 81491939.96155272\n",
      "Iteration 1789, loss = 81453696.27676369\n",
      "Iteration 1790, loss = 81434073.58662419\n",
      "Iteration 1791, loss = 81405221.13201554\n",
      "Iteration 1792, loss = 81402511.80392866\n",
      "Iteration 1793, loss = 81341850.67195894\n",
      "Iteration 1794, loss = 81333664.90662213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1795, loss = 81284545.77594233\n",
      "Iteration 1796, loss = 81273947.34589295\n",
      "Iteration 1797, loss = 81237862.10209580\n",
      "Iteration 1798, loss = 81209530.43704662\n",
      "Iteration 1799, loss = 81177491.51421930\n",
      "Iteration 1800, loss = 81142625.73204167\n",
      "Iteration 1801, loss = 81102533.47622246\n",
      "Iteration 1802, loss = 81090840.23225637\n",
      "Iteration 1803, loss = 81074368.11011858\n",
      "Iteration 1804, loss = 81020893.41505064\n",
      "Iteration 1805, loss = 81003447.58481646\n",
      "Iteration 1806, loss = 80955834.76304251\n",
      "Iteration 1807, loss = 80962785.47621314\n",
      "Iteration 1808, loss = 80930276.92389059\n",
      "Iteration 1809, loss = 80891397.75288779\n",
      "Iteration 1810, loss = 80873354.98331511\n",
      "Iteration 1811, loss = 80851085.75973044\n",
      "Iteration 1812, loss = 80811353.89307842\n",
      "Iteration 1813, loss = 80798449.31104124\n",
      "Iteration 1814, loss = 80765225.28149568\n",
      "Iteration 1815, loss = 80718133.78213869\n",
      "Iteration 1816, loss = 80705841.54967967\n",
      "Iteration 1817, loss = 80670293.69116184\n",
      "Iteration 1818, loss = 80646396.54809949\n",
      "Iteration 1819, loss = 80617907.93762606\n",
      "Iteration 1820, loss = 80572162.06232502\n",
      "Iteration 1821, loss = 80580696.79248133\n",
      "Iteration 1822, loss = 80535645.97071566\n",
      "Iteration 1823, loss = 80522202.03310943\n",
      "Iteration 1824, loss = 80466309.44590653\n",
      "Iteration 1825, loss = 80490547.35941896\n",
      "Iteration 1826, loss = 80416681.00141124\n",
      "Iteration 1827, loss = 80399493.34834333\n",
      "Iteration 1828, loss = 80373825.72176504\n",
      "Iteration 1829, loss = 80333060.53587359\n",
      "Iteration 1830, loss = 80315782.08098146\n",
      "Iteration 1831, loss = 80288929.62086906\n",
      "Iteration 1832, loss = 80256177.05683114\n",
      "Iteration 1833, loss = 80233151.86172482\n",
      "Iteration 1834, loss = 80218029.61634952\n",
      "Iteration 1835, loss = 80177999.69670083\n",
      "Iteration 1836, loss = 80135904.61470050\n",
      "Iteration 1837, loss = 80124141.02796109\n",
      "Iteration 1838, loss = 80063975.81574507\n",
      "Iteration 1839, loss = 80065910.19672944\n",
      "Iteration 1840, loss = 80054012.56689830\n",
      "Iteration 1841, loss = 80024580.91253532\n",
      "Iteration 1842, loss = 79996532.37568986\n",
      "Iteration 1843, loss = 79973269.71210220\n",
      "Iteration 1844, loss = 79949278.54796155\n",
      "Iteration 1845, loss = 79902355.16813621\n",
      "Iteration 1846, loss = 79877508.14586891\n",
      "Iteration 1847, loss = 79851434.03640251\n",
      "Iteration 1848, loss = 79831561.88180952\n",
      "Iteration 1849, loss = 79817192.52499811\n",
      "Iteration 1850, loss = 79797057.23160797\n",
      "Iteration 1851, loss = 79778544.29010996\n",
      "Iteration 1852, loss = 79735310.82508731\n",
      "Iteration 1853, loss = 79695322.97227089\n",
      "Iteration 1854, loss = 79694556.17725343\n",
      "Iteration 1855, loss = 79644040.04653920\n",
      "Iteration 1856, loss = 79611596.54443818\n",
      "Iteration 1857, loss = 79575134.47471333\n",
      "Iteration 1858, loss = 79556045.09891097\n",
      "Iteration 1859, loss = 79543449.32422078\n",
      "Iteration 1860, loss = 79512376.01720430\n",
      "Iteration 1861, loss = 79484669.64886789\n",
      "Iteration 1862, loss = 79452472.98880126\n",
      "Iteration 1863, loss = 79454733.50566457\n",
      "Iteration 1864, loss = 79402815.86988890\n",
      "Iteration 1865, loss = 79412118.49065395\n",
      "Iteration 1866, loss = 79365949.36998950\n",
      "Iteration 1867, loss = 79327591.69741337\n",
      "Iteration 1868, loss = 79306967.91667174\n",
      "Iteration 1869, loss = 79289964.99402465\n",
      "Iteration 1870, loss = 79265014.78506128\n",
      "Iteration 1871, loss = 79248084.12751289\n",
      "Iteration 1872, loss = 79212333.69320470\n",
      "Iteration 1873, loss = 79189734.26778047\n",
      "Iteration 1874, loss = 79164626.10852982\n",
      "Iteration 1875, loss = 79127245.63833854\n",
      "Iteration 1876, loss = 79107457.35498738\n",
      "Iteration 1877, loss = 79070528.60849185\n",
      "Iteration 1878, loss = 79040413.46056502\n",
      "Iteration 1879, loss = 78999822.53015052\n",
      "Iteration 1880, loss = 79038350.51758863\n",
      "Iteration 1881, loss = 79041404.24897908\n",
      "Iteration 1882, loss = 78962262.34565870\n",
      "Iteration 1883, loss = 78910829.17824036\n",
      "Iteration 1884, loss = 78872482.82659045\n",
      "Iteration 1885, loss = 78866716.75234079\n",
      "Iteration 1886, loss = 78839038.08628221\n",
      "Iteration 1887, loss = 78802748.55030365\n",
      "Iteration 1888, loss = 78793018.26321845\n",
      "Iteration 1889, loss = 78763119.54871616\n",
      "Iteration 1890, loss = 78739421.47033228\n",
      "Iteration 1891, loss = 78698204.17154042\n",
      "Iteration 1892, loss = 78688441.54862058\n",
      "Iteration 1893, loss = 78681444.44273843\n",
      "Iteration 1894, loss = 78624668.62652457\n",
      "Iteration 1895, loss = 78631785.64576592\n",
      "Iteration 1896, loss = 78600875.43166097\n",
      "Iteration 1897, loss = 78559954.96107510\n",
      "Iteration 1898, loss = 78535168.24006476\n",
      "Iteration 1899, loss = 78526705.86919779\n",
      "Iteration 1900, loss = 78523414.28704388\n",
      "Iteration 1901, loss = 78480822.63941361\n",
      "Iteration 1902, loss = 78437812.59476636\n",
      "Iteration 1903, loss = 78409642.61960937\n",
      "Iteration 1904, loss = 78405435.37504624\n",
      "Iteration 1905, loss = 78364888.57115155\n",
      "Iteration 1906, loss = 78339622.73481095\n",
      "Iteration 1907, loss = 78337260.25114463\n",
      "Iteration 1908, loss = 78304174.34254123\n",
      "Iteration 1909, loss = 78294704.97709537\n",
      "Iteration 1910, loss = 78246730.72457270\n",
      "Iteration 1911, loss = 78222930.21487527\n",
      "Iteration 1912, loss = 78207221.23356789\n",
      "Iteration 1913, loss = 78181354.40382932\n",
      "Iteration 1914, loss = 78138284.72082758\n",
      "Iteration 1915, loss = 78132248.08068137\n",
      "Iteration 1916, loss = 78101659.09401768\n",
      "Iteration 1917, loss = 78111391.92004962\n",
      "Iteration 1918, loss = 78040347.09401353\n",
      "Iteration 1919, loss = 78013989.51798911\n",
      "Iteration 1920, loss = 78009999.77095969\n",
      "Iteration 1921, loss = 77977446.07163747\n",
      "Iteration 1922, loss = 77946374.32453746\n",
      "Iteration 1923, loss = 77929910.41123180\n",
      "Iteration 1924, loss = 77910080.27866386\n",
      "Iteration 1925, loss = 77889801.49519351\n",
      "Iteration 1926, loss = 77859455.51916443\n",
      "Iteration 1927, loss = 77842884.72422640\n",
      "Iteration 1928, loss = 77814511.87278615\n",
      "Iteration 1929, loss = 77796402.75899236\n",
      "Iteration 1930, loss = 77769706.04888563\n",
      "Iteration 1931, loss = 77744820.80856253\n",
      "Iteration 1932, loss = 77703801.45008835\n",
      "Iteration 1933, loss = 77711056.44495562\n",
      "Iteration 1934, loss = 77688957.80354166\n",
      "Iteration 1935, loss = 77632642.77052678\n",
      "Iteration 1936, loss = 77622174.28732416\n",
      "Iteration 1937, loss = 77569603.95758097\n",
      "Iteration 1938, loss = 77564834.62049304\n",
      "Iteration 1939, loss = 77530333.98605268\n",
      "Iteration 1940, loss = 77517041.56818764\n",
      "Iteration 1941, loss = 77488197.09131637\n",
      "Iteration 1942, loss = 77492864.57140718\n",
      "Iteration 1943, loss = 77442354.07297096\n",
      "Iteration 1944, loss = 77427849.58776669\n",
      "Iteration 1945, loss = 77407316.04977214\n",
      "Iteration 1946, loss = 77382089.21958362\n",
      "Iteration 1947, loss = 77344712.55040915\n",
      "Iteration 1948, loss = 77314077.96058214\n",
      "Iteration 1949, loss = 77314433.60853498\n",
      "Iteration 1950, loss = 77269240.16187370\n",
      "Iteration 1951, loss = 77249603.93477216\n",
      "Iteration 1952, loss = 77225020.18472199\n",
      "Iteration 1953, loss = 77221970.74400698\n",
      "Iteration 1954, loss = 77178922.47613347\n",
      "Iteration 1955, loss = 77162825.32780313\n",
      "Iteration 1956, loss = 77170616.38760108\n",
      "Iteration 1957, loss = 77110272.89471044\n",
      "Iteration 1958, loss = 77069656.30156267\n",
      "Iteration 1959, loss = 77070706.57897086\n",
      "Iteration 1960, loss = 77045668.48017962\n",
      "Iteration 1961, loss = 77008657.09737775\n",
      "Iteration 1962, loss = 76982225.42709111\n",
      "Iteration 1963, loss = 76984091.66672158\n",
      "Iteration 1964, loss = 76964346.61325768\n",
      "Iteration 1965, loss = 76918307.68266921\n",
      "Iteration 1966, loss = 76893759.53509641\n",
      "Iteration 1967, loss = 76889662.83468685\n",
      "Iteration 1968, loss = 76844355.63670065\n",
      "Iteration 1969, loss = 76852109.85202698\n",
      "Iteration 1970, loss = 76814182.45484056\n",
      "Iteration 1971, loss = 76781320.92276242\n",
      "Iteration 1972, loss = 76768489.81443585\n",
      "Iteration 1973, loss = 76757752.54400046\n",
      "Iteration 1974, loss = 76718128.96550442\n",
      "Iteration 1975, loss = 76689011.15189815\n",
      "Iteration 1976, loss = 76677883.19024803\n",
      "Iteration 1977, loss = 76657940.13077027\n",
      "Iteration 1978, loss = 76632391.25649022\n",
      "Iteration 1979, loss = 76605885.63678998\n",
      "Iteration 1980, loss = 76614780.33736524\n",
      "Iteration 1981, loss = 76546248.83233233\n",
      "Iteration 1982, loss = 76517601.29763694\n",
      "Iteration 1983, loss = 76502854.90468347\n",
      "Iteration 1984, loss = 76496313.30389936\n",
      "Iteration 1985, loss = 76463217.23431487\n",
      "Iteration 1986, loss = 76442090.63712963\n",
      "Iteration 1987, loss = 76425990.68611275\n",
      "Iteration 1988, loss = 76451478.04837997\n",
      "Iteration 1989, loss = 76372495.68690127\n",
      "Iteration 1990, loss = 76356647.69570579\n",
      "Iteration 1991, loss = 76345243.29342023\n",
      "Iteration 1992, loss = 76306051.18762924\n",
      "Iteration 1993, loss = 76295124.39787096\n",
      "Iteration 1994, loss = 76258848.91969454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1995, loss = 76239533.30125427\n",
      "Iteration 1996, loss = 76218397.54604635\n",
      "Iteration 1997, loss = 76201663.14556535\n",
      "Iteration 1998, loss = 76160799.66130686\n",
      "Iteration 1999, loss = 76143789.52817802\n",
      "Iteration 2000, loss = 76135198.60352844\n",
      "Iteration 1, loss = 2737678165.13412428\n",
      "Iteration 2, loss = 2734697244.28392172\n",
      "Iteration 3, loss = 2728315089.76758671\n",
      "Iteration 4, loss = 2718726211.27241182\n",
      "Iteration 5, loss = 2706771114.84068537\n",
      "Iteration 6, loss = 2692412549.09030437\n",
      "Iteration 7, loss = 2675824663.63992739\n",
      "Iteration 8, loss = 2656983825.07263756\n",
      "Iteration 9, loss = 2636247573.81408691\n",
      "Iteration 10, loss = 2613748492.67872381\n",
      "Iteration 11, loss = 2589519288.25505781\n",
      "Iteration 12, loss = 2563398731.86204624\n",
      "Iteration 13, loss = 2536001322.37146616\n",
      "Iteration 14, loss = 2507241901.64643526\n",
      "Iteration 15, loss = 2477126500.26975775\n",
      "Iteration 16, loss = 2445733285.85910273\n",
      "Iteration 17, loss = 2413364256.06537533\n",
      "Iteration 18, loss = 2380006715.51232529\n",
      "Iteration 19, loss = 2345571558.93242455\n",
      "Iteration 20, loss = 2310438227.17250299\n",
      "Iteration 21, loss = 2274113159.90213728\n",
      "Iteration 22, loss = 2237431807.64405537\n",
      "Iteration 23, loss = 2200273041.70108843\n",
      "Iteration 24, loss = 2162970433.83109093\n",
      "Iteration 25, loss = 2124922787.87823343\n",
      "Iteration 26, loss = 2086877146.87982607\n",
      "Iteration 27, loss = 2048698079.28858113\n",
      "Iteration 28, loss = 2010221980.39048004\n",
      "Iteration 29, loss = 1971291487.16203380\n",
      "Iteration 30, loss = 1932741396.53876972\n",
      "Iteration 31, loss = 1894141183.19624424\n",
      "Iteration 32, loss = 1855654048.39923191\n",
      "Iteration 33, loss = 1817104353.47542119\n",
      "Iteration 34, loss = 1778788621.18965530\n",
      "Iteration 35, loss = 1740902621.91918325\n",
      "Iteration 36, loss = 1703398509.32288051\n",
      "Iteration 37, loss = 1666298868.25671792\n",
      "Iteration 38, loss = 1629203848.26912260\n",
      "Iteration 39, loss = 1592947502.71206403\n",
      "Iteration 40, loss = 1557321798.12491107\n",
      "Iteration 41, loss = 1522335647.05319071\n",
      "Iteration 42, loss = 1487812337.08296013\n",
      "Iteration 43, loss = 1453663389.02956462\n",
      "Iteration 44, loss = 1420642684.59511685\n",
      "Iteration 45, loss = 1388263067.76771164\n",
      "Iteration 46, loss = 1356811278.29713345\n",
      "Iteration 47, loss = 1325934980.45726752\n",
      "Iteration 48, loss = 1296117134.88929176\n",
      "Iteration 49, loss = 1267277979.48727703\n",
      "Iteration 50, loss = 1239330445.31167340\n",
      "Iteration 51, loss = 1212489305.15025496\n",
      "Iteration 52, loss = 1186486129.66610909\n",
      "Iteration 53, loss = 1161256948.04115558\n",
      "Iteration 54, loss = 1137289073.36191750\n",
      "Iteration 55, loss = 1114458591.51179743\n",
      "Iteration 56, loss = 1092654859.29153395\n",
      "Iteration 57, loss = 1071913588.32269573\n",
      "Iteration 58, loss = 1052015152.80377924\n",
      "Iteration 59, loss = 1033512556.36302447\n",
      "Iteration 60, loss = 1016111821.99273717\n",
      "Iteration 61, loss = 999860069.67677808\n",
      "Iteration 62, loss = 984725457.88863075\n",
      "Iteration 63, loss = 970596192.46749246\n",
      "Iteration 64, loss = 957862729.83212793\n",
      "Iteration 65, loss = 945912362.68630803\n",
      "Iteration 66, loss = 934807841.51441765\n",
      "Iteration 67, loss = 924518727.18025529\n",
      "Iteration 68, loss = 915410685.38833320\n",
      "Iteration 69, loss = 907093745.23321140\n",
      "Iteration 70, loss = 899682486.09935999\n",
      "Iteration 71, loss = 893065437.56685877\n",
      "Iteration 72, loss = 887175195.10137773\n",
      "Iteration 73, loss = 882036094.95770109\n",
      "Iteration 74, loss = 877631230.78881741\n",
      "Iteration 75, loss = 873897327.61169517\n",
      "Iteration 76, loss = 870609216.06754827\n",
      "Iteration 77, loss = 867822202.63344872\n",
      "Iteration 78, loss = 865406341.64057302\n",
      "Iteration 79, loss = 863330502.99634409\n",
      "Iteration 80, loss = 861755723.27862060\n",
      "Iteration 81, loss = 860435570.42604125\n",
      "Iteration 82, loss = 859293688.01258147\n",
      "Iteration 83, loss = 858373355.91427386\n",
      "Iteration 84, loss = 857579444.17448056\n",
      "Iteration 85, loss = 856856438.32920718\n",
      "Iteration 86, loss = 856314992.11660552\n",
      "Iteration 87, loss = 855816892.30054629\n",
      "Iteration 88, loss = 855362784.14248121\n",
      "Iteration 89, loss = 854953998.29843950\n",
      "Iteration 90, loss = 854570659.71121502\n",
      "Iteration 91, loss = 854176168.29081273\n",
      "Iteration 92, loss = 853827835.74696612\n",
      "Iteration 93, loss = 853472509.26087296\n",
      "Iteration 94, loss = 853117760.63834107\n",
      "Iteration 95, loss = 852797955.94847238\n",
      "Iteration 96, loss = 852442560.52111650\n",
      "Iteration 97, loss = 852096092.99003685\n",
      "Iteration 98, loss = 851742370.34901333\n",
      "Iteration 99, loss = 851396493.50989461\n",
      "Iteration 100, loss = 851053291.52439797\n",
      "Iteration 101, loss = 850703541.73800099\n",
      "Iteration 102, loss = 850357002.49113882\n",
      "Iteration 103, loss = 849990937.85949922\n",
      "Iteration 104, loss = 849624711.77162135\n",
      "Iteration 105, loss = 849269143.45188320\n",
      "Iteration 106, loss = 848909260.88051283\n",
      "Iteration 107, loss = 848537533.58965886\n",
      "Iteration 108, loss = 848179464.97596395\n",
      "Iteration 109, loss = 847793987.08060658\n",
      "Iteration 110, loss = 847434959.50101888\n",
      "Iteration 111, loss = 847072938.40585685\n",
      "Iteration 112, loss = 846685640.12422705\n",
      "Iteration 113, loss = 846338194.58608413\n",
      "Iteration 114, loss = 845960877.30812371\n",
      "Iteration 115, loss = 845600711.89124990\n",
      "Iteration 116, loss = 845245574.45182097\n",
      "Iteration 117, loss = 844848877.48036432\n",
      "Iteration 118, loss = 844481707.43537331\n",
      "Iteration 119, loss = 844097735.85496545\n",
      "Iteration 120, loss = 843745567.80758750\n",
      "Iteration 121, loss = 843346163.78236496\n",
      "Iteration 122, loss = 842975770.92340827\n",
      "Iteration 123, loss = 842601496.04412496\n",
      "Iteration 124, loss = 842241993.62949157\n",
      "Iteration 125, loss = 841837452.53798330\n",
      "Iteration 126, loss = 841462047.35266685\n",
      "Iteration 127, loss = 841095323.75390887\n",
      "Iteration 128, loss = 840705518.16953194\n",
      "Iteration 129, loss = 840350530.23083687\n",
      "Iteration 130, loss = 839947327.94488561\n",
      "Iteration 131, loss = 839569268.82470191\n",
      "Iteration 132, loss = 839235537.55842435\n",
      "Iteration 133, loss = 838862452.77238631\n",
      "Iteration 134, loss = 838462402.31466770\n",
      "Iteration 135, loss = 838094787.89963055\n",
      "Iteration 136, loss = 837723208.38382494\n",
      "Iteration 137, loss = 837331995.93417645\n",
      "Iteration 138, loss = 836978440.35244143\n",
      "Iteration 139, loss = 836595833.74786949\n",
      "Iteration 140, loss = 836230247.33183622\n",
      "Iteration 141, loss = 835848145.73082662\n",
      "Iteration 142, loss = 835466177.35219765\n",
      "Iteration 143, loss = 835089088.10858715\n",
      "Iteration 144, loss = 834716782.10986507\n",
      "Iteration 145, loss = 834356521.91679466\n",
      "Iteration 146, loss = 833963813.29222727\n",
      "Iteration 147, loss = 833577879.55763423\n",
      "Iteration 148, loss = 833205953.23828530\n",
      "Iteration 149, loss = 832846878.10085475\n",
      "Iteration 150, loss = 832455337.68901265\n",
      "Iteration 151, loss = 832074667.11787736\n",
      "Iteration 152, loss = 831708310.00548601\n",
      "Iteration 153, loss = 831330697.73110843\n",
      "Iteration 154, loss = 830946995.64734256\n",
      "Iteration 155, loss = 830564614.66805375\n",
      "Iteration 156, loss = 830201265.30462086\n",
      "Iteration 157, loss = 829834839.66545391\n",
      "Iteration 158, loss = 829438678.16812980\n",
      "Iteration 159, loss = 829053101.21808052\n",
      "Iteration 160, loss = 828681727.34126282\n",
      "Iteration 161, loss = 828303105.25579667\n",
      "Iteration 162, loss = 827925197.01468432\n",
      "Iteration 163, loss = 827562658.43319726\n",
      "Iteration 164, loss = 827156860.18151128\n",
      "Iteration 165, loss = 826787747.45976996\n",
      "Iteration 166, loss = 826398035.33250201\n",
      "Iteration 167, loss = 826007424.20714581\n",
      "Iteration 168, loss = 825623232.03846514\n",
      "Iteration 169, loss = 825268239.04248130\n",
      "Iteration 170, loss = 824856802.05500770\n",
      "Iteration 171, loss = 824496642.58344686\n",
      "Iteration 172, loss = 824079812.73276746\n",
      "Iteration 173, loss = 823734730.21170402\n",
      "Iteration 174, loss = 823327997.20289195\n",
      "Iteration 175, loss = 822952243.43795383\n",
      "Iteration 176, loss = 822577698.38615596\n",
      "Iteration 177, loss = 822184719.82011187\n",
      "Iteration 178, loss = 821795829.13098049\n",
      "Iteration 179, loss = 821420287.61601257\n",
      "Iteration 180, loss = 821017526.83737993\n",
      "Iteration 181, loss = 820627469.15047789\n",
      "Iteration 182, loss = 820252334.20648289\n",
      "Iteration 183, loss = 819871519.57343841\n",
      "Iteration 184, loss = 819488125.18771303\n",
      "Iteration 185, loss = 819087550.41482079\n",
      "Iteration 186, loss = 818696278.04203331\n",
      "Iteration 187, loss = 818308535.19222164\n",
      "Iteration 188, loss = 817937948.27127612\n",
      "Iteration 189, loss = 817544296.66682673\n",
      "Iteration 190, loss = 817143474.06515443\n",
      "Iteration 191, loss = 816743209.28691280\n",
      "Iteration 192, loss = 816365692.38856924\n",
      "Iteration 193, loss = 815976333.72111511\n",
      "Iteration 194, loss = 815601613.43816054\n",
      "Iteration 195, loss = 815192545.98944223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 196, loss = 814807068.24932289\n",
      "Iteration 197, loss = 814414857.77020872\n",
      "Iteration 198, loss = 814013521.04873228\n",
      "Iteration 199, loss = 813628898.19819391\n",
      "Iteration 200, loss = 813246999.92156565\n",
      "Iteration 201, loss = 812830205.02468944\n",
      "Iteration 202, loss = 812438204.94492650\n",
      "Iteration 203, loss = 812087338.14454865\n",
      "Iteration 204, loss = 811685460.09499705\n",
      "Iteration 205, loss = 811282312.95012546\n",
      "Iteration 206, loss = 810885361.53360069\n",
      "Iteration 207, loss = 810498026.54822600\n",
      "Iteration 208, loss = 810104158.22414994\n",
      "Iteration 209, loss = 809716856.02278078\n",
      "Iteration 210, loss = 809308480.86606920\n",
      "Iteration 211, loss = 808937057.13907123\n",
      "Iteration 212, loss = 808554093.73918962\n",
      "Iteration 213, loss = 808148154.97025883\n",
      "Iteration 214, loss = 807763098.82702279\n",
      "Iteration 215, loss = 807350570.99215043\n",
      "Iteration 216, loss = 806965900.22057855\n",
      "Iteration 217, loss = 806601393.30321193\n",
      "Iteration 218, loss = 806184547.47828090\n",
      "Iteration 219, loss = 805812669.92134464\n",
      "Iteration 220, loss = 805412430.57903564\n",
      "Iteration 221, loss = 805016896.49811995\n",
      "Iteration 222, loss = 804620514.87772286\n",
      "Iteration 223, loss = 804247676.17914617\n",
      "Iteration 224, loss = 803834343.53454566\n",
      "Iteration 225, loss = 803449694.29763365\n",
      "Iteration 226, loss = 803076075.29161656\n",
      "Iteration 227, loss = 802695783.61796606\n",
      "Iteration 228, loss = 802272920.52228844\n",
      "Iteration 229, loss = 801882321.27352881\n",
      "Iteration 230, loss = 801461387.49362612\n",
      "Iteration 231, loss = 801062848.33139610\n",
      "Iteration 232, loss = 800668992.41196191\n",
      "Iteration 233, loss = 800275398.39663136\n",
      "Iteration 234, loss = 799866226.27014184\n",
      "Iteration 235, loss = 799467698.87372923\n",
      "Iteration 236, loss = 799086792.47137344\n",
      "Iteration 237, loss = 798670051.78950083\n",
      "Iteration 238, loss = 798283484.94643462\n",
      "Iteration 239, loss = 797875286.22370982\n",
      "Iteration 240, loss = 797461279.63241267\n",
      "Iteration 241, loss = 797054612.23482418\n",
      "Iteration 242, loss = 796650432.81466293\n",
      "Iteration 243, loss = 796232671.92490852\n",
      "Iteration 244, loss = 795821684.31202471\n",
      "Iteration 245, loss = 795412526.78710151\n",
      "Iteration 246, loss = 795000500.17103493\n",
      "Iteration 247, loss = 794595216.92510486\n",
      "Iteration 248, loss = 794178658.68649328\n",
      "Iteration 249, loss = 793767073.44450390\n",
      "Iteration 250, loss = 793350716.74778008\n",
      "Iteration 251, loss = 792928109.52406967\n",
      "Iteration 252, loss = 792510421.33985734\n",
      "Iteration 253, loss = 792073284.01894915\n",
      "Iteration 254, loss = 791662320.68128085\n",
      "Iteration 255, loss = 791258606.75615120\n",
      "Iteration 256, loss = 790838103.69063044\n",
      "Iteration 257, loss = 790414640.18257165\n",
      "Iteration 258, loss = 790010965.35972548\n",
      "Iteration 259, loss = 789587881.24672365\n",
      "Iteration 260, loss = 789171329.48849332\n",
      "Iteration 261, loss = 788750752.15851057\n",
      "Iteration 262, loss = 788330523.63454831\n",
      "Iteration 263, loss = 787919868.22616911\n",
      "Iteration 264, loss = 787501927.46860659\n",
      "Iteration 265, loss = 787073814.21865618\n",
      "Iteration 266, loss = 786651457.79573512\n",
      "Iteration 267, loss = 786239245.54386055\n",
      "Iteration 268, loss = 785824246.90113366\n",
      "Iteration 269, loss = 785376926.48836839\n",
      "Iteration 270, loss = 784971717.84909308\n",
      "Iteration 271, loss = 784510778.97959495\n",
      "Iteration 272, loss = 784098324.75973034\n",
      "Iteration 273, loss = 783657009.42954457\n",
      "Iteration 274, loss = 783237278.76371634\n",
      "Iteration 275, loss = 782805472.19847810\n",
      "Iteration 276, loss = 782369361.29610813\n",
      "Iteration 277, loss = 781920392.66330707\n",
      "Iteration 278, loss = 781482053.91830242\n",
      "Iteration 279, loss = 781060186.82321680\n",
      "Iteration 280, loss = 780604066.01807415\n",
      "Iteration 281, loss = 780166093.51092017\n",
      "Iteration 282, loss = 779730094.41758084\n",
      "Iteration 283, loss = 779282241.61723721\n",
      "Iteration 284, loss = 778848180.89622951\n",
      "Iteration 285, loss = 778404999.79320776\n",
      "Iteration 286, loss = 777967695.07172191\n",
      "Iteration 287, loss = 777530887.94480491\n",
      "Iteration 288, loss = 777110556.91588485\n",
      "Iteration 289, loss = 776686582.09501243\n",
      "Iteration 290, loss = 776228643.46373165\n",
      "Iteration 291, loss = 775771746.79426754\n",
      "Iteration 292, loss = 775356239.42389560\n",
      "Iteration 293, loss = 774925316.29135668\n",
      "Iteration 294, loss = 774473391.34673381\n",
      "Iteration 295, loss = 774023571.48740268\n",
      "Iteration 296, loss = 773595651.05010688\n",
      "Iteration 297, loss = 773158677.99352074\n",
      "Iteration 298, loss = 772712514.91857767\n",
      "Iteration 299, loss = 772279382.30821455\n",
      "Iteration 300, loss = 771817156.45129192\n",
      "Iteration 301, loss = 771375420.14386070\n",
      "Iteration 302, loss = 770927458.90379918\n",
      "Iteration 303, loss = 770465785.41877854\n",
      "Iteration 304, loss = 770027127.04820049\n",
      "Iteration 305, loss = 769563514.46586037\n",
      "Iteration 306, loss = 769095601.76473749\n",
      "Iteration 307, loss = 768644936.96372187\n",
      "Iteration 308, loss = 768196385.77674448\n",
      "Iteration 309, loss = 767725174.61529529\n",
      "Iteration 310, loss = 767266466.43512189\n",
      "Iteration 311, loss = 766788261.19078720\n",
      "Iteration 312, loss = 766329680.48410106\n",
      "Iteration 313, loss = 765852123.64515018\n",
      "Iteration 314, loss = 765375920.77945101\n",
      "Iteration 315, loss = 764903619.41783202\n",
      "Iteration 316, loss = 764440581.99993110\n",
      "Iteration 317, loss = 763974923.63252461\n",
      "Iteration 318, loss = 763498043.86736333\n",
      "Iteration 319, loss = 763031675.72543037\n",
      "Iteration 320, loss = 762552370.84107518\n",
      "Iteration 321, loss = 762094677.67160594\n",
      "Iteration 322, loss = 761593418.36124337\n",
      "Iteration 323, loss = 761123653.66668975\n",
      "Iteration 324, loss = 760648940.99867094\n",
      "Iteration 325, loss = 760151734.61154592\n",
      "Iteration 326, loss = 759668788.92403674\n",
      "Iteration 327, loss = 759187085.35371423\n",
      "Iteration 328, loss = 758689450.64957297\n",
      "Iteration 329, loss = 758201326.34042120\n",
      "Iteration 330, loss = 757740429.12512755\n",
      "Iteration 331, loss = 757244509.95750570\n",
      "Iteration 332, loss = 756761005.01765907\n",
      "Iteration 333, loss = 756288999.56459355\n",
      "Iteration 334, loss = 755783961.94646239\n",
      "Iteration 335, loss = 755299825.86115110\n",
      "Iteration 336, loss = 754806167.38587403\n",
      "Iteration 337, loss = 754338178.13149107\n",
      "Iteration 338, loss = 753840609.15828562\n",
      "Iteration 339, loss = 753355255.80500615\n",
      "Iteration 340, loss = 752859171.75717223\n",
      "Iteration 341, loss = 752384011.93798947\n",
      "Iteration 342, loss = 751890425.04293585\n",
      "Iteration 343, loss = 751422221.67489648\n",
      "Iteration 344, loss = 750908494.01278460\n",
      "Iteration 345, loss = 750407051.66289902\n",
      "Iteration 346, loss = 749905691.33856797\n",
      "Iteration 347, loss = 749397136.30769539\n",
      "Iteration 348, loss = 748907070.04810417\n",
      "Iteration 349, loss = 748413791.94673920\n",
      "Iteration 350, loss = 747894923.09080338\n",
      "Iteration 351, loss = 747384425.42372477\n",
      "Iteration 352, loss = 746891340.59031665\n",
      "Iteration 353, loss = 746372339.51182342\n",
      "Iteration 354, loss = 745855378.69266641\n",
      "Iteration 355, loss = 745379531.71112382\n",
      "Iteration 356, loss = 744839090.95005393\n",
      "Iteration 357, loss = 744322709.98135507\n",
      "Iteration 358, loss = 743812293.04327524\n",
      "Iteration 359, loss = 743278851.66612113\n",
      "Iteration 360, loss = 742765297.29539073\n",
      "Iteration 361, loss = 742251266.78611875\n",
      "Iteration 362, loss = 741734215.82305551\n",
      "Iteration 363, loss = 741230245.49329638\n",
      "Iteration 364, loss = 740696574.42705941\n",
      "Iteration 365, loss = 740176979.80330646\n",
      "Iteration 366, loss = 739669463.36132956\n",
      "Iteration 367, loss = 739130997.45207489\n",
      "Iteration 368, loss = 738613358.17525268\n",
      "Iteration 369, loss = 738080827.65912902\n",
      "Iteration 370, loss = 737572828.00509334\n",
      "Iteration 371, loss = 737028787.04224634\n",
      "Iteration 372, loss = 736503220.15532970\n",
      "Iteration 373, loss = 735945204.66793156\n",
      "Iteration 374, loss = 735424165.14530599\n",
      "Iteration 375, loss = 734881699.03836954\n",
      "Iteration 376, loss = 734336976.48453259\n",
      "Iteration 377, loss = 733788896.99663186\n",
      "Iteration 378, loss = 733243106.93372452\n",
      "Iteration 379, loss = 732697454.47659492\n",
      "Iteration 380, loss = 732177060.75249994\n",
      "Iteration 381, loss = 731644084.71218312\n",
      "Iteration 382, loss = 731055640.93068910\n",
      "Iteration 383, loss = 730522319.83797371\n",
      "Iteration 384, loss = 729964082.58473444\n",
      "Iteration 385, loss = 729404654.52424932\n",
      "Iteration 386, loss = 728889467.79902363\n",
      "Iteration 387, loss = 728351045.09742415\n",
      "Iteration 388, loss = 727796895.42481244\n",
      "Iteration 389, loss = 727236452.24279702\n",
      "Iteration 390, loss = 726703556.52731419\n",
      "Iteration 391, loss = 726159456.84068704\n",
      "Iteration 392, loss = 725623568.93359780\n",
      "Iteration 393, loss = 725074678.27178979\n",
      "Iteration 394, loss = 724521790.28410625\n",
      "Iteration 395, loss = 723970759.58282149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 396, loss = 723430163.56560230\n",
      "Iteration 397, loss = 722870707.54274392\n",
      "Iteration 398, loss = 722305254.62006807\n",
      "Iteration 399, loss = 721759284.94508743\n",
      "Iteration 400, loss = 721191388.24849713\n",
      "Iteration 401, loss = 720637121.88609385\n",
      "Iteration 402, loss = 720077005.38241911\n",
      "Iteration 403, loss = 719499110.79980326\n",
      "Iteration 404, loss = 718930298.88328755\n",
      "Iteration 405, loss = 718369527.00380564\n",
      "Iteration 406, loss = 717800689.55009580\n",
      "Iteration 407, loss = 717233188.63773096\n",
      "Iteration 408, loss = 716640289.69852078\n",
      "Iteration 409, loss = 716049196.21847248\n",
      "Iteration 410, loss = 715466527.16696870\n",
      "Iteration 411, loss = 714913020.35556972\n",
      "Iteration 412, loss = 714315801.52857292\n",
      "Iteration 413, loss = 713715348.55851519\n",
      "Iteration 414, loss = 713135581.89726162\n",
      "Iteration 415, loss = 712570575.21958399\n",
      "Iteration 416, loss = 711971240.70560384\n",
      "Iteration 417, loss = 711363359.45541549\n",
      "Iteration 418, loss = 710777894.61455965\n",
      "Iteration 419, loss = 710193181.48621559\n",
      "Iteration 420, loss = 709599942.83440638\n",
      "Iteration 421, loss = 709037847.37773800\n",
      "Iteration 422, loss = 708411878.13160169\n",
      "Iteration 423, loss = 707818070.22102129\n",
      "Iteration 424, loss = 707243314.43073297\n",
      "Iteration 425, loss = 706630987.65326023\n",
      "Iteration 426, loss = 706019878.22947979\n",
      "Iteration 427, loss = 705391881.46865261\n",
      "Iteration 428, loss = 704785258.48423350\n",
      "Iteration 429, loss = 704192822.47268844\n",
      "Iteration 430, loss = 703602061.99783945\n",
      "Iteration 431, loss = 703003213.11111438\n",
      "Iteration 432, loss = 702388956.41660964\n",
      "Iteration 433, loss = 701819581.02123404\n",
      "Iteration 434, loss = 701181865.85374629\n",
      "Iteration 435, loss = 700599678.42592180\n",
      "Iteration 436, loss = 699956251.51497138\n",
      "Iteration 437, loss = 699362773.37236345\n",
      "Iteration 438, loss = 698735039.78338659\n",
      "Iteration 439, loss = 698121231.84272659\n",
      "Iteration 440, loss = 697484580.90469098\n",
      "Iteration 441, loss = 696880811.26357365\n",
      "Iteration 442, loss = 696234499.48075926\n",
      "Iteration 443, loss = 695585477.30757618\n",
      "Iteration 444, loss = 694965350.47308338\n",
      "Iteration 445, loss = 694332286.65319407\n",
      "Iteration 446, loss = 693698436.34485626\n",
      "Iteration 447, loss = 693058315.65779209\n",
      "Iteration 448, loss = 692424104.65081263\n",
      "Iteration 449, loss = 691811921.80638099\n",
      "Iteration 450, loss = 691159092.60464680\n",
      "Iteration 451, loss = 690510904.47201312\n",
      "Iteration 452, loss = 689883152.86925590\n",
      "Iteration 453, loss = 689251263.28329337\n",
      "Iteration 454, loss = 688642800.45169044\n",
      "Iteration 455, loss = 688021306.52783346\n",
      "Iteration 456, loss = 687365954.02437258\n",
      "Iteration 457, loss = 686737949.00738406\n",
      "Iteration 458, loss = 686166532.15462685\n",
      "Iteration 459, loss = 685536953.71005654\n",
      "Iteration 460, loss = 684922093.66237402\n",
      "Iteration 461, loss = 684299151.90094554\n",
      "Iteration 462, loss = 683679855.40881228\n",
      "Iteration 463, loss = 683056513.57021284\n",
      "Iteration 464, loss = 682405658.65803874\n",
      "Iteration 465, loss = 681769597.98622215\n",
      "Iteration 466, loss = 681126937.99640501\n",
      "Iteration 467, loss = 680480089.06324732\n",
      "Iteration 468, loss = 679796681.55289817\n",
      "Iteration 469, loss = 679160897.32263422\n",
      "Iteration 470, loss = 678497721.73844898\n",
      "Iteration 471, loss = 677815970.25550377\n",
      "Iteration 472, loss = 677150961.62149119\n",
      "Iteration 473, loss = 676464670.48061609\n",
      "Iteration 474, loss = 675783111.46924901\n",
      "Iteration 475, loss = 675082947.69807351\n",
      "Iteration 476, loss = 674384259.93821371\n",
      "Iteration 477, loss = 673709631.40902317\n",
      "Iteration 478, loss = 673027834.45137584\n",
      "Iteration 479, loss = 672319191.92358124\n",
      "Iteration 480, loss = 671633929.76382577\n",
      "Iteration 481, loss = 670940564.31874478\n",
      "Iteration 482, loss = 670236928.87802577\n",
      "Iteration 483, loss = 669538369.80191934\n",
      "Iteration 484, loss = 668838477.15021718\n",
      "Iteration 485, loss = 668156148.00258291\n",
      "Iteration 486, loss = 667418495.24775720\n",
      "Iteration 487, loss = 666731522.63050187\n",
      "Iteration 488, loss = 666009086.03285730\n",
      "Iteration 489, loss = 665288577.16436756\n",
      "Iteration 490, loss = 664570161.89379191\n",
      "Iteration 491, loss = 663859190.51183069\n",
      "Iteration 492, loss = 663172960.74479723\n",
      "Iteration 493, loss = 662453326.90032113\n",
      "Iteration 494, loss = 661765716.77095771\n",
      "Iteration 495, loss = 661061218.77713108\n",
      "Iteration 496, loss = 660316434.53974473\n",
      "Iteration 497, loss = 659578351.57773042\n",
      "Iteration 498, loss = 658859901.60514724\n",
      "Iteration 499, loss = 658146097.37504673\n",
      "Iteration 500, loss = 657420322.71104872\n",
      "Iteration 501, loss = 656698482.44187057\n",
      "Iteration 502, loss = 655979784.90277100\n",
      "Iteration 503, loss = 655269842.66339636\n",
      "Iteration 504, loss = 654531870.70640934\n",
      "Iteration 505, loss = 653825164.14530134\n",
      "Iteration 506, loss = 653089487.61334550\n",
      "Iteration 507, loss = 652353112.35165834\n",
      "Iteration 508, loss = 651620539.73491120\n",
      "Iteration 509, loss = 650892754.40836012\n",
      "Iteration 510, loss = 650148847.45911705\n",
      "Iteration 511, loss = 649403475.34768116\n",
      "Iteration 512, loss = 648644735.97748470\n",
      "Iteration 513, loss = 647906678.88939130\n",
      "Iteration 514, loss = 647170189.51707852\n",
      "Iteration 515, loss = 646424195.21555734\n",
      "Iteration 516, loss = 645693361.16666007\n",
      "Iteration 517, loss = 644913655.43017888\n",
      "Iteration 518, loss = 644174385.82139504\n",
      "Iteration 519, loss = 643431143.54666865\n",
      "Iteration 520, loss = 642686621.09861290\n",
      "Iteration 521, loss = 641955950.50066829\n",
      "Iteration 522, loss = 641198156.71164179\n",
      "Iteration 523, loss = 640430790.73691499\n",
      "Iteration 524, loss = 639706051.05553067\n",
      "Iteration 525, loss = 638945386.15512788\n",
      "Iteration 526, loss = 638191845.42655969\n",
      "Iteration 527, loss = 637462961.85453606\n",
      "Iteration 528, loss = 636686435.71298635\n",
      "Iteration 529, loss = 635926042.05470276\n",
      "Iteration 530, loss = 635158322.48998320\n",
      "Iteration 531, loss = 634395310.05012143\n",
      "Iteration 532, loss = 633649525.52947998\n",
      "Iteration 533, loss = 632863222.88517034\n",
      "Iteration 534, loss = 632097673.01408386\n",
      "Iteration 535, loss = 631320928.58906603\n",
      "Iteration 536, loss = 630549877.06197655\n",
      "Iteration 537, loss = 629782716.94389153\n",
      "Iteration 538, loss = 629004137.16094160\n",
      "Iteration 539, loss = 628238406.36351430\n",
      "Iteration 540, loss = 627448630.69217587\n",
      "Iteration 541, loss = 626667279.46102798\n",
      "Iteration 542, loss = 625872048.77373409\n",
      "Iteration 543, loss = 625092484.46991622\n",
      "Iteration 544, loss = 624318864.05543137\n",
      "Iteration 545, loss = 623539206.94914567\n",
      "Iteration 546, loss = 622744208.64118659\n",
      "Iteration 547, loss = 621962939.92444682\n",
      "Iteration 548, loss = 621199461.43832576\n",
      "Iteration 549, loss = 620406595.89075100\n",
      "Iteration 550, loss = 619617951.82660246\n",
      "Iteration 551, loss = 618862705.75481296\n",
      "Iteration 552, loss = 618081993.43507898\n",
      "Iteration 553, loss = 617259786.73044467\n",
      "Iteration 554, loss = 616506227.67182207\n",
      "Iteration 555, loss = 615716798.55905354\n",
      "Iteration 556, loss = 614947187.90910530\n",
      "Iteration 557, loss = 614171016.87487674\n",
      "Iteration 558, loss = 613423554.10485911\n",
      "Iteration 559, loss = 612652858.36184347\n",
      "Iteration 560, loss = 611853971.13397098\n",
      "Iteration 561, loss = 611062781.22364056\n",
      "Iteration 562, loss = 610298514.16047859\n",
      "Iteration 563, loss = 609508244.03370631\n",
      "Iteration 564, loss = 608734412.66901577\n",
      "Iteration 565, loss = 607964976.32469904\n",
      "Iteration 566, loss = 607166256.92338049\n",
      "Iteration 567, loss = 606377569.94955802\n",
      "Iteration 568, loss = 605587239.94220269\n",
      "Iteration 569, loss = 604796786.88394153\n",
      "Iteration 570, loss = 604025424.74884760\n",
      "Iteration 571, loss = 603203757.34576750\n",
      "Iteration 572, loss = 602423955.44490135\n",
      "Iteration 573, loss = 601636954.90745997\n",
      "Iteration 574, loss = 600862471.60374582\n",
      "Iteration 575, loss = 600071448.81502223\n",
      "Iteration 576, loss = 599294025.24533296\n",
      "Iteration 577, loss = 598476704.60023952\n",
      "Iteration 578, loss = 597676529.33132470\n",
      "Iteration 579, loss = 596845650.77331257\n",
      "Iteration 580, loss = 596036408.29385924\n",
      "Iteration 581, loss = 595257807.96332049\n",
      "Iteration 582, loss = 594461294.22386503\n",
      "Iteration 583, loss = 593635749.75801003\n",
      "Iteration 584, loss = 592858419.00067127\n",
      "Iteration 585, loss = 592049651.11932898\n",
      "Iteration 586, loss = 591254671.63573337\n",
      "Iteration 587, loss = 590466149.03777313\n",
      "Iteration 588, loss = 589667677.06978917\n",
      "Iteration 589, loss = 588879341.57428837\n",
      "Iteration 590, loss = 588078051.22718966\n",
      "Iteration 591, loss = 587334241.49365354\n",
      "Iteration 592, loss = 586529325.40850234\n",
      "Iteration 593, loss = 585792618.93469393\n",
      "Iteration 594, loss = 585053731.27237010\n",
      "Iteration 595, loss = 584286642.98311484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 596, loss = 583523714.69545817\n",
      "Iteration 597, loss = 582741123.89602435\n",
      "Iteration 598, loss = 581945347.54534614\n",
      "Iteration 599, loss = 581166079.61816585\n",
      "Iteration 600, loss = 580391239.47368348\n",
      "Iteration 601, loss = 579597434.34058034\n",
      "Iteration 602, loss = 578792023.79128063\n",
      "Iteration 603, loss = 578038749.11059988\n",
      "Iteration 604, loss = 577217142.56773615\n",
      "Iteration 605, loss = 576435148.49621367\n",
      "Iteration 606, loss = 575652088.31046057\n",
      "Iteration 607, loss = 574849962.92223382\n",
      "Iteration 608, loss = 574064488.06926131\n",
      "Iteration 609, loss = 573253573.79966700\n",
      "Iteration 610, loss = 572466615.70497751\n",
      "Iteration 611, loss = 571677715.16420937\n",
      "Iteration 612, loss = 570913249.00346041\n",
      "Iteration 613, loss = 570079829.23080826\n",
      "Iteration 614, loss = 569285812.35662460\n",
      "Iteration 615, loss = 568485241.09671354\n",
      "Iteration 616, loss = 567726126.73265374\n",
      "Iteration 617, loss = 566889519.51425159\n",
      "Iteration 618, loss = 566076247.52955532\n",
      "Iteration 619, loss = 565275060.18876660\n",
      "Iteration 620, loss = 564495151.74110031\n",
      "Iteration 621, loss = 563704317.51101506\n",
      "Iteration 622, loss = 562935689.70090866\n",
      "Iteration 623, loss = 562122994.48728120\n",
      "Iteration 624, loss = 561361267.62153006\n",
      "Iteration 625, loss = 560554016.86297846\n",
      "Iteration 626, loss = 559756060.80928993\n",
      "Iteration 627, loss = 558993697.43461394\n",
      "Iteration 628, loss = 558214164.87778568\n",
      "Iteration 629, loss = 557408372.28846979\n",
      "Iteration 630, loss = 556638322.95649779\n",
      "Iteration 631, loss = 555864882.71010816\n",
      "Iteration 632, loss = 555074276.43708372\n",
      "Iteration 633, loss = 554305754.08664310\n",
      "Iteration 634, loss = 553489740.14225578\n",
      "Iteration 635, loss = 552718428.89955771\n",
      "Iteration 636, loss = 551946787.32711875\n",
      "Iteration 637, loss = 551235743.38021493\n",
      "Iteration 638, loss = 550458961.65025258\n",
      "Iteration 639, loss = 549698694.34143555\n",
      "Iteration 640, loss = 548934885.56997073\n",
      "Iteration 641, loss = 548199378.79082286\n",
      "Iteration 642, loss = 547415033.84709442\n",
      "Iteration 643, loss = 546646968.57381189\n",
      "Iteration 644, loss = 545885470.94295120\n",
      "Iteration 645, loss = 545125907.71106458\n",
      "Iteration 646, loss = 544358832.77066672\n",
      "Iteration 647, loss = 543581752.00289071\n",
      "Iteration 648, loss = 542806777.10922325\n",
      "Iteration 649, loss = 542045547.18112087\n",
      "Iteration 650, loss = 541283594.20814168\n",
      "Iteration 651, loss = 540485912.90696764\n",
      "Iteration 652, loss = 539702567.06398106\n",
      "Iteration 653, loss = 538919074.03126383\n",
      "Iteration 654, loss = 538174833.46420634\n",
      "Iteration 655, loss = 537414222.68825924\n",
      "Iteration 656, loss = 536612768.54921508\n",
      "Iteration 657, loss = 535830691.96101564\n",
      "Iteration 658, loss = 535071304.82365352\n",
      "Iteration 659, loss = 534285635.13450199\n",
      "Iteration 660, loss = 533512427.41162992\n",
      "Iteration 661, loss = 532758174.48862380\n",
      "Iteration 662, loss = 532001839.00654286\n",
      "Iteration 663, loss = 531248773.69939983\n",
      "Iteration 664, loss = 530491740.29529381\n",
      "Iteration 665, loss = 529743549.19944888\n",
      "Iteration 666, loss = 528980428.12160355\n",
      "Iteration 667, loss = 528216080.44247848\n",
      "Iteration 668, loss = 527486569.92689645\n",
      "Iteration 669, loss = 526713304.20049918\n",
      "Iteration 670, loss = 525956525.47080570\n",
      "Iteration 671, loss = 525208404.65676546\n",
      "Iteration 672, loss = 524437768.02302867\n",
      "Iteration 673, loss = 523689218.43506289\n",
      "Iteration 674, loss = 522901496.33859861\n",
      "Iteration 675, loss = 522124454.18764335\n",
      "Iteration 676, loss = 521383305.79728168\n",
      "Iteration 677, loss = 520625448.60667723\n",
      "Iteration 678, loss = 519861004.56315231\n",
      "Iteration 679, loss = 519107541.70766234\n",
      "Iteration 680, loss = 518372757.61595422\n",
      "Iteration 681, loss = 517587024.96605885\n",
      "Iteration 682, loss = 516837917.08675492\n",
      "Iteration 683, loss = 516117500.83906955\n",
      "Iteration 684, loss = 515356640.47911215\n",
      "Iteration 685, loss = 514585732.08245444\n",
      "Iteration 686, loss = 513837532.74918491\n",
      "Iteration 687, loss = 513102285.80481249\n",
      "Iteration 688, loss = 512340578.12209046\n",
      "Iteration 689, loss = 511595760.53638875\n",
      "Iteration 690, loss = 510866142.83633709\n",
      "Iteration 691, loss = 510130259.42086917\n",
      "Iteration 692, loss = 509369723.57718074\n",
      "Iteration 693, loss = 508622239.80496281\n",
      "Iteration 694, loss = 507876410.59848779\n",
      "Iteration 695, loss = 507130817.50946683\n",
      "Iteration 696, loss = 506432182.60645497\n",
      "Iteration 697, loss = 505658452.42003143\n",
      "Iteration 698, loss = 504924973.20701838\n",
      "Iteration 699, loss = 504206788.92059237\n",
      "Iteration 700, loss = 503474533.46417069\n",
      "Iteration 701, loss = 502758142.12545037\n",
      "Iteration 702, loss = 502018675.55242205\n",
      "Iteration 703, loss = 501323271.47633165\n",
      "Iteration 704, loss = 500561650.90232831\n",
      "Iteration 705, loss = 499840363.63997918\n",
      "Iteration 706, loss = 499112447.45940357\n",
      "Iteration 707, loss = 498397930.04986000\n",
      "Iteration 708, loss = 497673440.94231057\n",
      "Iteration 709, loss = 496944308.93969041\n",
      "Iteration 710, loss = 496215276.76182348\n",
      "Iteration 711, loss = 495488479.88684154\n",
      "Iteration 712, loss = 494798990.87329113\n",
      "Iteration 713, loss = 494076874.86333770\n",
      "Iteration 714, loss = 493327167.43606400\n",
      "Iteration 715, loss = 492590302.22714925\n",
      "Iteration 716, loss = 491886403.29935974\n",
      "Iteration 717, loss = 491194609.33237773\n",
      "Iteration 718, loss = 490472876.98613656\n",
      "Iteration 719, loss = 489769924.45977020\n",
      "Iteration 720, loss = 489041150.97661400\n",
      "Iteration 721, loss = 488332989.67326123\n",
      "Iteration 722, loss = 487652822.78258502\n",
      "Iteration 723, loss = 486943319.48785937\n",
      "Iteration 724, loss = 486229357.24957341\n",
      "Iteration 725, loss = 485543933.94654334\n",
      "Iteration 726, loss = 484834520.60666800\n",
      "Iteration 727, loss = 484113795.87586755\n",
      "Iteration 728, loss = 483423539.28996116\n",
      "Iteration 729, loss = 482748631.79487151\n",
      "Iteration 730, loss = 482060544.00691378\n",
      "Iteration 731, loss = 481334835.43660080\n",
      "Iteration 732, loss = 480630295.55221134\n",
      "Iteration 733, loss = 479949134.67185050\n",
      "Iteration 734, loss = 479244914.50821495\n",
      "Iteration 735, loss = 478536720.39190638\n",
      "Iteration 736, loss = 477835131.65668696\n",
      "Iteration 737, loss = 477141082.32393843\n",
      "Iteration 738, loss = 476450185.94784427\n",
      "Iteration 739, loss = 475746611.57650644\n",
      "Iteration 740, loss = 475037611.42705375\n",
      "Iteration 741, loss = 474318546.36904836\n",
      "Iteration 742, loss = 473665320.87258667\n",
      "Iteration 743, loss = 472961201.68865329\n",
      "Iteration 744, loss = 472265735.45183724\n",
      "Iteration 745, loss = 471573776.15138549\n",
      "Iteration 746, loss = 470881446.22386730\n",
      "Iteration 747, loss = 470187938.19893032\n",
      "Iteration 748, loss = 469505879.19980550\n",
      "Iteration 749, loss = 468816765.68759149\n",
      "Iteration 750, loss = 468149802.09859097\n",
      "Iteration 751, loss = 467454674.77110147\n",
      "Iteration 752, loss = 466808755.32022142\n",
      "Iteration 753, loss = 466102878.84830636\n",
      "Iteration 754, loss = 465463822.98277885\n",
      "Iteration 755, loss = 464764557.98512918\n",
      "Iteration 756, loss = 464086305.01627409\n",
      "Iteration 757, loss = 463404222.96816880\n",
      "Iteration 758, loss = 462739796.42868042\n",
      "Iteration 759, loss = 462069217.98662341\n",
      "Iteration 760, loss = 461419669.62730294\n",
      "Iteration 761, loss = 460737444.95728755\n",
      "Iteration 762, loss = 460052456.47628903\n",
      "Iteration 763, loss = 459413362.37166655\n",
      "Iteration 764, loss = 458707976.77257574\n",
      "Iteration 765, loss = 458048385.76278394\n",
      "Iteration 766, loss = 457365942.62146175\n",
      "Iteration 767, loss = 456713241.57089072\n",
      "Iteration 768, loss = 456114711.85409027\n",
      "Iteration 769, loss = 455469171.30769634\n",
      "Iteration 770, loss = 454815940.89381021\n",
      "Iteration 771, loss = 454213908.68134469\n",
      "Iteration 772, loss = 453564455.69106710\n",
      "Iteration 773, loss = 452943654.67107213\n",
      "Iteration 774, loss = 452330991.40067518\n",
      "Iteration 775, loss = 451679769.51686925\n",
      "Iteration 776, loss = 451053183.26206917\n",
      "Iteration 777, loss = 450413835.12768507\n",
      "Iteration 778, loss = 449801391.31913429\n",
      "Iteration 779, loss = 449160144.36693984\n",
      "Iteration 780, loss = 448533951.89244974\n",
      "Iteration 781, loss = 447922730.80950201\n",
      "Iteration 782, loss = 447252206.93825763\n",
      "Iteration 783, loss = 446637097.36482680\n",
      "Iteration 784, loss = 446001384.60847646\n",
      "Iteration 785, loss = 445363644.70587593\n",
      "Iteration 786, loss = 444746383.96755773\n",
      "Iteration 787, loss = 444111545.71734309\n",
      "Iteration 788, loss = 443474248.33243781\n",
      "Iteration 789, loss = 442887201.73666245\n",
      "Iteration 790, loss = 442204257.78032529\n",
      "Iteration 791, loss = 441582999.09035069\n",
      "Iteration 792, loss = 440937769.54497486\n",
      "Iteration 793, loss = 440316381.44100094\n",
      "Iteration 794, loss = 439713406.40194184\n",
      "Iteration 795, loss = 439044977.54390174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 796, loss = 438412141.64545220\n",
      "Iteration 797, loss = 437780105.80416512\n",
      "Iteration 798, loss = 437135330.33038473\n",
      "Iteration 799, loss = 436542872.96030331\n",
      "Iteration 800, loss = 435889923.13597399\n",
      "Iteration 801, loss = 435260373.48393571\n",
      "Iteration 802, loss = 434628590.80588078\n",
      "Iteration 803, loss = 434044338.73531199\n",
      "Iteration 804, loss = 433381203.29778731\n",
      "Iteration 805, loss = 432751086.63515490\n",
      "Iteration 806, loss = 432122987.01329374\n",
      "Iteration 807, loss = 431523428.75790101\n",
      "Iteration 808, loss = 430866967.39089286\n",
      "Iteration 809, loss = 430255614.50167084\n",
      "Iteration 810, loss = 429630956.19880551\n",
      "Iteration 811, loss = 429010205.61392534\n",
      "Iteration 812, loss = 428393584.10399884\n",
      "Iteration 813, loss = 427742487.72168350\n",
      "Iteration 814, loss = 427122957.96119457\n",
      "Iteration 815, loss = 426494793.56255192\n",
      "Iteration 816, loss = 425874198.42644382\n",
      "Iteration 817, loss = 425248338.06063837\n",
      "Iteration 818, loss = 424664283.00634950\n",
      "Iteration 819, loss = 424024151.95964694\n",
      "Iteration 820, loss = 423412690.40656197\n",
      "Iteration 821, loss = 422789135.59007758\n",
      "Iteration 822, loss = 422156075.37823176\n",
      "Iteration 823, loss = 421536999.75211817\n",
      "Iteration 824, loss = 420902435.44454437\n",
      "Iteration 825, loss = 420312166.92703640\n",
      "Iteration 826, loss = 419662336.90082192\n",
      "Iteration 827, loss = 419079147.69626153\n",
      "Iteration 828, loss = 418476600.52116150\n",
      "Iteration 829, loss = 417852756.92429173\n",
      "Iteration 830, loss = 417238949.56687242\n",
      "Iteration 831, loss = 416643021.62514573\n",
      "Iteration 832, loss = 416036322.69576669\n",
      "Iteration 833, loss = 415429068.69832361\n",
      "Iteration 834, loss = 414816263.84220004\n",
      "Iteration 835, loss = 414199875.52241713\n",
      "Iteration 836, loss = 413639304.74460399\n",
      "Iteration 837, loss = 413010836.82554966\n",
      "Iteration 838, loss = 412404923.97276098\n",
      "Iteration 839, loss = 411792060.48370582\n",
      "Iteration 840, loss = 411195438.50472170\n",
      "Iteration 841, loss = 410582042.25829005\n",
      "Iteration 842, loss = 409993887.25151092\n",
      "Iteration 843, loss = 409378378.75619316\n",
      "Iteration 844, loss = 408742650.70482236\n",
      "Iteration 845, loss = 408149417.93311846\n",
      "Iteration 846, loss = 407562388.14669073\n",
      "Iteration 847, loss = 406944754.29435700\n",
      "Iteration 848, loss = 406328830.42965561\n",
      "Iteration 849, loss = 405723488.16022754\n",
      "Iteration 850, loss = 405104161.52402878\n",
      "Iteration 851, loss = 404497919.81457669\n",
      "Iteration 852, loss = 403879633.06176764\n",
      "Iteration 853, loss = 403280769.04464310\n",
      "Iteration 854, loss = 402688852.03474265\n",
      "Iteration 855, loss = 402063153.79189050\n",
      "Iteration 856, loss = 401441128.95258158\n",
      "Iteration 857, loss = 400837053.99295437\n",
      "Iteration 858, loss = 400227370.09637761\n",
      "Iteration 859, loss = 399639063.32685173\n",
      "Iteration 860, loss = 399023276.51884264\n",
      "Iteration 861, loss = 398449790.48056436\n",
      "Iteration 862, loss = 397849923.56800580\n",
      "Iteration 863, loss = 397235349.24293435\n",
      "Iteration 864, loss = 396633233.59412915\n",
      "Iteration 865, loss = 396027291.32927018\n",
      "Iteration 866, loss = 395467205.07717943\n",
      "Iteration 867, loss = 394827716.29230505\n",
      "Iteration 868, loss = 394230698.85692716\n",
      "Iteration 869, loss = 393637002.67964339\n",
      "Iteration 870, loss = 393065169.23788613\n",
      "Iteration 871, loss = 392462084.48672086\n",
      "Iteration 872, loss = 391854161.09478968\n",
      "Iteration 873, loss = 391256551.87618047\n",
      "Iteration 874, loss = 390658976.03733808\n",
      "Iteration 875, loss = 390080141.43840528\n",
      "Iteration 876, loss = 389489105.86202598\n",
      "Iteration 877, loss = 388862368.49184096\n",
      "Iteration 878, loss = 388283188.01656616\n",
      "Iteration 879, loss = 387692659.21483892\n",
      "Iteration 880, loss = 387091472.60572773\n",
      "Iteration 881, loss = 386512802.67638141\n",
      "Iteration 882, loss = 385896685.17735326\n",
      "Iteration 883, loss = 385309186.81631202\n",
      "Iteration 884, loss = 384705161.09947991\n",
      "Iteration 885, loss = 384168820.98333603\n",
      "Iteration 886, loss = 383556017.84097379\n",
      "Iteration 887, loss = 382965940.87635845\n",
      "Iteration 888, loss = 382406340.39597976\n",
      "Iteration 889, loss = 381822875.84837443\n",
      "Iteration 890, loss = 381223477.10751683\n",
      "Iteration 891, loss = 380655493.83871287\n",
      "Iteration 892, loss = 380065148.87881100\n",
      "Iteration 893, loss = 379503749.60355067\n",
      "Iteration 894, loss = 378942548.30545580\n",
      "Iteration 895, loss = 378358031.64569265\n",
      "Iteration 896, loss = 377764726.08780563\n",
      "Iteration 897, loss = 377198194.50219345\n",
      "Iteration 898, loss = 376628460.69792747\n",
      "Iteration 899, loss = 376052077.64975345\n",
      "Iteration 900, loss = 375487416.50655413\n",
      "Iteration 901, loss = 374867218.13825017\n",
      "Iteration 902, loss = 374312842.42857242\n",
      "Iteration 903, loss = 373700154.17602909\n",
      "Iteration 904, loss = 373142493.11509377\n",
      "Iteration 905, loss = 372571480.10253233\n",
      "Iteration 906, loss = 371993502.40119934\n",
      "Iteration 907, loss = 371368695.69904160\n",
      "Iteration 908, loss = 370835797.58796096\n",
      "Iteration 909, loss = 370238210.60495639\n",
      "Iteration 910, loss = 369683309.60409456\n",
      "Iteration 911, loss = 369123733.98397571\n",
      "Iteration 912, loss = 368498389.61931437\n",
      "Iteration 913, loss = 367969337.07028490\n",
      "Iteration 914, loss = 367399152.48340559\n",
      "Iteration 915, loss = 366789367.55103099\n",
      "Iteration 916, loss = 366251494.81761938\n",
      "Iteration 917, loss = 365660624.15091121\n",
      "Iteration 918, loss = 365075084.54250920\n",
      "Iteration 919, loss = 364543318.57858908\n",
      "Iteration 920, loss = 363915245.91903418\n",
      "Iteration 921, loss = 363353138.08299571\n",
      "Iteration 922, loss = 362778181.22490895\n",
      "Iteration 923, loss = 362193763.84813976\n",
      "Iteration 924, loss = 361599906.21685505\n",
      "Iteration 925, loss = 361055572.28932774\n",
      "Iteration 926, loss = 360515668.02257276\n",
      "Iteration 927, loss = 359885950.46393192\n",
      "Iteration 928, loss = 359323169.59270847\n",
      "Iteration 929, loss = 358804582.04807770\n",
      "Iteration 930, loss = 358185113.25080848\n",
      "Iteration 931, loss = 357610935.07138169\n",
      "Iteration 932, loss = 357026273.56278050\n",
      "Iteration 933, loss = 356470490.77997947\n",
      "Iteration 934, loss = 355886496.95192897\n",
      "Iteration 935, loss = 355332919.83840317\n",
      "Iteration 936, loss = 354757263.17465085\n",
      "Iteration 937, loss = 354220641.36265093\n",
      "Iteration 938, loss = 353620613.89603329\n",
      "Iteration 939, loss = 353112565.58036494\n",
      "Iteration 940, loss = 352487181.78472620\n",
      "Iteration 941, loss = 351931062.46005046\n",
      "Iteration 942, loss = 351357785.21108896\n",
      "Iteration 943, loss = 350817491.34524959\n",
      "Iteration 944, loss = 350255574.93462205\n",
      "Iteration 945, loss = 349708782.56395394\n",
      "Iteration 946, loss = 349160822.78878862\n",
      "Iteration 947, loss = 348583426.87257904\n",
      "Iteration 948, loss = 348020413.51966238\n",
      "Iteration 949, loss = 347483383.57815683\n",
      "Iteration 950, loss = 346921030.04169220\n",
      "Iteration 951, loss = 346389130.93777645\n",
      "Iteration 952, loss = 345819647.25796521\n",
      "Iteration 953, loss = 345241817.75738579\n",
      "Iteration 954, loss = 344688158.27103347\n",
      "Iteration 955, loss = 344133545.20499676\n",
      "Iteration 956, loss = 343591681.67511708\n",
      "Iteration 957, loss = 343037750.58026421\n",
      "Iteration 958, loss = 342486199.80184197\n",
      "Iteration 959, loss = 341945006.88767868\n",
      "Iteration 960, loss = 341392468.58560890\n",
      "Iteration 961, loss = 340840519.92303860\n",
      "Iteration 962, loss = 340287988.91388160\n",
      "Iteration 963, loss = 339755705.95850205\n",
      "Iteration 964, loss = 339189104.91990036\n",
      "Iteration 965, loss = 338636073.05062127\n",
      "Iteration 966, loss = 338058811.03077382\n",
      "Iteration 967, loss = 337550034.51468289\n",
      "Iteration 968, loss = 336983923.40044844\n",
      "Iteration 969, loss = 336400884.60159546\n",
      "Iteration 970, loss = 335868553.16834646\n",
      "Iteration 971, loss = 335297708.35540199\n",
      "Iteration 972, loss = 334721541.71606559\n",
      "Iteration 973, loss = 334176515.44776273\n",
      "Iteration 974, loss = 333622837.85159755\n",
      "Iteration 975, loss = 333075800.06708854\n",
      "Iteration 976, loss = 332514679.62992781\n",
      "Iteration 977, loss = 331975129.54121482\n",
      "Iteration 978, loss = 331394274.66088498\n",
      "Iteration 979, loss = 330833695.45160049\n",
      "Iteration 980, loss = 330301877.17070359\n",
      "Iteration 981, loss = 329733041.31671005\n",
      "Iteration 982, loss = 329198194.19065768\n",
      "Iteration 983, loss = 328648891.75893652\n",
      "Iteration 984, loss = 328094144.00969756\n",
      "Iteration 985, loss = 327529046.64378285\n",
      "Iteration 986, loss = 326999290.56315702\n",
      "Iteration 987, loss = 326444805.09630173\n",
      "Iteration 988, loss = 325883393.99331707\n",
      "Iteration 989, loss = 325394363.34167558\n",
      "Iteration 990, loss = 324760105.66662812\n",
      "Iteration 991, loss = 324213622.18925899\n",
      "Iteration 992, loss = 323688742.62332642\n",
      "Iteration 993, loss = 323124917.97182494\n",
      "Iteration 994, loss = 322560719.47494948\n",
      "Iteration 995, loss = 321984702.68965018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 996, loss = 321399332.89039624\n",
      "Iteration 997, loss = 320823391.19425768\n",
      "Iteration 998, loss = 320241512.84701473\n",
      "Iteration 999, loss = 319663286.77118909\n",
      "Iteration 1000, loss = 319084463.71506697\n",
      "Iteration 1001, loss = 318586994.43838441\n",
      "Iteration 1002, loss = 317917735.68962556\n",
      "Iteration 1003, loss = 317320382.78017104\n",
      "Iteration 1004, loss = 316754314.48525399\n",
      "Iteration 1005, loss = 316181643.48962373\n",
      "Iteration 1006, loss = 315624719.07146460\n",
      "Iteration 1007, loss = 314993079.89112085\n",
      "Iteration 1008, loss = 314384080.31281316\n",
      "Iteration 1009, loss = 313762491.26393545\n",
      "Iteration 1010, loss = 313140536.50961423\n",
      "Iteration 1011, loss = 312516773.77698290\n",
      "Iteration 1012, loss = 311881333.45191681\n",
      "Iteration 1013, loss = 311268668.92117530\n",
      "Iteration 1014, loss = 310605746.48502463\n",
      "Iteration 1015, loss = 309964395.14211202\n",
      "Iteration 1016, loss = 309344557.49670744\n",
      "Iteration 1017, loss = 308667503.15447021\n",
      "Iteration 1018, loss = 308013959.49623251\n",
      "Iteration 1019, loss = 307395156.68086118\n",
      "Iteration 1020, loss = 306731100.43889719\n",
      "Iteration 1021, loss = 306079660.68730229\n",
      "Iteration 1022, loss = 305477571.10971498\n",
      "Iteration 1023, loss = 304878227.35090250\n",
      "Iteration 1024, loss = 304164582.08378100\n",
      "Iteration 1025, loss = 303525942.83893269\n",
      "Iteration 1026, loss = 302824938.96377134\n",
      "Iteration 1027, loss = 302181093.48381281\n",
      "Iteration 1028, loss = 301449638.53247142\n",
      "Iteration 1029, loss = 300797873.99936175\n",
      "Iteration 1030, loss = 300180494.90677029\n",
      "Iteration 1031, loss = 299594560.04014307\n",
      "Iteration 1032, loss = 298979962.90239942\n",
      "Iteration 1033, loss = 298399319.21043730\n",
      "Iteration 1034, loss = 297795749.97011238\n",
      "Iteration 1035, loss = 297204441.14194232\n",
      "Iteration 1036, loss = 296596158.00548583\n",
      "Iteration 1037, loss = 296055141.35165703\n",
      "Iteration 1038, loss = 295492290.61111206\n",
      "Iteration 1039, loss = 294895359.67557049\n",
      "Iteration 1040, loss = 294332285.94648582\n",
      "Iteration 1041, loss = 293788284.44371378\n",
      "Iteration 1042, loss = 293226877.31679440\n",
      "Iteration 1043, loss = 292668883.79947609\n",
      "Iteration 1044, loss = 292157488.64050823\n",
      "Iteration 1045, loss = 291562802.22567755\n",
      "Iteration 1046, loss = 290981982.52813095\n",
      "Iteration 1047, loss = 290414523.46442884\n",
      "Iteration 1048, loss = 289907213.94228911\n",
      "Iteration 1049, loss = 289329196.11571127\n",
      "Iteration 1050, loss = 288805760.46083921\n",
      "Iteration 1051, loss = 288197367.42208320\n",
      "Iteration 1052, loss = 287659428.93474209\n",
      "Iteration 1053, loss = 287096111.14287621\n",
      "Iteration 1054, loss = 286549203.50666159\n",
      "Iteration 1055, loss = 285980291.18080866\n",
      "Iteration 1056, loss = 285433006.62579376\n",
      "Iteration 1057, loss = 284866317.51619399\n",
      "Iteration 1058, loss = 284308470.96676606\n",
      "Iteration 1059, loss = 283760634.80341452\n",
      "Iteration 1060, loss = 283195474.28586805\n",
      "Iteration 1061, loss = 282647078.15720820\n",
      "Iteration 1062, loss = 282104790.93200135\n",
      "Iteration 1063, loss = 281550874.32823473\n",
      "Iteration 1064, loss = 281010224.51815414\n",
      "Iteration 1065, loss = 280405531.31476086\n",
      "Iteration 1066, loss = 279862566.24068904\n",
      "Iteration 1067, loss = 279323520.27664107\n",
      "Iteration 1068, loss = 278781889.25772834\n",
      "Iteration 1069, loss = 278245179.70899874\n",
      "Iteration 1070, loss = 277730407.67949897\n",
      "Iteration 1071, loss = 277207564.36202842\n",
      "Iteration 1072, loss = 276675580.44636208\n",
      "Iteration 1073, loss = 276157193.60724813\n",
      "Iteration 1074, loss = 275606167.55562884\n",
      "Iteration 1075, loss = 275053353.55495930\n",
      "Iteration 1076, loss = 274513445.36029011\n",
      "Iteration 1077, loss = 274020612.07898307\n",
      "Iteration 1078, loss = 273507252.46196151\n",
      "Iteration 1079, loss = 272947517.63497025\n",
      "Iteration 1080, loss = 272419856.93347406\n",
      "Iteration 1081, loss = 271907394.97927141\n",
      "Iteration 1082, loss = 271354330.03991652\n",
      "Iteration 1083, loss = 270842509.70065182\n",
      "Iteration 1084, loss = 270318620.58270943\n",
      "Iteration 1085, loss = 269773223.53923941\n",
      "Iteration 1086, loss = 269244549.87105012\n",
      "Iteration 1087, loss = 268699734.61076003\n",
      "Iteration 1088, loss = 268189490.33726743\n",
      "Iteration 1089, loss = 267648600.26711398\n",
      "Iteration 1090, loss = 267117087.55191234\n",
      "Iteration 1091, loss = 266591239.82600421\n",
      "Iteration 1092, loss = 266066532.95444065\n",
      "Iteration 1093, loss = 265551416.50864047\n",
      "Iteration 1094, loss = 265045521.01707822\n",
      "Iteration 1095, loss = 264500867.97684181\n",
      "Iteration 1096, loss = 263962565.66530091\n",
      "Iteration 1097, loss = 263436264.24468127\n",
      "Iteration 1098, loss = 262942913.08757889\n",
      "Iteration 1099, loss = 262395779.05315626\n",
      "Iteration 1100, loss = 261862705.31545365\n",
      "Iteration 1101, loss = 261357028.30838394\n",
      "Iteration 1102, loss = 260826487.48737916\n",
      "Iteration 1103, loss = 260297641.00297457\n",
      "Iteration 1104, loss = 259803754.68860912\n",
      "Iteration 1105, loss = 259239725.61721799\n",
      "Iteration 1106, loss = 258724113.24862793\n",
      "Iteration 1107, loss = 258205941.90258223\n",
      "Iteration 1108, loss = 257670793.82928422\n",
      "Iteration 1109, loss = 257137004.75305304\n",
      "Iteration 1110, loss = 256610005.60074946\n",
      "Iteration 1111, loss = 256091353.61402413\n",
      "Iteration 1112, loss = 255610354.73053658\n",
      "Iteration 1113, loss = 255042103.57327604\n",
      "Iteration 1114, loss = 254516290.67874703\n",
      "Iteration 1115, loss = 253983527.64034298\n",
      "Iteration 1116, loss = 253437805.85559803\n",
      "Iteration 1117, loss = 252898416.48961887\n",
      "Iteration 1118, loss = 252341047.75217962\n",
      "Iteration 1119, loss = 251805031.03489798\n",
      "Iteration 1120, loss = 251260287.87224421\n",
      "Iteration 1121, loss = 250713687.02742362\n",
      "Iteration 1122, loss = 250124641.09947726\n",
      "Iteration 1123, loss = 249587528.60755050\n",
      "Iteration 1124, loss = 249042336.57557392\n",
      "Iteration 1125, loss = 248490102.72736868\n",
      "Iteration 1126, loss = 247949941.61126477\n",
      "Iteration 1127, loss = 247401554.23863527\n",
      "Iteration 1128, loss = 246804738.85970157\n",
      "Iteration 1129, loss = 246264102.64543852\n",
      "Iteration 1130, loss = 245709176.81838250\n",
      "Iteration 1131, loss = 245162080.78075275\n",
      "Iteration 1132, loss = 244586329.88432395\n",
      "Iteration 1133, loss = 244021276.58182690\n",
      "Iteration 1134, loss = 243476910.84828699\n",
      "Iteration 1135, loss = 242928256.72180820\n",
      "Iteration 1136, loss = 242391603.23810366\n",
      "Iteration 1137, loss = 241798071.24951339\n",
      "Iteration 1138, loss = 241275483.55588946\n",
      "Iteration 1139, loss = 240649415.79155010\n",
      "Iteration 1140, loss = 240096975.82503283\n",
      "Iteration 1141, loss = 239555348.01080251\n",
      "Iteration 1142, loss = 239020795.08528307\n",
      "Iteration 1143, loss = 238492226.52772981\n",
      "Iteration 1144, loss = 237972555.03666693\n",
      "Iteration 1145, loss = 237461880.35534292\n",
      "Iteration 1146, loss = 236932848.12421125\n",
      "Iteration 1147, loss = 236453288.88375604\n",
      "Iteration 1148, loss = 235919352.97047588\n",
      "Iteration 1149, loss = 235441001.93100619\n",
      "Iteration 1150, loss = 234956725.58788091\n",
      "Iteration 1151, loss = 234443641.69450918\n",
      "Iteration 1152, loss = 233953218.43579340\n",
      "Iteration 1153, loss = 233483945.47230178\n",
      "Iteration 1154, loss = 232997983.20904332\n",
      "Iteration 1155, loss = 232491599.40915558\n",
      "Iteration 1156, loss = 232033140.91943899\n",
      "Iteration 1157, loss = 231544124.65706643\n",
      "Iteration 1158, loss = 231066222.03363475\n",
      "Iteration 1159, loss = 230591033.51756755\n",
      "Iteration 1160, loss = 230114872.48120305\n",
      "Iteration 1161, loss = 229650347.29544833\n",
      "Iteration 1162, loss = 229179645.40310183\n",
      "Iteration 1163, loss = 228759713.97563425\n",
      "Iteration 1164, loss = 228227084.96454650\n",
      "Iteration 1165, loss = 227763602.49875101\n",
      "Iteration 1166, loss = 227412412.59688073\n",
      "Iteration 1167, loss = 226923267.35564050\n",
      "Iteration 1168, loss = 226471696.66593152\n",
      "Iteration 1169, loss = 225985011.77451569\n",
      "Iteration 1170, loss = 225549625.98958811\n",
      "Iteration 1171, loss = 225109184.63081139\n",
      "Iteration 1172, loss = 224647103.86890838\n",
      "Iteration 1173, loss = 224207940.34494904\n",
      "Iteration 1174, loss = 223775218.70943540\n",
      "Iteration 1175, loss = 223328551.75951412\n",
      "Iteration 1176, loss = 222870368.36767170\n",
      "Iteration 1177, loss = 222419025.29127929\n",
      "Iteration 1178, loss = 221986119.38132212\n",
      "Iteration 1179, loss = 221545501.80423272\n",
      "Iteration 1180, loss = 221083715.06650138\n",
      "Iteration 1181, loss = 220621781.13614416\n",
      "Iteration 1182, loss = 220199659.43170851\n",
      "Iteration 1183, loss = 219752781.76078972\n",
      "Iteration 1184, loss = 219277503.40148345\n",
      "Iteration 1185, loss = 218851213.01135340\n",
      "Iteration 1186, loss = 218391913.55412677\n",
      "Iteration 1187, loss = 217995149.88044646\n",
      "Iteration 1188, loss = 217486208.27078375\n",
      "Iteration 1189, loss = 217048196.55747062\n",
      "Iteration 1190, loss = 216599531.69407377\n",
      "Iteration 1191, loss = 216146858.19652840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1192, loss = 215693352.96340349\n",
      "Iteration 1193, loss = 215260195.82462245\n",
      "Iteration 1194, loss = 214834394.32232505\n",
      "Iteration 1195, loss = 214362177.86534566\n",
      "Iteration 1196, loss = 213924735.02644998\n",
      "Iteration 1197, loss = 213491442.16138875\n",
      "Iteration 1198, loss = 213051721.15217638\n",
      "Iteration 1199, loss = 212624777.68718284\n",
      "Iteration 1200, loss = 212171598.06706142\n",
      "Iteration 1201, loss = 211741651.40489310\n",
      "Iteration 1202, loss = 211295502.49738246\n",
      "Iteration 1203, loss = 210904026.57948318\n",
      "Iteration 1204, loss = 210480087.51278356\n",
      "Iteration 1205, loss = 210002938.16746178\n",
      "Iteration 1206, loss = 209575466.54839310\n",
      "Iteration 1207, loss = 209180720.76423600\n",
      "Iteration 1208, loss = 208733597.75610444\n",
      "Iteration 1209, loss = 208287904.67524403\n",
      "Iteration 1210, loss = 207873064.95529106\n",
      "Iteration 1211, loss = 207453501.01537329\n",
      "Iteration 1212, loss = 206995254.32511610\n",
      "Iteration 1213, loss = 206589545.46431464\n",
      "Iteration 1214, loss = 206195566.90089646\n",
      "Iteration 1215, loss = 205736624.56966421\n",
      "Iteration 1216, loss = 205316739.47922248\n",
      "Iteration 1217, loss = 204914498.73304498\n",
      "Iteration 1218, loss = 204483045.50842661\n",
      "Iteration 1219, loss = 204070039.66071400\n",
      "Iteration 1220, loss = 203665363.68446246\n",
      "Iteration 1221, loss = 203259912.13037223\n",
      "Iteration 1222, loss = 202807834.28801948\n",
      "Iteration 1223, loss = 202409067.61045718\n",
      "Iteration 1224, loss = 201989228.17192736\n",
      "Iteration 1225, loss = 201605345.75588146\n",
      "Iteration 1226, loss = 201154871.96765804\n",
      "Iteration 1227, loss = 200736913.11459371\n",
      "Iteration 1228, loss = 200349401.70910883\n",
      "Iteration 1229, loss = 199925163.88118055\n",
      "Iteration 1230, loss = 199522970.42052621\n",
      "Iteration 1231, loss = 199125097.70011562\n",
      "Iteration 1232, loss = 198700307.48089650\n",
      "Iteration 1233, loss = 198302887.38178548\n",
      "Iteration 1234, loss = 197888561.93752757\n",
      "Iteration 1235, loss = 197503584.70231536\n",
      "Iteration 1236, loss = 197081209.34443170\n",
      "Iteration 1237, loss = 196681288.67047173\n",
      "Iteration 1238, loss = 196278608.23351747\n",
      "Iteration 1239, loss = 195932312.01333916\n",
      "Iteration 1240, loss = 195485846.10845938\n",
      "Iteration 1241, loss = 195161303.93551615\n",
      "Iteration 1242, loss = 194718438.64793167\n",
      "Iteration 1243, loss = 194354010.43058982\n",
      "Iteration 1244, loss = 193969281.13724238\n",
      "Iteration 1245, loss = 193594510.54027832\n",
      "Iteration 1246, loss = 193200050.93449125\n",
      "Iteration 1247, loss = 192831771.38536876\n",
      "Iteration 1248, loss = 192473510.78309333\n",
      "Iteration 1249, loss = 192106108.72655302\n",
      "Iteration 1250, loss = 191741669.67094696\n",
      "Iteration 1251, loss = 191335205.30443680\n",
      "Iteration 1252, loss = 190952802.90115595\n",
      "Iteration 1253, loss = 190565148.62082911\n",
      "Iteration 1254, loss = 190197556.03367126\n",
      "Iteration 1255, loss = 189808417.96533903\n",
      "Iteration 1256, loss = 189463811.16299400\n",
      "Iteration 1257, loss = 189065152.29083857\n",
      "Iteration 1258, loss = 188678131.55697036\n",
      "Iteration 1259, loss = 188314357.21986982\n",
      "Iteration 1260, loss = 187944072.02246583\n",
      "Iteration 1261, loss = 187557971.36449435\n",
      "Iteration 1262, loss = 187169216.33545536\n",
      "Iteration 1263, loss = 186846758.64051428\n",
      "Iteration 1264, loss = 186441606.52043745\n",
      "Iteration 1265, loss = 186052966.22984654\n",
      "Iteration 1266, loss = 185681885.61948177\n",
      "Iteration 1267, loss = 185352899.81146729\n",
      "Iteration 1268, loss = 184956377.75450519\n",
      "Iteration 1269, loss = 184583893.29558435\n",
      "Iteration 1270, loss = 184221439.65205526\n",
      "Iteration 1271, loss = 183867233.97684705\n",
      "Iteration 1272, loss = 183495181.43130520\n",
      "Iteration 1273, loss = 183121331.77680600\n",
      "Iteration 1274, loss = 182749816.57423884\n",
      "Iteration 1275, loss = 182386851.40709072\n",
      "Iteration 1276, loss = 182046357.00047129\n",
      "Iteration 1277, loss = 181671073.19025111\n",
      "Iteration 1278, loss = 181326565.17501488\n",
      "Iteration 1279, loss = 180980601.84779260\n",
      "Iteration 1280, loss = 180617450.65129286\n",
      "Iteration 1281, loss = 180322647.35152212\n",
      "Iteration 1282, loss = 179929888.16739860\n",
      "Iteration 1283, loss = 179585446.29000407\n",
      "Iteration 1284, loss = 179247878.56295294\n",
      "Iteration 1285, loss = 178891985.41487637\n",
      "Iteration 1286, loss = 178570283.58372131\n",
      "Iteration 1287, loss = 178190115.54654035\n",
      "Iteration 1288, loss = 177868776.90664637\n",
      "Iteration 1289, loss = 177491253.66631061\n",
      "Iteration 1290, loss = 177173675.41797414\n",
      "Iteration 1291, loss = 176818820.05865064\n",
      "Iteration 1292, loss = 176457780.59603235\n",
      "Iteration 1293, loss = 176129967.53476599\n",
      "Iteration 1294, loss = 175758572.66993266\n",
      "Iteration 1295, loss = 175416907.02085567\n",
      "Iteration 1296, loss = 175072903.07399037\n",
      "Iteration 1297, loss = 174789105.74278271\n",
      "Iteration 1298, loss = 174413147.22783226\n",
      "Iteration 1299, loss = 174070286.54547128\n",
      "Iteration 1300, loss = 173720273.80962908\n",
      "Iteration 1301, loss = 173416922.86717892\n",
      "Iteration 1302, loss = 173074400.37662008\n",
      "Iteration 1303, loss = 172767992.81160182\n",
      "Iteration 1304, loss = 172395670.29609743\n",
      "Iteration 1305, loss = 172082084.27213344\n",
      "Iteration 1306, loss = 171738633.73773062\n",
      "Iteration 1307, loss = 171415437.87370238\n",
      "Iteration 1308, loss = 171085722.39288765\n",
      "Iteration 1309, loss = 170754529.75379780\n",
      "Iteration 1310, loss = 170428654.83407068\n",
      "Iteration 1311, loss = 170108749.17454529\n",
      "Iteration 1312, loss = 169801569.07037121\n",
      "Iteration 1313, loss = 169466720.44958586\n",
      "Iteration 1314, loss = 169133345.73488089\n",
      "Iteration 1315, loss = 168811043.29955488\n",
      "Iteration 1316, loss = 168496279.48934743\n",
      "Iteration 1317, loss = 168175971.24249834\n",
      "Iteration 1318, loss = 167865313.08893874\n",
      "Iteration 1319, loss = 167580588.12007141\n",
      "Iteration 1320, loss = 167236130.67180565\n",
      "Iteration 1321, loss = 166915467.36616975\n",
      "Iteration 1322, loss = 166636872.37089029\n",
      "Iteration 1323, loss = 166305745.70254821\n",
      "Iteration 1324, loss = 165978295.15776095\n",
      "Iteration 1325, loss = 165676251.44265705\n",
      "Iteration 1326, loss = 165370385.05986708\n",
      "Iteration 1327, loss = 165070257.00981224\n",
      "Iteration 1328, loss = 164729565.91922814\n",
      "Iteration 1329, loss = 164433176.79292551\n",
      "Iteration 1330, loss = 164126492.86520615\n",
      "Iteration 1331, loss = 163868093.52901083\n",
      "Iteration 1332, loss = 163530605.41780552\n",
      "Iteration 1333, loss = 163228693.12175518\n",
      "Iteration 1334, loss = 162886886.37805665\n",
      "Iteration 1335, loss = 162592659.32587123\n",
      "Iteration 1336, loss = 162312309.42640945\n",
      "Iteration 1337, loss = 162005573.30810487\n",
      "Iteration 1338, loss = 161726957.43250325\n",
      "Iteration 1339, loss = 161397804.46506602\n",
      "Iteration 1340, loss = 161107592.79022160\n",
      "Iteration 1341, loss = 160830318.08513731\n",
      "Iteration 1342, loss = 160521730.85438347\n",
      "Iteration 1343, loss = 160220774.00456142\n",
      "Iteration 1344, loss = 159916903.16377458\n",
      "Iteration 1345, loss = 159643886.37832543\n",
      "Iteration 1346, loss = 159366637.66250253\n",
      "Iteration 1347, loss = 159074864.72100887\n",
      "Iteration 1348, loss = 158771000.57306316\n",
      "Iteration 1349, loss = 158487620.04129764\n",
      "Iteration 1350, loss = 158190247.84713101\n",
      "Iteration 1351, loss = 157902374.67282593\n",
      "Iteration 1352, loss = 157628028.95744637\n",
      "Iteration 1353, loss = 157335821.51115558\n",
      "Iteration 1354, loss = 157064906.31026641\n",
      "Iteration 1355, loss = 156801692.37880746\n",
      "Iteration 1356, loss = 156531848.31691998\n",
      "Iteration 1357, loss = 156236983.02736142\n",
      "Iteration 1358, loss = 155940544.47084960\n",
      "Iteration 1359, loss = 155654634.38790858\n",
      "Iteration 1360, loss = 155368623.29016352\n",
      "Iteration 1361, loss = 155104285.70623735\n",
      "Iteration 1362, loss = 154865600.55797973\n",
      "Iteration 1363, loss = 154553856.32570177\n",
      "Iteration 1364, loss = 154286827.08043224\n",
      "Iteration 1365, loss = 154017514.31424594\n",
      "Iteration 1366, loss = 153737302.76292431\n",
      "Iteration 1367, loss = 153469770.68569276\n",
      "Iteration 1368, loss = 153181790.67504126\n",
      "Iteration 1369, loss = 152920468.22943011\n",
      "Iteration 1370, loss = 152657483.81774420\n",
      "Iteration 1371, loss = 152390046.92756099\n",
      "Iteration 1372, loss = 152117620.60399911\n",
      "Iteration 1373, loss = 151856128.62118840\n",
      "Iteration 1374, loss = 151596311.96057895\n",
      "Iteration 1375, loss = 151333177.29964954\n",
      "Iteration 1376, loss = 151102037.83853689\n",
      "Iteration 1377, loss = 150818208.04719475\n",
      "Iteration 1378, loss = 150568767.34087637\n",
      "Iteration 1379, loss = 150303668.90907556\n",
      "Iteration 1380, loss = 150044377.80041054\n",
      "Iteration 1381, loss = 149784201.65991142\n",
      "Iteration 1382, loss = 149539367.95892286\n",
      "Iteration 1383, loss = 149263714.82185838\n",
      "Iteration 1384, loss = 149021766.46754196\n",
      "Iteration 1385, loss = 148764992.92800424\n",
      "Iteration 1386, loss = 148520953.78754106\n",
      "Iteration 1387, loss = 148241476.97381431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1388, loss = 147984379.14480084\n",
      "Iteration 1389, loss = 147805134.89561030\n",
      "Iteration 1390, loss = 147526685.34836417\n",
      "Iteration 1391, loss = 147261231.98849314\n",
      "Iteration 1392, loss = 147018269.03197578\n",
      "Iteration 1393, loss = 146742573.55555937\n",
      "Iteration 1394, loss = 146501037.06306526\n",
      "Iteration 1395, loss = 146273229.67594343\n",
      "Iteration 1396, loss = 146042606.82268128\n",
      "Iteration 1397, loss = 145773986.61871028\n",
      "Iteration 1398, loss = 145546754.94978741\n",
      "Iteration 1399, loss = 145307165.89999521\n",
      "Iteration 1400, loss = 145056277.07493123\n",
      "Iteration 1401, loss = 144813699.18480748\n",
      "Iteration 1402, loss = 144577220.49518332\n",
      "Iteration 1403, loss = 144357817.57285804\n",
      "Iteration 1404, loss = 144104030.32075265\n",
      "Iteration 1405, loss = 143875621.11901036\n",
      "Iteration 1406, loss = 143637028.40803000\n",
      "Iteration 1407, loss = 143417976.71585432\n",
      "Iteration 1408, loss = 143159466.51232898\n",
      "Iteration 1409, loss = 142935211.71303236\n",
      "Iteration 1410, loss = 142692003.14725757\n",
      "Iteration 1411, loss = 142506602.39160317\n",
      "Iteration 1412, loss = 142226981.22100925\n",
      "Iteration 1413, loss = 142023575.35414529\n",
      "Iteration 1414, loss = 141789877.07371163\n",
      "Iteration 1415, loss = 141571894.42300761\n",
      "Iteration 1416, loss = 141333960.63568011\n",
      "Iteration 1417, loss = 141121187.81447557\n",
      "Iteration 1418, loss = 140924266.39065996\n",
      "Iteration 1419, loss = 140639799.63660148\n",
      "Iteration 1420, loss = 140451860.94400099\n",
      "Iteration 1421, loss = 140210401.51194060\n",
      "Iteration 1422, loss = 139996702.58260685\n",
      "Iteration 1423, loss = 139767615.24140975\n",
      "Iteration 1424, loss = 139566369.00751498\n",
      "Iteration 1425, loss = 139363589.67685184\n",
      "Iteration 1426, loss = 139106309.11020911\n",
      "Iteration 1427, loss = 138896301.96448687\n",
      "Iteration 1428, loss = 138662205.64992064\n",
      "Iteration 1429, loss = 138478220.80522394\n",
      "Iteration 1430, loss = 138250359.78192523\n",
      "Iteration 1431, loss = 138051580.98085809\n",
      "Iteration 1432, loss = 137807905.12004632\n",
      "Iteration 1433, loss = 137574343.66253889\n",
      "Iteration 1434, loss = 137413823.94547024\n",
      "Iteration 1435, loss = 137179601.32620597\n",
      "Iteration 1436, loss = 136951651.29897761\n",
      "Iteration 1437, loss = 136735215.00613266\n",
      "Iteration 1438, loss = 136522841.55647713\n",
      "Iteration 1439, loss = 136320474.02630225\n",
      "Iteration 1440, loss = 136108513.18944570\n",
      "Iteration 1441, loss = 135895144.21997708\n",
      "Iteration 1442, loss = 135705984.97156763\n",
      "Iteration 1443, loss = 135472045.82338959\n",
      "Iteration 1444, loss = 135274058.18238863\n",
      "Iteration 1445, loss = 135059029.57368791\n",
      "Iteration 1446, loss = 134852018.28817242\n",
      "Iteration 1447, loss = 134685845.70870653\n",
      "Iteration 1448, loss = 134461398.43719089\n",
      "Iteration 1449, loss = 134251587.21664387\n",
      "Iteration 1450, loss = 134059109.33596471\n",
      "Iteration 1451, loss = 133893775.84454368\n",
      "Iteration 1452, loss = 133640554.21375474\n",
      "Iteration 1453, loss = 133442413.66132665\n",
      "Iteration 1454, loss = 133242659.75311427\n",
      "Iteration 1455, loss = 133054380.55510598\n",
      "Iteration 1456, loss = 132849144.14720926\n",
      "Iteration 1457, loss = 132667714.28446405\n",
      "Iteration 1458, loss = 132447705.52885158\n",
      "Iteration 1459, loss = 132274622.82523592\n",
      "Iteration 1460, loss = 132047478.68096104\n",
      "Iteration 1461, loss = 131850786.61309142\n",
      "Iteration 1462, loss = 131655251.23582362\n",
      "Iteration 1463, loss = 131462893.42465676\n",
      "Iteration 1464, loss = 131267650.97660959\n",
      "Iteration 1465, loss = 131081157.65857203\n",
      "Iteration 1466, loss = 130872405.67686626\n",
      "Iteration 1467, loss = 130660940.74748819\n",
      "Iteration 1468, loss = 130482783.59954478\n",
      "Iteration 1469, loss = 130285517.68604557\n",
      "Iteration 1470, loss = 130096492.98778293\n",
      "Iteration 1471, loss = 129902445.25925353\n",
      "Iteration 1472, loss = 129733424.01369263\n",
      "Iteration 1473, loss = 129515929.74542244\n",
      "Iteration 1474, loss = 129368296.76900846\n",
      "Iteration 1475, loss = 129165268.38521948\n",
      "Iteration 1476, loss = 128975080.89603154\n",
      "Iteration 1477, loss = 128785299.64338687\n",
      "Iteration 1478, loss = 128613449.64860122\n",
      "Iteration 1479, loss = 128416270.19714977\n",
      "Iteration 1480, loss = 128243033.71820495\n",
      "Iteration 1481, loss = 128090364.16608889\n",
      "Iteration 1482, loss = 127872895.91579375\n",
      "Iteration 1483, loss = 127711407.49640201\n",
      "Iteration 1484, loss = 127536882.07475087\n",
      "Iteration 1485, loss = 127332454.03447281\n",
      "Iteration 1486, loss = 127168305.25360863\n",
      "Iteration 1487, loss = 126990045.37952651\n",
      "Iteration 1488, loss = 126814409.96580422\n",
      "Iteration 1489, loss = 126630388.62850292\n",
      "Iteration 1490, loss = 126475358.57954361\n",
      "Iteration 1491, loss = 126278647.77123702\n",
      "Iteration 1492, loss = 126162030.03473170\n",
      "Iteration 1493, loss = 125933616.80542585\n",
      "Iteration 1494, loss = 125742097.18717374\n",
      "Iteration 1495, loss = 125578889.97409290\n",
      "Iteration 1496, loss = 125398846.38342723\n",
      "Iteration 1497, loss = 125244473.63406304\n",
      "Iteration 1498, loss = 125100264.46296431\n",
      "Iteration 1499, loss = 124913971.21312405\n",
      "Iteration 1500, loss = 124709465.76776470\n",
      "Iteration 1501, loss = 124558872.46453930\n",
      "Iteration 1502, loss = 124410088.72110686\n",
      "Iteration 1503, loss = 124348312.94302863\n",
      "Iteration 1504, loss = 124036521.74724711\n",
      "Iteration 1505, loss = 123967114.45731066\n",
      "Iteration 1506, loss = 123756473.93403150\n",
      "Iteration 1507, loss = 123587462.26595646\n",
      "Iteration 1508, loss = 123434677.88471052\n",
      "Iteration 1509, loss = 123284835.22847049\n",
      "Iteration 1510, loss = 123148659.07267258\n",
      "Iteration 1511, loss = 122974483.73115629\n",
      "Iteration 1512, loss = 122842881.70254087\n",
      "Iteration 1513, loss = 122658373.18037774\n",
      "Iteration 1514, loss = 122500323.31428340\n",
      "Iteration 1515, loss = 122346742.87412585\n",
      "Iteration 1516, loss = 122189485.18122867\n",
      "Iteration 1517, loss = 122041848.15552518\n",
      "Iteration 1518, loss = 121904400.06774884\n",
      "Iteration 1519, loss = 121719195.24805932\n",
      "Iteration 1520, loss = 121566062.35645781\n",
      "Iteration 1521, loss = 121450650.73987943\n",
      "Iteration 1522, loss = 121285180.31702209\n",
      "Iteration 1523, loss = 121097613.35893218\n",
      "Iteration 1524, loss = 120936937.43732566\n",
      "Iteration 1525, loss = 120826970.47775443\n",
      "Iteration 1526, loss = 120641829.44045651\n",
      "Iteration 1527, loss = 120484390.18885495\n",
      "Iteration 1528, loss = 120350009.09272879\n",
      "Iteration 1529, loss = 120158672.32199936\n",
      "Iteration 1530, loss = 120026816.16999921\n",
      "Iteration 1531, loss = 119869187.55495867\n",
      "Iteration 1532, loss = 119729525.04817872\n",
      "Iteration 1533, loss = 119574024.05748945\n",
      "Iteration 1534, loss = 119404801.92639659\n",
      "Iteration 1535, loss = 119251635.30655620\n",
      "Iteration 1536, loss = 119105777.03372620\n",
      "Iteration 1537, loss = 118963727.69739926\n",
      "Iteration 1538, loss = 118797507.92181568\n",
      "Iteration 1539, loss = 118671216.88096683\n",
      "Iteration 1540, loss = 118487996.27516666\n",
      "Iteration 1541, loss = 118329895.02673770\n",
      "Iteration 1542, loss = 118218866.89841802\n",
      "Iteration 1543, loss = 118051663.07061052\n",
      "Iteration 1544, loss = 117957719.56462348\n",
      "Iteration 1545, loss = 117774774.93808842\n",
      "Iteration 1546, loss = 117623578.46171916\n",
      "Iteration 1547, loss = 117434586.40302029\n",
      "Iteration 1548, loss = 117286910.95116216\n",
      "Iteration 1549, loss = 117200981.49066217\n",
      "Iteration 1550, loss = 117015126.63588066\n",
      "Iteration 1551, loss = 116870034.51243660\n",
      "Iteration 1552, loss = 116741245.44151984\n",
      "Iteration 1553, loss = 116569479.46901822\n",
      "Iteration 1554, loss = 116431585.25151600\n",
      "Iteration 1555, loss = 116334439.89564395\n",
      "Iteration 1556, loss = 116186208.45997201\n",
      "Iteration 1557, loss = 116008375.79590687\n",
      "Iteration 1558, loss = 115857391.43807703\n",
      "Iteration 1559, loss = 115739255.43826459\n",
      "Iteration 1560, loss = 115585167.12372042\n",
      "Iteration 1561, loss = 115449844.02885103\n",
      "Iteration 1562, loss = 115294244.33289734\n",
      "Iteration 1563, loss = 115186534.12652019\n",
      "Iteration 1564, loss = 115025584.29227208\n",
      "Iteration 1565, loss = 114909609.37707266\n",
      "Iteration 1566, loss = 114765495.79340442\n",
      "Iteration 1567, loss = 114605925.95427015\n",
      "Iteration 1568, loss = 114499117.52869783\n",
      "Iteration 1569, loss = 114381938.03192003\n",
      "Iteration 1570, loss = 114173777.96409717\n",
      "Iteration 1571, loss = 114085922.05352847\n",
      "Iteration 1572, loss = 113947956.36912291\n",
      "Iteration 1573, loss = 113811576.79285136\n",
      "Iteration 1574, loss = 113685455.02805789\n",
      "Iteration 1575, loss = 113547491.38298222\n",
      "Iteration 1576, loss = 113413544.76628448\n",
      "Iteration 1577, loss = 113274752.17667408\n",
      "Iteration 1578, loss = 113172992.10522693\n",
      "Iteration 1579, loss = 113029301.50222947\n",
      "Iteration 1580, loss = 112900688.65998447\n",
      "Iteration 1581, loss = 112755714.39434500\n",
      "Iteration 1582, loss = 112660353.52036381\n",
      "Iteration 1583, loss = 112541250.14889304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1584, loss = 112368834.34287123\n",
      "Iteration 1585, loss = 112243080.23316793\n",
      "Iteration 1586, loss = 112118551.20819138\n",
      "Iteration 1587, loss = 111993343.65482409\n",
      "Iteration 1588, loss = 111902416.74308267\n",
      "Iteration 1589, loss = 111767610.23647404\n",
      "Iteration 1590, loss = 111623830.24882415\n",
      "Iteration 1591, loss = 111476000.70943423\n",
      "Iteration 1592, loss = 111379299.64073476\n",
      "Iteration 1593, loss = 111233421.77022506\n",
      "Iteration 1594, loss = 111145784.86063448\n",
      "Iteration 1595, loss = 110991676.45235291\n",
      "Iteration 1596, loss = 110876891.84125164\n",
      "Iteration 1597, loss = 110778222.11458063\n",
      "Iteration 1598, loss = 110638021.33550584\n",
      "Iteration 1599, loss = 110509950.16822620\n",
      "Iteration 1600, loss = 110419230.90274753\n",
      "Iteration 1601, loss = 110266676.34357579\n",
      "Iteration 1602, loss = 110158060.37750326\n",
      "Iteration 1603, loss = 110042719.53707325\n",
      "Iteration 1604, loss = 109901700.03298058\n",
      "Iteration 1605, loss = 109791487.67860338\n",
      "Iteration 1606, loss = 109670249.98465298\n",
      "Iteration 1607, loss = 109567065.89161287\n",
      "Iteration 1608, loss = 109435161.32970707\n",
      "Iteration 1609, loss = 109314928.56198442\n",
      "Iteration 1610, loss = 109224196.23100343\n",
      "Iteration 1611, loss = 109086908.10221948\n",
      "Iteration 1612, loss = 108970055.35232309\n",
      "Iteration 1613, loss = 108841120.08904240\n",
      "Iteration 1614, loss = 108711252.63786633\n",
      "Iteration 1615, loss = 108605854.97311062\n",
      "Iteration 1616, loss = 108484741.46481371\n",
      "Iteration 1617, loss = 108365588.76762670\n",
      "Iteration 1618, loss = 108276203.94783822\n",
      "Iteration 1619, loss = 108125194.75502878\n",
      "Iteration 1620, loss = 108009156.53398754\n",
      "Iteration 1621, loss = 107909600.13046937\n",
      "Iteration 1622, loss = 107774207.07787974\n",
      "Iteration 1623, loss = 107676173.50642639\n",
      "Iteration 1624, loss = 107552470.71049075\n",
      "Iteration 1625, loss = 107424366.31976169\n",
      "Iteration 1626, loss = 107337344.36164016\n",
      "Iteration 1627, loss = 107221241.04813771\n",
      "Iteration 1628, loss = 107087809.85868628\n",
      "Iteration 1629, loss = 107008370.36794491\n",
      "Iteration 1630, loss = 106891593.32968479\n",
      "Iteration 1631, loss = 106753172.02130927\n",
      "Iteration 1632, loss = 106668844.22193085\n",
      "Iteration 1633, loss = 106548688.74975444\n",
      "Iteration 1634, loss = 106439204.50365093\n",
      "Iteration 1635, loss = 106330578.54637516\n",
      "Iteration 1636, loss = 106206063.80956358\n",
      "Iteration 1637, loss = 106104976.96067140\n",
      "Iteration 1638, loss = 106008558.16379555\n",
      "Iteration 1639, loss = 105903422.79234143\n",
      "Iteration 1640, loss = 105781042.38652028\n",
      "Iteration 1641, loss = 105682157.20410165\n",
      "Iteration 1642, loss = 105568959.33990438\n",
      "Iteration 1643, loss = 105462350.14211243\n",
      "Iteration 1644, loss = 105360590.98289397\n",
      "Iteration 1645, loss = 105242155.16020821\n",
      "Iteration 1646, loss = 105140262.57466379\n",
      "Iteration 1647, loss = 105031825.06710161\n",
      "Iteration 1648, loss = 104946796.51239368\n",
      "Iteration 1649, loss = 104831122.95995449\n",
      "Iteration 1650, loss = 104743889.01799765\n",
      "Iteration 1651, loss = 104603523.10974982\n",
      "Iteration 1652, loss = 104509416.34622239\n",
      "Iteration 1653, loss = 104414564.56931227\n",
      "Iteration 1654, loss = 104321599.99641795\n",
      "Iteration 1655, loss = 104209003.31886557\n",
      "Iteration 1656, loss = 104115822.55458812\n",
      "Iteration 1657, loss = 104048288.11970808\n",
      "Iteration 1658, loss = 103902081.47320262\n",
      "Iteration 1659, loss = 103802271.67377429\n",
      "Iteration 1660, loss = 103711501.27089256\n",
      "Iteration 1661, loss = 103596301.63103411\n",
      "Iteration 1662, loss = 103513999.51746736\n",
      "Iteration 1663, loss = 103416778.42701520\n",
      "Iteration 1664, loss = 103307696.92987218\n",
      "Iteration 1665, loss = 103204616.68842021\n",
      "Iteration 1666, loss = 103113446.63086441\n",
      "Iteration 1667, loss = 103017178.34587353\n",
      "Iteration 1668, loss = 102913359.41832742\n",
      "Iteration 1669, loss = 102838346.73195736\n",
      "Iteration 1670, loss = 102754486.14881191\n",
      "Iteration 1671, loss = 102640275.35484433\n",
      "Iteration 1672, loss = 102536890.35407883\n",
      "Iteration 1673, loss = 102441610.80633733\n",
      "Iteration 1674, loss = 102377010.71680200\n",
      "Iteration 1675, loss = 102246426.88485704\n",
      "Iteration 1676, loss = 102147893.41481826\n",
      "Iteration 1677, loss = 102048984.08375807\n",
      "Iteration 1678, loss = 101973549.90019485\n",
      "Iteration 1679, loss = 101915774.27562921\n",
      "Iteration 1680, loss = 101797483.81256101\n",
      "Iteration 1681, loss = 101702557.06113182\n",
      "Iteration 1682, loss = 101595599.46036454\n",
      "Iteration 1683, loss = 101520375.85726044\n",
      "Iteration 1684, loss = 101483986.79784845\n",
      "Iteration 1685, loss = 101348804.24445890\n",
      "Iteration 1686, loss = 101233464.20633452\n",
      "Iteration 1687, loss = 101172087.79552212\n",
      "Iteration 1688, loss = 101126480.78491390\n",
      "Iteration 1689, loss = 100995233.75744030\n",
      "Iteration 1690, loss = 100922119.59700505\n",
      "Iteration 1691, loss = 100831401.75605589\n",
      "Iteration 1692, loss = 100739945.18561393\n",
      "Iteration 1693, loss = 100676452.38085234\n",
      "Iteration 1694, loss = 100589980.42418727\n",
      "Iteration 1695, loss = 100494786.03313838\n",
      "Iteration 1696, loss = 100418280.40670991\n",
      "Iteration 1697, loss = 100350550.15668721\n",
      "Iteration 1698, loss = 100255009.46938869\n",
      "Iteration 1699, loss = 100174883.79322639\n",
      "Iteration 1700, loss = 100084682.24102858\n",
      "Iteration 1701, loss = 100010375.96701221\n",
      "Iteration 1702, loss = 99949308.52166174\n",
      "Iteration 1703, loss = 99851955.81417604\n",
      "Iteration 1704, loss = 99792332.44791022\n",
      "Iteration 1705, loss = 99663930.63610895\n",
      "Iteration 1706, loss = 99591609.42227031\n",
      "Iteration 1707, loss = 99584022.67240477\n",
      "Iteration 1708, loss = 99414608.04806750\n",
      "Iteration 1709, loss = 99360476.91857377\n",
      "Iteration 1710, loss = 99252902.91954553\n",
      "Iteration 1711, loss = 99159516.97538146\n",
      "Iteration 1712, loss = 99095722.45055361\n",
      "Iteration 1713, loss = 99017069.54006065\n",
      "Iteration 1714, loss = 98942661.41699331\n",
      "Iteration 1715, loss = 98887824.55989785\n",
      "Iteration 1716, loss = 98769963.61979097\n",
      "Iteration 1717, loss = 98698823.36465845\n",
      "Iteration 1718, loss = 98622780.43575481\n",
      "Iteration 1719, loss = 98542235.13965291\n",
      "Iteration 1720, loss = 98479199.88003738\n",
      "Iteration 1721, loss = 98431067.94777688\n",
      "Iteration 1722, loss = 98291598.67192949\n",
      "Iteration 1723, loss = 98290639.62875599\n",
      "Iteration 1724, loss = 98154000.79144242\n",
      "Iteration 1725, loss = 98060093.11102244\n",
      "Iteration 1726, loss = 97987173.39849953\n",
      "Iteration 1727, loss = 97905627.43055603\n",
      "Iteration 1728, loss = 97834423.10471761\n",
      "Iteration 1729, loss = 97769144.29093659\n",
      "Iteration 1730, loss = 97695867.83219381\n",
      "Iteration 1731, loss = 97611908.20546420\n",
      "Iteration 1732, loss = 97569766.26158762\n",
      "Iteration 1733, loss = 97474921.75941774\n",
      "Iteration 1734, loss = 97387597.72113799\n",
      "Iteration 1735, loss = 97332438.43996364\n",
      "Iteration 1736, loss = 97253395.26608792\n",
      "Iteration 1737, loss = 97167978.54344624\n",
      "Iteration 1738, loss = 97113746.26315226\n",
      "Iteration 1739, loss = 97026753.82117723\n",
      "Iteration 1740, loss = 97029304.43521142\n",
      "Iteration 1741, loss = 96916123.18910860\n",
      "Iteration 1742, loss = 96808725.22831403\n",
      "Iteration 1743, loss = 96742879.99864833\n",
      "Iteration 1744, loss = 96681972.18242019\n",
      "Iteration 1745, loss = 96602783.62668231\n",
      "Iteration 1746, loss = 96531079.13624734\n",
      "Iteration 1747, loss = 96452883.36821471\n",
      "Iteration 1748, loss = 96394681.82044941\n",
      "Iteration 1749, loss = 96349645.63783625\n",
      "Iteration 1750, loss = 96238854.43011817\n",
      "Iteration 1751, loss = 96171552.22368321\n",
      "Iteration 1752, loss = 96102193.87483463\n",
      "Iteration 1753, loss = 96039427.73844892\n",
      "Iteration 1754, loss = 95964411.18656926\n",
      "Iteration 1755, loss = 95892088.49398364\n",
      "Iteration 1756, loss = 95820923.04903023\n",
      "Iteration 1757, loss = 95760207.35458407\n",
      "Iteration 1758, loss = 95690162.35913035\n",
      "Iteration 1759, loss = 95624759.02272962\n",
      "Iteration 1760, loss = 95563685.30125660\n",
      "Iteration 1761, loss = 95469660.81721775\n",
      "Iteration 1762, loss = 95435196.42379561\n",
      "Iteration 1763, loss = 95366680.87026224\n",
      "Iteration 1764, loss = 95291184.93742146\n",
      "Iteration 1765, loss = 95200568.67013498\n",
      "Iteration 1766, loss = 95148700.46536483\n",
      "Iteration 1767, loss = 95066650.12386821\n",
      "Iteration 1768, loss = 95024878.83015630\n",
      "Iteration 1769, loss = 95052650.94947015\n",
      "Iteration 1770, loss = 94889482.61928380\n",
      "Iteration 1771, loss = 94826771.74405023\n",
      "Iteration 1772, loss = 94785858.52134289\n",
      "Iteration 1773, loss = 94719669.24005608\n",
      "Iteration 1774, loss = 94634256.02166776\n",
      "Iteration 1775, loss = 94551336.29473227\n",
      "Iteration 1776, loss = 94503699.46946086\n",
      "Iteration 1777, loss = 94418413.80370404\n",
      "Iteration 1778, loss = 94379111.26478702\n",
      "Iteration 1779, loss = 94303916.69609599\n",
      "Iteration 1780, loss = 94265975.26114677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1781, loss = 94185832.43392910\n",
      "Iteration 1782, loss = 94126168.05405083\n",
      "Iteration 1783, loss = 94062456.37277137\n",
      "Iteration 1784, loss = 94000485.24384022\n",
      "Iteration 1785, loss = 93943517.10655729\n",
      "Iteration 1786, loss = 93874479.20742334\n",
      "Iteration 1787, loss = 93812723.35464692\n",
      "Iteration 1788, loss = 93745824.23562175\n",
      "Iteration 1789, loss = 93713453.51348142\n",
      "Iteration 1790, loss = 93622623.94666234\n",
      "Iteration 1791, loss = 93569632.68829949\n",
      "Iteration 1792, loss = 93504433.44717926\n",
      "Iteration 1793, loss = 93443363.64089678\n",
      "Iteration 1794, loss = 93390355.76333538\n",
      "Iteration 1795, loss = 93315023.27680998\n",
      "Iteration 1796, loss = 93267789.73885031\n",
      "Iteration 1797, loss = 93205787.26081069\n",
      "Iteration 1798, loss = 93184063.44275427\n",
      "Iteration 1799, loss = 93085642.00991201\n",
      "Iteration 1800, loss = 93044830.21948616\n",
      "Iteration 1801, loss = 92958579.67482339\n",
      "Iteration 1802, loss = 92897485.80634572\n",
      "Iteration 1803, loss = 92826102.02200532\n",
      "Iteration 1804, loss = 92771851.70379370\n",
      "Iteration 1805, loss = 92738190.09225753\n",
      "Iteration 1806, loss = 92680757.34879415\n",
      "Iteration 1807, loss = 92625679.22415695\n",
      "Iteration 1808, loss = 92582332.94197130\n",
      "Iteration 1809, loss = 92492852.05743794\n",
      "Iteration 1810, loss = 92445969.54306190\n",
      "Iteration 1811, loss = 92388335.77614526\n",
      "Iteration 1812, loss = 92330586.48956200\n",
      "Iteration 1813, loss = 92265283.94625753\n",
      "Iteration 1814, loss = 92222085.91354084\n",
      "Iteration 1815, loss = 92181361.28264411\n",
      "Iteration 1816, loss = 92081604.82168664\n",
      "Iteration 1817, loss = 92057921.50929458\n",
      "Iteration 1818, loss = 92018296.67520353\n",
      "Iteration 1819, loss = 91935904.00961599\n",
      "Iteration 1820, loss = 91887954.43184850\n",
      "Iteration 1821, loss = 91811196.45963760\n",
      "Iteration 1822, loss = 91757959.58438957\n",
      "Iteration 1823, loss = 91699405.15561123\n",
      "Iteration 1824, loss = 91650702.50794633\n",
      "Iteration 1825, loss = 91676778.33844656\n",
      "Iteration 1826, loss = 91565805.93389988\n",
      "Iteration 1827, loss = 91501909.96176726\n",
      "Iteration 1828, loss = 91432171.57616697\n",
      "Iteration 1829, loss = 91405907.07097772\n",
      "Iteration 1830, loss = 91334751.85094553\n",
      "Iteration 1831, loss = 91298077.57139862\n",
      "Iteration 1832, loss = 91224684.61915980\n",
      "Iteration 1833, loss = 91184950.67873821\n",
      "Iteration 1834, loss = 91128304.98231320\n",
      "Iteration 1835, loss = 91061787.86652140\n",
      "Iteration 1836, loss = 91044850.86703558\n",
      "Iteration 1837, loss = 90988279.89802615\n",
      "Iteration 1838, loss = 90921729.42979258\n",
      "Iteration 1839, loss = 90861855.62336349\n",
      "Iteration 1840, loss = 90818467.85240687\n",
      "Iteration 1841, loss = 90762391.04474965\n",
      "Iteration 1842, loss = 90713016.72221091\n",
      "Iteration 1843, loss = 90656101.55646887\n",
      "Iteration 1844, loss = 90623677.53510042\n",
      "Iteration 1845, loss = 90548328.40291739\n",
      "Iteration 1846, loss = 90519738.35883932\n",
      "Iteration 1847, loss = 90452489.63379061\n",
      "Iteration 1848, loss = 90407001.64203049\n",
      "Iteration 1849, loss = 90376292.11968194\n",
      "Iteration 1850, loss = 90314147.90250112\n",
      "Iteration 1851, loss = 90263274.47380228\n",
      "Iteration 1852, loss = 90205533.82288098\n",
      "Iteration 1853, loss = 90158890.31710552\n",
      "Iteration 1854, loss = 90101198.84144720\n",
      "Iteration 1855, loss = 90049254.62392601\n",
      "Iteration 1856, loss = 90016453.32191758\n",
      "Iteration 1857, loss = 89972424.10019234\n",
      "Iteration 1858, loss = 89931425.43249510\n",
      "Iteration 1859, loss = 89846095.65381752\n",
      "Iteration 1860, loss = 89799245.73437989\n",
      "Iteration 1861, loss = 89769553.25385007\n",
      "Iteration 1862, loss = 89745407.49308437\n",
      "Iteration 1863, loss = 89673203.46271791\n",
      "Iteration 1864, loss = 89600866.20968284\n",
      "Iteration 1865, loss = 89561927.64875713\n",
      "Iteration 1866, loss = 89524594.76823774\n",
      "Iteration 1867, loss = 89465858.51825497\n",
      "Iteration 1868, loss = 89415317.98608319\n",
      "Iteration 1869, loss = 89389106.97009113\n",
      "Iteration 1870, loss = 89346311.70712438\n",
      "Iteration 1871, loss = 89273903.00986245\n",
      "Iteration 1872, loss = 89214456.98467693\n",
      "Iteration 1873, loss = 89200478.75462441\n",
      "Iteration 1874, loss = 89135830.73558722\n",
      "Iteration 1875, loss = 89083283.54908772\n",
      "Iteration 1876, loss = 89040523.44345972\n",
      "Iteration 1877, loss = 89011478.28113888\n",
      "Iteration 1878, loss = 88954846.80999821\n",
      "Iteration 1879, loss = 88903392.13334852\n",
      "Iteration 1880, loss = 88863648.81180780\n",
      "Iteration 1881, loss = 88811850.40401639\n",
      "Iteration 1882, loss = 88779057.38458432\n",
      "Iteration 1883, loss = 88707929.49763158\n",
      "Iteration 1884, loss = 88666649.01576227\n",
      "Iteration 1885, loss = 88641812.04421660\n",
      "Iteration 1886, loss = 88651243.07079776\n",
      "Iteration 1887, loss = 88538009.63378417\n",
      "Iteration 1888, loss = 88495203.99972598\n",
      "Iteration 1889, loss = 88445380.28375302\n",
      "Iteration 1890, loss = 88409560.66187927\n",
      "Iteration 1891, loss = 88389145.60311586\n",
      "Iteration 1892, loss = 88344804.54481964\n",
      "Iteration 1893, loss = 88275839.13260664\n",
      "Iteration 1894, loss = 88230862.11843406\n",
      "Iteration 1895, loss = 88194493.71587317\n",
      "Iteration 1896, loss = 88151565.41195478\n",
      "Iteration 1897, loss = 88108015.18378051\n",
      "Iteration 1898, loss = 88058241.84825723\n",
      "Iteration 1899, loss = 88039864.74361923\n",
      "Iteration 1900, loss = 88035661.43625788\n",
      "Iteration 1901, loss = 87925702.21285573\n",
      "Iteration 1902, loss = 87902412.84576000\n",
      "Iteration 1903, loss = 87848904.64347294\n",
      "Iteration 1904, loss = 87827823.92371672\n",
      "Iteration 1905, loss = 87774212.30555740\n",
      "Iteration 1906, loss = 87726978.44049945\n",
      "Iteration 1907, loss = 87705879.01163562\n",
      "Iteration 1908, loss = 87653226.33155988\n",
      "Iteration 1909, loss = 87633826.52688046\n",
      "Iteration 1910, loss = 87607951.91491984\n",
      "Iteration 1911, loss = 87538699.08346531\n",
      "Iteration 1912, loss = 87513910.39980790\n",
      "Iteration 1913, loss = 87464602.80438915\n",
      "Iteration 1914, loss = 87417456.50582084\n",
      "Iteration 1915, loss = 87369492.71236169\n",
      "Iteration 1916, loss = 87344599.63302493\n",
      "Iteration 1917, loss = 87306809.69620956\n",
      "Iteration 1918, loss = 87304410.90879057\n",
      "Iteration 1919, loss = 87263211.56514296\n",
      "Iteration 1920, loss = 87202120.03608692\n",
      "Iteration 1921, loss = 87138702.64037667\n",
      "Iteration 1922, loss = 87110689.44873595\n",
      "Iteration 1923, loss = 87063630.42297406\n",
      "Iteration 1924, loss = 87042679.63196646\n",
      "Iteration 1925, loss = 87002994.71088588\n",
      "Iteration 1926, loss = 86938970.78223266\n",
      "Iteration 1927, loss = 86884858.77792740\n",
      "Iteration 1928, loss = 86861209.57480483\n",
      "Iteration 1929, loss = 86820382.60793345\n",
      "Iteration 1930, loss = 86789347.44882299\n",
      "Iteration 1931, loss = 86727742.99712494\n",
      "Iteration 1932, loss = 86711643.68602644\n",
      "Iteration 1933, loss = 86669735.97020854\n",
      "Iteration 1934, loss = 86663377.65708561\n",
      "Iteration 1935, loss = 86614793.26733649\n",
      "Iteration 1936, loss = 86572094.69743067\n",
      "Iteration 1937, loss = 86514209.14260301\n",
      "Iteration 1938, loss = 86481442.37539148\n",
      "Iteration 1939, loss = 86432741.42003450\n",
      "Iteration 1940, loss = 86415009.36321680\n",
      "Iteration 1941, loss = 86344768.01098476\n",
      "Iteration 1942, loss = 86320397.10331140\n",
      "Iteration 1943, loss = 86287971.27415588\n",
      "Iteration 1944, loss = 86239377.03058873\n",
      "Iteration 1945, loss = 86207027.16125798\n",
      "Iteration 1946, loss = 86173220.67547879\n",
      "Iteration 1947, loss = 86119338.47998296\n",
      "Iteration 1948, loss = 86075387.87448184\n",
      "Iteration 1949, loss = 86046102.04320303\n",
      "Iteration 1950, loss = 86014118.79754563\n",
      "Iteration 1951, loss = 85959886.40012400\n",
      "Iteration 1952, loss = 85954319.28958671\n",
      "Iteration 1953, loss = 85895322.85447221\n",
      "Iteration 1954, loss = 85875521.37792823\n",
      "Iteration 1955, loss = 85812495.92410465\n",
      "Iteration 1956, loss = 85780810.86860687\n",
      "Iteration 1957, loss = 85748118.78537874\n",
      "Iteration 1958, loss = 85706013.65117288\n",
      "Iteration 1959, loss = 85674048.17535403\n",
      "Iteration 1960, loss = 85638324.09076598\n",
      "Iteration 1961, loss = 85595823.02387346\n",
      "Iteration 1962, loss = 85561004.72063649\n",
      "Iteration 1963, loss = 85557751.26064420\n",
      "Iteration 1964, loss = 85535973.43650308\n",
      "Iteration 1965, loss = 85476727.09947981\n",
      "Iteration 1966, loss = 85439633.97845639\n",
      "Iteration 1967, loss = 85397613.54736061\n",
      "Iteration 1968, loss = 85352789.89066619\n",
      "Iteration 1969, loss = 85324448.09492743\n",
      "Iteration 1970, loss = 85287745.57446903\n",
      "Iteration 1971, loss = 85275172.02573110\n",
      "Iteration 1972, loss = 85233094.14059211\n",
      "Iteration 1973, loss = 85180083.58738689\n",
      "Iteration 1974, loss = 85137506.83923069\n",
      "Iteration 1975, loss = 85085277.49718753\n",
      "Iteration 1976, loss = 85061198.44710712\n",
      "Iteration 1977, loss = 85019971.65037763\n",
      "Iteration 1978, loss = 85016373.88956787\n",
      "Iteration 1979, loss = 84979036.91623446\n",
      "Iteration 1980, loss = 84926289.22451386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1981, loss = 84900057.64679454\n",
      "Iteration 1982, loss = 84863826.58371381\n",
      "Iteration 1983, loss = 84857044.10765971\n",
      "Iteration 1984, loss = 84808388.39004189\n",
      "Iteration 1985, loss = 84773240.55738986\n",
      "Iteration 1986, loss = 84746379.61287971\n",
      "Iteration 1987, loss = 84703303.24155413\n",
      "Iteration 1988, loss = 84682745.05280456\n",
      "Iteration 1989, loss = 84637197.96456790\n",
      "Iteration 1990, loss = 84599645.11085887\n",
      "Iteration 1991, loss = 84568166.51100685\n",
      "Iteration 1992, loss = 84551295.96143147\n",
      "Iteration 1993, loss = 84492708.78951451\n",
      "Iteration 1994, loss = 84496959.52393357\n",
      "Iteration 1995, loss = 84459664.59464064\n",
      "Iteration 1996, loss = 84401647.58324134\n",
      "Iteration 1997, loss = 84400872.58790976\n",
      "Iteration 1998, loss = 84350271.74918349\n",
      "Iteration 1999, loss = 84333128.07462969\n",
      "Iteration 2000, loss = 84257401.17633151\n",
      "Iteration 1, loss = 2737904361.82250643\n",
      "Iteration 2, loss = 2735040491.49783516\n",
      "Iteration 3, loss = 2728929934.32746315\n",
      "Iteration 4, loss = 2719294410.54264450\n",
      "Iteration 5, loss = 2707356924.81436634\n",
      "Iteration 6, loss = 2693102958.53539848\n",
      "Iteration 7, loss = 2676621847.45483351\n",
      "Iteration 8, loss = 2657905499.86019278\n",
      "Iteration 9, loss = 2637335428.30476904\n",
      "Iteration 10, loss = 2614868077.41245127\n",
      "Iteration 11, loss = 2590730450.56610584\n",
      "Iteration 12, loss = 2564919345.87303972\n",
      "Iteration 13, loss = 2537509746.86435699\n",
      "Iteration 14, loss = 2508647731.96847439\n",
      "Iteration 15, loss = 2478590831.51830101\n",
      "Iteration 16, loss = 2447255400.89590788\n",
      "Iteration 17, loss = 2414868889.34891653\n",
      "Iteration 18, loss = 2381260779.03872490\n",
      "Iteration 19, loss = 2347008588.40647888\n",
      "Iteration 20, loss = 2311979209.48968029\n",
      "Iteration 21, loss = 2275773240.22127295\n",
      "Iteration 22, loss = 2239552566.25271273\n",
      "Iteration 23, loss = 2202981259.09433794\n",
      "Iteration 24, loss = 2165948561.62985754\n",
      "Iteration 25, loss = 2128188746.02136040\n",
      "Iteration 26, loss = 2090155325.79498982\n",
      "Iteration 27, loss = 2052144863.95379043\n",
      "Iteration 28, loss = 2013878370.09997821\n",
      "Iteration 29, loss = 1975201970.07999587\n",
      "Iteration 30, loss = 1936599424.07212543\n",
      "Iteration 31, loss = 1898162604.54194212\n",
      "Iteration 32, loss = 1860072120.25387192\n",
      "Iteration 33, loss = 1821995415.21403098\n",
      "Iteration 34, loss = 1784139089.09950209\n",
      "Iteration 35, loss = 1746546559.61789608\n",
      "Iteration 36, loss = 1709106518.77690291\n",
      "Iteration 37, loss = 1672064265.87907648\n",
      "Iteration 38, loss = 1635657475.74019742\n",
      "Iteration 39, loss = 1599773701.12165546\n",
      "Iteration 40, loss = 1564144005.40024734\n",
      "Iteration 41, loss = 1529060494.62280250\n",
      "Iteration 42, loss = 1494938059.57828474\n",
      "Iteration 43, loss = 1461612424.34692574\n",
      "Iteration 44, loss = 1428885388.18419719\n",
      "Iteration 45, loss = 1396741099.19833612\n",
      "Iteration 46, loss = 1365422154.97981596\n",
      "Iteration 47, loss = 1334799936.08810449\n",
      "Iteration 48, loss = 1305162716.93521595\n",
      "Iteration 49, loss = 1276513564.50545645\n",
      "Iteration 50, loss = 1248825548.70840669\n",
      "Iteration 51, loss = 1221986191.66540670\n",
      "Iteration 52, loss = 1196171159.16482902\n",
      "Iteration 53, loss = 1171696422.18946385\n",
      "Iteration 54, loss = 1147894524.02889562\n",
      "Iteration 55, loss = 1125266318.83497572\n",
      "Iteration 56, loss = 1103745289.06338596\n",
      "Iteration 57, loss = 1083347533.08589292\n",
      "Iteration 58, loss = 1064021823.54255497\n",
      "Iteration 59, loss = 1045798665.98961329\n",
      "Iteration 60, loss = 1028638898.60020268\n",
      "Iteration 61, loss = 1012624751.52225065\n",
      "Iteration 62, loss = 997546039.58787727\n",
      "Iteration 63, loss = 983527238.83736908\n",
      "Iteration 64, loss = 970646591.46143365\n",
      "Iteration 65, loss = 958745587.88896775\n",
      "Iteration 66, loss = 947872135.87709320\n",
      "Iteration 67, loss = 937923565.45791507\n",
      "Iteration 68, loss = 928905647.59333277\n",
      "Iteration 69, loss = 920869389.62521541\n",
      "Iteration 70, loss = 913596751.98844993\n",
      "Iteration 71, loss = 907221722.75259662\n",
      "Iteration 72, loss = 901523328.74633074\n",
      "Iteration 73, loss = 896507296.29891956\n",
      "Iteration 74, loss = 892166869.18952346\n",
      "Iteration 75, loss = 888290007.87861574\n",
      "Iteration 76, loss = 885109068.47139072\n",
      "Iteration 77, loss = 882374547.91445625\n",
      "Iteration 78, loss = 880093319.75826621\n",
      "Iteration 79, loss = 878202760.19690108\n",
      "Iteration 80, loss = 876565111.01516223\n",
      "Iteration 81, loss = 875253612.47404778\n",
      "Iteration 82, loss = 874134715.12343681\n",
      "Iteration 83, loss = 873200206.15674186\n",
      "Iteration 84, loss = 872425190.37557578\n",
      "Iteration 85, loss = 871792256.51677561\n",
      "Iteration 86, loss = 871215790.62397397\n",
      "Iteration 87, loss = 870710081.31536198\n",
      "Iteration 88, loss = 870271873.83732426\n",
      "Iteration 89, loss = 869863591.67590380\n",
      "Iteration 90, loss = 869443486.31304324\n",
      "Iteration 91, loss = 869085245.97112310\n",
      "Iteration 92, loss = 868727072.47147334\n",
      "Iteration 93, loss = 868377290.93205738\n",
      "Iteration 94, loss = 868057420.19919622\n",
      "Iteration 95, loss = 867693193.97619689\n",
      "Iteration 96, loss = 867345389.95775175\n",
      "Iteration 97, loss = 866997495.04904830\n",
      "Iteration 98, loss = 866651666.92068899\n",
      "Iteration 99, loss = 866290124.95110381\n",
      "Iteration 100, loss = 865956623.85636282\n",
      "Iteration 101, loss = 865582604.13781273\n",
      "Iteration 102, loss = 865229327.31639147\n",
      "Iteration 103, loss = 864884387.14563274\n",
      "Iteration 104, loss = 864525918.70179296\n",
      "Iteration 105, loss = 864174873.26468122\n",
      "Iteration 106, loss = 863767615.95845711\n",
      "Iteration 107, loss = 863408427.30555880\n",
      "Iteration 108, loss = 863040376.19917321\n",
      "Iteration 109, loss = 862681638.82457709\n",
      "Iteration 110, loss = 862306190.35736394\n",
      "Iteration 111, loss = 861925205.17829823\n",
      "Iteration 112, loss = 861551886.67141438\n",
      "Iteration 113, loss = 861177167.14159536\n",
      "Iteration 114, loss = 860783904.75087976\n",
      "Iteration 115, loss = 860421467.09478319\n",
      "Iteration 116, loss = 860046771.65810442\n",
      "Iteration 117, loss = 859666112.89520299\n",
      "Iteration 118, loss = 859273182.58416951\n",
      "Iteration 119, loss = 858896361.17977226\n",
      "Iteration 120, loss = 858505659.07798731\n",
      "Iteration 121, loss = 858131918.53650606\n",
      "Iteration 122, loss = 857750067.16773796\n",
      "Iteration 123, loss = 857353575.70459104\n",
      "Iteration 124, loss = 856991530.44913113\n",
      "Iteration 125, loss = 856586868.32912910\n",
      "Iteration 126, loss = 856217457.58339500\n",
      "Iteration 127, loss = 855828867.45239353\n",
      "Iteration 128, loss = 855458443.65880203\n",
      "Iteration 129, loss = 855060632.37277126\n",
      "Iteration 130, loss = 854684678.16239440\n",
      "Iteration 131, loss = 854280395.78018200\n",
      "Iteration 132, loss = 853904802.12672257\n",
      "Iteration 133, loss = 853499493.44401813\n",
      "Iteration 134, loss = 853126970.59358740\n",
      "Iteration 135, loss = 852749484.60979497\n",
      "Iteration 136, loss = 852349789.50639296\n",
      "Iteration 137, loss = 851964997.00175142\n",
      "Iteration 138, loss = 851566652.98595071\n",
      "Iteration 139, loss = 851196078.58065844\n",
      "Iteration 140, loss = 850799697.04696476\n",
      "Iteration 141, loss = 850415767.72238612\n",
      "Iteration 142, loss = 850015981.86205852\n",
      "Iteration 143, loss = 849630033.28878450\n",
      "Iteration 144, loss = 849262071.12829280\n",
      "Iteration 145, loss = 848845984.23143494\n",
      "Iteration 146, loss = 848465080.66540253\n",
      "Iteration 147, loss = 848075440.33680749\n",
      "Iteration 148, loss = 847711236.11898386\n",
      "Iteration 149, loss = 847336145.32588041\n",
      "Iteration 150, loss = 846960256.72667861\n",
      "Iteration 151, loss = 846560596.46255457\n",
      "Iteration 152, loss = 846211466.13751543\n",
      "Iteration 153, loss = 845807544.05253243\n",
      "Iteration 154, loss = 845418310.83956492\n",
      "Iteration 155, loss = 845041397.19405222\n",
      "Iteration 156, loss = 844656745.92136276\n",
      "Iteration 157, loss = 844259362.57322919\n",
      "Iteration 158, loss = 843883323.17164481\n",
      "Iteration 159, loss = 843519126.91195309\n",
      "Iteration 160, loss = 843111136.10495579\n",
      "Iteration 161, loss = 842715598.79677129\n",
      "Iteration 162, loss = 842314291.88247800\n",
      "Iteration 163, loss = 841962005.10409760\n",
      "Iteration 164, loss = 841539923.73253608\n",
      "Iteration 165, loss = 841167138.14184761\n",
      "Iteration 166, loss = 840775069.75270247\n",
      "Iteration 167, loss = 840358377.02768147\n",
      "Iteration 168, loss = 839962111.72521985\n",
      "Iteration 169, loss = 839570936.74015498\n",
      "Iteration 170, loss = 839190546.02708733\n",
      "Iteration 171, loss = 838784444.30661249\n",
      "Iteration 172, loss = 838404387.81465137\n",
      "Iteration 173, loss = 838014110.49853110\n",
      "Iteration 174, loss = 837622382.24823940\n",
      "Iteration 175, loss = 837222252.21510887\n",
      "Iteration 176, loss = 836855173.63361967\n",
      "Iteration 177, loss = 836447639.81139028\n",
      "Iteration 178, loss = 836063205.56024218\n",
      "Iteration 179, loss = 835669516.32392108\n",
      "Iteration 180, loss = 835272800.52233028\n",
      "Iteration 181, loss = 834892674.54701829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 182, loss = 834490756.58424437\n",
      "Iteration 183, loss = 834087535.87163496\n",
      "Iteration 184, loss = 833693900.26066375\n",
      "Iteration 185, loss = 833331734.21611905\n",
      "Iteration 186, loss = 832913411.02930498\n",
      "Iteration 187, loss = 832521014.60863602\n",
      "Iteration 188, loss = 832150064.79452980\n",
      "Iteration 189, loss = 831750927.10046518\n",
      "Iteration 190, loss = 831351401.48893714\n",
      "Iteration 191, loss = 830946295.60214269\n",
      "Iteration 192, loss = 830569930.09429204\n",
      "Iteration 193, loss = 830164385.86474669\n",
      "Iteration 194, loss = 829766147.36990309\n",
      "Iteration 195, loss = 829361144.02894354\n",
      "Iteration 196, loss = 828969720.20805657\n",
      "Iteration 197, loss = 828596724.95890880\n",
      "Iteration 198, loss = 828169719.08656526\n",
      "Iteration 199, loss = 827773314.43293309\n",
      "Iteration 200, loss = 827371547.63197982\n",
      "Iteration 201, loss = 826965575.99085176\n",
      "Iteration 202, loss = 826580988.63039207\n",
      "Iteration 203, loss = 826175251.15957880\n",
      "Iteration 204, loss = 825786053.25516462\n",
      "Iteration 205, loss = 825393273.11162698\n",
      "Iteration 206, loss = 825010011.76310742\n",
      "Iteration 207, loss = 824618729.18314409\n",
      "Iteration 208, loss = 824202434.21159768\n",
      "Iteration 209, loss = 823803806.99250507\n",
      "Iteration 210, loss = 823398684.81582618\n",
      "Iteration 211, loss = 822986166.03760386\n",
      "Iteration 212, loss = 822583693.39761281\n",
      "Iteration 213, loss = 822177720.92329144\n",
      "Iteration 214, loss = 821785473.41847420\n",
      "Iteration 215, loss = 821407437.42081428\n",
      "Iteration 216, loss = 821008484.50323772\n",
      "Iteration 217, loss = 820606880.93949509\n",
      "Iteration 218, loss = 820234854.40707922\n",
      "Iteration 219, loss = 819799293.38397789\n",
      "Iteration 220, loss = 819402127.41751683\n",
      "Iteration 221, loss = 819022099.58678126\n",
      "Iteration 222, loss = 818602371.59661281\n",
      "Iteration 223, loss = 818235915.35703051\n",
      "Iteration 224, loss = 817793791.28322887\n",
      "Iteration 225, loss = 817428077.37850225\n",
      "Iteration 226, loss = 816989079.11460352\n",
      "Iteration 227, loss = 816601834.75642085\n",
      "Iteration 228, loss = 816183318.11676121\n",
      "Iteration 229, loss = 815780335.04658651\n",
      "Iteration 230, loss = 815358420.94140053\n",
      "Iteration 231, loss = 814955742.14122701\n",
      "Iteration 232, loss = 814570710.98797369\n",
      "Iteration 233, loss = 814145096.18324864\n",
      "Iteration 234, loss = 813748214.06486177\n",
      "Iteration 235, loss = 813331948.69831383\n",
      "Iteration 236, loss = 812914101.03459799\n",
      "Iteration 237, loss = 812512442.43702269\n",
      "Iteration 238, loss = 812105248.08027554\n",
      "Iteration 239, loss = 811678205.17647123\n",
      "Iteration 240, loss = 811260186.67276037\n",
      "Iteration 241, loss = 810835619.43209982\n",
      "Iteration 242, loss = 810419373.00642872\n",
      "Iteration 243, loss = 810015125.90946710\n",
      "Iteration 244, loss = 809593825.50262094\n",
      "Iteration 245, loss = 809162190.48229575\n",
      "Iteration 246, loss = 808744179.09478748\n",
      "Iteration 247, loss = 808334755.97530246\n",
      "Iteration 248, loss = 807932065.80379522\n",
      "Iteration 249, loss = 807523734.02441072\n",
      "Iteration 250, loss = 807080746.26240039\n",
      "Iteration 251, loss = 806679900.80694628\n",
      "Iteration 252, loss = 806262555.78513789\n",
      "Iteration 253, loss = 805827423.11818063\n",
      "Iteration 254, loss = 805406210.05314660\n",
      "Iteration 255, loss = 805025029.59956694\n",
      "Iteration 256, loss = 804555338.11402750\n",
      "Iteration 257, loss = 804119622.63309968\n",
      "Iteration 258, loss = 803724108.75725460\n",
      "Iteration 259, loss = 803276636.33074462\n",
      "Iteration 260, loss = 802836381.85766244\n",
      "Iteration 261, loss = 802407865.85776305\n",
      "Iteration 262, loss = 801979393.50439751\n",
      "Iteration 263, loss = 801550941.82045853\n",
      "Iteration 264, loss = 801121381.88339078\n",
      "Iteration 265, loss = 800667671.31870329\n",
      "Iteration 266, loss = 800233720.90743935\n",
      "Iteration 267, loss = 799791987.04157329\n",
      "Iteration 268, loss = 799372825.75068367\n",
      "Iteration 269, loss = 798922936.83122289\n",
      "Iteration 270, loss = 798498107.03849542\n",
      "Iteration 271, loss = 798054257.01966000\n",
      "Iteration 272, loss = 797599550.10278213\n",
      "Iteration 273, loss = 797165269.37493253\n",
      "Iteration 274, loss = 796722095.37838519\n",
      "Iteration 275, loss = 796280927.00604451\n",
      "Iteration 276, loss = 795835404.09642351\n",
      "Iteration 277, loss = 795375789.07364714\n",
      "Iteration 278, loss = 794939127.82543218\n",
      "Iteration 279, loss = 794493093.56263423\n",
      "Iteration 280, loss = 794047333.98533237\n",
      "Iteration 281, loss = 793607021.62611330\n",
      "Iteration 282, loss = 793165304.83521688\n",
      "Iteration 283, loss = 792732064.13228321\n",
      "Iteration 284, loss = 792262376.29655254\n",
      "Iteration 285, loss = 791816502.34962249\n",
      "Iteration 286, loss = 791373210.42630553\n",
      "Iteration 287, loss = 790910392.47479069\n",
      "Iteration 288, loss = 790450911.47202063\n",
      "Iteration 289, loss = 790011167.20256329\n",
      "Iteration 290, loss = 789549255.50001478\n",
      "Iteration 291, loss = 789102962.74859357\n",
      "Iteration 292, loss = 788666574.49367619\n",
      "Iteration 293, loss = 788213401.81932139\n",
      "Iteration 294, loss = 787755130.84230483\n",
      "Iteration 295, loss = 787299432.11306441\n",
      "Iteration 296, loss = 786829124.35578716\n",
      "Iteration 297, loss = 786378574.87936461\n",
      "Iteration 298, loss = 785938370.65831506\n",
      "Iteration 299, loss = 785452709.75624096\n",
      "Iteration 300, loss = 785001824.09197962\n",
      "Iteration 301, loss = 784532167.66058075\n",
      "Iteration 302, loss = 784054805.15322244\n",
      "Iteration 303, loss = 783577555.11352611\n",
      "Iteration 304, loss = 783140226.67453384\n",
      "Iteration 305, loss = 782644567.19549835\n",
      "Iteration 306, loss = 782216468.67306638\n",
      "Iteration 307, loss = 781696401.70774996\n",
      "Iteration 308, loss = 781238123.15015912\n",
      "Iteration 309, loss = 780748867.06437778\n",
      "Iteration 310, loss = 780283318.16778553\n",
      "Iteration 311, loss = 779806531.94156790\n",
      "Iteration 312, loss = 779326445.25292599\n",
      "Iteration 313, loss = 778855862.54998541\n",
      "Iteration 314, loss = 778381964.08168817\n",
      "Iteration 315, loss = 777934921.97683561\n",
      "Iteration 316, loss = 777463433.83229458\n",
      "Iteration 317, loss = 776964813.08371139\n",
      "Iteration 318, loss = 776496792.15398610\n",
      "Iteration 319, loss = 776047908.86743176\n",
      "Iteration 320, loss = 775556220.40741634\n",
      "Iteration 321, loss = 775065439.53155243\n",
      "Iteration 322, loss = 774600387.31985188\n",
      "Iteration 323, loss = 774117567.10526514\n",
      "Iteration 324, loss = 773618481.76371443\n",
      "Iteration 325, loss = 773132489.09921598\n",
      "Iteration 326, loss = 772654308.48719120\n",
      "Iteration 327, loss = 772178044.24761307\n",
      "Iteration 328, loss = 771655216.29930162\n",
      "Iteration 329, loss = 771189034.57663310\n",
      "Iteration 330, loss = 770672510.81702781\n",
      "Iteration 331, loss = 770175030.08725297\n",
      "Iteration 332, loss = 769705380.10051644\n",
      "Iteration 333, loss = 769212829.80775237\n",
      "Iteration 334, loss = 768697936.63481379\n",
      "Iteration 335, loss = 768196348.49193680\n",
      "Iteration 336, loss = 767713545.59031320\n",
      "Iteration 337, loss = 767207522.08234906\n",
      "Iteration 338, loss = 766691739.14969623\n",
      "Iteration 339, loss = 766207868.22826850\n",
      "Iteration 340, loss = 765691700.49315095\n",
      "Iteration 341, loss = 765180964.95421445\n",
      "Iteration 342, loss = 764677234.45114863\n",
      "Iteration 343, loss = 764166654.36446226\n",
      "Iteration 344, loss = 763656820.30064940\n",
      "Iteration 345, loss = 763143919.79977071\n",
      "Iteration 346, loss = 762640761.44121373\n",
      "Iteration 347, loss = 762128678.10558581\n",
      "Iteration 348, loss = 761615768.38887811\n",
      "Iteration 349, loss = 761091909.81824255\n",
      "Iteration 350, loss = 760570799.83701098\n",
      "Iteration 351, loss = 760066619.23538089\n",
      "Iteration 352, loss = 759537477.83160686\n",
      "Iteration 353, loss = 759017199.89047384\n",
      "Iteration 354, loss = 758505027.78918540\n",
      "Iteration 355, loss = 757978587.23993230\n",
      "Iteration 356, loss = 757470896.09732985\n",
      "Iteration 357, loss = 756942010.98185968\n",
      "Iteration 358, loss = 756447636.43011606\n",
      "Iteration 359, loss = 755919748.17766666\n",
      "Iteration 360, loss = 755425807.99741781\n",
      "Iteration 361, loss = 754902619.66736662\n",
      "Iteration 362, loss = 754380269.41461515\n",
      "Iteration 363, loss = 753871340.75922441\n",
      "Iteration 364, loss = 753357378.64997447\n",
      "Iteration 365, loss = 752835624.44694495\n",
      "Iteration 366, loss = 752318375.23719585\n",
      "Iteration 367, loss = 751799914.26607347\n",
      "Iteration 368, loss = 751268738.86286664\n",
      "Iteration 369, loss = 750744187.49203670\n",
      "Iteration 370, loss = 750235832.06936789\n",
      "Iteration 371, loss = 749721375.79234171\n",
      "Iteration 372, loss = 749225045.29432952\n",
      "Iteration 373, loss = 748696686.82341659\n",
      "Iteration 374, loss = 748171520.41139138\n",
      "Iteration 375, loss = 747661419.26406515\n",
      "Iteration 376, loss = 747148266.38721931\n",
      "Iteration 377, loss = 746601190.58071566\n",
      "Iteration 378, loss = 746073073.60672224\n",
      "Iteration 379, loss = 745539560.64336085\n",
      "Iteration 380, loss = 745007508.76681507\n",
      "Iteration 381, loss = 744463672.69452608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 382, loss = 743921685.74893236\n",
      "Iteration 383, loss = 743367315.45398271\n",
      "Iteration 384, loss = 742810093.23051465\n",
      "Iteration 385, loss = 742275877.92330754\n",
      "Iteration 386, loss = 741734299.13903594\n",
      "Iteration 387, loss = 741155856.51237190\n",
      "Iteration 388, loss = 740608132.24174416\n",
      "Iteration 389, loss = 740042997.57544708\n",
      "Iteration 390, loss = 739492862.69496739\n",
      "Iteration 391, loss = 738940097.62855232\n",
      "Iteration 392, loss = 738345893.62248862\n",
      "Iteration 393, loss = 737790515.32382464\n",
      "Iteration 394, loss = 737195024.24463141\n",
      "Iteration 395, loss = 736632594.42074513\n",
      "Iteration 396, loss = 736050527.75360191\n",
      "Iteration 397, loss = 735456190.39878011\n",
      "Iteration 398, loss = 734903456.78325248\n",
      "Iteration 399, loss = 734312059.60847223\n",
      "Iteration 400, loss = 733749783.98605943\n",
      "Iteration 401, loss = 733183336.08158183\n",
      "Iteration 402, loss = 732578346.09069884\n",
      "Iteration 403, loss = 732001956.42691207\n",
      "Iteration 404, loss = 731431317.11371648\n",
      "Iteration 405, loss = 730808582.17887330\n",
      "Iteration 406, loss = 730230410.76154649\n",
      "Iteration 407, loss = 729634296.15955639\n",
      "Iteration 408, loss = 729042814.18935573\n",
      "Iteration 409, loss = 728437500.84259772\n",
      "Iteration 410, loss = 727838477.46523440\n",
      "Iteration 411, loss = 727247291.56514299\n",
      "Iteration 412, loss = 726641721.48383653\n",
      "Iteration 413, loss = 726094408.13763976\n",
      "Iteration 414, loss = 725466885.59028971\n",
      "Iteration 415, loss = 724880508.21492505\n",
      "Iteration 416, loss = 724277491.81768394\n",
      "Iteration 417, loss = 723670686.32378149\n",
      "Iteration 418, loss = 723067052.12762821\n",
      "Iteration 419, loss = 722470443.87813568\n",
      "Iteration 420, loss = 721868584.61994576\n",
      "Iteration 421, loss = 721236769.90476060\n",
      "Iteration 422, loss = 720639765.78862596\n",
      "Iteration 423, loss = 720040929.19243884\n",
      "Iteration 424, loss = 719416869.24878967\n",
      "Iteration 425, loss = 718803629.71774912\n",
      "Iteration 426, loss = 718160158.98877156\n",
      "Iteration 427, loss = 717552978.90633428\n",
      "Iteration 428, loss = 716922167.59066451\n",
      "Iteration 429, loss = 716311689.41712761\n",
      "Iteration 430, loss = 715677972.75589311\n",
      "Iteration 431, loss = 715050435.16609967\n",
      "Iteration 432, loss = 714419898.01073956\n",
      "Iteration 433, loss = 713791366.64073598\n",
      "Iteration 434, loss = 713158822.22562373\n",
      "Iteration 435, loss = 712542868.17748570\n",
      "Iteration 436, loss = 711880172.52785850\n",
      "Iteration 437, loss = 711241421.80793405\n",
      "Iteration 438, loss = 710600116.43984056\n",
      "Iteration 439, loss = 709948936.27736914\n",
      "Iteration 440, loss = 709318833.87124813\n",
      "Iteration 441, loss = 708665415.04970920\n",
      "Iteration 442, loss = 708014862.39149880\n",
      "Iteration 443, loss = 707362570.95115387\n",
      "Iteration 444, loss = 706705474.86595607\n",
      "Iteration 445, loss = 706045779.27936828\n",
      "Iteration 446, loss = 705394189.53377867\n",
      "Iteration 447, loss = 704754236.26602709\n",
      "Iteration 448, loss = 704100685.07067490\n",
      "Iteration 449, loss = 703454918.19312501\n",
      "Iteration 450, loss = 702776966.79520941\n",
      "Iteration 451, loss = 702122340.70807910\n",
      "Iteration 452, loss = 701455522.98609149\n",
      "Iteration 453, loss = 700818606.56019497\n",
      "Iteration 454, loss = 700143914.25900614\n",
      "Iteration 455, loss = 699471629.94558382\n",
      "Iteration 456, loss = 698827705.78442717\n",
      "Iteration 457, loss = 698133089.00667322\n",
      "Iteration 458, loss = 697480096.31301677\n",
      "Iteration 459, loss = 696814625.89572227\n",
      "Iteration 460, loss = 696133382.53999233\n",
      "Iteration 461, loss = 695458955.02185488\n",
      "Iteration 462, loss = 694792703.43160808\n",
      "Iteration 463, loss = 694158076.99604404\n",
      "Iteration 464, loss = 693458473.11367667\n",
      "Iteration 465, loss = 692778417.48820376\n",
      "Iteration 466, loss = 692106488.09503794\n",
      "Iteration 467, loss = 691436057.48631549\n",
      "Iteration 468, loss = 690740063.34030461\n",
      "Iteration 469, loss = 690062722.02935004\n",
      "Iteration 470, loss = 689371955.76461697\n",
      "Iteration 471, loss = 688699495.90046656\n",
      "Iteration 472, loss = 688005197.55993116\n",
      "Iteration 473, loss = 687307303.57357776\n",
      "Iteration 474, loss = 686617179.13341689\n",
      "Iteration 475, loss = 685913500.53400409\n",
      "Iteration 476, loss = 685213252.57187998\n",
      "Iteration 477, loss = 684497896.18230426\n",
      "Iteration 478, loss = 683815221.55085599\n",
      "Iteration 479, loss = 683112322.16268027\n",
      "Iteration 480, loss = 682421703.27282405\n",
      "Iteration 481, loss = 681726709.25899148\n",
      "Iteration 482, loss = 681028484.61151981\n",
      "Iteration 483, loss = 680331902.35042667\n",
      "Iteration 484, loss = 679614594.41636825\n",
      "Iteration 485, loss = 678933993.94700539\n",
      "Iteration 486, loss = 678201472.15944469\n",
      "Iteration 487, loss = 677495809.24233544\n",
      "Iteration 488, loss = 676782919.86620641\n",
      "Iteration 489, loss = 676072322.52358198\n",
      "Iteration 490, loss = 675369006.78805387\n",
      "Iteration 491, loss = 674632706.56071126\n",
      "Iteration 492, loss = 673903881.55730522\n",
      "Iteration 493, loss = 673196457.15729940\n",
      "Iteration 494, loss = 672485930.39768088\n",
      "Iteration 495, loss = 671727519.03734410\n",
      "Iteration 496, loss = 671031165.12405276\n",
      "Iteration 497, loss = 670260323.32653594\n",
      "Iteration 498, loss = 669531860.29534638\n",
      "Iteration 499, loss = 668816721.97444451\n",
      "Iteration 500, loss = 668077774.92299902\n",
      "Iteration 501, loss = 667345837.36776459\n",
      "Iteration 502, loss = 666631605.47938132\n",
      "Iteration 503, loss = 665914021.01357460\n",
      "Iteration 504, loss = 665171103.64126539\n",
      "Iteration 505, loss = 664441867.76828897\n",
      "Iteration 506, loss = 663704391.65619540\n",
      "Iteration 507, loss = 662961258.77423716\n",
      "Iteration 508, loss = 662237639.47884572\n",
      "Iteration 509, loss = 661540651.16779566\n",
      "Iteration 510, loss = 660814317.71826279\n",
      "Iteration 511, loss = 660091511.53335357\n",
      "Iteration 512, loss = 659313257.45226586\n",
      "Iteration 513, loss = 658597278.17753625\n",
      "Iteration 514, loss = 657868306.18172169\n",
      "Iteration 515, loss = 657137864.44489920\n",
      "Iteration 516, loss = 656413079.29988015\n",
      "Iteration 517, loss = 655691572.60661697\n",
      "Iteration 518, loss = 654925680.01259232\n",
      "Iteration 519, loss = 654168848.41869044\n",
      "Iteration 520, loss = 653479678.42448640\n",
      "Iteration 521, loss = 652694854.38279510\n",
      "Iteration 522, loss = 651966506.15087700\n",
      "Iteration 523, loss = 651221335.59326398\n",
      "Iteration 524, loss = 650437850.17062473\n",
      "Iteration 525, loss = 649704589.73481858\n",
      "Iteration 526, loss = 648958509.59692848\n",
      "Iteration 527, loss = 648188068.18796897\n",
      "Iteration 528, loss = 647447716.23091316\n",
      "Iteration 529, loss = 646694494.81580746\n",
      "Iteration 530, loss = 645945035.71038342\n",
      "Iteration 531, loss = 645183521.64404869\n",
      "Iteration 532, loss = 644424965.24425590\n",
      "Iteration 533, loss = 643671957.10965216\n",
      "Iteration 534, loss = 642903401.16663480\n",
      "Iteration 535, loss = 642154177.67017794\n",
      "Iteration 536, loss = 641382447.09879673\n",
      "Iteration 537, loss = 640621988.78659701\n",
      "Iteration 538, loss = 639838156.10939169\n",
      "Iteration 539, loss = 639094733.63534641\n",
      "Iteration 540, loss = 638340089.20077288\n",
      "Iteration 541, loss = 637557681.88435817\n",
      "Iteration 542, loss = 636792086.43417418\n",
      "Iteration 543, loss = 636010463.92206490\n",
      "Iteration 544, loss = 635265877.01869142\n",
      "Iteration 545, loss = 634471398.74886799\n",
      "Iteration 546, loss = 633704373.58073950\n",
      "Iteration 547, loss = 632910006.69157839\n",
      "Iteration 548, loss = 632130750.13925695\n",
      "Iteration 549, loss = 631375687.98786402\n",
      "Iteration 550, loss = 630582629.34197414\n",
      "Iteration 551, loss = 629803929.64896762\n",
      "Iteration 552, loss = 629038569.76439643\n",
      "Iteration 553, loss = 628294308.52847695\n",
      "Iteration 554, loss = 627516625.82208633\n",
      "Iteration 555, loss = 626757043.32797384\n",
      "Iteration 556, loss = 626025094.14523816\n",
      "Iteration 557, loss = 625210783.52918077\n",
      "Iteration 558, loss = 624446352.96743906\n",
      "Iteration 559, loss = 623660714.70972872\n",
      "Iteration 560, loss = 622889868.79004657\n",
      "Iteration 561, loss = 622083745.23248649\n",
      "Iteration 562, loss = 621293838.33145499\n",
      "Iteration 563, loss = 620537265.68249190\n",
      "Iteration 564, loss = 619737573.83995926\n",
      "Iteration 565, loss = 618931723.90226197\n",
      "Iteration 566, loss = 618141106.61914992\n",
      "Iteration 567, loss = 617313049.04326820\n",
      "Iteration 568, loss = 616534285.58249116\n",
      "Iteration 569, loss = 615762396.41345513\n",
      "Iteration 570, loss = 614965294.03592026\n",
      "Iteration 571, loss = 614173357.31069314\n",
      "Iteration 572, loss = 613366212.98050916\n",
      "Iteration 573, loss = 612590011.22085142\n",
      "Iteration 574, loss = 611790941.75579894\n",
      "Iteration 575, loss = 611002731.69114470\n",
      "Iteration 576, loss = 610193988.71678782\n",
      "Iteration 577, loss = 609388110.97631967\n",
      "Iteration 578, loss = 608581138.11313629\n",
      "Iteration 579, loss = 607770810.83065164\n",
      "Iteration 580, loss = 606972313.14336777\n",
      "Iteration 581, loss = 606135271.05568874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 582, loss = 605338416.84771454\n",
      "Iteration 583, loss = 604511522.65125382\n",
      "Iteration 584, loss = 603702210.84594822\n",
      "Iteration 585, loss = 602901034.90522873\n",
      "Iteration 586, loss = 602070308.80165052\n",
      "Iteration 587, loss = 601273618.26706457\n",
      "Iteration 588, loss = 600456047.55956745\n",
      "Iteration 589, loss = 599684457.64789605\n",
      "Iteration 590, loss = 598869848.14746678\n",
      "Iteration 591, loss = 598066852.21961284\n",
      "Iteration 592, loss = 597265549.74675572\n",
      "Iteration 593, loss = 596467912.41015661\n",
      "Iteration 594, loss = 595666654.04400229\n",
      "Iteration 595, loss = 594872371.75355196\n",
      "Iteration 596, loss = 594087316.75938451\n",
      "Iteration 597, loss = 593307919.75492108\n",
      "Iteration 598, loss = 592502576.64549053\n",
      "Iteration 599, loss = 591709680.77727497\n",
      "Iteration 600, loss = 590905027.90753484\n",
      "Iteration 601, loss = 590118916.33850586\n",
      "Iteration 602, loss = 589329304.15569592\n",
      "Iteration 603, loss = 588538762.90948594\n",
      "Iteration 604, loss = 587725370.20266104\n",
      "Iteration 605, loss = 586949517.35750949\n",
      "Iteration 606, loss = 586135305.31310701\n",
      "Iteration 607, loss = 585341472.21537042\n",
      "Iteration 608, loss = 584547623.62472272\n",
      "Iteration 609, loss = 583725411.11905301\n",
      "Iteration 610, loss = 582933680.98451412\n",
      "Iteration 611, loss = 582125486.60492635\n",
      "Iteration 612, loss = 581366808.87066948\n",
      "Iteration 613, loss = 580526166.50222790\n",
      "Iteration 614, loss = 579736149.27478278\n",
      "Iteration 615, loss = 578951823.79887259\n",
      "Iteration 616, loss = 578130864.02943230\n",
      "Iteration 617, loss = 577327468.59311545\n",
      "Iteration 618, loss = 576518094.36288655\n",
      "Iteration 619, loss = 575734395.23785329\n",
      "Iteration 620, loss = 574895943.65690231\n",
      "Iteration 621, loss = 574096631.47298002\n",
      "Iteration 622, loss = 573315199.61801052\n",
      "Iteration 623, loss = 572477707.10497808\n",
      "Iteration 624, loss = 571705969.14662766\n",
      "Iteration 625, loss = 570894336.00290501\n",
      "Iteration 626, loss = 570096074.76881301\n",
      "Iteration 627, loss = 569283116.52223825\n",
      "Iteration 628, loss = 568503704.73485553\n",
      "Iteration 629, loss = 567702686.27511191\n",
      "Iteration 630, loss = 566906731.67241979\n",
      "Iteration 631, loss = 566074105.37490273\n",
      "Iteration 632, loss = 565302829.96757877\n",
      "Iteration 633, loss = 564486196.87049747\n",
      "Iteration 634, loss = 563694602.18267977\n",
      "Iteration 635, loss = 562895165.52813590\n",
      "Iteration 636, loss = 562102751.75501943\n",
      "Iteration 637, loss = 561272506.95052612\n",
      "Iteration 638, loss = 560479445.00954688\n",
      "Iteration 639, loss = 559683795.28221452\n",
      "Iteration 640, loss = 558900997.81679785\n",
      "Iteration 641, loss = 558090667.42641556\n",
      "Iteration 642, loss = 557317304.47913992\n",
      "Iteration 643, loss = 556520533.56329644\n",
      "Iteration 644, loss = 555733349.16130829\n",
      "Iteration 645, loss = 554945467.77699113\n",
      "Iteration 646, loss = 554214360.97030509\n",
      "Iteration 647, loss = 553381627.57305539\n",
      "Iteration 648, loss = 552592811.52012062\n",
      "Iteration 649, loss = 551825334.52986228\n",
      "Iteration 650, loss = 551008777.73606038\n",
      "Iteration 651, loss = 550244509.16367471\n",
      "Iteration 652, loss = 549462535.47456157\n",
      "Iteration 653, loss = 548689544.07391477\n",
      "Iteration 654, loss = 547909443.11385322\n",
      "Iteration 655, loss = 547134903.98497093\n",
      "Iteration 656, loss = 546348537.07676005\n",
      "Iteration 657, loss = 545557187.91858697\n",
      "Iteration 658, loss = 544779134.53102016\n",
      "Iteration 659, loss = 543981635.95874119\n",
      "Iteration 660, loss = 543177514.16419303\n",
      "Iteration 661, loss = 542413860.41283751\n",
      "Iteration 662, loss = 541619674.84247100\n",
      "Iteration 663, loss = 540827897.06392062\n",
      "Iteration 664, loss = 540076633.79791868\n",
      "Iteration 665, loss = 539276038.03326714\n",
      "Iteration 666, loss = 538512693.58629501\n",
      "Iteration 667, loss = 537733153.61907077\n",
      "Iteration 668, loss = 536947487.25928795\n",
      "Iteration 669, loss = 536189354.48629665\n",
      "Iteration 670, loss = 535406575.16799945\n",
      "Iteration 671, loss = 534644670.97763914\n",
      "Iteration 672, loss = 533875285.21906614\n",
      "Iteration 673, loss = 533103932.62684727\n",
      "Iteration 674, loss = 532335015.04705232\n",
      "Iteration 675, loss = 531571606.25634581\n",
      "Iteration 676, loss = 530823716.01169354\n",
      "Iteration 677, loss = 530061887.56987661\n",
      "Iteration 678, loss = 529345137.14689571\n",
      "Iteration 679, loss = 528575805.77792352\n",
      "Iteration 680, loss = 527805360.48735589\n",
      "Iteration 681, loss = 527069771.83065927\n",
      "Iteration 682, loss = 526312206.90418935\n",
      "Iteration 683, loss = 525545146.28387010\n",
      "Iteration 684, loss = 524812954.46281219\n",
      "Iteration 685, loss = 524053465.31230199\n",
      "Iteration 686, loss = 523302548.22823113\n",
      "Iteration 687, loss = 522568332.21937937\n",
      "Iteration 688, loss = 521804231.79475474\n",
      "Iteration 689, loss = 521051716.44122308\n",
      "Iteration 690, loss = 520282775.41731668\n",
      "Iteration 691, loss = 519559510.01164854\n",
      "Iteration 692, loss = 518820839.59417909\n",
      "Iteration 693, loss = 518050223.02575165\n",
      "Iteration 694, loss = 517311774.37296921\n",
      "Iteration 695, loss = 516567853.96342784\n",
      "Iteration 696, loss = 515847604.24823153\n",
      "Iteration 697, loss = 515102798.73479861\n",
      "Iteration 698, loss = 514357901.56714106\n",
      "Iteration 699, loss = 513629438.50283033\n",
      "Iteration 700, loss = 512894291.56854743\n",
      "Iteration 701, loss = 512149851.17110586\n",
      "Iteration 702, loss = 511428290.93400270\n",
      "Iteration 703, loss = 510692737.33270448\n",
      "Iteration 704, loss = 509945679.17024213\n",
      "Iteration 705, loss = 509232136.50224191\n",
      "Iteration 706, loss = 508494138.46619499\n",
      "Iteration 707, loss = 507782368.12933272\n",
      "Iteration 708, loss = 507053418.80602497\n",
      "Iteration 709, loss = 506315397.49806821\n",
      "Iteration 710, loss = 505583877.33770013\n",
      "Iteration 711, loss = 504891905.86304468\n",
      "Iteration 712, loss = 504140864.59059089\n",
      "Iteration 713, loss = 503409579.52837950\n",
      "Iteration 714, loss = 502713344.38656259\n",
      "Iteration 715, loss = 501994854.65377688\n",
      "Iteration 716, loss = 501284058.07330036\n",
      "Iteration 717, loss = 500605538.16404116\n",
      "Iteration 718, loss = 499870942.93567115\n",
      "Iteration 719, loss = 499174450.09276426\n",
      "Iteration 720, loss = 498452397.41127533\n",
      "Iteration 721, loss = 497744159.90031499\n",
      "Iteration 722, loss = 497067923.41825765\n",
      "Iteration 723, loss = 496332189.77182746\n",
      "Iteration 724, loss = 495619514.97195154\n",
      "Iteration 725, loss = 494917433.11483926\n",
      "Iteration 726, loss = 494217775.45626622\n",
      "Iteration 727, loss = 493568590.76058078\n",
      "Iteration 728, loss = 492927729.22999817\n",
      "Iteration 729, loss = 492228395.40159792\n",
      "Iteration 730, loss = 491569278.18641829\n",
      "Iteration 731, loss = 490906637.89540488\n",
      "Iteration 732, loss = 490237824.93306166\n",
      "Iteration 733, loss = 489570069.68488818\n",
      "Iteration 734, loss = 488884751.24561125\n",
      "Iteration 735, loss = 488221586.74049699\n",
      "Iteration 736, loss = 487555337.66104364\n",
      "Iteration 737, loss = 486883423.79834753\n",
      "Iteration 738, loss = 486201218.42579591\n",
      "Iteration 739, loss = 485548011.41660511\n",
      "Iteration 740, loss = 484849130.45536447\n",
      "Iteration 741, loss = 484210224.64693099\n",
      "Iteration 742, loss = 483521364.36162937\n",
      "Iteration 743, loss = 482890821.30409104\n",
      "Iteration 744, loss = 482201647.56028795\n",
      "Iteration 745, loss = 481556528.59988213\n",
      "Iteration 746, loss = 480880622.30454069\n",
      "Iteration 747, loss = 480204103.97591048\n",
      "Iteration 748, loss = 479543616.14437133\n",
      "Iteration 749, loss = 478882658.64724433\n",
      "Iteration 750, loss = 478209937.45508528\n",
      "Iteration 751, loss = 477522898.89177060\n",
      "Iteration 752, loss = 476865585.05304635\n",
      "Iteration 753, loss = 476196983.46004325\n",
      "Iteration 754, loss = 475548580.39696687\n",
      "Iteration 755, loss = 474900868.77549160\n",
      "Iteration 756, loss = 474248869.68018508\n",
      "Iteration 757, loss = 473566916.90067708\n",
      "Iteration 758, loss = 472924663.54246783\n",
      "Iteration 759, loss = 472275461.02077484\n",
      "Iteration 760, loss = 471635636.59610540\n",
      "Iteration 761, loss = 471005576.93674415\n",
      "Iteration 762, loss = 470349286.07717252\n",
      "Iteration 763, loss = 469672961.32203496\n",
      "Iteration 764, loss = 469000514.49617732\n",
      "Iteration 765, loss = 468346707.70328671\n",
      "Iteration 766, loss = 467726819.60059130\n",
      "Iteration 767, loss = 467043948.96180123\n",
      "Iteration 768, loss = 466366155.39105546\n",
      "Iteration 769, loss = 465732509.41770804\n",
      "Iteration 770, loss = 465050158.41369694\n",
      "Iteration 771, loss = 464390177.38012511\n",
      "Iteration 772, loss = 463737855.63835287\n",
      "Iteration 773, loss = 463059252.12247097\n",
      "Iteration 774, loss = 462396260.67374647\n",
      "Iteration 775, loss = 461738573.71477562\n",
      "Iteration 776, loss = 461074084.02825493\n",
      "Iteration 777, loss = 460418919.49087864\n",
      "Iteration 778, loss = 459764269.98572075\n",
      "Iteration 779, loss = 459115099.69783580\n",
      "Iteration 780, loss = 458446477.63297659\n",
      "Iteration 781, loss = 457807160.87688613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 782, loss = 457159070.30290282\n",
      "Iteration 783, loss = 456472498.01243120\n",
      "Iteration 784, loss = 455824894.55610269\n",
      "Iteration 785, loss = 455155224.95927709\n",
      "Iteration 786, loss = 454538835.08303767\n",
      "Iteration 787, loss = 453894103.49151790\n",
      "Iteration 788, loss = 453269321.93592727\n",
      "Iteration 789, loss = 452646547.01186204\n",
      "Iteration 790, loss = 452000548.94116294\n",
      "Iteration 791, loss = 451363792.70443684\n",
      "Iteration 792, loss = 450728085.27475071\n",
      "Iteration 793, loss = 450078706.90445375\n",
      "Iteration 794, loss = 449458786.00528735\n",
      "Iteration 795, loss = 448807338.36892188\n",
      "Iteration 796, loss = 448201764.30542719\n",
      "Iteration 797, loss = 447547007.48776823\n",
      "Iteration 798, loss = 446885800.85258305\n",
      "Iteration 799, loss = 446283485.67771906\n",
      "Iteration 800, loss = 445626046.05223513\n",
      "Iteration 801, loss = 444989136.93100858\n",
      "Iteration 802, loss = 444361616.82191855\n",
      "Iteration 803, loss = 443727365.38210726\n",
      "Iteration 804, loss = 443080585.94965780\n",
      "Iteration 805, loss = 442453679.60634267\n",
      "Iteration 806, loss = 441830118.03786689\n",
      "Iteration 807, loss = 441186804.34539044\n",
      "Iteration 808, loss = 440561789.53151500\n",
      "Iteration 809, loss = 439934397.23901153\n",
      "Iteration 810, loss = 439297002.72311348\n",
      "Iteration 811, loss = 438662922.22624862\n",
      "Iteration 812, loss = 438041296.92279172\n",
      "Iteration 813, loss = 437410929.72824991\n",
      "Iteration 814, loss = 436775637.47442210\n",
      "Iteration 815, loss = 436134883.95174927\n",
      "Iteration 816, loss = 435513572.14967692\n",
      "Iteration 817, loss = 434858675.44463199\n",
      "Iteration 818, loss = 434253206.80575466\n",
      "Iteration 819, loss = 433619956.66060209\n",
      "Iteration 820, loss = 433002835.30912548\n",
      "Iteration 821, loss = 432376772.51850373\n",
      "Iteration 822, loss = 431744576.79069591\n",
      "Iteration 823, loss = 431107516.17284769\n",
      "Iteration 824, loss = 430481807.15839481\n",
      "Iteration 825, loss = 429876041.46557087\n",
      "Iteration 826, loss = 429267693.20873749\n",
      "Iteration 827, loss = 428641448.80472749\n",
      "Iteration 828, loss = 428048547.95400918\n",
      "Iteration 829, loss = 427444349.32009691\n",
      "Iteration 830, loss = 426841279.17417467\n",
      "Iteration 831, loss = 426217949.57301390\n",
      "Iteration 832, loss = 425605230.35666388\n",
      "Iteration 833, loss = 425049028.33929259\n",
      "Iteration 834, loss = 424425095.54073399\n",
      "Iteration 835, loss = 423840382.38929981\n",
      "Iteration 836, loss = 423219282.02998173\n",
      "Iteration 837, loss = 422609329.56200153\n",
      "Iteration 838, loss = 422025503.29319227\n",
      "Iteration 839, loss = 421409536.32663423\n",
      "Iteration 840, loss = 420821424.27398312\n",
      "Iteration 841, loss = 420199030.71193749\n",
      "Iteration 842, loss = 419612859.75240129\n",
      "Iteration 843, loss = 419050417.63097012\n",
      "Iteration 844, loss = 418395268.61568499\n",
      "Iteration 845, loss = 417801245.23005986\n",
      "Iteration 846, loss = 417182749.81403285\n",
      "Iteration 847, loss = 416606215.10074520\n",
      "Iteration 848, loss = 415953507.90695107\n",
      "Iteration 849, loss = 415367007.26541275\n",
      "Iteration 850, loss = 414758165.13563401\n",
      "Iteration 851, loss = 414193037.52328318\n",
      "Iteration 852, loss = 413576066.75679195\n",
      "Iteration 853, loss = 412999382.25687474\n",
      "Iteration 854, loss = 412425057.25757354\n",
      "Iteration 855, loss = 411802689.17194474\n",
      "Iteration 856, loss = 411217432.90766686\n",
      "Iteration 857, loss = 410583942.64444488\n",
      "Iteration 858, loss = 410004075.52226663\n",
      "Iteration 859, loss = 409408582.26931036\n",
      "Iteration 860, loss = 408793818.15151215\n",
      "Iteration 861, loss = 408201930.19266617\n",
      "Iteration 862, loss = 407660527.67708892\n",
      "Iteration 863, loss = 406998236.98708165\n",
      "Iteration 864, loss = 406412704.89563340\n",
      "Iteration 865, loss = 405829648.31979358\n",
      "Iteration 866, loss = 405229458.43082577\n",
      "Iteration 867, loss = 404623262.21117908\n",
      "Iteration 868, loss = 404023337.69530255\n",
      "Iteration 869, loss = 403425295.53495842\n",
      "Iteration 870, loss = 402871394.64094037\n",
      "Iteration 871, loss = 402249337.09858596\n",
      "Iteration 872, loss = 401648123.21426541\n",
      "Iteration 873, loss = 401083583.43011642\n",
      "Iteration 874, loss = 400490852.50627321\n",
      "Iteration 875, loss = 399917066.79182625\n",
      "Iteration 876, loss = 399308058.34623414\n",
      "Iteration 877, loss = 398744684.75326246\n",
      "Iteration 878, loss = 398134656.10607284\n",
      "Iteration 879, loss = 397499084.47153091\n",
      "Iteration 880, loss = 396926308.29231405\n",
      "Iteration 881, loss = 396353376.83746856\n",
      "Iteration 882, loss = 395770905.26317167\n",
      "Iteration 883, loss = 395186305.99973071\n",
      "Iteration 884, loss = 394602924.97359347\n",
      "Iteration 885, loss = 394038579.94932777\n",
      "Iteration 886, loss = 393400076.47276586\n",
      "Iteration 887, loss = 392847338.88893384\n",
      "Iteration 888, loss = 392266040.34198987\n",
      "Iteration 889, loss = 391675372.12615788\n",
      "Iteration 890, loss = 391123408.13209796\n",
      "Iteration 891, loss = 390547125.10262102\n",
      "Iteration 892, loss = 389968526.80671650\n",
      "Iteration 893, loss = 389389777.21853238\n",
      "Iteration 894, loss = 388814645.97968358\n",
      "Iteration 895, loss = 388247065.71337891\n",
      "Iteration 896, loss = 387677670.77411741\n",
      "Iteration 897, loss = 387091417.67614430\n",
      "Iteration 898, loss = 386510781.29525614\n",
      "Iteration 899, loss = 385921499.99774265\n",
      "Iteration 900, loss = 385340201.37100744\n",
      "Iteration 901, loss = 384767638.59689063\n",
      "Iteration 902, loss = 384208085.80774552\n",
      "Iteration 903, loss = 383630910.97055233\n",
      "Iteration 904, loss = 383067361.21436459\n",
      "Iteration 905, loss = 382528364.73584729\n",
      "Iteration 906, loss = 381946990.36387205\n",
      "Iteration 907, loss = 381365527.22977847\n",
      "Iteration 908, loss = 380835555.93165660\n",
      "Iteration 909, loss = 380234012.43604982\n",
      "Iteration 910, loss = 379680464.15677100\n",
      "Iteration 911, loss = 379135636.72349423\n",
      "Iteration 912, loss = 378562157.76801205\n",
      "Iteration 913, loss = 378001807.14397341\n",
      "Iteration 914, loss = 377447631.92646426\n",
      "Iteration 915, loss = 376890123.21097881\n",
      "Iteration 916, loss = 376286412.07808143\n",
      "Iteration 917, loss = 375733454.59457874\n",
      "Iteration 918, loss = 375185912.54325551\n",
      "Iteration 919, loss = 374573146.77899003\n",
      "Iteration 920, loss = 374014797.86453182\n",
      "Iteration 921, loss = 373471296.35383064\n",
      "Iteration 922, loss = 372889862.79737139\n",
      "Iteration 923, loss = 372313981.09442866\n",
      "Iteration 924, loss = 371744587.70119089\n",
      "Iteration 925, loss = 371179563.98184711\n",
      "Iteration 926, loss = 370638391.79347104\n",
      "Iteration 927, loss = 370069656.23087841\n",
      "Iteration 928, loss = 369505933.36847180\n",
      "Iteration 929, loss = 368940878.18231773\n",
      "Iteration 930, loss = 368378172.05241567\n",
      "Iteration 931, loss = 367830837.44995129\n",
      "Iteration 932, loss = 367275674.31190223\n",
      "Iteration 933, loss = 366675011.99360919\n",
      "Iteration 934, loss = 366129127.42768782\n",
      "Iteration 935, loss = 365579455.40972757\n",
      "Iteration 936, loss = 365039422.53854895\n",
      "Iteration 937, loss = 364476621.22762161\n",
      "Iteration 938, loss = 363908775.55133158\n",
      "Iteration 939, loss = 363381873.46250534\n",
      "Iteration 940, loss = 362818771.76407039\n",
      "Iteration 941, loss = 362263617.35502452\n",
      "Iteration 942, loss = 361699302.03545576\n",
      "Iteration 943, loss = 361180358.61974227\n",
      "Iteration 944, loss = 360626775.46040565\n",
      "Iteration 945, loss = 360088805.70932758\n",
      "Iteration 946, loss = 359536945.68554533\n",
      "Iteration 947, loss = 358983860.57514083\n",
      "Iteration 948, loss = 358431165.82971168\n",
      "Iteration 949, loss = 357906602.99932778\n",
      "Iteration 950, loss = 357362543.09558916\n",
      "Iteration 951, loss = 356799296.90091276\n",
      "Iteration 952, loss = 356278254.98632383\n",
      "Iteration 953, loss = 355690429.54841566\n",
      "Iteration 954, loss = 355181423.18726569\n",
      "Iteration 955, loss = 354580227.26819164\n",
      "Iteration 956, loss = 354142671.02555192\n",
      "Iteration 957, loss = 353486368.92646730\n",
      "Iteration 958, loss = 352958082.06727159\n",
      "Iteration 959, loss = 352405339.74096304\n",
      "Iteration 960, loss = 351886180.22738242\n",
      "Iteration 961, loss = 351354651.01065952\n",
      "Iteration 962, loss = 350786920.23559529\n",
      "Iteration 963, loss = 350245377.67156553\n",
      "Iteration 964, loss = 349751553.61636621\n",
      "Iteration 965, loss = 349159926.28676474\n",
      "Iteration 966, loss = 348621490.26563096\n",
      "Iteration 967, loss = 348088464.26204586\n",
      "Iteration 968, loss = 347558132.13823301\n",
      "Iteration 969, loss = 346998858.38411826\n",
      "Iteration 970, loss = 346477387.82148272\n",
      "Iteration 971, loss = 345910398.69972438\n",
      "Iteration 972, loss = 345372851.15348727\n",
      "Iteration 973, loss = 344811647.99347287\n",
      "Iteration 974, loss = 344274403.25872749\n",
      "Iteration 975, loss = 343741499.33649784\n",
      "Iteration 976, loss = 343161260.14738613\n",
      "Iteration 977, loss = 342641426.82658011\n",
      "Iteration 978, loss = 342102891.20505267\n",
      "Iteration 979, loss = 341528725.94902545\n",
      "Iteration 980, loss = 341008991.51133680\n",
      "Iteration 981, loss = 340437662.95381731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 982, loss = 339880574.34569186\n",
      "Iteration 983, loss = 339351381.98284245\n",
      "Iteration 984, loss = 338833996.62293035\n",
      "Iteration 985, loss = 338272366.69822979\n",
      "Iteration 986, loss = 337715145.20923102\n",
      "Iteration 987, loss = 337134520.76956153\n",
      "Iteration 988, loss = 336597257.68762511\n",
      "Iteration 989, loss = 336038742.28780806\n",
      "Iteration 990, loss = 335490206.98877490\n",
      "Iteration 991, loss = 334918578.49329001\n",
      "Iteration 992, loss = 334375298.66248703\n",
      "Iteration 993, loss = 333800904.96662265\n",
      "Iteration 994, loss = 333268325.82327497\n",
      "Iteration 995, loss = 332689225.43220681\n",
      "Iteration 996, loss = 332151493.39508694\n",
      "Iteration 997, loss = 331534558.40115881\n",
      "Iteration 998, loss = 330957303.14557868\n",
      "Iteration 999, loss = 330378926.39451611\n",
      "Iteration 1000, loss = 329823003.18595797\n",
      "Iteration 1001, loss = 329226173.06474215\n",
      "Iteration 1002, loss = 328662981.49930865\n",
      "Iteration 1003, loss = 328077969.81989515\n",
      "Iteration 1004, loss = 327507010.99550635\n",
      "Iteration 1005, loss = 326876512.73909837\n",
      "Iteration 1006, loss = 326291975.90573478\n",
      "Iteration 1007, loss = 325729303.60274965\n",
      "Iteration 1008, loss = 325106402.73286074\n",
      "Iteration 1009, loss = 324506097.60753363\n",
      "Iteration 1010, loss = 323897783.13283658\n",
      "Iteration 1011, loss = 323290192.68379438\n",
      "Iteration 1012, loss = 322680105.07791144\n",
      "Iteration 1013, loss = 322073410.42629588\n",
      "Iteration 1014, loss = 321444856.00458711\n",
      "Iteration 1015, loss = 320807423.32866055\n",
      "Iteration 1016, loss = 320212114.54795361\n",
      "Iteration 1017, loss = 319611915.01999944\n",
      "Iteration 1018, loss = 318952149.01131022\n",
      "Iteration 1019, loss = 318322444.81935370\n",
      "Iteration 1020, loss = 317728361.82144833\n",
      "Iteration 1021, loss = 317090981.52906370\n",
      "Iteration 1022, loss = 316462029.03877038\n",
      "Iteration 1023, loss = 315798194.64220339\n",
      "Iteration 1024, loss = 315131464.69006652\n",
      "Iteration 1025, loss = 314451051.32938820\n",
      "Iteration 1026, loss = 313697378.65389508\n",
      "Iteration 1027, loss = 312994359.23720890\n",
      "Iteration 1028, loss = 312300615.48477495\n",
      "Iteration 1029, loss = 311634856.91592008\n",
      "Iteration 1030, loss = 310979892.31159031\n",
      "Iteration 1031, loss = 310335586.19928116\n",
      "Iteration 1032, loss = 309700589.41584527\n",
      "Iteration 1033, loss = 309109306.53183776\n",
      "Iteration 1034, loss = 308449427.26329881\n",
      "Iteration 1035, loss = 307870320.05546552\n",
      "Iteration 1036, loss = 307281822.90775126\n",
      "Iteration 1037, loss = 306717814.18867427\n",
      "Iteration 1038, loss = 306150098.45027411\n",
      "Iteration 1039, loss = 305614364.63347411\n",
      "Iteration 1040, loss = 305025452.96117878\n",
      "Iteration 1041, loss = 304457183.59524238\n",
      "Iteration 1042, loss = 303902906.15330398\n",
      "Iteration 1043, loss = 303315261.92535663\n",
      "Iteration 1044, loss = 302758479.30355841\n",
      "Iteration 1045, loss = 302251055.91970927\n",
      "Iteration 1046, loss = 301670267.36600631\n",
      "Iteration 1047, loss = 301140966.45102042\n",
      "Iteration 1048, loss = 300599104.40597868\n",
      "Iteration 1049, loss = 300028984.01219922\n",
      "Iteration 1050, loss = 299445490.39171338\n",
      "Iteration 1051, loss = 298917575.95278674\n",
      "Iteration 1052, loss = 298364302.01560718\n",
      "Iteration 1053, loss = 297849749.16627258\n",
      "Iteration 1054, loss = 297262715.33010465\n",
      "Iteration 1055, loss = 296715515.77155310\n",
      "Iteration 1056, loss = 296211103.66924316\n",
      "Iteration 1057, loss = 295660243.85805219\n",
      "Iteration 1058, loss = 295073991.35349649\n",
      "Iteration 1059, loss = 294548859.29653466\n",
      "Iteration 1060, loss = 293980521.75785208\n",
      "Iteration 1061, loss = 293468691.09955758\n",
      "Iteration 1062, loss = 292909114.68315697\n",
      "Iteration 1063, loss = 292354373.87550700\n",
      "Iteration 1064, loss = 291853675.32402241\n",
      "Iteration 1065, loss = 291288260.05233294\n",
      "Iteration 1066, loss = 290773465.93082744\n",
      "Iteration 1067, loss = 290212498.71142608\n",
      "Iteration 1068, loss = 289699077.57965529\n",
      "Iteration 1069, loss = 289132938.28941876\n",
      "Iteration 1070, loss = 288588807.35771167\n",
      "Iteration 1071, loss = 288081653.37308729\n",
      "Iteration 1072, loss = 287563892.54662949\n",
      "Iteration 1073, loss = 287019736.49235582\n",
      "Iteration 1074, loss = 286477842.55197442\n",
      "Iteration 1075, loss = 285964841.19365996\n",
      "Iteration 1076, loss = 285427058.34676665\n",
      "Iteration 1077, loss = 284897939.61082959\n",
      "Iteration 1078, loss = 284343904.43696189\n",
      "Iteration 1079, loss = 283825072.33724767\n",
      "Iteration 1080, loss = 283296625.92245090\n",
      "Iteration 1081, loss = 282784570.67590380\n",
      "Iteration 1082, loss = 282200839.49885625\n",
      "Iteration 1083, loss = 281709224.87334907\n",
      "Iteration 1084, loss = 281150312.43177050\n",
      "Iteration 1085, loss = 280647888.63397628\n",
      "Iteration 1086, loss = 280090753.13896334\n",
      "Iteration 1087, loss = 279591645.96943200\n",
      "Iteration 1088, loss = 279050477.31919068\n",
      "Iteration 1089, loss = 278516850.18801087\n",
      "Iteration 1090, loss = 277967015.62833345\n",
      "Iteration 1091, loss = 277455304.89336163\n",
      "Iteration 1092, loss = 276929257.71375424\n",
      "Iteration 1093, loss = 276389147.13725239\n",
      "Iteration 1094, loss = 275888450.91834152\n",
      "Iteration 1095, loss = 275337898.88295817\n",
      "Iteration 1096, loss = 274802207.25145531\n",
      "Iteration 1097, loss = 274303597.01743460\n",
      "Iteration 1098, loss = 273744372.99244231\n",
      "Iteration 1099, loss = 273226661.75283837\n",
      "Iteration 1100, loss = 272706812.97843415\n",
      "Iteration 1101, loss = 272185694.57224596\n",
      "Iteration 1102, loss = 271649755.89997143\n",
      "Iteration 1103, loss = 271149238.55519557\n",
      "Iteration 1104, loss = 270590532.96461266\n",
      "Iteration 1105, loss = 270066554.07692808\n",
      "Iteration 1106, loss = 269532491.36206150\n",
      "Iteration 1107, loss = 269046790.23875254\n",
      "Iteration 1108, loss = 268489422.96547198\n",
      "Iteration 1109, loss = 267928368.81426138\n",
      "Iteration 1110, loss = 267388193.43007141\n",
      "Iteration 1111, loss = 266837321.13562098\n",
      "Iteration 1112, loss = 266286632.89588073\n",
      "Iteration 1113, loss = 265785928.28946400\n",
      "Iteration 1114, loss = 265197381.59045798\n",
      "Iteration 1115, loss = 264661968.05559522\n",
      "Iteration 1116, loss = 264082900.35168216\n",
      "Iteration 1117, loss = 263538775.99909508\n",
      "Iteration 1118, loss = 262981764.68633381\n",
      "Iteration 1119, loss = 262428370.62517738\n",
      "Iteration 1120, loss = 261869692.72431761\n",
      "Iteration 1121, loss = 261327157.16464356\n",
      "Iteration 1122, loss = 260727893.21104419\n",
      "Iteration 1123, loss = 260186086.61732861\n",
      "Iteration 1124, loss = 259658424.09400588\n",
      "Iteration 1125, loss = 259104405.05542001\n",
      "Iteration 1126, loss = 258532055.52484187\n",
      "Iteration 1127, loss = 257991805.32295275\n",
      "Iteration 1128, loss = 257439275.26562512\n",
      "Iteration 1129, loss = 256849617.59387487\n",
      "Iteration 1130, loss = 256299900.05921751\n",
      "Iteration 1131, loss = 255706163.78086421\n",
      "Iteration 1132, loss = 255098785.32791632\n",
      "Iteration 1133, loss = 254516946.60258865\n",
      "Iteration 1134, loss = 253946274.25474808\n",
      "Iteration 1135, loss = 253367582.52661586\n",
      "Iteration 1136, loss = 252822180.22091937\n",
      "Iteration 1137, loss = 252265334.92756641\n",
      "Iteration 1138, loss = 251741521.82122141\n",
      "Iteration 1139, loss = 251224133.20767227\n",
      "Iteration 1140, loss = 250719071.53267795\n",
      "Iteration 1141, loss = 250168337.17156094\n",
      "Iteration 1142, loss = 249690815.76900348\n",
      "Iteration 1143, loss = 249211110.48570213\n",
      "Iteration 1144, loss = 248723802.22460693\n",
      "Iteration 1145, loss = 248240133.86419782\n",
      "Iteration 1146, loss = 247752145.80570549\n",
      "Iteration 1147, loss = 247275640.28701839\n",
      "Iteration 1148, loss = 246813133.63087305\n",
      "Iteration 1149, loss = 246323104.28778744\n",
      "Iteration 1150, loss = 245842715.58765844\n",
      "Iteration 1151, loss = 245369238.07858035\n",
      "Iteration 1152, loss = 244900451.46245700\n",
      "Iteration 1153, loss = 244433333.74666083\n",
      "Iteration 1154, loss = 243930768.69961661\n",
      "Iteration 1155, loss = 243457894.14141351\n",
      "Iteration 1156, loss = 243011963.10279283\n",
      "Iteration 1157, loss = 242521066.72977662\n",
      "Iteration 1158, loss = 242072939.73497131\n",
      "Iteration 1159, loss = 241587238.60823333\n",
      "Iteration 1160, loss = 241110474.62801662\n",
      "Iteration 1161, loss = 240633806.54495171\n",
      "Iteration 1162, loss = 240184181.29203254\n",
      "Iteration 1163, loss = 239711834.59926498\n",
      "Iteration 1164, loss = 239233094.07585615\n",
      "Iteration 1165, loss = 238791289.29787388\n",
      "Iteration 1166, loss = 238339872.21657443\n",
      "Iteration 1167, loss = 237878155.02267230\n",
      "Iteration 1168, loss = 237399767.06691355\n",
      "Iteration 1169, loss = 236939552.33014762\n",
      "Iteration 1170, loss = 236569733.23593804\n",
      "Iteration 1171, loss = 236061409.36658847\n",
      "Iteration 1172, loss = 235620528.98715401\n",
      "Iteration 1173, loss = 235229727.17184880\n",
      "Iteration 1174, loss = 234771158.49749765\n",
      "Iteration 1175, loss = 234331489.11972168\n",
      "Iteration 1176, loss = 233892415.05357608\n",
      "Iteration 1177, loss = 233495913.72261032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1178, loss = 233035586.73213613\n",
      "Iteration 1179, loss = 232623312.30459386\n",
      "Iteration 1180, loss = 232153479.25280881\n",
      "Iteration 1181, loss = 231704534.56089714\n",
      "Iteration 1182, loss = 231283597.88142666\n",
      "Iteration 1183, loss = 230836757.35212460\n",
      "Iteration 1184, loss = 230383013.64331657\n",
      "Iteration 1185, loss = 229949605.99573720\n",
      "Iteration 1186, loss = 229522887.90697742\n",
      "Iteration 1187, loss = 229079509.11808297\n",
      "Iteration 1188, loss = 228600618.46910056\n",
      "Iteration 1189, loss = 228184084.36714676\n",
      "Iteration 1190, loss = 227758739.75356403\n",
      "Iteration 1191, loss = 227310739.12050584\n",
      "Iteration 1192, loss = 226873378.55481914\n",
      "Iteration 1193, loss = 226432660.86422554\n",
      "Iteration 1194, loss = 226019209.67291549\n",
      "Iteration 1195, loss = 225591561.77375898\n",
      "Iteration 1196, loss = 225146245.42457172\n",
      "Iteration 1197, loss = 224707356.76603836\n",
      "Iteration 1198, loss = 224282748.47594947\n",
      "Iteration 1199, loss = 223840312.95300615\n",
      "Iteration 1200, loss = 223402721.39745751\n",
      "Iteration 1201, loss = 223000049.04223278\n",
      "Iteration 1202, loss = 222578817.83002463\n",
      "Iteration 1203, loss = 222121342.48247769\n",
      "Iteration 1204, loss = 221703779.21349281\n",
      "Iteration 1205, loss = 221278772.95929626\n",
      "Iteration 1206, loss = 220887679.04200652\n",
      "Iteration 1207, loss = 220435477.31809548\n",
      "Iteration 1208, loss = 220024223.45596954\n",
      "Iteration 1209, loss = 219684749.54747629\n",
      "Iteration 1210, loss = 219201466.41324422\n",
      "Iteration 1211, loss = 218809084.15255493\n",
      "Iteration 1212, loss = 218403013.27914324\n",
      "Iteration 1213, loss = 218005696.28444281\n",
      "Iteration 1214, loss = 217579882.50361115\n",
      "Iteration 1215, loss = 217179882.71216634\n",
      "Iteration 1216, loss = 216789651.98353699\n",
      "Iteration 1217, loss = 216411759.52674642\n",
      "Iteration 1218, loss = 215966505.50738010\n",
      "Iteration 1219, loss = 215575576.53298628\n",
      "Iteration 1220, loss = 215176063.02868447\n",
      "Iteration 1221, loss = 214774710.45827547\n",
      "Iteration 1222, loss = 214415471.75905693\n",
      "Iteration 1223, loss = 213979790.40144265\n",
      "Iteration 1224, loss = 213584557.29979128\n",
      "Iteration 1225, loss = 213218461.77678522\n",
      "Iteration 1226, loss = 212783647.14830592\n",
      "Iteration 1227, loss = 212394058.44932002\n",
      "Iteration 1228, loss = 212002836.49862093\n",
      "Iteration 1229, loss = 211613664.13164720\n",
      "Iteration 1230, loss = 211173049.77065411\n",
      "Iteration 1231, loss = 210788276.33659574\n",
      "Iteration 1232, loss = 210400075.62295333\n",
      "Iteration 1233, loss = 209987997.71131301\n",
      "Iteration 1234, loss = 209603089.49501732\n",
      "Iteration 1235, loss = 209205071.88624635\n",
      "Iteration 1236, loss = 208838913.78927505\n",
      "Iteration 1237, loss = 208404133.20990974\n",
      "Iteration 1238, loss = 208030220.81840217\n",
      "Iteration 1239, loss = 207664357.86039296\n",
      "Iteration 1240, loss = 207237135.40608203\n",
      "Iteration 1241, loss = 206859987.57496211\n",
      "Iteration 1242, loss = 206460539.10950023\n",
      "Iteration 1243, loss = 206113528.83275846\n",
      "Iteration 1244, loss = 205693480.80117923\n",
      "Iteration 1245, loss = 205276170.73322216\n",
      "Iteration 1246, loss = 204904502.77187631\n",
      "Iteration 1247, loss = 204490274.74800724\n",
      "Iteration 1248, loss = 204122000.92065540\n",
      "Iteration 1249, loss = 203739652.05523488\n",
      "Iteration 1250, loss = 203352808.24473611\n",
      "Iteration 1251, loss = 203032651.05106530\n",
      "Iteration 1252, loss = 202608943.14719245\n",
      "Iteration 1253, loss = 202229765.96900249\n",
      "Iteration 1254, loss = 201856313.27583107\n",
      "Iteration 1255, loss = 201503636.46936300\n",
      "Iteration 1256, loss = 201077789.23994938\n",
      "Iteration 1257, loss = 200722270.57583407\n",
      "Iteration 1258, loss = 200374861.54581586\n",
      "Iteration 1259, loss = 200028296.87330064\n",
      "Iteration 1260, loss = 199634354.81472453\n",
      "Iteration 1261, loss = 199321083.11131504\n",
      "Iteration 1262, loss = 198932394.37522826\n",
      "Iteration 1263, loss = 198536749.02795231\n",
      "Iteration 1264, loss = 198194353.84565732\n",
      "Iteration 1265, loss = 197820394.55102524\n",
      "Iteration 1266, loss = 197451760.95976979\n",
      "Iteration 1267, loss = 197085955.58629405\n",
      "Iteration 1268, loss = 196721475.76180276\n",
      "Iteration 1269, loss = 196385391.72827941\n",
      "Iteration 1270, loss = 196003916.53321838\n",
      "Iteration 1271, loss = 195631783.09376404\n",
      "Iteration 1272, loss = 195277559.34454215\n",
      "Iteration 1273, loss = 194927909.25943005\n",
      "Iteration 1274, loss = 194561644.66711226\n",
      "Iteration 1275, loss = 194225338.24104521\n",
      "Iteration 1276, loss = 193841444.11850223\n",
      "Iteration 1277, loss = 193512480.37475753\n",
      "Iteration 1278, loss = 193157714.24723816\n",
      "Iteration 1279, loss = 192800652.70570427\n",
      "Iteration 1280, loss = 192473936.34387860\n",
      "Iteration 1281, loss = 192073173.57826811\n",
      "Iteration 1282, loss = 191709780.93737838\n",
      "Iteration 1283, loss = 191440093.59608755\n",
      "Iteration 1284, loss = 191068664.47468820\n",
      "Iteration 1285, loss = 190692969.44700027\n",
      "Iteration 1286, loss = 190325401.10167307\n",
      "Iteration 1287, loss = 189991983.73367068\n",
      "Iteration 1288, loss = 189657059.78620502\n",
      "Iteration 1289, loss = 189317310.10633001\n",
      "Iteration 1290, loss = 188973578.67363393\n",
      "Iteration 1291, loss = 188619794.15342605\n",
      "Iteration 1292, loss = 188301819.73994198\n",
      "Iteration 1293, loss = 187937261.39803392\n",
      "Iteration 1294, loss = 187598708.09851313\n",
      "Iteration 1295, loss = 187254841.04068860\n",
      "Iteration 1296, loss = 186917387.68604583\n",
      "Iteration 1297, loss = 186583085.19903454\n",
      "Iteration 1298, loss = 186262212.42370555\n",
      "Iteration 1299, loss = 185915997.11443290\n",
      "Iteration 1300, loss = 185559738.12675568\n",
      "Iteration 1301, loss = 185220936.83248660\n",
      "Iteration 1302, loss = 184908539.48876005\n",
      "Iteration 1303, loss = 184560347.37164575\n",
      "Iteration 1304, loss = 184226525.97035533\n",
      "Iteration 1305, loss = 183892414.98005641\n",
      "Iteration 1306, loss = 183566688.53608337\n",
      "Iteration 1307, loss = 183228339.13978940\n",
      "Iteration 1308, loss = 182906089.25216326\n",
      "Iteration 1309, loss = 182591786.46898159\n",
      "Iteration 1310, loss = 182231006.78060287\n",
      "Iteration 1311, loss = 181927405.03431350\n",
      "Iteration 1312, loss = 181596406.53453428\n",
      "Iteration 1313, loss = 181257196.17618793\n",
      "Iteration 1314, loss = 180929547.59391993\n",
      "Iteration 1315, loss = 180616918.63417768\n",
      "Iteration 1316, loss = 180309472.12546077\n",
      "Iteration 1317, loss = 179998296.66212326\n",
      "Iteration 1318, loss = 179663696.44750434\n",
      "Iteration 1319, loss = 179324893.63478425\n",
      "Iteration 1320, loss = 178992774.14678878\n",
      "Iteration 1321, loss = 178696321.51664150\n",
      "Iteration 1322, loss = 178400606.23768765\n",
      "Iteration 1323, loss = 178046399.80505142\n",
      "Iteration 1324, loss = 177742157.59374282\n",
      "Iteration 1325, loss = 177435051.41803384\n",
      "Iteration 1326, loss = 177124400.16914627\n",
      "Iteration 1327, loss = 176813257.51951188\n",
      "Iteration 1328, loss = 176512248.46730468\n",
      "Iteration 1329, loss = 176197830.83254257\n",
      "Iteration 1330, loss = 175876243.98155332\n",
      "Iteration 1331, loss = 175592068.79737052\n",
      "Iteration 1332, loss = 175279834.20067963\n",
      "Iteration 1333, loss = 174978596.45921189\n",
      "Iteration 1334, loss = 174680466.55534872\n",
      "Iteration 1335, loss = 174389444.45862591\n",
      "Iteration 1336, loss = 174063811.70446458\n",
      "Iteration 1337, loss = 173778636.31611222\n",
      "Iteration 1338, loss = 173501787.57948464\n",
      "Iteration 1339, loss = 173207570.75069234\n",
      "Iteration 1340, loss = 172877132.49417630\n",
      "Iteration 1341, loss = 172603332.29396439\n",
      "Iteration 1342, loss = 172285086.78621635\n",
      "Iteration 1343, loss = 171987185.16339383\n",
      "Iteration 1344, loss = 171678082.45867935\n",
      "Iteration 1345, loss = 171402417.01880255\n",
      "Iteration 1346, loss = 171107120.22270685\n",
      "Iteration 1347, loss = 170868445.10035720\n",
      "Iteration 1348, loss = 170540940.56396806\n",
      "Iteration 1349, loss = 170233691.03859609\n",
      "Iteration 1350, loss = 169938398.61411336\n",
      "Iteration 1351, loss = 169706310.74791479\n",
      "Iteration 1352, loss = 169388523.58356023\n",
      "Iteration 1353, loss = 169101291.49928281\n",
      "Iteration 1354, loss = 168787736.29891065\n",
      "Iteration 1355, loss = 168564175.02705669\n",
      "Iteration 1356, loss = 168281929.80111322\n",
      "Iteration 1357, loss = 167983989.81444579\n",
      "Iteration 1358, loss = 167706112.37357068\n",
      "Iteration 1359, loss = 167437404.50932950\n",
      "Iteration 1360, loss = 167142370.50213939\n",
      "Iteration 1361, loss = 166893361.46465126\n",
      "Iteration 1362, loss = 166612981.28172034\n",
      "Iteration 1363, loss = 166323457.11306873\n",
      "Iteration 1364, loss = 166068954.69833642\n",
      "Iteration 1365, loss = 165783798.30394936\n",
      "Iteration 1366, loss = 165529957.58573511\n",
      "Iteration 1367, loss = 165252391.02798328\n",
      "Iteration 1368, loss = 164986808.60404462\n",
      "Iteration 1369, loss = 164736157.01589110\n",
      "Iteration 1370, loss = 164463192.74043339\n",
      "Iteration 1371, loss = 164196524.61840692\n",
      "Iteration 1372, loss = 163927651.07869959\n",
      "Iteration 1373, loss = 163699655.47925898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1374, loss = 163409193.98534808\n",
      "Iteration 1375, loss = 163171297.76604486\n",
      "Iteration 1376, loss = 162925207.91686699\n",
      "Iteration 1377, loss = 162625000.40535766\n",
      "Iteration 1378, loss = 162356218.46080059\n",
      "Iteration 1379, loss = 162094157.83703831\n",
      "Iteration 1380, loss = 161862530.52413112\n",
      "Iteration 1381, loss = 161572820.12355816\n",
      "Iteration 1382, loss = 161333430.72963458\n",
      "Iteration 1383, loss = 161078416.75258297\n",
      "Iteration 1384, loss = 160812062.60444775\n",
      "Iteration 1385, loss = 160544259.41874188\n",
      "Iteration 1386, loss = 160286112.12392318\n",
      "Iteration 1387, loss = 160044893.93069100\n",
      "Iteration 1388, loss = 159796553.93418893\n",
      "Iteration 1389, loss = 159536485.67393067\n",
      "Iteration 1390, loss = 159294124.73227063\n",
      "Iteration 1391, loss = 159024940.33777389\n",
      "Iteration 1392, loss = 158783004.99323699\n",
      "Iteration 1393, loss = 158526147.26834944\n",
      "Iteration 1394, loss = 158286590.88713536\n",
      "Iteration 1395, loss = 158007812.09885961\n",
      "Iteration 1396, loss = 157762954.27136377\n",
      "Iteration 1397, loss = 157531725.67865872\n",
      "Iteration 1398, loss = 157277544.11011955\n",
      "Iteration 1399, loss = 157024429.19019106\n",
      "Iteration 1400, loss = 156793002.64622518\n",
      "Iteration 1401, loss = 156566103.19719779\n",
      "Iteration 1402, loss = 156311072.41278696\n",
      "Iteration 1403, loss = 156099454.38902861\n",
      "Iteration 1404, loss = 155849350.18213040\n",
      "Iteration 1405, loss = 155597849.93159902\n",
      "Iteration 1406, loss = 155369747.76424256\n",
      "Iteration 1407, loss = 155122045.02743825\n",
      "Iteration 1408, loss = 154900610.33827117\n",
      "Iteration 1409, loss = 154661086.35050747\n",
      "Iteration 1410, loss = 154414758.37744382\n",
      "Iteration 1411, loss = 154211326.85782599\n",
      "Iteration 1412, loss = 153955354.85753661\n",
      "Iteration 1413, loss = 153733755.87985182\n",
      "Iteration 1414, loss = 153500803.27769130\n",
      "Iteration 1415, loss = 153319388.44703308\n",
      "Iteration 1416, loss = 153041679.78644794\n",
      "Iteration 1417, loss = 152824981.08553115\n",
      "Iteration 1418, loss = 152602274.01642141\n",
      "Iteration 1419, loss = 152397218.30260235\n",
      "Iteration 1420, loss = 152191825.40110272\n",
      "Iteration 1421, loss = 151937072.83898142\n",
      "Iteration 1422, loss = 151710456.33216995\n",
      "Iteration 1423, loss = 151469782.21201840\n",
      "Iteration 1424, loss = 151311876.18487999\n",
      "Iteration 1425, loss = 151055481.57170022\n",
      "Iteration 1426, loss = 150838793.88413349\n",
      "Iteration 1427, loss = 150618431.99267617\n",
      "Iteration 1428, loss = 150413812.14359546\n",
      "Iteration 1429, loss = 150169760.71335962\n",
      "Iteration 1430, loss = 149958718.13069913\n",
      "Iteration 1431, loss = 149741885.62804905\n",
      "Iteration 1432, loss = 149520145.58667022\n",
      "Iteration 1433, loss = 149334318.12788096\n",
      "Iteration 1434, loss = 149082309.57817069\n",
      "Iteration 1435, loss = 148882510.94175026\n",
      "Iteration 1436, loss = 148656769.20862487\n",
      "Iteration 1437, loss = 148464013.72981116\n",
      "Iteration 1438, loss = 148235341.64023063\n",
      "Iteration 1439, loss = 148052551.45006928\n",
      "Iteration 1440, loss = 147804334.98876143\n",
      "Iteration 1441, loss = 147595975.32720342\n",
      "Iteration 1442, loss = 147397485.26420489\n",
      "Iteration 1443, loss = 147172982.40073901\n",
      "Iteration 1444, loss = 146981037.59462273\n",
      "Iteration 1445, loss = 146764130.34404311\n",
      "Iteration 1446, loss = 146568561.38731712\n",
      "Iteration 1447, loss = 146348873.72458771\n",
      "Iteration 1448, loss = 146149178.70774612\n",
      "Iteration 1449, loss = 145957461.90573722\n",
      "Iteration 1450, loss = 145763177.00282484\n",
      "Iteration 1451, loss = 145522214.72864690\n",
      "Iteration 1452, loss = 145333657.39621899\n",
      "Iteration 1453, loss = 145146192.17778316\n",
      "Iteration 1454, loss = 144905625.17120981\n",
      "Iteration 1455, loss = 144715123.43809363\n",
      "Iteration 1456, loss = 144496584.18139347\n",
      "Iteration 1457, loss = 144312028.98622325\n",
      "Iteration 1458, loss = 144097867.97173461\n",
      "Iteration 1459, loss = 143923786.85801733\n",
      "Iteration 1460, loss = 143732141.33105749\n",
      "Iteration 1461, loss = 143524466.86978588\n",
      "Iteration 1462, loss = 143326089.31754223\n",
      "Iteration 1463, loss = 143118316.18358392\n",
      "Iteration 1464, loss = 142942536.87380797\n",
      "Iteration 1465, loss = 142732170.59758350\n",
      "Iteration 1466, loss = 142543596.12935272\n",
      "Iteration 1467, loss = 142368570.28361070\n",
      "Iteration 1468, loss = 142146855.55135867\n",
      "Iteration 1469, loss = 141959956.41664594\n",
      "Iteration 1470, loss = 141771662.67049974\n",
      "Iteration 1471, loss = 141570590.87263131\n",
      "Iteration 1472, loss = 141397736.56720862\n",
      "Iteration 1473, loss = 141218134.17754534\n",
      "Iteration 1474, loss = 141007744.70619807\n",
      "Iteration 1475, loss = 140824925.27476493\n",
      "Iteration 1476, loss = 140639021.75874358\n",
      "Iteration 1477, loss = 140433103.11304635\n",
      "Iteration 1478, loss = 140245126.89589041\n",
      "Iteration 1479, loss = 140063167.95619050\n",
      "Iteration 1480, loss = 139868246.91839659\n",
      "Iteration 1481, loss = 139729118.68664959\n",
      "Iteration 1482, loss = 139489983.60862720\n",
      "Iteration 1483, loss = 139354672.15750650\n",
      "Iteration 1484, loss = 139165978.54471388\n",
      "Iteration 1485, loss = 138938159.01934543\n",
      "Iteration 1486, loss = 138808868.39264640\n",
      "Iteration 1487, loss = 138581985.16533241\n",
      "Iteration 1488, loss = 138416055.97849980\n",
      "Iteration 1489, loss = 138242401.39655083\n",
      "Iteration 1490, loss = 138048943.13805723\n",
      "Iteration 1491, loss = 137872020.75066426\n",
      "Iteration 1492, loss = 137709388.01452062\n",
      "Iteration 1493, loss = 137524915.95419550\n",
      "Iteration 1494, loss = 137343281.39678586\n",
      "Iteration 1495, loss = 137204915.46306205\n",
      "Iteration 1496, loss = 136988691.04865453\n",
      "Iteration 1497, loss = 136848712.03594017\n",
      "Iteration 1498, loss = 136640337.57242262\n",
      "Iteration 1499, loss = 136487751.57131031\n",
      "Iteration 1500, loss = 136273721.55399647\n",
      "Iteration 1501, loss = 136105844.52578092\n",
      "Iteration 1502, loss = 135907580.86950335\n",
      "Iteration 1503, loss = 135778172.24952754\n",
      "Iteration 1504, loss = 135571965.86507154\n",
      "Iteration 1505, loss = 135411311.15248650\n",
      "Iteration 1506, loss = 135248776.47189447\n",
      "Iteration 1507, loss = 135089468.96503353\n",
      "Iteration 1508, loss = 134882540.08724672\n",
      "Iteration 1509, loss = 134736869.00225762\n",
      "Iteration 1510, loss = 134542152.75349674\n",
      "Iteration 1511, loss = 134356366.88407999\n",
      "Iteration 1512, loss = 134228749.95415404\n",
      "Iteration 1513, loss = 134044412.91138117\n",
      "Iteration 1514, loss = 133862843.15429021\n",
      "Iteration 1515, loss = 133694251.12740213\n",
      "Iteration 1516, loss = 133549114.08039358\n",
      "Iteration 1517, loss = 133364363.56954026\n",
      "Iteration 1518, loss = 133203749.63433926\n",
      "Iteration 1519, loss = 133022249.23802935\n",
      "Iteration 1520, loss = 132893441.44320235\n",
      "Iteration 1521, loss = 132720773.78819807\n",
      "Iteration 1522, loss = 132554660.99101201\n",
      "Iteration 1523, loss = 132445460.94511653\n",
      "Iteration 1524, loss = 132247018.47473869\n",
      "Iteration 1525, loss = 132119316.52133004\n",
      "Iteration 1526, loss = 131917676.28429435\n",
      "Iteration 1527, loss = 131732127.06516200\n",
      "Iteration 1528, loss = 131607172.90794113\n",
      "Iteration 1529, loss = 131431777.59789130\n",
      "Iteration 1530, loss = 131261454.44895822\n",
      "Iteration 1531, loss = 131106624.20771489\n",
      "Iteration 1532, loss = 131017874.32563129\n",
      "Iteration 1533, loss = 130790895.90329495\n",
      "Iteration 1534, loss = 130666240.15239823\n",
      "Iteration 1535, loss = 130504586.10696048\n",
      "Iteration 1536, loss = 130359319.19616523\n",
      "Iteration 1537, loss = 130201456.11290804\n",
      "Iteration 1538, loss = 130074541.16108811\n",
      "Iteration 1539, loss = 129940095.88713938\n",
      "Iteration 1540, loss = 129752722.45392239\n",
      "Iteration 1541, loss = 129611693.64685850\n",
      "Iteration 1542, loss = 129445804.12554827\n",
      "Iteration 1543, loss = 129317403.55150586\n",
      "Iteration 1544, loss = 129175494.39251488\n",
      "Iteration 1545, loss = 129008456.91814587\n",
      "Iteration 1546, loss = 128852208.97952306\n",
      "Iteration 1547, loss = 128713647.14504234\n",
      "Iteration 1548, loss = 128587306.44264980\n",
      "Iteration 1549, loss = 128431859.47065346\n",
      "Iteration 1550, loss = 128255484.43900011\n",
      "Iteration 1551, loss = 128124268.22243655\n",
      "Iteration 1552, loss = 127964515.80007982\n",
      "Iteration 1553, loss = 127823981.62431359\n",
      "Iteration 1554, loss = 127676608.43209450\n",
      "Iteration 1555, loss = 127526065.50763336\n",
      "Iteration 1556, loss = 127406386.19455767\n",
      "Iteration 1557, loss = 127247526.33101027\n",
      "Iteration 1558, loss = 127244890.27669419\n",
      "Iteration 1559, loss = 126988412.01519245\n",
      "Iteration 1560, loss = 126849787.57027093\n",
      "Iteration 1561, loss = 126704707.71579227\n",
      "Iteration 1562, loss = 126550332.21750262\n",
      "Iteration 1563, loss = 126425598.57057883\n",
      "Iteration 1564, loss = 126278868.51699458\n",
      "Iteration 1565, loss = 126157635.67902286\n",
      "Iteration 1566, loss = 126009039.75714758\n",
      "Iteration 1567, loss = 125868887.03025618\n",
      "Iteration 1568, loss = 125729912.42286645\n",
      "Iteration 1569, loss = 125598585.65122893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1570, loss = 125484673.69050834\n",
      "Iteration 1571, loss = 125340921.00138582\n",
      "Iteration 1572, loss = 125210361.58000501\n",
      "Iteration 1573, loss = 125059905.47065304\n",
      "Iteration 1574, loss = 124975180.52295491\n",
      "Iteration 1575, loss = 124795801.06039211\n",
      "Iteration 1576, loss = 124754541.93568408\n",
      "Iteration 1577, loss = 124531742.12792718\n",
      "Iteration 1578, loss = 124401687.04670948\n",
      "Iteration 1579, loss = 124272234.44549881\n",
      "Iteration 1580, loss = 124143093.45686573\n",
      "Iteration 1581, loss = 124015840.66432633\n",
      "Iteration 1582, loss = 123873803.19613430\n",
      "Iteration 1583, loss = 123743946.19262770\n",
      "Iteration 1584, loss = 123613404.01663189\n",
      "Iteration 1585, loss = 123491943.70641840\n",
      "Iteration 1586, loss = 123355419.93167374\n",
      "Iteration 1587, loss = 123218805.85875675\n",
      "Iteration 1588, loss = 123102743.61565116\n",
      "Iteration 1589, loss = 123006637.01345092\n",
      "Iteration 1590, loss = 122834709.23159403\n",
      "Iteration 1591, loss = 122710573.19851758\n",
      "Iteration 1592, loss = 122583252.52907568\n",
      "Iteration 1593, loss = 122466612.83303742\n",
      "Iteration 1594, loss = 122332925.93786520\n",
      "Iteration 1595, loss = 122230653.80456024\n",
      "Iteration 1596, loss = 122092140.76815127\n",
      "Iteration 1597, loss = 121965374.99853568\n",
      "Iteration 1598, loss = 121853255.98134238\n",
      "Iteration 1599, loss = 121712751.01851469\n",
      "Iteration 1600, loss = 121580078.03286174\n",
      "Iteration 1601, loss = 121469737.39576852\n",
      "Iteration 1602, loss = 121364980.04557596\n",
      "Iteration 1603, loss = 121229954.80330808\n",
      "Iteration 1604, loss = 121059379.67206083\n",
      "Iteration 1605, loss = 120950900.83744846\n",
      "Iteration 1606, loss = 120840003.15849096\n",
      "Iteration 1607, loss = 120698163.88502324\n",
      "Iteration 1608, loss = 120565173.30732937\n",
      "Iteration 1609, loss = 120454395.42344864\n",
      "Iteration 1610, loss = 120336833.04004407\n",
      "Iteration 1611, loss = 120235512.52885443\n",
      "Iteration 1612, loss = 120121587.86275907\n",
      "Iteration 1613, loss = 119992842.36380683\n",
      "Iteration 1614, loss = 119866430.18130395\n",
      "Iteration 1615, loss = 119729879.92019197\n",
      "Iteration 1616, loss = 119591276.38629705\n",
      "Iteration 1617, loss = 119478974.10855488\n",
      "Iteration 1618, loss = 119354515.12074192\n",
      "Iteration 1619, loss = 119234086.70737435\n",
      "Iteration 1620, loss = 119140604.04267320\n",
      "Iteration 1621, loss = 119008341.81353436\n",
      "Iteration 1622, loss = 118898688.51946414\n",
      "Iteration 1623, loss = 118788575.73826516\n",
      "Iteration 1624, loss = 118647951.43106696\n",
      "Iteration 1625, loss = 118521636.12371977\n",
      "Iteration 1626, loss = 118408694.91830713\n",
      "Iteration 1627, loss = 118313239.70229948\n",
      "Iteration 1628, loss = 118174302.81270012\n",
      "Iteration 1629, loss = 118057973.30943598\n",
      "Iteration 1630, loss = 117963375.59491117\n",
      "Iteration 1631, loss = 117828950.24402627\n",
      "Iteration 1632, loss = 117729746.26001459\n",
      "Iteration 1633, loss = 117590111.89670543\n",
      "Iteration 1634, loss = 117492013.73076625\n",
      "Iteration 1635, loss = 117379829.78274605\n",
      "Iteration 1636, loss = 117278120.18274902\n",
      "Iteration 1637, loss = 117150547.69821200\n",
      "Iteration 1638, loss = 117047485.17934322\n",
      "Iteration 1639, loss = 116939606.27616957\n",
      "Iteration 1640, loss = 116833780.09851626\n",
      "Iteration 1641, loss = 116701451.47265291\n",
      "Iteration 1642, loss = 116599687.96058685\n",
      "Iteration 1643, loss = 116489622.08830437\n",
      "Iteration 1644, loss = 116369627.47975610\n",
      "Iteration 1645, loss = 116296505.56992471\n",
      "Iteration 1646, loss = 116143278.88314693\n",
      "Iteration 1647, loss = 116041452.77143891\n",
      "Iteration 1648, loss = 115939271.57231571\n",
      "Iteration 1649, loss = 115844900.47840282\n",
      "Iteration 1650, loss = 115739479.58782472\n",
      "Iteration 1651, loss = 115605349.62966458\n",
      "Iteration 1652, loss = 115517936.72730823\n",
      "Iteration 1653, loss = 115390268.64813648\n",
      "Iteration 1654, loss = 115289890.68553908\n",
      "Iteration 1655, loss = 115193650.40731940\n",
      "Iteration 1656, loss = 115082346.54620957\n",
      "Iteration 1657, loss = 114961037.18130070\n",
      "Iteration 1658, loss = 114940621.62388869\n",
      "Iteration 1659, loss = 114773096.40663679\n",
      "Iteration 1660, loss = 114709163.66163075\n",
      "Iteration 1661, loss = 114575088.21080816\n",
      "Iteration 1662, loss = 114467396.16175921\n",
      "Iteration 1663, loss = 114385958.50788034\n",
      "Iteration 1664, loss = 114259773.54241578\n",
      "Iteration 1665, loss = 114188353.23855087\n",
      "Iteration 1666, loss = 114068836.26254743\n",
      "Iteration 1667, loss = 113991002.86967909\n",
      "Iteration 1668, loss = 113914109.64326788\n",
      "Iteration 1669, loss = 113794590.58797349\n",
      "Iteration 1670, loss = 113679538.77588946\n",
      "Iteration 1671, loss = 113598281.85554622\n",
      "Iteration 1672, loss = 113483221.74060269\n",
      "Iteration 1673, loss = 113449219.83826399\n",
      "Iteration 1674, loss = 113306100.80494916\n",
      "Iteration 1675, loss = 113217530.70453675\n",
      "Iteration 1676, loss = 113111258.25905898\n",
      "Iteration 1677, loss = 113049438.82989183\n",
      "Iteration 1678, loss = 112957610.55963391\n",
      "Iteration 1679, loss = 112854453.06804807\n",
      "Iteration 1680, loss = 112732261.79400472\n",
      "Iteration 1681, loss = 112641141.05951349\n",
      "Iteration 1682, loss = 112573451.67420705\n",
      "Iteration 1683, loss = 112452613.56387140\n",
      "Iteration 1684, loss = 112363214.31546620\n",
      "Iteration 1685, loss = 112273873.11623926\n",
      "Iteration 1686, loss = 112202587.92520230\n",
      "Iteration 1687, loss = 112091241.60411534\n",
      "Iteration 1688, loss = 111978790.42027269\n",
      "Iteration 1689, loss = 111915908.23330148\n",
      "Iteration 1690, loss = 111808614.88406894\n",
      "Iteration 1691, loss = 111736369.08880103\n",
      "Iteration 1692, loss = 111624278.55812684\n",
      "Iteration 1693, loss = 111543624.85228786\n",
      "Iteration 1694, loss = 111436358.00570340\n",
      "Iteration 1695, loss = 111356195.02741200\n",
      "Iteration 1696, loss = 111263170.81494276\n",
      "Iteration 1697, loss = 111170251.71910837\n",
      "Iteration 1698, loss = 111098267.99935767\n",
      "Iteration 1699, loss = 110996135.51278777\n",
      "Iteration 1700, loss = 110930285.08726594\n",
      "Iteration 1701, loss = 110820630.04275601\n",
      "Iteration 1702, loss = 110720028.82222909\n",
      "Iteration 1703, loss = 110644912.80972701\n",
      "Iteration 1704, loss = 110571564.02133207\n",
      "Iteration 1705, loss = 110467950.80631992\n",
      "Iteration 1706, loss = 110401644.96869728\n",
      "Iteration 1707, loss = 110330738.29028119\n",
      "Iteration 1708, loss = 110219686.31211995\n",
      "Iteration 1709, loss = 110142171.97133763\n",
      "Iteration 1710, loss = 110059082.24548334\n",
      "Iteration 1711, loss = 109978093.74122481\n",
      "Iteration 1712, loss = 109894882.38675006\n",
      "Iteration 1713, loss = 109835630.95050079\n",
      "Iteration 1714, loss = 109733112.01457219\n",
      "Iteration 1715, loss = 109673229.61007440\n",
      "Iteration 1716, loss = 109567382.34109603\n",
      "Iteration 1717, loss = 109499834.96429378\n",
      "Iteration 1718, loss = 109397284.78317225\n",
      "Iteration 1719, loss = 109329441.28246076\n",
      "Iteration 1720, loss = 109252561.25966741\n",
      "Iteration 1721, loss = 109165823.40587743\n",
      "Iteration 1722, loss = 109099399.63314264\n",
      "Iteration 1723, loss = 109012081.70503017\n",
      "Iteration 1724, loss = 108947396.95709434\n",
      "Iteration 1725, loss = 108876667.96724837\n",
      "Iteration 1726, loss = 108792480.87484504\n",
      "Iteration 1727, loss = 108673755.24721979\n",
      "Iteration 1728, loss = 108625564.77406423\n",
      "Iteration 1729, loss = 108557724.17673913\n",
      "Iteration 1730, loss = 108474644.64911832\n",
      "Iteration 1731, loss = 108391712.39555793\n",
      "Iteration 1732, loss = 108307914.69992582\n",
      "Iteration 1733, loss = 108226380.70367302\n",
      "Iteration 1734, loss = 108181724.01271908\n",
      "Iteration 1735, loss = 108080193.02236988\n",
      "Iteration 1736, loss = 108038333.22879493\n",
      "Iteration 1737, loss = 107927937.43146579\n",
      "Iteration 1738, loss = 107852152.07578135\n",
      "Iteration 1739, loss = 107761883.02703662\n",
      "Iteration 1740, loss = 107716500.23356065\n",
      "Iteration 1741, loss = 107633650.11959316\n",
      "Iteration 1742, loss = 107550928.04460053\n",
      "Iteration 1743, loss = 107525188.60682654\n",
      "Iteration 1744, loss = 107409110.59137276\n",
      "Iteration 1745, loss = 107342853.93262732\n",
      "Iteration 1746, loss = 107270068.19027522\n",
      "Iteration 1747, loss = 107197462.83989540\n",
      "Iteration 1748, loss = 107143762.71446067\n",
      "Iteration 1749, loss = 107061857.98140407\n",
      "Iteration 1750, loss = 106971467.98342907\n",
      "Iteration 1751, loss = 106923148.85251595\n",
      "Iteration 1752, loss = 106841251.69589919\n",
      "Iteration 1753, loss = 106770639.42165631\n",
      "Iteration 1754, loss = 106698772.51505794\n",
      "Iteration 1755, loss = 106630866.84014440\n",
      "Iteration 1756, loss = 106535333.76315804\n",
      "Iteration 1757, loss = 106462723.84762165\n",
      "Iteration 1758, loss = 106406260.57457925\n",
      "Iteration 1759, loss = 106340779.47050917\n",
      "Iteration 1760, loss = 106260830.46967588\n",
      "Iteration 1761, loss = 106203982.96222085\n",
      "Iteration 1762, loss = 106115877.83014050\n",
      "Iteration 1763, loss = 106051364.57174268\n",
      "Iteration 1764, loss = 106004670.70972583\n",
      "Iteration 1765, loss = 105894280.55833095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1766, loss = 105832296.42696925\n",
      "Iteration 1767, loss = 105791013.68574187\n",
      "Iteration 1768, loss = 105713809.82539162\n",
      "Iteration 1769, loss = 105638170.45322031\n",
      "Iteration 1770, loss = 105572481.69611560\n",
      "Iteration 1771, loss = 105494840.97423808\n",
      "Iteration 1772, loss = 105445278.69609648\n",
      "Iteration 1773, loss = 105359976.26281321\n",
      "Iteration 1774, loss = 105311763.40045981\n",
      "Iteration 1775, loss = 105240600.33718430\n",
      "Iteration 1776, loss = 105178705.23040034\n",
      "Iteration 1777, loss = 105099537.42164902\n",
      "Iteration 1778, loss = 105031047.21056065\n",
      "Iteration 1779, loss = 104995900.27558246\n",
      "Iteration 1780, loss = 104889635.32726994\n",
      "Iteration 1781, loss = 104867630.15333070\n",
      "Iteration 1782, loss = 104781317.59476760\n",
      "Iteration 1783, loss = 104711816.00320183\n",
      "Iteration 1784, loss = 104653313.56949121\n",
      "Iteration 1785, loss = 104589333.60860318\n",
      "Iteration 1786, loss = 104539592.31576662\n",
      "Iteration 1787, loss = 104463154.82971640\n",
      "Iteration 1788, loss = 104408418.05169494\n",
      "Iteration 1789, loss = 104335642.67339519\n",
      "Iteration 1790, loss = 104273138.75748926\n",
      "Iteration 1791, loss = 104215085.72455162\n",
      "Iteration 1792, loss = 104182168.45827810\n",
      "Iteration 1793, loss = 104096924.40343259\n",
      "Iteration 1794, loss = 104011305.40464719\n",
      "Iteration 1795, loss = 103944322.22370379\n",
      "Iteration 1796, loss = 103891963.19841398\n",
      "Iteration 1797, loss = 103847657.95793252\n",
      "Iteration 1798, loss = 103778711.77618061\n",
      "Iteration 1799, loss = 103724673.99341562\n",
      "Iteration 1800, loss = 103643196.60618064\n",
      "Iteration 1801, loss = 103582970.38321586\n",
      "Iteration 1802, loss = 103533205.11616099\n",
      "Iteration 1803, loss = 103451335.60362145\n",
      "Iteration 1804, loss = 103437017.94832304\n",
      "Iteration 1805, loss = 103346030.46278536\n",
      "Iteration 1806, loss = 103302389.82456228\n",
      "Iteration 1807, loss = 103261616.23181915\n",
      "Iteration 1808, loss = 103166911.02477466\n",
      "Iteration 1809, loss = 103139412.17169026\n",
      "Iteration 1810, loss = 103078974.36936870\n",
      "Iteration 1811, loss = 102974240.27213450\n",
      "Iteration 1812, loss = 102924608.26208732\n",
      "Iteration 1813, loss = 102865226.34619668\n",
      "Iteration 1814, loss = 102819893.88376148\n",
      "Iteration 1815, loss = 102789316.03302804\n",
      "Iteration 1816, loss = 102687595.63503960\n",
      "Iteration 1817, loss = 102643089.89368883\n",
      "Iteration 1818, loss = 102578860.66771795\n",
      "Iteration 1819, loss = 102530051.70413159\n",
      "Iteration 1820, loss = 102471490.91695645\n",
      "Iteration 1821, loss = 102406772.41805910\n",
      "Iteration 1822, loss = 102361731.91378123\n",
      "Iteration 1823, loss = 102304090.27125713\n",
      "Iteration 1824, loss = 102244686.40089338\n",
      "Iteration 1825, loss = 102190480.48193039\n",
      "Iteration 1826, loss = 102127721.86083446\n",
      "Iteration 1827, loss = 102079911.28504746\n",
      "Iteration 1828, loss = 102021048.47715715\n",
      "Iteration 1829, loss = 101970583.94085757\n",
      "Iteration 1830, loss = 101917194.02633621\n",
      "Iteration 1831, loss = 101851847.07608002\n",
      "Iteration 1832, loss = 101809133.84475926\n",
      "Iteration 1833, loss = 101731681.87206365\n",
      "Iteration 1834, loss = 101676615.43690641\n",
      "Iteration 1835, loss = 101616186.26266070\n",
      "Iteration 1836, loss = 101581091.41635668\n",
      "Iteration 1837, loss = 101532001.45168009\n",
      "Iteration 1838, loss = 101481577.37401621\n",
      "Iteration 1839, loss = 101434938.53974940\n",
      "Iteration 1840, loss = 101372982.84185304\n",
      "Iteration 1841, loss = 101313052.74284039\n",
      "Iteration 1842, loss = 101246380.19808993\n",
      "Iteration 1843, loss = 101212427.27853718\n",
      "Iteration 1844, loss = 101137110.30654651\n",
      "Iteration 1845, loss = 101099585.10091488\n",
      "Iteration 1846, loss = 101032139.62411779\n",
      "Iteration 1847, loss = 100972191.18322821\n",
      "Iteration 1848, loss = 100923725.22306268\n",
      "Iteration 1849, loss = 100873788.74014106\n",
      "Iteration 1850, loss = 100819391.32595974\n",
      "Iteration 1851, loss = 100787177.60759488\n",
      "Iteration 1852, loss = 100717842.97650379\n",
      "Iteration 1853, loss = 100685553.94557841\n",
      "Iteration 1854, loss = 100620196.72578742\n",
      "Iteration 1855, loss = 100562654.35926235\n",
      "Iteration 1856, loss = 100542908.82463215\n",
      "Iteration 1857, loss = 100482639.76901747\n",
      "Iteration 1858, loss = 100403212.41450784\n",
      "Iteration 1859, loss = 100368786.35576007\n",
      "Iteration 1860, loss = 100298279.84781036\n",
      "Iteration 1861, loss = 100239701.04003808\n",
      "Iteration 1862, loss = 100218029.72621687\n",
      "Iteration 1863, loss = 100178981.39966856\n",
      "Iteration 1864, loss = 100105399.64022499\n",
      "Iteration 1865, loss = 100092588.02879885\n",
      "Iteration 1866, loss = 100017214.69085982\n",
      "Iteration 1867, loss = 99963705.47837138\n",
      "Iteration 1868, loss = 99900320.91346782\n",
      "Iteration 1869, loss = 99906225.49177310\n",
      "Iteration 1870, loss = 99811172.60204558\n",
      "Iteration 1871, loss = 99729495.24555755\n",
      "Iteration 1872, loss = 99756180.21791731\n",
      "Iteration 1873, loss = 99664981.26108782\n",
      "Iteration 1874, loss = 99611542.43725154\n",
      "Iteration 1875, loss = 99593678.94746897\n",
      "Iteration 1876, loss = 99528130.34115174\n",
      "Iteration 1877, loss = 99483883.06457120\n",
      "Iteration 1878, loss = 99455256.83246201\n",
      "Iteration 1879, loss = 99391401.27199779\n",
      "Iteration 1880, loss = 99408655.34143539\n",
      "Iteration 1881, loss = 99308732.11385874\n",
      "Iteration 1882, loss = 99256116.29290575\n",
      "Iteration 1883, loss = 99224881.52381073\n",
      "Iteration 1884, loss = 99166284.38051823\n",
      "Iteration 1885, loss = 99121071.45494533\n",
      "Iteration 1886, loss = 99065648.93064177\n",
      "Iteration 1887, loss = 99140870.35000509\n",
      "Iteration 1888, loss = 98970679.44702674\n",
      "Iteration 1889, loss = 98949262.89076129\n",
      "Iteration 1890, loss = 98887181.50589459\n",
      "Iteration 1891, loss = 98904679.98873360\n",
      "Iteration 1892, loss = 98825256.14849643\n",
      "Iteration 1893, loss = 98765486.05327103\n",
      "Iteration 1894, loss = 98718378.96994781\n",
      "Iteration 1895, loss = 98707202.22092967\n",
      "Iteration 1896, loss = 98654489.62850276\n",
      "Iteration 1897, loss = 98602449.38162784\n",
      "Iteration 1898, loss = 98572484.85403249\n",
      "Iteration 1899, loss = 98529220.72414197\n",
      "Iteration 1900, loss = 98481453.04580960\n",
      "Iteration 1901, loss = 98417160.82774743\n",
      "Iteration 1902, loss = 98383264.97794430\n",
      "Iteration 1903, loss = 98361597.46040890\n",
      "Iteration 1904, loss = 98294891.70420662\n",
      "Iteration 1905, loss = 98245440.39392596\n",
      "Iteration 1906, loss = 98224583.77340549\n",
      "Iteration 1907, loss = 98170157.51521441\n",
      "Iteration 1908, loss = 98129196.17590521\n",
      "Iteration 1909, loss = 98080642.42391767\n",
      "Iteration 1910, loss = 98051579.72144784\n",
      "Iteration 1911, loss = 98025778.76827374\n",
      "Iteration 1912, loss = 97970858.49729258\n",
      "Iteration 1913, loss = 97963448.16818947\n",
      "Iteration 1914, loss = 97883250.53692156\n",
      "Iteration 1915, loss = 97842534.33396159\n",
      "Iteration 1916, loss = 97802801.51253097\n",
      "Iteration 1917, loss = 97942960.62330538\n",
      "Iteration 1918, loss = 97710819.62645473\n",
      "Iteration 1919, loss = 97701177.55443655\n",
      "Iteration 1920, loss = 97653519.82881767\n",
      "Iteration 1921, loss = 97607795.03010634\n",
      "Iteration 1922, loss = 97564573.93992586\n",
      "Iteration 1923, loss = 97523625.93703012\n",
      "Iteration 1924, loss = 97506231.65729073\n",
      "Iteration 1925, loss = 97444712.63692449\n",
      "Iteration 1926, loss = 97424955.16099994\n",
      "Iteration 1927, loss = 97373627.43744630\n",
      "Iteration 1928, loss = 97331886.91309787\n",
      "Iteration 1929, loss = 97319167.00509959\n",
      "Iteration 1930, loss = 97255748.83778226\n",
      "Iteration 1931, loss = 97231462.11224356\n",
      "Iteration 1932, loss = 97179537.46692039\n",
      "Iteration 1933, loss = 97130585.36808488\n",
      "Iteration 1934, loss = 97122849.13265726\n",
      "Iteration 1935, loss = 97100558.46423110\n",
      "Iteration 1936, loss = 97032192.85381187\n",
      "Iteration 1937, loss = 96984545.41554987\n",
      "Iteration 1938, loss = 96945458.08296613\n",
      "Iteration 1939, loss = 96898969.42918448\n",
      "Iteration 1940, loss = 96862802.12285593\n",
      "Iteration 1941, loss = 96832991.64998721\n",
      "Iteration 1942, loss = 96793323.24956729\n",
      "Iteration 1943, loss = 96753459.06780390\n",
      "Iteration 1944, loss = 96720239.87534094\n",
      "Iteration 1945, loss = 96685755.60008213\n",
      "Iteration 1946, loss = 96658360.85330281\n",
      "Iteration 1947, loss = 96592390.02211787\n",
      "Iteration 1948, loss = 96565585.66993405\n",
      "Iteration 1949, loss = 96518444.35917048\n",
      "Iteration 1950, loss = 96469745.51961657\n",
      "Iteration 1951, loss = 96448121.80821253\n",
      "Iteration 1952, loss = 96407801.69204816\n",
      "Iteration 1953, loss = 96359831.52717508\n",
      "Iteration 1954, loss = 96326306.27264158\n",
      "Iteration 1955, loss = 96311587.51617582\n",
      "Iteration 1956, loss = 96244143.30290066\n",
      "Iteration 1957, loss = 96228172.79062772\n",
      "Iteration 1958, loss = 96192865.24973638\n",
      "Iteration 1959, loss = 96137724.80551049\n",
      "Iteration 1960, loss = 96093482.74016917\n",
      "Iteration 1961, loss = 96060422.67338465\n",
      "Iteration 1962, loss = 96022455.67717834\n",
      "Iteration 1963, loss = 95972907.37980071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1964, loss = 95964502.41967611\n",
      "Iteration 1965, loss = 95907119.71560976\n",
      "Iteration 1966, loss = 95883116.16032447\n",
      "Iteration 1967, loss = 95843183.48472674\n",
      "Iteration 1968, loss = 95812542.18523732\n",
      "Iteration 1969, loss = 95762927.89824772\n",
      "Iteration 1970, loss = 95742350.09774183\n",
      "Iteration 1971, loss = 95714896.89121489\n",
      "Iteration 1972, loss = 95632298.41511478\n",
      "Iteration 1973, loss = 95609592.59522712\n",
      "Iteration 1974, loss = 95572435.34529851\n",
      "Iteration 1975, loss = 95550399.01908684\n",
      "Iteration 1976, loss = 95533950.84525585\n",
      "Iteration 1977, loss = 95488683.16370872\n",
      "Iteration 1978, loss = 95439608.23871033\n",
      "Iteration 1979, loss = 95417541.59935544\n",
      "Iteration 1980, loss = 95363762.70560700\n",
      "Iteration 1981, loss = 95326731.93731576\n",
      "Iteration 1982, loss = 95272229.10881676\n",
      "Iteration 1983, loss = 95259591.08195111\n",
      "Iteration 1984, loss = 95218333.54756378\n",
      "Iteration 1985, loss = 95197475.50676595\n",
      "Iteration 1986, loss = 95152023.88812433\n",
      "Iteration 1987, loss = 95125763.28268285\n",
      "Iteration 1988, loss = 95071347.67823383\n",
      "Iteration 1989, loss = 95052472.16339459\n",
      "Iteration 1990, loss = 95002791.76701432\n",
      "Iteration 1991, loss = 94954910.01170219\n",
      "Iteration 1992, loss = 94923345.35098632\n",
      "Iteration 1993, loss = 94925148.52503693\n",
      "Iteration 1994, loss = 94863999.83388838\n",
      "Iteration 1995, loss = 94832384.56773145\n",
      "Iteration 1996, loss = 94796686.54944058\n",
      "Iteration 1997, loss = 94756684.68507980\n",
      "Iteration 1998, loss = 94734511.40826629\n",
      "Iteration 1999, loss = 94679339.24883600\n",
      "Iteration 2000, loss = 94653354.86700489\n",
      "Iteration 1, loss = 2742858365.56866550\n",
      "Iteration 2, loss = 2739961976.57172823\n",
      "Iteration 3, loss = 2734416467.78320503\n",
      "Iteration 4, loss = 2724758169.16560841\n",
      "Iteration 5, loss = 2712692953.87201023\n",
      "Iteration 6, loss = 2698325613.09931469\n",
      "Iteration 7, loss = 2681680717.86428785\n",
      "Iteration 8, loss = 2662861763.54265308\n",
      "Iteration 9, loss = 2642142491.63709784\n",
      "Iteration 10, loss = 2619462786.37294817\n",
      "Iteration 11, loss = 2595135597.90737152\n",
      "Iteration 12, loss = 2569115115.99231339\n",
      "Iteration 13, loss = 2541515415.10050583\n",
      "Iteration 14, loss = 2512461278.30547428\n",
      "Iteration 15, loss = 2482251580.39285517\n",
      "Iteration 16, loss = 2450804872.25938892\n",
      "Iteration 17, loss = 2418251662.06577539\n",
      "Iteration 18, loss = 2384656038.35271120\n",
      "Iteration 19, loss = 2350190602.10813904\n",
      "Iteration 20, loss = 2314957677.94394779\n",
      "Iteration 21, loss = 2279088393.06547928\n",
      "Iteration 22, loss = 2242485363.01021814\n",
      "Iteration 23, loss = 2205329859.26598501\n",
      "Iteration 24, loss = 2167816150.95032310\n",
      "Iteration 25, loss = 2129645097.99617648\n",
      "Iteration 26, loss = 2091131026.73798347\n",
      "Iteration 27, loss = 2052733797.26164746\n",
      "Iteration 28, loss = 2014127655.65542674\n",
      "Iteration 29, loss = 1975050702.97184396\n",
      "Iteration 30, loss = 1935980763.79468489\n",
      "Iteration 31, loss = 1897241772.62562633\n",
      "Iteration 32, loss = 1858900635.66626096\n",
      "Iteration 33, loss = 1820587793.76205873\n",
      "Iteration 34, loss = 1782492449.96894407\n",
      "Iteration 35, loss = 1744680766.28873134\n",
      "Iteration 36, loss = 1706957209.28115249\n",
      "Iteration 37, loss = 1669578174.30775070\n",
      "Iteration 38, loss = 1632855910.98519349\n",
      "Iteration 39, loss = 1596678986.40467191\n",
      "Iteration 40, loss = 1560752899.28456450\n",
      "Iteration 41, loss = 1525608408.16753292\n",
      "Iteration 42, loss = 1491109178.26196694\n",
      "Iteration 43, loss = 1457321558.46402216\n",
      "Iteration 44, loss = 1424285252.51664662\n",
      "Iteration 45, loss = 1391903452.67148232\n",
      "Iteration 46, loss = 1360235612.76361632\n",
      "Iteration 47, loss = 1329301847.04199815\n",
      "Iteration 48, loss = 1299335262.31321883\n",
      "Iteration 49, loss = 1270538851.97383761\n",
      "Iteration 50, loss = 1242533094.80284286\n",
      "Iteration 51, loss = 1215343502.81661725\n",
      "Iteration 52, loss = 1189216599.97950053\n",
      "Iteration 53, loss = 1164209795.66946578\n",
      "Iteration 54, loss = 1140137800.34208918\n",
      "Iteration 55, loss = 1117246008.37458849\n",
      "Iteration 56, loss = 1095476105.76444626\n",
      "Iteration 57, loss = 1074829683.63300133\n",
      "Iteration 58, loss = 1055301011.60884225\n",
      "Iteration 59, loss = 1036780901.40739679\n",
      "Iteration 60, loss = 1019369692.57871950\n",
      "Iteration 61, loss = 1003000620.53349376\n",
      "Iteration 62, loss = 987800688.39479721\n",
      "Iteration 63, loss = 973403047.22402024\n",
      "Iteration 64, loss = 960259214.68688583\n",
      "Iteration 65, loss = 948053227.98004448\n",
      "Iteration 66, loss = 936975287.76174748\n",
      "Iteration 67, loss = 926751980.54921949\n",
      "Iteration 68, loss = 917571719.22105563\n",
      "Iteration 69, loss = 909272663.37612331\n",
      "Iteration 70, loss = 901893425.38738120\n",
      "Iteration 71, loss = 895434675.73682368\n",
      "Iteration 72, loss = 889567337.10483360\n",
      "Iteration 73, loss = 884448414.56764352\n",
      "Iteration 74, loss = 880197129.10301590\n",
      "Iteration 75, loss = 876243700.10600448\n",
      "Iteration 76, loss = 873018680.66685736\n",
      "Iteration 77, loss = 870253418.81065714\n",
      "Iteration 78, loss = 867917601.44012439\n",
      "Iteration 79, loss = 865967042.20712984\n",
      "Iteration 80, loss = 864272811.27154982\n",
      "Iteration 81, loss = 862898642.06840003\n",
      "Iteration 82, loss = 861749661.03246915\n",
      "Iteration 83, loss = 860824889.70448422\n",
      "Iteration 84, loss = 860018070.73885059\n",
      "Iteration 85, loss = 859364225.70850098\n",
      "Iteration 86, loss = 858734707.34009624\n",
      "Iteration 87, loss = 858244548.47168982\n",
      "Iteration 88, loss = 857822428.56073487\n",
      "Iteration 89, loss = 857421247.95878208\n",
      "Iteration 90, loss = 857044399.32650411\n",
      "Iteration 91, loss = 856698282.23373711\n",
      "Iteration 92, loss = 856347359.72068226\n",
      "Iteration 93, loss = 855991310.62934053\n",
      "Iteration 94, loss = 855681433.58453166\n",
      "Iteration 95, loss = 855332023.68047929\n",
      "Iteration 96, loss = 855006807.44793475\n",
      "Iteration 97, loss = 854661854.66476607\n",
      "Iteration 98, loss = 854323361.76355672\n",
      "Iteration 99, loss = 853987319.21192253\n",
      "Iteration 100, loss = 853646882.06353652\n",
      "Iteration 101, loss = 853295036.52686930\n",
      "Iteration 102, loss = 852952522.98469067\n",
      "Iteration 103, loss = 852623286.46557522\n",
      "Iteration 104, loss = 852270133.61271346\n",
      "Iteration 105, loss = 851936056.87649202\n",
      "Iteration 106, loss = 851541504.43806016\n",
      "Iteration 107, loss = 851193745.87888634\n",
      "Iteration 108, loss = 850841963.62117779\n",
      "Iteration 109, loss = 850501383.10588264\n",
      "Iteration 110, loss = 850127557.90411365\n",
      "Iteration 111, loss = 849761018.50323451\n",
      "Iteration 112, loss = 849415969.31363285\n",
      "Iteration 113, loss = 849058331.61793864\n",
      "Iteration 114, loss = 848668832.50270736\n",
      "Iteration 115, loss = 848345462.65353191\n",
      "Iteration 116, loss = 847960753.94409108\n",
      "Iteration 117, loss = 847598209.32985425\n",
      "Iteration 118, loss = 847232405.55505192\n",
      "Iteration 119, loss = 846864634.21880174\n",
      "Iteration 120, loss = 846488803.72500527\n",
      "Iteration 121, loss = 846138368.19677877\n",
      "Iteration 122, loss = 845761862.23738670\n",
      "Iteration 123, loss = 845406407.49993169\n",
      "Iteration 124, loss = 845039421.61142874\n",
      "Iteration 125, loss = 844681048.13845277\n",
      "Iteration 126, loss = 844313301.65089226\n",
      "Iteration 127, loss = 843943680.64168012\n",
      "Iteration 128, loss = 843600550.43091416\n",
      "Iteration 129, loss = 843215865.83238995\n",
      "Iteration 130, loss = 842865704.03524911\n",
      "Iteration 131, loss = 842487195.24253976\n",
      "Iteration 132, loss = 842119738.95109808\n",
      "Iteration 133, loss = 841740844.19984341\n",
      "Iteration 134, loss = 841380440.70396423\n",
      "Iteration 135, loss = 841004591.04194307\n",
      "Iteration 136, loss = 840642405.73538864\n",
      "Iteration 137, loss = 840265259.56533873\n",
      "Iteration 138, loss = 839888930.13893425\n",
      "Iteration 139, loss = 839543057.60656881\n",
      "Iteration 140, loss = 839156956.54515362\n",
      "Iteration 141, loss = 838771032.07624602\n",
      "Iteration 142, loss = 838384750.41118574\n",
      "Iteration 143, loss = 838022707.44856966\n",
      "Iteration 144, loss = 837666811.58040047\n",
      "Iteration 145, loss = 837276560.53321493\n",
      "Iteration 146, loss = 836896645.54909170\n",
      "Iteration 147, loss = 836510630.86380887\n",
      "Iteration 148, loss = 836174981.37039781\n",
      "Iteration 149, loss = 835801881.13911557\n",
      "Iteration 150, loss = 835428009.43858635\n",
      "Iteration 151, loss = 835038239.16454268\n",
      "Iteration 152, loss = 834670634.78024077\n",
      "Iteration 153, loss = 834311505.27390802\n",
      "Iteration 154, loss = 833927354.86845767\n",
      "Iteration 155, loss = 833552808.43143344\n",
      "Iteration 156, loss = 833181155.87114954\n",
      "Iteration 157, loss = 832803256.40836263\n",
      "Iteration 158, loss = 832450239.09235275\n",
      "Iteration 159, loss = 832077096.87071121\n",
      "Iteration 160, loss = 831685418.44195485\n",
      "Iteration 161, loss = 831308160.46361649\n",
      "Iteration 162, loss = 830925482.62450194\n",
      "Iteration 163, loss = 830566094.98977137\n",
      "Iteration 164, loss = 830198671.10457170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 165, loss = 829798680.52664840\n",
      "Iteration 166, loss = 829428268.92179096\n",
      "Iteration 167, loss = 829046092.66407144\n",
      "Iteration 168, loss = 828663104.01000190\n",
      "Iteration 169, loss = 828264457.46624327\n",
      "Iteration 170, loss = 827889020.88757157\n",
      "Iteration 171, loss = 827517665.03514194\n",
      "Iteration 172, loss = 827120693.81943083\n",
      "Iteration 173, loss = 826751708.64557958\n",
      "Iteration 174, loss = 826369629.04487562\n",
      "Iteration 175, loss = 825986462.71657634\n",
      "Iteration 176, loss = 825623213.69527352\n",
      "Iteration 177, loss = 825235734.98851812\n",
      "Iteration 178, loss = 824854874.99562895\n",
      "Iteration 179, loss = 824486801.79053116\n",
      "Iteration 180, loss = 824105907.26475179\n",
      "Iteration 181, loss = 823727893.58326709\n",
      "Iteration 182, loss = 823355314.27422476\n",
      "Iteration 183, loss = 822959151.42802274\n",
      "Iteration 184, loss = 822582613.65813267\n",
      "Iteration 185, loss = 822214445.06901515\n",
      "Iteration 186, loss = 821820684.15681672\n",
      "Iteration 187, loss = 821440509.00462747\n",
      "Iteration 188, loss = 821076857.42807853\n",
      "Iteration 189, loss = 820696021.49397707\n",
      "Iteration 190, loss = 820295532.46149659\n",
      "Iteration 191, loss = 819903513.56676495\n",
      "Iteration 192, loss = 819549119.43041265\n",
      "Iteration 193, loss = 819138911.08627331\n",
      "Iteration 194, loss = 818772959.53241825\n",
      "Iteration 195, loss = 818375861.42226875\n",
      "Iteration 196, loss = 817997540.17846859\n",
      "Iteration 197, loss = 817618448.40226030\n",
      "Iteration 198, loss = 817212624.06593287\n",
      "Iteration 199, loss = 816836794.81573629\n",
      "Iteration 200, loss = 816453104.54694808\n",
      "Iteration 201, loss = 816058275.07884169\n",
      "Iteration 202, loss = 815683174.83557796\n",
      "Iteration 203, loss = 815293704.42031586\n",
      "Iteration 204, loss = 814908615.63202298\n",
      "Iteration 205, loss = 814525406.69661987\n",
      "Iteration 206, loss = 814151152.54920411\n",
      "Iteration 207, loss = 813752393.37145257\n",
      "Iteration 208, loss = 813355920.10487044\n",
      "Iteration 209, loss = 812952961.21495569\n",
      "Iteration 210, loss = 812563200.33952761\n",
      "Iteration 211, loss = 812171592.26664793\n",
      "Iteration 212, loss = 811791591.41342807\n",
      "Iteration 213, loss = 811396183.15561104\n",
      "Iteration 214, loss = 811006580.62536824\n",
      "Iteration 215, loss = 810662137.03063524\n",
      "Iteration 216, loss = 810256094.83645666\n",
      "Iteration 217, loss = 809888879.44171476\n",
      "Iteration 218, loss = 809497219.68569648\n",
      "Iteration 219, loss = 809093144.59812820\n",
      "Iteration 220, loss = 808697847.60576069\n",
      "Iteration 221, loss = 808324402.46023822\n",
      "Iteration 222, loss = 807930617.82919300\n",
      "Iteration 223, loss = 807544764.46350992\n",
      "Iteration 224, loss = 807149440.00296199\n",
      "Iteration 225, loss = 806811250.83236051\n",
      "Iteration 226, loss = 806375829.09384096\n",
      "Iteration 227, loss = 805995001.89725566\n",
      "Iteration 228, loss = 805593594.90409005\n",
      "Iteration 229, loss = 805197298.27156949\n",
      "Iteration 230, loss = 804806375.24349642\n",
      "Iteration 231, loss = 804422193.26545286\n",
      "Iteration 232, loss = 804035946.06880426\n",
      "Iteration 233, loss = 803632917.79004598\n",
      "Iteration 234, loss = 803242534.81037629\n",
      "Iteration 235, loss = 802851384.03650534\n",
      "Iteration 236, loss = 802447930.28979135\n",
      "Iteration 237, loss = 802093654.33733487\n",
      "Iteration 238, loss = 801674978.75476551\n",
      "Iteration 239, loss = 801277430.74317741\n",
      "Iteration 240, loss = 800882434.88386989\n",
      "Iteration 241, loss = 800469362.03728509\n",
      "Iteration 242, loss = 800067600.59238112\n",
      "Iteration 243, loss = 799680357.53566289\n",
      "Iteration 244, loss = 799263024.36995935\n",
      "Iteration 245, loss = 798864973.71255910\n",
      "Iteration 246, loss = 798448798.66950250\n",
      "Iteration 247, loss = 798052512.48408270\n",
      "Iteration 248, loss = 797669438.29294157\n",
      "Iteration 249, loss = 797241358.61403871\n",
      "Iteration 250, loss = 796823311.04990256\n",
      "Iteration 251, loss = 796439343.89567494\n",
      "Iteration 252, loss = 796048561.91529763\n",
      "Iteration 253, loss = 795618768.06630063\n",
      "Iteration 254, loss = 795194794.85682261\n",
      "Iteration 255, loss = 794828752.34476626\n",
      "Iteration 256, loss = 794377192.34395039\n",
      "Iteration 257, loss = 793946726.20663655\n",
      "Iteration 258, loss = 793539027.73134089\n",
      "Iteration 259, loss = 793122091.74585676\n",
      "Iteration 260, loss = 792694250.91227436\n",
      "Iteration 261, loss = 792283836.34486091\n",
      "Iteration 262, loss = 791862719.57480538\n",
      "Iteration 263, loss = 791454190.17293000\n",
      "Iteration 264, loss = 791022231.17572546\n",
      "Iteration 265, loss = 790592264.78837669\n",
      "Iteration 266, loss = 790168059.81457639\n",
      "Iteration 267, loss = 789741621.64498734\n",
      "Iteration 268, loss = 789339067.01905489\n",
      "Iteration 269, loss = 788889069.43384457\n",
      "Iteration 270, loss = 788460350.44669616\n",
      "Iteration 271, loss = 788050064.36309862\n",
      "Iteration 272, loss = 787603847.48154950\n",
      "Iteration 273, loss = 787183563.13866389\n",
      "Iteration 274, loss = 786738963.85069513\n",
      "Iteration 275, loss = 786300735.23680866\n",
      "Iteration 276, loss = 785878898.97580302\n",
      "Iteration 277, loss = 785432810.67332697\n",
      "Iteration 278, loss = 785013665.03437638\n",
      "Iteration 279, loss = 784577780.59954572\n",
      "Iteration 280, loss = 784136330.55476141\n",
      "Iteration 281, loss = 783716415.63384879\n",
      "Iteration 282, loss = 783271009.88782704\n",
      "Iteration 283, loss = 782836515.01035726\n",
      "Iteration 284, loss = 782389774.57616055\n",
      "Iteration 285, loss = 781953888.01254761\n",
      "Iteration 286, loss = 781513491.83120668\n",
      "Iteration 287, loss = 781075151.01810634\n",
      "Iteration 288, loss = 780636355.29611838\n",
      "Iteration 289, loss = 780209050.85212374\n",
      "Iteration 290, loss = 779747694.96387637\n",
      "Iteration 291, loss = 779310545.58486104\n",
      "Iteration 292, loss = 778884567.00650334\n",
      "Iteration 293, loss = 778449594.16224432\n",
      "Iteration 294, loss = 778019845.24172223\n",
      "Iteration 295, loss = 777587685.32845390\n",
      "Iteration 296, loss = 777131376.13530672\n",
      "Iteration 297, loss = 776707021.52544713\n",
      "Iteration 298, loss = 776275947.11848080\n",
      "Iteration 299, loss = 775799565.93246365\n",
      "Iteration 300, loss = 775353324.99095535\n",
      "Iteration 301, loss = 774928861.15591085\n",
      "Iteration 302, loss = 774455288.28065586\n",
      "Iteration 303, loss = 773990406.45138609\n",
      "Iteration 304, loss = 773561449.90370774\n",
      "Iteration 305, loss = 773101681.29709125\n",
      "Iteration 306, loss = 772662575.11637521\n",
      "Iteration 307, loss = 772184443.47190130\n",
      "Iteration 308, loss = 771729803.21051514\n",
      "Iteration 309, loss = 771270011.15796518\n",
      "Iteration 310, loss = 770818317.66467333\n",
      "Iteration 311, loss = 770346435.68491769\n",
      "Iteration 312, loss = 769879082.65725183\n",
      "Iteration 313, loss = 769441387.66352248\n",
      "Iteration 314, loss = 768972658.71614945\n",
      "Iteration 315, loss = 768534666.61875236\n",
      "Iteration 316, loss = 768076943.87258399\n",
      "Iteration 317, loss = 767595339.30839765\n",
      "Iteration 318, loss = 767124548.63221455\n",
      "Iteration 319, loss = 766701805.36473334\n",
      "Iteration 320, loss = 766203419.36513436\n",
      "Iteration 321, loss = 765726560.86304975\n",
      "Iteration 322, loss = 765275491.73784673\n",
      "Iteration 323, loss = 764818577.28510225\n",
      "Iteration 324, loss = 764318204.52732754\n",
      "Iteration 325, loss = 763870957.08182037\n",
      "Iteration 326, loss = 763380899.68449092\n",
      "Iteration 327, loss = 762913055.78730416\n",
      "Iteration 328, loss = 762432487.91942751\n",
      "Iteration 329, loss = 761957280.36175287\n",
      "Iteration 330, loss = 761468036.23384249\n",
      "Iteration 331, loss = 760993343.29012525\n",
      "Iteration 332, loss = 760527002.20814168\n",
      "Iteration 333, loss = 760026105.47000253\n",
      "Iteration 334, loss = 759549873.07596910\n",
      "Iteration 335, loss = 759045319.95021713\n",
      "Iteration 336, loss = 758568105.46578717\n",
      "Iteration 337, loss = 758065157.59763467\n",
      "Iteration 338, loss = 757570671.67570019\n",
      "Iteration 339, loss = 757087805.59244323\n",
      "Iteration 340, loss = 756592334.01152980\n",
      "Iteration 341, loss = 756086416.63245952\n",
      "Iteration 342, loss = 755592517.74920821\n",
      "Iteration 343, loss = 755078569.09622717\n",
      "Iteration 344, loss = 754591193.59716547\n",
      "Iteration 345, loss = 754080648.31187046\n",
      "Iteration 346, loss = 753583540.77812052\n",
      "Iteration 347, loss = 753099508.77606332\n",
      "Iteration 348, loss = 752586086.07655871\n",
      "Iteration 349, loss = 752078613.75837362\n",
      "Iteration 350, loss = 751566099.08703208\n",
      "Iteration 351, loss = 751105179.33465874\n",
      "Iteration 352, loss = 750563715.28320348\n",
      "Iteration 353, loss = 750060145.55819643\n",
      "Iteration 354, loss = 749562922.21222186\n",
      "Iteration 355, loss = 749039825.66255260\n",
      "Iteration 356, loss = 748532003.75533247\n",
      "Iteration 357, loss = 748012169.04480767\n",
      "Iteration 358, loss = 747518679.86581922\n",
      "Iteration 359, loss = 747004520.33226085\n",
      "Iteration 360, loss = 746496192.62291741\n",
      "Iteration 361, loss = 745983085.49640822\n",
      "Iteration 362, loss = 745465113.30681860\n",
      "Iteration 363, loss = 744957518.13350260\n",
      "Iteration 364, loss = 744441208.59754884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 365, loss = 743920880.05261469\n",
      "Iteration 366, loss = 743406710.40927982\n",
      "Iteration 367, loss = 742895681.05738592\n",
      "Iteration 368, loss = 742393828.64064479\n",
      "Iteration 369, loss = 741863923.03243458\n",
      "Iteration 370, loss = 741344731.52568233\n",
      "Iteration 371, loss = 740827145.00517583\n",
      "Iteration 372, loss = 740319438.33632267\n",
      "Iteration 373, loss = 739807256.65779889\n",
      "Iteration 374, loss = 739274159.08035970\n",
      "Iteration 375, loss = 738742915.37710810\n",
      "Iteration 376, loss = 738242054.35269618\n",
      "Iteration 377, loss = 737680229.21886003\n",
      "Iteration 378, loss = 737153454.07659483\n",
      "Iteration 379, loss = 736632364.58421206\n",
      "Iteration 380, loss = 736090465.48999178\n",
      "Iteration 381, loss = 735562405.95694733\n",
      "Iteration 382, loss = 735037332.22866082\n",
      "Iteration 383, loss = 734488558.14838362\n",
      "Iteration 384, loss = 733955108.28126085\n",
      "Iteration 385, loss = 733407667.55048048\n",
      "Iteration 386, loss = 732885994.47224534\n",
      "Iteration 387, loss = 732329035.20924830\n",
      "Iteration 388, loss = 731785373.67341244\n",
      "Iteration 389, loss = 731227840.57025111\n",
      "Iteration 390, loss = 730691099.92754018\n",
      "Iteration 391, loss = 730135766.75786257\n",
      "Iteration 392, loss = 729552186.74153185\n",
      "Iteration 393, loss = 729033589.58825803\n",
      "Iteration 394, loss = 728428866.55766416\n",
      "Iteration 395, loss = 727863640.60164893\n",
      "Iteration 396, loss = 727307962.03884923\n",
      "Iteration 397, loss = 726727976.46393383\n",
      "Iteration 398, loss = 726191542.31289577\n",
      "Iteration 399, loss = 725615557.13461351\n",
      "Iteration 400, loss = 725055374.09042025\n",
      "Iteration 401, loss = 724501445.26073122\n",
      "Iteration 402, loss = 723939803.31371331\n",
      "Iteration 403, loss = 723381381.82090676\n",
      "Iteration 404, loss = 722836968.72672725\n",
      "Iteration 405, loss = 722221795.18254364\n",
      "Iteration 406, loss = 721667871.43852067\n",
      "Iteration 407, loss = 721090136.71856642\n",
      "Iteration 408, loss = 720548070.28100336\n",
      "Iteration 409, loss = 719948189.60899246\n",
      "Iteration 410, loss = 719373433.66798544\n",
      "Iteration 411, loss = 718796757.41601229\n",
      "Iteration 412, loss = 718213439.05530179\n",
      "Iteration 413, loss = 717654560.18459177\n",
      "Iteration 414, loss = 717046600.93980706\n",
      "Iteration 415, loss = 716461274.24792671\n",
      "Iteration 416, loss = 715867381.62808812\n",
      "Iteration 417, loss = 715280356.59724939\n",
      "Iteration 418, loss = 714669737.31455517\n",
      "Iteration 419, loss = 714094174.42161322\n",
      "Iteration 420, loss = 713486609.02558064\n",
      "Iteration 421, loss = 712871765.38089752\n",
      "Iteration 422, loss = 712281048.90662205\n",
      "Iteration 423, loss = 711665077.27346170\n",
      "Iteration 424, loss = 711039376.33756948\n",
      "Iteration 425, loss = 710421768.18615639\n",
      "Iteration 426, loss = 709801158.27764034\n",
      "Iteration 427, loss = 709185309.36459386\n",
      "Iteration 428, loss = 708559219.87883890\n",
      "Iteration 429, loss = 707946975.42573500\n",
      "Iteration 430, loss = 707328218.98974705\n",
      "Iteration 431, loss = 706708437.22223341\n",
      "Iteration 432, loss = 706047718.73548353\n",
      "Iteration 433, loss = 705432496.05379677\n",
      "Iteration 434, loss = 704795033.51052749\n",
      "Iteration 435, loss = 704195591.46479571\n",
      "Iteration 436, loss = 703543695.41467595\n",
      "Iteration 437, loss = 702914795.58131862\n",
      "Iteration 438, loss = 702274515.45128524\n",
      "Iteration 439, loss = 701615548.20580852\n",
      "Iteration 440, loss = 700992841.67721784\n",
      "Iteration 441, loss = 700355279.51099360\n",
      "Iteration 442, loss = 699706615.32439792\n",
      "Iteration 443, loss = 699069855.42606974\n",
      "Iteration 444, loss = 698407729.59867167\n",
      "Iteration 445, loss = 697761238.95286667\n",
      "Iteration 446, loss = 697122743.68523729\n",
      "Iteration 447, loss = 696474543.42835200\n",
      "Iteration 448, loss = 695828002.87793124\n",
      "Iteration 449, loss = 695195862.67415392\n",
      "Iteration 450, loss = 694529037.80942154\n",
      "Iteration 451, loss = 693879646.29379988\n",
      "Iteration 452, loss = 693242897.58443797\n",
      "Iteration 453, loss = 692579472.10391116\n",
      "Iteration 454, loss = 691949078.24689019\n",
      "Iteration 455, loss = 691287287.52649009\n",
      "Iteration 456, loss = 690641398.22759533\n",
      "Iteration 457, loss = 689980004.02127028\n",
      "Iteration 458, loss = 689335316.10446560\n",
      "Iteration 459, loss = 688705409.68408024\n",
      "Iteration 460, loss = 688012410.16542518\n",
      "Iteration 461, loss = 687349423.53586328\n",
      "Iteration 462, loss = 686705160.37903821\n",
      "Iteration 463, loss = 686046065.93859565\n",
      "Iteration 464, loss = 685371045.91589785\n",
      "Iteration 465, loss = 684698816.61260307\n",
      "Iteration 466, loss = 684038050.46106625\n",
      "Iteration 467, loss = 683381888.30546594\n",
      "Iteration 468, loss = 682690480.96096158\n",
      "Iteration 469, loss = 682021928.36156225\n",
      "Iteration 470, loss = 681344325.59235656\n",
      "Iteration 471, loss = 680669224.64201689\n",
      "Iteration 472, loss = 679988238.34798431\n",
      "Iteration 473, loss = 679294017.91176343\n",
      "Iteration 474, loss = 678598786.80283308\n",
      "Iteration 475, loss = 677906804.51810217\n",
      "Iteration 476, loss = 677207138.83404446\n",
      "Iteration 477, loss = 676514848.37705731\n",
      "Iteration 478, loss = 675849707.17287421\n",
      "Iteration 479, loss = 675132920.41623700\n",
      "Iteration 480, loss = 674450179.92718637\n",
      "Iteration 481, loss = 673754818.29738164\n",
      "Iteration 482, loss = 673067370.43233728\n",
      "Iteration 483, loss = 672382361.33621514\n",
      "Iteration 484, loss = 671677587.21276784\n",
      "Iteration 485, loss = 670991812.42049873\n",
      "Iteration 486, loss = 670289474.49663496\n",
      "Iteration 487, loss = 669602016.97678947\n",
      "Iteration 488, loss = 668929033.63220167\n",
      "Iteration 489, loss = 668205466.50065517\n",
      "Iteration 490, loss = 667498894.15861762\n",
      "Iteration 491, loss = 666775840.98258853\n",
      "Iteration 492, loss = 666085128.90141404\n",
      "Iteration 493, loss = 665403904.47271228\n",
      "Iteration 494, loss = 664659400.32787669\n",
      "Iteration 495, loss = 663964448.86721683\n",
      "Iteration 496, loss = 663250255.38944948\n",
      "Iteration 497, loss = 662500334.03097665\n",
      "Iteration 498, loss = 661781350.99598110\n",
      "Iteration 499, loss = 661071643.81887496\n",
      "Iteration 500, loss = 660357369.22168636\n",
      "Iteration 501, loss = 659644317.52981329\n",
      "Iteration 502, loss = 658930014.18477988\n",
      "Iteration 503, loss = 658214262.51595056\n",
      "Iteration 504, loss = 657482648.06043589\n",
      "Iteration 505, loss = 656775292.43403256\n",
      "Iteration 506, loss = 656039732.44389260\n",
      "Iteration 507, loss = 655327774.70384240\n",
      "Iteration 508, loss = 654577225.73205924\n",
      "Iteration 509, loss = 653842795.22175360\n",
      "Iteration 510, loss = 653097969.74642372\n",
      "Iteration 511, loss = 652359576.04275703\n",
      "Iteration 512, loss = 651596522.64212406\n",
      "Iteration 513, loss = 650888273.81495368\n",
      "Iteration 514, loss = 650138417.74073350\n",
      "Iteration 515, loss = 649423396.93257546\n",
      "Iteration 516, loss = 648680688.80927372\n",
      "Iteration 517, loss = 647976878.41960037\n",
      "Iteration 518, loss = 647224576.23557508\n",
      "Iteration 519, loss = 646480120.07532227\n",
      "Iteration 520, loss = 645807552.05837131\n",
      "Iteration 521, loss = 645040426.69982636\n",
      "Iteration 522, loss = 644309282.45729482\n",
      "Iteration 523, loss = 643579123.49990535\n",
      "Iteration 524, loss = 642815489.92941940\n",
      "Iteration 525, loss = 642088194.31906939\n",
      "Iteration 526, loss = 641374898.37406778\n",
      "Iteration 527, loss = 640603383.14603603\n",
      "Iteration 528, loss = 639904116.78709209\n",
      "Iteration 529, loss = 639154336.90837944\n",
      "Iteration 530, loss = 638429930.61792779\n",
      "Iteration 531, loss = 637675978.04338515\n",
      "Iteration 532, loss = 636941961.48334825\n",
      "Iteration 533, loss = 636206719.05868006\n",
      "Iteration 534, loss = 635442214.55494642\n",
      "Iteration 535, loss = 634706014.09636283\n",
      "Iteration 536, loss = 633953487.49453950\n",
      "Iteration 537, loss = 633212100.52111769\n",
      "Iteration 538, loss = 632440021.41042459\n",
      "Iteration 539, loss = 631711592.21111131\n",
      "Iteration 540, loss = 630985090.06556475\n",
      "Iteration 541, loss = 630199810.46727121\n",
      "Iteration 542, loss = 629446179.41269398\n",
      "Iteration 543, loss = 628677062.74201977\n",
      "Iteration 544, loss = 627931671.02705336\n",
      "Iteration 545, loss = 627165458.77550352\n",
      "Iteration 546, loss = 626397991.99585378\n",
      "Iteration 547, loss = 625615023.75813043\n",
      "Iteration 548, loss = 624833818.99462116\n",
      "Iteration 549, loss = 624099947.19658816\n",
      "Iteration 550, loss = 623331784.47318268\n",
      "Iteration 551, loss = 622542669.27615547\n",
      "Iteration 552, loss = 621788826.84457827\n",
      "Iteration 553, loss = 621044722.18244255\n",
      "Iteration 554, loss = 620253264.95875859\n",
      "Iteration 555, loss = 619509259.54483938\n",
      "Iteration 556, loss = 618726774.28581917\n",
      "Iteration 557, loss = 617954764.28923917\n",
      "Iteration 558, loss = 617186100.19470751\n",
      "Iteration 559, loss = 616410213.61422575\n",
      "Iteration 560, loss = 615643395.47786784\n",
      "Iteration 561, loss = 614856285.42072070\n",
      "Iteration 562, loss = 614080280.01541746\n",
      "Iteration 563, loss = 613331666.28153205\n",
      "Iteration 564, loss = 612521277.79924834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 565, loss = 611748621.08963752\n",
      "Iteration 566, loss = 610944860.06733799\n",
      "Iteration 567, loss = 610150260.50383699\n",
      "Iteration 568, loss = 609368678.15644419\n",
      "Iteration 569, loss = 608614948.38331711\n",
      "Iteration 570, loss = 607855069.93846357\n",
      "Iteration 571, loss = 607056403.86836040\n",
      "Iteration 572, loss = 606273991.95388579\n",
      "Iteration 573, loss = 605497805.82575095\n",
      "Iteration 574, loss = 604716094.78267968\n",
      "Iteration 575, loss = 603932188.97078919\n",
      "Iteration 576, loss = 603136572.77000344\n",
      "Iteration 577, loss = 602365110.58715296\n",
      "Iteration 578, loss = 601537547.46061182\n",
      "Iteration 579, loss = 600758348.68726444\n",
      "Iteration 580, loss = 599972921.08088875\n",
      "Iteration 581, loss = 599153082.13154280\n",
      "Iteration 582, loss = 598377194.64601934\n",
      "Iteration 583, loss = 597571386.65409565\n",
      "Iteration 584, loss = 596754283.09880662\n",
      "Iteration 585, loss = 595955265.85366976\n",
      "Iteration 586, loss = 595168623.39330101\n",
      "Iteration 587, loss = 594371073.09093332\n",
      "Iteration 588, loss = 593589467.88202548\n",
      "Iteration 589, loss = 592786526.42323661\n",
      "Iteration 590, loss = 592005331.53248513\n",
      "Iteration 591, loss = 591197995.88898444\n",
      "Iteration 592, loss = 590400482.63562644\n",
      "Iteration 593, loss = 589608588.00525689\n",
      "Iteration 594, loss = 588817451.05591083\n",
      "Iteration 595, loss = 588036715.58421993\n",
      "Iteration 596, loss = 587241339.57980931\n",
      "Iteration 597, loss = 586486068.07901037\n",
      "Iteration 598, loss = 585668487.33908749\n",
      "Iteration 599, loss = 584880383.23167527\n",
      "Iteration 600, loss = 584085173.47495151\n",
      "Iteration 601, loss = 583304668.25346470\n",
      "Iteration 602, loss = 582510635.43090081\n",
      "Iteration 603, loss = 581733501.38408804\n",
      "Iteration 604, loss = 580917579.21363330\n",
      "Iteration 605, loss = 580146381.99943936\n",
      "Iteration 606, loss = 579368913.07527459\n",
      "Iteration 607, loss = 578553995.23286462\n",
      "Iteration 608, loss = 577762027.70565295\n",
      "Iteration 609, loss = 576944390.07555270\n",
      "Iteration 610, loss = 576148770.63274717\n",
      "Iteration 611, loss = 575348441.44958401\n",
      "Iteration 612, loss = 574566560.89980471\n",
      "Iteration 613, loss = 573749210.51559663\n",
      "Iteration 614, loss = 572957635.53519595\n",
      "Iteration 615, loss = 572176865.64294565\n",
      "Iteration 616, loss = 571360703.02291167\n",
      "Iteration 617, loss = 570572855.59910512\n",
      "Iteration 618, loss = 569758976.35976696\n",
      "Iteration 619, loss = 568970423.99482882\n",
      "Iteration 620, loss = 568158844.64893293\n",
      "Iteration 621, loss = 567364118.40517712\n",
      "Iteration 622, loss = 566584793.72970784\n",
      "Iteration 623, loss = 565764357.60003388\n",
      "Iteration 624, loss = 565002377.29593933\n",
      "Iteration 625, loss = 564171608.96332085\n",
      "Iteration 626, loss = 563385783.76338530\n",
      "Iteration 627, loss = 562585314.92083895\n",
      "Iteration 628, loss = 561832470.41913640\n",
      "Iteration 629, loss = 560996491.46029890\n",
      "Iteration 630, loss = 560220426.42196751\n",
      "Iteration 631, loss = 559419708.43132389\n",
      "Iteration 632, loss = 558651677.68646455\n",
      "Iteration 633, loss = 557846504.79141128\n",
      "Iteration 634, loss = 557049643.88615417\n",
      "Iteration 635, loss = 556261592.99574184\n",
      "Iteration 636, loss = 555451140.92816925\n",
      "Iteration 637, loss = 554659387.44463205\n",
      "Iteration 638, loss = 553872230.76258636\n",
      "Iteration 639, loss = 553071811.50121391\n",
      "Iteration 640, loss = 552304808.08959341\n",
      "Iteration 641, loss = 551492312.72212768\n",
      "Iteration 642, loss = 550729699.86265230\n",
      "Iteration 643, loss = 549950979.69324255\n",
      "Iteration 644, loss = 549145801.84319818\n",
      "Iteration 645, loss = 548364111.83509052\n",
      "Iteration 646, loss = 547618996.36576903\n",
      "Iteration 647, loss = 546817549.51809084\n",
      "Iteration 648, loss = 546034873.71501803\n",
      "Iteration 649, loss = 545252364.09343374\n",
      "Iteration 650, loss = 544492234.92054427\n",
      "Iteration 651, loss = 543704138.35068405\n",
      "Iteration 652, loss = 542929957.23102713\n",
      "Iteration 653, loss = 542154398.43196011\n",
      "Iteration 654, loss = 541374585.18845642\n",
      "Iteration 655, loss = 540620803.86920249\n",
      "Iteration 656, loss = 539835265.86719894\n",
      "Iteration 657, loss = 539062029.47614670\n",
      "Iteration 658, loss = 538285869.30415237\n",
      "Iteration 659, loss = 537506147.94001484\n",
      "Iteration 660, loss = 536738033.47471315\n",
      "Iteration 661, loss = 535985469.25554490\n",
      "Iteration 662, loss = 535202871.73235005\n",
      "Iteration 663, loss = 534430161.31717640\n",
      "Iteration 664, loss = 533687079.01220745\n",
      "Iteration 665, loss = 532910733.87142628\n",
      "Iteration 666, loss = 532163357.74405497\n",
      "Iteration 667, loss = 531395284.97785032\n",
      "Iteration 668, loss = 530609401.35787326\n",
      "Iteration 669, loss = 529868017.60072809\n",
      "Iteration 670, loss = 529079699.29096115\n",
      "Iteration 671, loss = 528323344.19344205\n",
      "Iteration 672, loss = 527573736.08075601\n",
      "Iteration 673, loss = 526820714.39813852\n",
      "Iteration 674, loss = 526041922.68004525\n",
      "Iteration 675, loss = 525264164.49435133\n",
      "Iteration 676, loss = 524528145.85772043\n",
      "Iteration 677, loss = 523778622.83518773\n",
      "Iteration 678, loss = 523039633.06482905\n",
      "Iteration 679, loss = 522285478.68990034\n",
      "Iteration 680, loss = 521528536.98038298\n",
      "Iteration 681, loss = 520787840.14866608\n",
      "Iteration 682, loss = 520031926.08639193\n",
      "Iteration 683, loss = 519246676.13314468\n",
      "Iteration 684, loss = 518498215.04417640\n",
      "Iteration 685, loss = 517751582.38925201\n",
      "Iteration 686, loss = 516986209.43372029\n",
      "Iteration 687, loss = 516258595.04468328\n",
      "Iteration 688, loss = 515489351.78255558\n",
      "Iteration 689, loss = 514733457.76135319\n",
      "Iteration 690, loss = 513969742.95796943\n",
      "Iteration 691, loss = 513242228.93153912\n",
      "Iteration 692, loss = 512479821.83352053\n",
      "Iteration 693, loss = 511742534.97539914\n",
      "Iteration 694, loss = 511005033.72907203\n",
      "Iteration 695, loss = 510233125.12031746\n",
      "Iteration 696, loss = 509494977.02365464\n",
      "Iteration 697, loss = 508763792.08508360\n",
      "Iteration 698, loss = 508003746.68726116\n",
      "Iteration 699, loss = 507264358.93129736\n",
      "Iteration 700, loss = 506526221.89469630\n",
      "Iteration 701, loss = 505772669.13861394\n",
      "Iteration 702, loss = 505043296.98751700\n",
      "Iteration 703, loss = 504327599.20712912\n",
      "Iteration 704, loss = 503538316.51243913\n",
      "Iteration 705, loss = 502805411.69338673\n",
      "Iteration 706, loss = 502078602.97343498\n",
      "Iteration 707, loss = 501352857.53777391\n",
      "Iteration 708, loss = 500616506.11902857\n",
      "Iteration 709, loss = 499880357.88061363\n",
      "Iteration 710, loss = 499153224.54576969\n",
      "Iteration 711, loss = 498444747.48181003\n",
      "Iteration 712, loss = 497714698.46138477\n",
      "Iteration 713, loss = 497008280.28982812\n",
      "Iteration 714, loss = 496276524.82419598\n",
      "Iteration 715, loss = 495554473.88025594\n",
      "Iteration 716, loss = 494848678.40419233\n",
      "Iteration 717, loss = 494127650.68276101\n",
      "Iteration 718, loss = 493418732.00053018\n",
      "Iteration 719, loss = 492709704.52106643\n",
      "Iteration 720, loss = 491974204.06442970\n",
      "Iteration 721, loss = 491279298.24951154\n",
      "Iteration 722, loss = 490611608.73997802\n",
      "Iteration 723, loss = 489853165.18599677\n",
      "Iteration 724, loss = 489134088.38688779\n",
      "Iteration 725, loss = 488425953.69399798\n",
      "Iteration 726, loss = 487738255.27063566\n",
      "Iteration 727, loss = 487037389.34773093\n",
      "Iteration 728, loss = 486426128.86693060\n",
      "Iteration 729, loss = 485730521.01098818\n",
      "Iteration 730, loss = 485075961.20958984\n",
      "Iteration 731, loss = 484411909.76097780\n",
      "Iteration 732, loss = 483715476.66386467\n",
      "Iteration 733, loss = 483071933.83181340\n",
      "Iteration 734, loss = 482372180.87169415\n",
      "Iteration 735, loss = 481717900.44011927\n",
      "Iteration 736, loss = 481037863.38828957\n",
      "Iteration 737, loss = 480376895.66113937\n",
      "Iteration 738, loss = 479695426.62757951\n",
      "Iteration 739, loss = 479036669.94596642\n",
      "Iteration 740, loss = 478378029.69288325\n",
      "Iteration 741, loss = 477721661.67227036\n",
      "Iteration 742, loss = 477036725.84346730\n",
      "Iteration 743, loss = 476384999.53962326\n",
      "Iteration 744, loss = 475733459.29136330\n",
      "Iteration 745, loss = 475087925.28436673\n",
      "Iteration 746, loss = 474414840.31112635\n",
      "Iteration 747, loss = 473756921.26660472\n",
      "Iteration 748, loss = 473083740.87443185\n",
      "Iteration 749, loss = 472411746.70057344\n",
      "Iteration 750, loss = 471741023.99359196\n",
      "Iteration 751, loss = 471058830.42791730\n",
      "Iteration 752, loss = 470407236.52319849\n",
      "Iteration 753, loss = 469718109.83863926\n",
      "Iteration 754, loss = 469059082.54096210\n",
      "Iteration 755, loss = 468383864.79364473\n",
      "Iteration 756, loss = 467735770.27833903\n",
      "Iteration 757, loss = 467051963.92394996\n",
      "Iteration 758, loss = 466391853.71100640\n",
      "Iteration 759, loss = 465739631.13313788\n",
      "Iteration 760, loss = 465087579.26684201\n",
      "Iteration 761, loss = 464440977.08529419\n",
      "Iteration 762, loss = 463752607.02401000\n",
      "Iteration 763, loss = 463117471.89435202\n",
      "Iteration 764, loss = 462413906.14066064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 765, loss = 461768751.74705189\n",
      "Iteration 766, loss = 461128223.71840996\n",
      "Iteration 767, loss = 460448787.16719395\n",
      "Iteration 768, loss = 459769874.99794489\n",
      "Iteration 769, loss = 459125863.52535570\n",
      "Iteration 770, loss = 458441215.37255532\n",
      "Iteration 771, loss = 457777903.12136382\n",
      "Iteration 772, loss = 457128468.59140831\n",
      "Iteration 773, loss = 456456852.75163758\n",
      "Iteration 774, loss = 455806339.79315263\n",
      "Iteration 775, loss = 455146446.64665735\n",
      "Iteration 776, loss = 454472094.06944954\n",
      "Iteration 777, loss = 453828743.46926075\n",
      "Iteration 778, loss = 453173836.23489326\n",
      "Iteration 779, loss = 452520239.39050561\n",
      "Iteration 780, loss = 451843115.55051059\n",
      "Iteration 781, loss = 451204129.24531275\n",
      "Iteration 782, loss = 450557330.87760013\n",
      "Iteration 783, loss = 449877113.99252641\n",
      "Iteration 784, loss = 449238972.71630633\n",
      "Iteration 785, loss = 448552449.65037727\n",
      "Iteration 786, loss = 447948252.60312241\n",
      "Iteration 787, loss = 447256994.66021627\n",
      "Iteration 788, loss = 446612208.74681824\n",
      "Iteration 789, loss = 445967315.24349803\n",
      "Iteration 790, loss = 445302797.12031686\n",
      "Iteration 791, loss = 444699601.15745622\n",
      "Iteration 792, loss = 444028365.14219731\n",
      "Iteration 793, loss = 443355153.50058693\n",
      "Iteration 794, loss = 442717598.63738322\n",
      "Iteration 795, loss = 442049058.60656965\n",
      "Iteration 796, loss = 441443260.77914900\n",
      "Iteration 797, loss = 440753404.83567232\n",
      "Iteration 798, loss = 440086600.61266601\n",
      "Iteration 799, loss = 439461698.00340712\n",
      "Iteration 800, loss = 438829198.93161041\n",
      "Iteration 801, loss = 438179279.81017888\n",
      "Iteration 802, loss = 437511061.30396038\n",
      "Iteration 803, loss = 436875544.48672342\n",
      "Iteration 804, loss = 436217899.78616446\n",
      "Iteration 805, loss = 435578405.85236388\n",
      "Iteration 806, loss = 434949101.56637639\n",
      "Iteration 807, loss = 434327278.83196884\n",
      "Iteration 808, loss = 433670598.39738649\n",
      "Iteration 809, loss = 433027166.93335855\n",
      "Iteration 810, loss = 432377753.78209955\n",
      "Iteration 811, loss = 431734781.64335483\n",
      "Iteration 812, loss = 431114573.84458315\n",
      "Iteration 813, loss = 430475421.48257881\n",
      "Iteration 814, loss = 429835876.89063013\n",
      "Iteration 815, loss = 429193974.76457119\n",
      "Iteration 816, loss = 428550399.78592491\n",
      "Iteration 817, loss = 427906849.92460650\n",
      "Iteration 818, loss = 427284014.03204930\n",
      "Iteration 819, loss = 426639254.92632717\n",
      "Iteration 820, loss = 426030768.20722121\n",
      "Iteration 821, loss = 425403073.92385870\n",
      "Iteration 822, loss = 424757323.32704163\n",
      "Iteration 823, loss = 424117727.20147806\n",
      "Iteration 824, loss = 423493401.62839496\n",
      "Iteration 825, loss = 422878975.88496220\n",
      "Iteration 826, loss = 422256083.46683723\n",
      "Iteration 827, loss = 421631212.46161318\n",
      "Iteration 828, loss = 421015447.71483737\n",
      "Iteration 829, loss = 420402337.67068273\n",
      "Iteration 830, loss = 419781341.34665316\n",
      "Iteration 831, loss = 419123738.95260090\n",
      "Iteration 832, loss = 418515417.96722013\n",
      "Iteration 833, loss = 417924322.10839742\n",
      "Iteration 834, loss = 417303576.07748485\n",
      "Iteration 835, loss = 416676034.20247221\n",
      "Iteration 836, loss = 416072878.07397556\n",
      "Iteration 837, loss = 415455607.40367275\n",
      "Iteration 838, loss = 414862824.91344398\n",
      "Iteration 839, loss = 414219272.08880782\n",
      "Iteration 840, loss = 413623783.79662114\n",
      "Iteration 841, loss = 412975482.89498693\n",
      "Iteration 842, loss = 412364037.22055304\n",
      "Iteration 843, loss = 411780544.68376684\n",
      "Iteration 844, loss = 411146372.48821616\n",
      "Iteration 845, loss = 410492253.24800467\n",
      "Iteration 846, loss = 409870145.84506822\n",
      "Iteration 847, loss = 409256725.75394422\n",
      "Iteration 848, loss = 408619567.71269149\n",
      "Iteration 849, loss = 408037553.24730414\n",
      "Iteration 850, loss = 407388058.83421034\n",
      "Iteration 851, loss = 406781371.68378854\n",
      "Iteration 852, loss = 406159664.52459329\n",
      "Iteration 853, loss = 405556395.23228657\n",
      "Iteration 854, loss = 404936034.48115981\n",
      "Iteration 855, loss = 404312541.52692723\n",
      "Iteration 856, loss = 403732239.03054947\n",
      "Iteration 857, loss = 403105410.51317012\n",
      "Iteration 858, loss = 402481109.90771878\n",
      "Iteration 859, loss = 401895098.22095799\n",
      "Iteration 860, loss = 401279080.88195926\n",
      "Iteration 861, loss = 400665591.29813236\n",
      "Iteration 862, loss = 400096212.14462954\n",
      "Iteration 863, loss = 399445018.27736920\n",
      "Iteration 864, loss = 398816848.62835807\n",
      "Iteration 865, loss = 398248855.14908165\n",
      "Iteration 866, loss = 397624426.06362617\n",
      "Iteration 867, loss = 397016964.04500294\n",
      "Iteration 868, loss = 396411161.00087368\n",
      "Iteration 869, loss = 395801616.08484840\n",
      "Iteration 870, loss = 395236929.63298202\n",
      "Iteration 871, loss = 394612567.61502498\n",
      "Iteration 872, loss = 394012621.32503021\n",
      "Iteration 873, loss = 393475347.33858985\n",
      "Iteration 874, loss = 392831802.48194021\n",
      "Iteration 875, loss = 392253284.36549616\n",
      "Iteration 876, loss = 391650017.60257286\n",
      "Iteration 877, loss = 391075281.69162184\n",
      "Iteration 878, loss = 390466827.62899852\n",
      "Iteration 879, loss = 389846809.32941014\n",
      "Iteration 880, loss = 389263181.51404351\n",
      "Iteration 881, loss = 388660964.13300580\n",
      "Iteration 882, loss = 388070498.40574181\n",
      "Iteration 883, loss = 387522929.00848526\n",
      "Iteration 884, loss = 386894263.63307303\n",
      "Iteration 885, loss = 386297390.18375713\n",
      "Iteration 886, loss = 385690275.39773864\n",
      "Iteration 887, loss = 385117204.36460072\n",
      "Iteration 888, loss = 384543125.26292175\n",
      "Iteration 889, loss = 383949315.46036607\n",
      "Iteration 890, loss = 383375488.16294879\n",
      "Iteration 891, loss = 382787853.06012905\n",
      "Iteration 892, loss = 382187108.23488718\n",
      "Iteration 893, loss = 381601904.45061934\n",
      "Iteration 894, loss = 381004354.66273361\n",
      "Iteration 895, loss = 380426743.99922001\n",
      "Iteration 896, loss = 379857674.41281241\n",
      "Iteration 897, loss = 379263751.75524575\n",
      "Iteration 898, loss = 378670055.47346383\n",
      "Iteration 899, loss = 378078110.35566062\n",
      "Iteration 900, loss = 377475005.94508576\n",
      "Iteration 901, loss = 376883063.71639860\n",
      "Iteration 902, loss = 376323471.93320441\n",
      "Iteration 903, loss = 375725027.85893947\n",
      "Iteration 904, loss = 375178244.59812510\n",
      "Iteration 905, loss = 374594633.10999942\n",
      "Iteration 906, loss = 373978187.90304470\n",
      "Iteration 907, loss = 373435215.84127557\n",
      "Iteration 908, loss = 372852258.93908244\n",
      "Iteration 909, loss = 372279859.99475640\n",
      "Iteration 910, loss = 371685989.89442056\n",
      "Iteration 911, loss = 371127395.49866939\n",
      "Iteration 912, loss = 370535473.14882243\n",
      "Iteration 913, loss = 369971642.24262559\n",
      "Iteration 914, loss = 369399625.00512981\n",
      "Iteration 915, loss = 368886677.07247508\n",
      "Iteration 916, loss = 368259705.64698392\n",
      "Iteration 917, loss = 367712965.36954421\n",
      "Iteration 918, loss = 367136589.06847185\n",
      "Iteration 919, loss = 366504938.06107980\n",
      "Iteration 920, loss = 365935363.66533476\n",
      "Iteration 921, loss = 365383764.27337039\n",
      "Iteration 922, loss = 364801129.16715980\n",
      "Iteration 923, loss = 364203602.46405888\n",
      "Iteration 924, loss = 363628195.63870859\n",
      "Iteration 925, loss = 363052477.14840961\n",
      "Iteration 926, loss = 362500569.15538728\n",
      "Iteration 927, loss = 361944376.76164621\n",
      "Iteration 928, loss = 361344794.50562608\n",
      "Iteration 929, loss = 360793209.71666187\n",
      "Iteration 930, loss = 360220496.82425064\n",
      "Iteration 931, loss = 359635285.68044096\n",
      "Iteration 932, loss = 359093049.01380682\n",
      "Iteration 933, loss = 358467695.15011960\n",
      "Iteration 934, loss = 357916919.80846149\n",
      "Iteration 935, loss = 357351061.23097372\n",
      "Iteration 936, loss = 356806928.56672400\n",
      "Iteration 937, loss = 356235591.21308213\n",
      "Iteration 938, loss = 355642364.69532990\n",
      "Iteration 939, loss = 355101427.09239006\n",
      "Iteration 940, loss = 354511153.46267658\n",
      "Iteration 941, loss = 353955477.44469267\n",
      "Iteration 942, loss = 353416578.50218129\n",
      "Iteration 943, loss = 352874739.07955533\n",
      "Iteration 944, loss = 352308854.25449961\n",
      "Iteration 945, loss = 351763616.08811551\n",
      "Iteration 946, loss = 351197185.97559220\n",
      "Iteration 947, loss = 350639612.55626106\n",
      "Iteration 948, loss = 350076547.32398659\n",
      "Iteration 949, loss = 349533825.84581119\n",
      "Iteration 950, loss = 349002613.00596046\n",
      "Iteration 951, loss = 348409856.12430161\n",
      "Iteration 952, loss = 347876330.86344779\n",
      "Iteration 953, loss = 347310191.54717380\n",
      "Iteration 954, loss = 346759594.45339251\n",
      "Iteration 955, loss = 346191763.12380475\n",
      "Iteration 956, loss = 345645915.16224796\n",
      "Iteration 957, loss = 345056484.33835119\n",
      "Iteration 958, loss = 344530763.65004361\n",
      "Iteration 959, loss = 343948278.18416798\n",
      "Iteration 960, loss = 343407038.94971877\n",
      "Iteration 961, loss = 342868443.24745858\n",
      "Iteration 962, loss = 342296364.56910574\n",
      "Iteration 963, loss = 341732571.87573010\n",
      "Iteration 964, loss = 341197441.35538626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 965, loss = 340618980.04236883\n",
      "Iteration 966, loss = 340084438.34811038\n",
      "Iteration 967, loss = 339499816.60247904\n",
      "Iteration 968, loss = 338967440.01082844\n",
      "Iteration 969, loss = 338400268.61485124\n",
      "Iteration 970, loss = 337870436.70136631\n",
      "Iteration 971, loss = 337281945.50182378\n",
      "Iteration 972, loss = 336728594.36178172\n",
      "Iteration 973, loss = 336161803.31857908\n",
      "Iteration 974, loss = 335611976.82883263\n",
      "Iteration 975, loss = 335059457.54723871\n",
      "Iteration 976, loss = 334494517.71601576\n",
      "Iteration 977, loss = 333941837.92381781\n",
      "Iteration 978, loss = 333385464.79464489\n",
      "Iteration 979, loss = 332806583.72301739\n",
      "Iteration 980, loss = 332232323.75184995\n",
      "Iteration 981, loss = 331679335.64554501\n",
      "Iteration 982, loss = 331104614.69519824\n",
      "Iteration 983, loss = 330550961.63733727\n",
      "Iteration 984, loss = 330001320.27807432\n",
      "Iteration 985, loss = 329410043.77732313\n",
      "Iteration 986, loss = 328825094.45072764\n",
      "Iteration 987, loss = 328256223.47555155\n",
      "Iteration 988, loss = 327642903.25447047\n",
      "Iteration 989, loss = 327096320.19000816\n",
      "Iteration 990, loss = 326503276.51194429\n",
      "Iteration 991, loss = 325900526.01639378\n",
      "Iteration 992, loss = 325315897.22272986\n",
      "Iteration 993, loss = 324706182.39280415\n",
      "Iteration 994, loss = 324145662.70166069\n",
      "Iteration 995, loss = 323545883.21296614\n",
      "Iteration 996, loss = 322974813.77123117\n",
      "Iteration 997, loss = 322360837.94531238\n",
      "Iteration 998, loss = 321758481.28679585\n",
      "Iteration 999, loss = 321177564.47190470\n",
      "Iteration 1000, loss = 320564991.45937592\n",
      "Iteration 1001, loss = 319949307.32064062\n",
      "Iteration 1002, loss = 319351178.02491707\n",
      "Iteration 1003, loss = 318720243.70673740\n",
      "Iteration 1004, loss = 318076322.06790590\n",
      "Iteration 1005, loss = 317471935.79444826\n",
      "Iteration 1006, loss = 316846629.35865802\n",
      "Iteration 1007, loss = 316236190.80764455\n",
      "Iteration 1008, loss = 315605643.19468814\n",
      "Iteration 1009, loss = 314975063.54771966\n",
      "Iteration 1010, loss = 314357655.32523900\n",
      "Iteration 1011, loss = 313730011.49854320\n",
      "Iteration 1012, loss = 313095445.16076666\n",
      "Iteration 1013, loss = 312483031.79882896\n",
      "Iteration 1014, loss = 311846146.54020840\n",
      "Iteration 1015, loss = 311209548.73292071\n",
      "Iteration 1016, loss = 310592009.98447174\n",
      "Iteration 1017, loss = 309989416.64289135\n",
      "Iteration 1018, loss = 309259261.12176216\n",
      "Iteration 1019, loss = 308560584.38099068\n",
      "Iteration 1020, loss = 307866375.40429127\n",
      "Iteration 1021, loss = 307162895.02337521\n",
      "Iteration 1022, loss = 306482137.22685379\n",
      "Iteration 1023, loss = 305829552.57505500\n",
      "Iteration 1024, loss = 305177813.76130748\n",
      "Iteration 1025, loss = 304554459.35786122\n",
      "Iteration 1026, loss = 303929313.70872605\n",
      "Iteration 1027, loss = 303315254.17359829\n",
      "Iteration 1028, loss = 302700571.60603803\n",
      "Iteration 1029, loss = 302112786.77837902\n",
      "Iteration 1030, loss = 301512245.77134353\n",
      "Iteration 1031, loss = 300940909.11845976\n",
      "Iteration 1032, loss = 300371711.03587925\n",
      "Iteration 1033, loss = 299840780.16321415\n",
      "Iteration 1034, loss = 299227961.22250408\n",
      "Iteration 1035, loss = 298676288.67972320\n",
      "Iteration 1036, loss = 298093678.87002397\n",
      "Iteration 1037, loss = 297551252.14948064\n",
      "Iteration 1038, loss = 296947231.20747197\n",
      "Iteration 1039, loss = 296396611.23300409\n",
      "Iteration 1040, loss = 295821817.78958493\n",
      "Iteration 1041, loss = 295253123.48952806\n",
      "Iteration 1042, loss = 294714661.35925376\n",
      "Iteration 1043, loss = 294129453.96365905\n",
      "Iteration 1044, loss = 293558880.11567301\n",
      "Iteration 1045, loss = 293040148.28419876\n",
      "Iteration 1046, loss = 292455576.31500429\n",
      "Iteration 1047, loss = 291896194.80920261\n",
      "Iteration 1048, loss = 291333682.30183733\n",
      "Iteration 1049, loss = 290778196.73468083\n",
      "Iteration 1050, loss = 290208766.25249416\n",
      "Iteration 1051, loss = 289674982.02286416\n",
      "Iteration 1052, loss = 289108875.73601002\n",
      "Iteration 1053, loss = 288568180.51313967\n",
      "Iteration 1054, loss = 287996733.29373968\n",
      "Iteration 1055, loss = 287440781.50663829\n",
      "Iteration 1056, loss = 286934365.53946984\n",
      "Iteration 1057, loss = 286333223.16021043\n",
      "Iteration 1058, loss = 285782669.34904158\n",
      "Iteration 1059, loss = 285247126.20387763\n",
      "Iteration 1060, loss = 284676818.86438268\n",
      "Iteration 1061, loss = 284180163.49979579\n",
      "Iteration 1062, loss = 283598636.56871229\n",
      "Iteration 1063, loss = 283040180.30551511\n",
      "Iteration 1064, loss = 282541663.42993885\n",
      "Iteration 1065, loss = 281972083.84554785\n",
      "Iteration 1066, loss = 281403846.22543001\n",
      "Iteration 1067, loss = 280861106.80076957\n",
      "Iteration 1068, loss = 280347249.45738089\n",
      "Iteration 1069, loss = 279763629.91974223\n",
      "Iteration 1070, loss = 279236701.73000753\n",
      "Iteration 1071, loss = 278702378.02450985\n",
      "Iteration 1072, loss = 278172498.32838047\n",
      "Iteration 1073, loss = 277616822.96292317\n",
      "Iteration 1074, loss = 277093323.28730732\n",
      "Iteration 1075, loss = 276572823.51348615\n",
      "Iteration 1076, loss = 276051521.77087641\n",
      "Iteration 1077, loss = 275492634.04685086\n",
      "Iteration 1078, loss = 274962346.30037349\n",
      "Iteration 1079, loss = 274429698.44696116\n",
      "Iteration 1080, loss = 273866011.71493638\n",
      "Iteration 1081, loss = 273325499.94099104\n",
      "Iteration 1082, loss = 272792711.80084473\n",
      "Iteration 1083, loss = 272248067.71306956\n",
      "Iteration 1084, loss = 271703861.34222358\n",
      "Iteration 1085, loss = 271225363.76516885\n",
      "Iteration 1086, loss = 270618756.02655631\n",
      "Iteration 1087, loss = 270071797.43477392\n",
      "Iteration 1088, loss = 269545167.54554802\n",
      "Iteration 1089, loss = 269013357.88105589\n",
      "Iteration 1090, loss = 268441037.80170149\n",
      "Iteration 1091, loss = 267921991.24825907\n",
      "Iteration 1092, loss = 267348054.15009311\n",
      "Iteration 1093, loss = 266798073.57185179\n",
      "Iteration 1094, loss = 266256268.77384201\n",
      "Iteration 1095, loss = 265717797.71299806\n",
      "Iteration 1096, loss = 265157454.45814323\n",
      "Iteration 1097, loss = 264617423.36129254\n",
      "Iteration 1098, loss = 264063949.96108669\n",
      "Iteration 1099, loss = 263564148.36186370\n",
      "Iteration 1100, loss = 262983691.47021788\n",
      "Iteration 1101, loss = 262462978.42744401\n",
      "Iteration 1102, loss = 261905348.87303171\n",
      "Iteration 1103, loss = 261395323.39287832\n",
      "Iteration 1104, loss = 260835371.39076281\n",
      "Iteration 1105, loss = 260294159.62333339\n",
      "Iteration 1106, loss = 259747825.92702791\n",
      "Iteration 1107, loss = 259219543.76482895\n",
      "Iteration 1108, loss = 258679323.67582992\n",
      "Iteration 1109, loss = 258135548.85019004\n",
      "Iteration 1110, loss = 257587084.88652605\n",
      "Iteration 1111, loss = 257040485.14115718\n",
      "Iteration 1112, loss = 256503207.38688272\n",
      "Iteration 1113, loss = 255986911.84110200\n",
      "Iteration 1114, loss = 255430017.55418494\n",
      "Iteration 1115, loss = 254879274.29348025\n",
      "Iteration 1116, loss = 254311881.64887837\n",
      "Iteration 1117, loss = 253761811.81246546\n",
      "Iteration 1118, loss = 253222892.97450855\n",
      "Iteration 1119, loss = 252678033.25279844\n",
      "Iteration 1120, loss = 252120262.43584341\n",
      "Iteration 1121, loss = 251600745.56574267\n",
      "Iteration 1122, loss = 251007386.54125619\n",
      "Iteration 1123, loss = 250461614.24559128\n",
      "Iteration 1124, loss = 249894301.72717381\n",
      "Iteration 1125, loss = 249337170.16198319\n",
      "Iteration 1126, loss = 248710588.46249914\n",
      "Iteration 1127, loss = 248115651.19467297\n",
      "Iteration 1128, loss = 247538709.59443367\n",
      "Iteration 1129, loss = 246955146.46236837\n",
      "Iteration 1130, loss = 246412656.38195986\n",
      "Iteration 1131, loss = 245865767.77114376\n",
      "Iteration 1132, loss = 245343065.00786453\n",
      "Iteration 1133, loss = 244821163.95339641\n",
      "Iteration 1134, loss = 244326584.52752283\n",
      "Iteration 1135, loss = 243802478.71362096\n",
      "Iteration 1136, loss = 243316198.23515958\n",
      "Iteration 1137, loss = 242822753.11350062\n",
      "Iteration 1138, loss = 242337795.37013617\n",
      "Iteration 1139, loss = 241869893.43622237\n",
      "Iteration 1140, loss = 241383753.19247052\n",
      "Iteration 1141, loss = 240867928.98051381\n",
      "Iteration 1142, loss = 240420704.06287110\n",
      "Iteration 1143, loss = 239940037.29584834\n",
      "Iteration 1144, loss = 239445712.33759159\n",
      "Iteration 1145, loss = 239005439.45290726\n",
      "Iteration 1146, loss = 238518027.32177559\n",
      "Iteration 1147, loss = 238047246.70701841\n",
      "Iteration 1148, loss = 237565726.75595021\n",
      "Iteration 1149, loss = 237086972.60955909\n",
      "Iteration 1150, loss = 236633046.50963500\n",
      "Iteration 1151, loss = 236165182.15420389\n",
      "Iteration 1152, loss = 235671126.13645339\n",
      "Iteration 1153, loss = 235228263.19522670\n",
      "Iteration 1154, loss = 234723513.41800287\n",
      "Iteration 1155, loss = 234265862.01165465\n",
      "Iteration 1156, loss = 233807469.12916088\n",
      "Iteration 1157, loss = 233324435.79401886\n",
      "Iteration 1158, loss = 232897766.45194501\n",
      "Iteration 1159, loss = 232378249.39302003\n",
      "Iteration 1160, loss = 231926891.10680351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1161, loss = 231446901.73450884\n",
      "Iteration 1162, loss = 230990576.14733794\n",
      "Iteration 1163, loss = 230520508.79734850\n",
      "Iteration 1164, loss = 230072976.27238443\n",
      "Iteration 1165, loss = 229588309.69398096\n",
      "Iteration 1166, loss = 229123450.15614265\n",
      "Iteration 1167, loss = 228673322.56909382\n",
      "Iteration 1168, loss = 228193101.01204082\n",
      "Iteration 1169, loss = 227783908.79751471\n",
      "Iteration 1170, loss = 227454011.80519557\n",
      "Iteration 1171, loss = 226862997.59972018\n",
      "Iteration 1172, loss = 226407417.16816875\n",
      "Iteration 1173, loss = 225995912.20496356\n",
      "Iteration 1174, loss = 225564500.48482785\n",
      "Iteration 1175, loss = 225128777.71795669\n",
      "Iteration 1176, loss = 224686256.99152139\n",
      "Iteration 1177, loss = 224295839.10548326\n",
      "Iteration 1178, loss = 223835990.02507409\n",
      "Iteration 1179, loss = 223416455.97469500\n",
      "Iteration 1180, loss = 222966415.43611574\n",
      "Iteration 1181, loss = 222503972.08919385\n",
      "Iteration 1182, loss = 222080623.40646181\n",
      "Iteration 1183, loss = 221633869.37706500\n",
      "Iteration 1184, loss = 221185921.00945365\n",
      "Iteration 1185, loss = 220748468.31237215\n",
      "Iteration 1186, loss = 220316186.94208065\n",
      "Iteration 1187, loss = 219869604.68995780\n",
      "Iteration 1188, loss = 219429310.30615249\n",
      "Iteration 1189, loss = 218988978.58565250\n",
      "Iteration 1190, loss = 218574363.46188834\n",
      "Iteration 1191, loss = 218106395.93621564\n",
      "Iteration 1192, loss = 217669591.08134127\n",
      "Iteration 1193, loss = 217228925.23564741\n",
      "Iteration 1194, loss = 216826312.68178904\n",
      "Iteration 1195, loss = 216379991.28788367\n",
      "Iteration 1196, loss = 215948188.49066406\n",
      "Iteration 1197, loss = 215506802.89537203\n",
      "Iteration 1198, loss = 215067445.59976301\n",
      "Iteration 1199, loss = 214635051.51927134\n",
      "Iteration 1200, loss = 214210430.09102798\n",
      "Iteration 1201, loss = 213795198.11816239\n",
      "Iteration 1202, loss = 213372792.05214328\n",
      "Iteration 1203, loss = 212933598.04762080\n",
      "Iteration 1204, loss = 212497387.49443620\n",
      "Iteration 1205, loss = 212088529.00993064\n",
      "Iteration 1206, loss = 211673638.34287757\n",
      "Iteration 1207, loss = 211254374.40266201\n",
      "Iteration 1208, loss = 210831133.12156287\n",
      "Iteration 1209, loss = 210514803.41942883\n",
      "Iteration 1210, loss = 210017741.20701551\n",
      "Iteration 1211, loss = 209613203.52279353\n",
      "Iteration 1212, loss = 209205173.42580542\n",
      "Iteration 1213, loss = 208800449.33665341\n",
      "Iteration 1214, loss = 208381479.25067344\n",
      "Iteration 1215, loss = 207990803.01133862\n",
      "Iteration 1216, loss = 207586975.65212700\n",
      "Iteration 1217, loss = 207191311.85686618\n",
      "Iteration 1218, loss = 206773775.43115434\n",
      "Iteration 1219, loss = 206375479.88865983\n",
      "Iteration 1220, loss = 206000713.43275064\n",
      "Iteration 1221, loss = 205576891.40211374\n",
      "Iteration 1222, loss = 205191887.66129529\n",
      "Iteration 1223, loss = 204789717.88120869\n",
      "Iteration 1224, loss = 204390165.46249139\n",
      "Iteration 1225, loss = 204018029.84000617\n",
      "Iteration 1226, loss = 203607141.65625361\n",
      "Iteration 1227, loss = 203219289.18301812\n",
      "Iteration 1228, loss = 202816121.09463593\n",
      "Iteration 1229, loss = 202448158.31432062\n",
      "Iteration 1230, loss = 202028334.50352833\n",
      "Iteration 1231, loss = 201629370.83393121\n",
      "Iteration 1232, loss = 201273735.64926928\n",
      "Iteration 1233, loss = 200844216.74535269\n",
      "Iteration 1234, loss = 200456534.87216961\n",
      "Iteration 1235, loss = 200065832.35803947\n",
      "Iteration 1236, loss = 199696164.57633731\n",
      "Iteration 1237, loss = 199277387.48656878\n",
      "Iteration 1238, loss = 198883237.37145540\n",
      "Iteration 1239, loss = 198529301.36142001\n",
      "Iteration 1240, loss = 198107133.83070093\n",
      "Iteration 1241, loss = 197738181.52696720\n",
      "Iteration 1242, loss = 197325499.17080301\n",
      "Iteration 1243, loss = 196977240.25481075\n",
      "Iteration 1244, loss = 196551087.86196762\n",
      "Iteration 1245, loss = 196160043.93949062\n",
      "Iteration 1246, loss = 195794114.10822102\n",
      "Iteration 1247, loss = 195384814.50387132\n",
      "Iteration 1248, loss = 195010238.33846471\n",
      "Iteration 1249, loss = 194654340.56723991\n",
      "Iteration 1250, loss = 194230369.24828857\n",
      "Iteration 1251, loss = 193913860.26849303\n",
      "Iteration 1252, loss = 193513398.64016610\n",
      "Iteration 1253, loss = 193139805.24755788\n",
      "Iteration 1254, loss = 192755572.85441238\n",
      "Iteration 1255, loss = 192404320.20552158\n",
      "Iteration 1256, loss = 192023043.82456800\n",
      "Iteration 1257, loss = 191650999.51825449\n",
      "Iteration 1258, loss = 191305388.69376913\n",
      "Iteration 1259, loss = 190946386.84589520\n",
      "Iteration 1260, loss = 190574983.77730569\n",
      "Iteration 1261, loss = 190242920.36491209\n",
      "Iteration 1262, loss = 189833374.77913642\n",
      "Iteration 1263, loss = 189468325.46802461\n",
      "Iteration 1264, loss = 189122251.37020835\n",
      "Iteration 1265, loss = 188735582.11532098\n",
      "Iteration 1266, loss = 188394772.76638198\n",
      "Iteration 1267, loss = 188022763.27500334\n",
      "Iteration 1268, loss = 187656399.44835550\n",
      "Iteration 1269, loss = 187293817.84218299\n",
      "Iteration 1270, loss = 186933053.43941283\n",
      "Iteration 1271, loss = 186566815.15418047\n",
      "Iteration 1272, loss = 186217313.49461761\n",
      "Iteration 1273, loss = 185851023.89279553\n",
      "Iteration 1274, loss = 185497251.38007641\n",
      "Iteration 1275, loss = 185149700.75241187\n",
      "Iteration 1276, loss = 184757800.34680343\n",
      "Iteration 1277, loss = 184439178.44093227\n",
      "Iteration 1278, loss = 184078265.00559261\n",
      "Iteration 1279, loss = 183716489.74101517\n",
      "Iteration 1280, loss = 183359509.00198686\n",
      "Iteration 1281, loss = 183004567.34457323\n",
      "Iteration 1282, loss = 182614202.70842060\n",
      "Iteration 1283, loss = 182313932.31347314\n",
      "Iteration 1284, loss = 181964250.78197575\n",
      "Iteration 1285, loss = 181596079.17121077\n",
      "Iteration 1286, loss = 181228368.61329523\n",
      "Iteration 1287, loss = 180891678.46931970\n",
      "Iteration 1288, loss = 180545662.52476224\n",
      "Iteration 1289, loss = 180235075.15208098\n",
      "Iteration 1290, loss = 179869398.37796128\n",
      "Iteration 1291, loss = 179511459.76338038\n",
      "Iteration 1292, loss = 179173491.82102087\n",
      "Iteration 1293, loss = 178835244.00085062\n",
      "Iteration 1294, loss = 178476109.34533167\n",
      "Iteration 1295, loss = 178139737.14255735\n",
      "Iteration 1296, loss = 177791500.05181292\n",
      "Iteration 1297, loss = 177463318.93097785\n",
      "Iteration 1298, loss = 177143102.13693535\n",
      "Iteration 1299, loss = 176784781.01057738\n",
      "Iteration 1300, loss = 176443638.23470381\n",
      "Iteration 1301, loss = 176103750.66633534\n",
      "Iteration 1302, loss = 175807527.05691910\n",
      "Iteration 1303, loss = 175473712.73379019\n",
      "Iteration 1304, loss = 175104052.80842325\n",
      "Iteration 1305, loss = 174771648.09270853\n",
      "Iteration 1306, loss = 174454799.82438877\n",
      "Iteration 1307, loss = 174129761.39009556\n",
      "Iteration 1308, loss = 173802329.38751942\n",
      "Iteration 1309, loss = 173480628.70332459\n",
      "Iteration 1310, loss = 173135430.65255690\n",
      "Iteration 1311, loss = 172824346.57561401\n",
      "Iteration 1312, loss = 172490395.03555605\n",
      "Iteration 1313, loss = 172170542.21368366\n",
      "Iteration 1314, loss = 171840915.27031219\n",
      "Iteration 1315, loss = 171538268.05922049\n",
      "Iteration 1316, loss = 171207266.30480316\n",
      "Iteration 1317, loss = 170899020.14823341\n",
      "Iteration 1318, loss = 170581756.36734879\n",
      "Iteration 1319, loss = 170269515.00479627\n",
      "Iteration 1320, loss = 169916953.31153896\n",
      "Iteration 1321, loss = 169640820.37779689\n",
      "Iteration 1322, loss = 169299311.68146840\n",
      "Iteration 1323, loss = 168991726.42937526\n",
      "Iteration 1324, loss = 168673083.32115611\n",
      "Iteration 1325, loss = 168355856.30592945\n",
      "Iteration 1326, loss = 168073664.72429588\n",
      "Iteration 1327, loss = 167758664.59239835\n",
      "Iteration 1328, loss = 167457080.47649458\n",
      "Iteration 1329, loss = 167156652.34895593\n",
      "Iteration 1330, loss = 166813850.85021248\n",
      "Iteration 1331, loss = 166530530.80171838\n",
      "Iteration 1332, loss = 166232961.05061138\n",
      "Iteration 1333, loss = 165930600.06397679\n",
      "Iteration 1334, loss = 165620088.48882204\n",
      "Iteration 1335, loss = 165320136.89200735\n",
      "Iteration 1336, loss = 165007957.14402276\n",
      "Iteration 1337, loss = 164707291.47460681\n",
      "Iteration 1338, loss = 164457031.62236533\n",
      "Iteration 1339, loss = 164135470.69285136\n",
      "Iteration 1340, loss = 163833935.88825297\n",
      "Iteration 1341, loss = 163567140.27843040\n",
      "Iteration 1342, loss = 163235440.40755567\n",
      "Iteration 1343, loss = 162964318.67789203\n",
      "Iteration 1344, loss = 162625411.43427691\n",
      "Iteration 1345, loss = 162358786.27843642\n",
      "Iteration 1346, loss = 162084577.82668802\n",
      "Iteration 1347, loss = 161813037.53320482\n",
      "Iteration 1348, loss = 161498470.12006742\n",
      "Iteration 1349, loss = 161211569.33333865\n",
      "Iteration 1350, loss = 160927540.65414256\n",
      "Iteration 1351, loss = 160710276.63689744\n",
      "Iteration 1352, loss = 160374768.31509358\n",
      "Iteration 1353, loss = 160113869.28549671\n",
      "Iteration 1354, loss = 159810560.51824120\n",
      "Iteration 1355, loss = 159552500.77223018\n",
      "Iteration 1356, loss = 159283459.77971417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1357, loss = 159007748.71200258\n",
      "Iteration 1358, loss = 158754256.17078853\n",
      "Iteration 1359, loss = 158463762.58974588\n",
      "Iteration 1360, loss = 158190645.93176433\n",
      "Iteration 1361, loss = 157923182.38689768\n",
      "Iteration 1362, loss = 157670332.06954840\n",
      "Iteration 1363, loss = 157386649.16647550\n",
      "Iteration 1364, loss = 157125170.15678701\n",
      "Iteration 1365, loss = 156841727.19992453\n",
      "Iteration 1366, loss = 156594625.92165953\n",
      "Iteration 1367, loss = 156327466.69697136\n",
      "Iteration 1368, loss = 156062598.01422742\n",
      "Iteration 1369, loss = 155823904.95197469\n",
      "Iteration 1370, loss = 155547730.87411046\n",
      "Iteration 1371, loss = 155281920.36432239\n",
      "Iteration 1372, loss = 155027072.64103317\n",
      "Iteration 1373, loss = 154775646.30150598\n",
      "Iteration 1374, loss = 154496753.43981412\n",
      "Iteration 1375, loss = 154298343.20742449\n",
      "Iteration 1376, loss = 154051746.50303599\n",
      "Iteration 1377, loss = 153737638.12642312\n",
      "Iteration 1378, loss = 153469402.88050646\n",
      "Iteration 1379, loss = 153220904.79928222\n",
      "Iteration 1380, loss = 152987580.50484768\n",
      "Iteration 1381, loss = 152702751.16835678\n",
      "Iteration 1382, loss = 152476837.82875854\n",
      "Iteration 1383, loss = 152221909.01113141\n",
      "Iteration 1384, loss = 151965847.91749567\n",
      "Iteration 1385, loss = 151695031.27803227\n",
      "Iteration 1386, loss = 151459161.52720496\n",
      "Iteration 1387, loss = 151203055.69772294\n",
      "Iteration 1388, loss = 150949530.23267394\n",
      "Iteration 1389, loss = 150697083.23001516\n",
      "Iteration 1390, loss = 150459426.08648616\n",
      "Iteration 1391, loss = 150201357.60115775\n",
      "Iteration 1392, loss = 150002393.70396468\n",
      "Iteration 1393, loss = 149728355.77405185\n",
      "Iteration 1394, loss = 149483798.53628859\n",
      "Iteration 1395, loss = 149220741.42474264\n",
      "Iteration 1396, loss = 148975367.13102916\n",
      "Iteration 1397, loss = 148739605.48660183\n",
      "Iteration 1398, loss = 148495286.59170872\n",
      "Iteration 1399, loss = 148263033.05580765\n",
      "Iteration 1400, loss = 148042725.07691929\n",
      "Iteration 1401, loss = 147812626.33022541\n",
      "Iteration 1402, loss = 147548914.40521178\n",
      "Iteration 1403, loss = 147327036.24524671\n",
      "Iteration 1404, loss = 147092762.08278763\n",
      "Iteration 1405, loss = 146841743.49155369\n",
      "Iteration 1406, loss = 146607551.07629859\n",
      "Iteration 1407, loss = 146383286.19935453\n",
      "Iteration 1408, loss = 146158998.55490804\n",
      "Iteration 1409, loss = 145932204.58072221\n",
      "Iteration 1410, loss = 145686751.55486068\n",
      "Iteration 1411, loss = 145477013.64581802\n",
      "Iteration 1412, loss = 145229197.46213505\n",
      "Iteration 1413, loss = 145017082.98606437\n",
      "Iteration 1414, loss = 144807454.28623387\n",
      "Iteration 1415, loss = 144617739.30392677\n",
      "Iteration 1416, loss = 144327400.16492534\n",
      "Iteration 1417, loss = 144118566.35233599\n",
      "Iteration 1418, loss = 143893414.00512406\n",
      "Iteration 1419, loss = 143706937.31770676\n",
      "Iteration 1420, loss = 143484197.95334145\n",
      "Iteration 1421, loss = 143258086.85516962\n",
      "Iteration 1422, loss = 143037060.48413971\n",
      "Iteration 1423, loss = 142813336.04302323\n",
      "Iteration 1424, loss = 142629027.05826527\n",
      "Iteration 1425, loss = 142376796.92002931\n",
      "Iteration 1426, loss = 142173514.61045325\n",
      "Iteration 1427, loss = 141947858.20114163\n",
      "Iteration 1428, loss = 141742434.14151779\n",
      "Iteration 1429, loss = 141526925.41068944\n",
      "Iteration 1430, loss = 141354185.14819151\n",
      "Iteration 1431, loss = 141101690.96034068\n",
      "Iteration 1432, loss = 140886402.09667414\n",
      "Iteration 1433, loss = 140717625.89606437\n",
      "Iteration 1434, loss = 140451349.43725786\n",
      "Iteration 1435, loss = 140248334.32085913\n",
      "Iteration 1436, loss = 140047361.91723371\n",
      "Iteration 1437, loss = 139810860.32696342\n",
      "Iteration 1438, loss = 139630403.39459819\n",
      "Iteration 1439, loss = 139426481.21690270\n",
      "Iteration 1440, loss = 139198708.02179030\n",
      "Iteration 1441, loss = 138999097.92645061\n",
      "Iteration 1442, loss = 138829002.86820629\n",
      "Iteration 1443, loss = 138593511.04828456\n",
      "Iteration 1444, loss = 138416755.57790738\n",
      "Iteration 1445, loss = 138202383.36352372\n",
      "Iteration 1446, loss = 138002345.70323542\n",
      "Iteration 1447, loss = 137785839.21970645\n",
      "Iteration 1448, loss = 137595989.60500196\n",
      "Iteration 1449, loss = 137396460.58229306\n",
      "Iteration 1450, loss = 137182910.01291993\n",
      "Iteration 1451, loss = 136970603.61675796\n",
      "Iteration 1452, loss = 136805750.85003170\n",
      "Iteration 1453, loss = 136606402.80654567\n",
      "Iteration 1454, loss = 136368428.65298229\n",
      "Iteration 1455, loss = 136183623.28965414\n",
      "Iteration 1456, loss = 135984201.99179360\n",
      "Iteration 1457, loss = 135824723.53290626\n",
      "Iteration 1458, loss = 135590123.68439445\n",
      "Iteration 1459, loss = 135430599.48815829\n",
      "Iteration 1460, loss = 135224603.45173234\n",
      "Iteration 1461, loss = 135025962.28687194\n",
      "Iteration 1462, loss = 134850980.66845790\n",
      "Iteration 1463, loss = 134634860.53614143\n",
      "Iteration 1464, loss = 134466410.05305052\n",
      "Iteration 1465, loss = 134264412.08172208\n",
      "Iteration 1466, loss = 134090419.85401332\n",
      "Iteration 1467, loss = 133904542.55644847\n",
      "Iteration 1468, loss = 133709088.00302966\n",
      "Iteration 1469, loss = 133502590.64775580\n",
      "Iteration 1470, loss = 133334518.99520980\n",
      "Iteration 1471, loss = 133134921.48386346\n",
      "Iteration 1472, loss = 132938302.73406373\n",
      "Iteration 1473, loss = 132758501.55889837\n",
      "Iteration 1474, loss = 132569515.78843045\n",
      "Iteration 1475, loss = 132395692.61994191\n",
      "Iteration 1476, loss = 132228221.01231939\n",
      "Iteration 1477, loss = 132020945.58351730\n",
      "Iteration 1478, loss = 131851531.46789920\n",
      "Iteration 1479, loss = 131650502.14139980\n",
      "Iteration 1480, loss = 131456386.16506721\n",
      "Iteration 1481, loss = 131282966.38827828\n",
      "Iteration 1482, loss = 131117516.92030066\n",
      "Iteration 1483, loss = 130953866.62573038\n",
      "Iteration 1484, loss = 130752313.60804969\n",
      "Iteration 1485, loss = 130566340.58822277\n",
      "Iteration 1486, loss = 130407150.31721199\n",
      "Iteration 1487, loss = 130212991.67281958\n",
      "Iteration 1488, loss = 130028622.25702438\n",
      "Iteration 1489, loss = 129852746.00895476\n",
      "Iteration 1490, loss = 129669190.84453192\n",
      "Iteration 1491, loss = 129503338.41351631\n",
      "Iteration 1492, loss = 129343710.84261662\n",
      "Iteration 1493, loss = 129158946.87895700\n",
      "Iteration 1494, loss = 128971821.80719465\n",
      "Iteration 1495, loss = 128881546.52399351\n",
      "Iteration 1496, loss = 128654243.26264934\n",
      "Iteration 1497, loss = 128530123.89831994\n",
      "Iteration 1498, loss = 128297818.39779973\n",
      "Iteration 1499, loss = 128142008.73205870\n",
      "Iteration 1500, loss = 127967373.69717212\n",
      "Iteration 1501, loss = 127796589.64789824\n",
      "Iteration 1502, loss = 127612432.24774793\n",
      "Iteration 1503, loss = 127437786.82733923\n",
      "Iteration 1504, loss = 127279777.47174095\n",
      "Iteration 1505, loss = 127110835.70066214\n",
      "Iteration 1506, loss = 126962295.52226068\n",
      "Iteration 1507, loss = 126793893.53558902\n",
      "Iteration 1508, loss = 126594334.58979048\n",
      "Iteration 1509, loss = 126456620.40636072\n",
      "Iteration 1510, loss = 126280846.08733921\n",
      "Iteration 1511, loss = 126109800.91960637\n",
      "Iteration 1512, loss = 125981331.34250446\n",
      "Iteration 1513, loss = 125807895.44162363\n",
      "Iteration 1514, loss = 125615899.50582005\n",
      "Iteration 1515, loss = 125466741.07873236\n",
      "Iteration 1516, loss = 125296813.73676148\n",
      "Iteration 1517, loss = 125140820.56044908\n",
      "Iteration 1518, loss = 124986508.69306298\n",
      "Iteration 1519, loss = 124829617.82589230\n",
      "Iteration 1520, loss = 124685604.23986465\n",
      "Iteration 1521, loss = 124532600.88981570\n",
      "Iteration 1522, loss = 124357814.93025425\n",
      "Iteration 1523, loss = 124270138.52585803\n",
      "Iteration 1524, loss = 124068110.03013839\n",
      "Iteration 1525, loss = 123889818.94511776\n",
      "Iteration 1526, loss = 123753560.78982905\n",
      "Iteration 1527, loss = 123571885.92091854\n",
      "Iteration 1528, loss = 123438655.51587552\n",
      "Iteration 1529, loss = 123290524.05673546\n",
      "Iteration 1530, loss = 123119855.61674331\n",
      "Iteration 1531, loss = 122967738.28355882\n",
      "Iteration 1532, loss = 122822901.32744274\n",
      "Iteration 1533, loss = 122667650.14569040\n",
      "Iteration 1534, loss = 122544301.39591533\n",
      "Iteration 1535, loss = 122415861.68937758\n",
      "Iteration 1536, loss = 122242883.97976573\n",
      "Iteration 1537, loss = 122102749.86372885\n",
      "Iteration 1538, loss = 121989487.51136254\n",
      "Iteration 1539, loss = 121844601.49647979\n",
      "Iteration 1540, loss = 121682929.80702804\n",
      "Iteration 1541, loss = 121536612.25229061\n",
      "Iteration 1542, loss = 121374331.93141995\n",
      "Iteration 1543, loss = 121263170.17403212\n",
      "Iteration 1544, loss = 121112572.33964618\n",
      "Iteration 1545, loss = 120968684.88466112\n",
      "Iteration 1546, loss = 120816565.81592590\n",
      "Iteration 1547, loss = 120675593.43136552\n",
      "Iteration 1548, loss = 120564690.86198720\n",
      "Iteration 1549, loss = 120416600.45986480\n",
      "Iteration 1550, loss = 120243924.53603625\n",
      "Iteration 1551, loss = 120125152.11828083\n",
      "Iteration 1552, loss = 119965606.71048532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1553, loss = 119830315.35277994\n",
      "Iteration 1554, loss = 119697537.04512902\n",
      "Iteration 1555, loss = 119550344.99062878\n",
      "Iteration 1556, loss = 119412745.38973819\n",
      "Iteration 1557, loss = 119270655.72373712\n",
      "Iteration 1558, loss = 119287610.04675607\n",
      "Iteration 1559, loss = 119012580.84436643\n",
      "Iteration 1560, loss = 118884168.17299452\n",
      "Iteration 1561, loss = 118749813.44790216\n",
      "Iteration 1562, loss = 118601210.89754368\n",
      "Iteration 1563, loss = 118458407.62590735\n",
      "Iteration 1564, loss = 118336908.74338786\n",
      "Iteration 1565, loss = 118205654.02413364\n",
      "Iteration 1566, loss = 118052471.40842889\n",
      "Iteration 1567, loss = 117915775.89743382\n",
      "Iteration 1568, loss = 117784930.82836896\n",
      "Iteration 1569, loss = 117658781.52009390\n",
      "Iteration 1570, loss = 117527007.79838882\n",
      "Iteration 1571, loss = 117384712.69943103\n",
      "Iteration 1572, loss = 117258198.88098173\n",
      "Iteration 1573, loss = 117112399.89129326\n",
      "Iteration 1574, loss = 117008206.20844503\n",
      "Iteration 1575, loss = 116855587.23783433\n",
      "Iteration 1576, loss = 116729338.89413044\n",
      "Iteration 1577, loss = 116586333.91889714\n",
      "Iteration 1578, loss = 116446273.24002855\n",
      "Iteration 1579, loss = 116309567.37534775\n",
      "Iteration 1580, loss = 116212895.53203890\n",
      "Iteration 1581, loss = 116063010.03441796\n",
      "Iteration 1582, loss = 115920144.60990967\n",
      "Iteration 1583, loss = 115781044.52497543\n",
      "Iteration 1584, loss = 115663642.21918713\n",
      "Iteration 1585, loss = 115544415.60167971\n",
      "Iteration 1586, loss = 115399341.60444918\n",
      "Iteration 1587, loss = 115268435.41637269\n",
      "Iteration 1588, loss = 115161078.63548705\n",
      "Iteration 1589, loss = 115035025.29885721\n",
      "Iteration 1590, loss = 114899712.34618746\n",
      "Iteration 1591, loss = 114782211.33319557\n",
      "Iteration 1592, loss = 114663842.69268233\n",
      "Iteration 1593, loss = 114543711.11106914\n",
      "Iteration 1594, loss = 114398876.97951297\n",
      "Iteration 1595, loss = 114276109.22482236\n",
      "Iteration 1596, loss = 114162322.99733233\n",
      "Iteration 1597, loss = 114034024.94771831\n",
      "Iteration 1598, loss = 113947305.57883815\n",
      "Iteration 1599, loss = 113806187.22030939\n",
      "Iteration 1600, loss = 113676582.17402843\n",
      "Iteration 1601, loss = 113555225.14222345\n",
      "Iteration 1602, loss = 113431493.14789040\n",
      "Iteration 1603, loss = 113356246.58670902\n",
      "Iteration 1604, loss = 113178877.51737061\n",
      "Iteration 1605, loss = 113117076.11858788\n",
      "Iteration 1606, loss = 112976517.41656564\n",
      "Iteration 1607, loss = 112857773.20268922\n",
      "Iteration 1608, loss = 112712028.98015478\n",
      "Iteration 1609, loss = 112627146.02413142\n",
      "Iteration 1610, loss = 112488578.43389361\n",
      "Iteration 1611, loss = 112417999.02973351\n",
      "Iteration 1612, loss = 112317927.94304754\n",
      "Iteration 1613, loss = 112144739.38766451\n",
      "Iteration 1614, loss = 112101980.73653319\n",
      "Iteration 1615, loss = 111952008.44792177\n",
      "Iteration 1616, loss = 111819738.76521938\n",
      "Iteration 1617, loss = 111709506.22007953\n",
      "Iteration 1618, loss = 111585974.75207497\n",
      "Iteration 1619, loss = 111473323.12732404\n",
      "Iteration 1620, loss = 111382414.73602030\n",
      "Iteration 1621, loss = 111252494.37068941\n",
      "Iteration 1622, loss = 111161347.47620158\n",
      "Iteration 1623, loss = 111052455.37990069\n",
      "Iteration 1624, loss = 110912774.12563808\n",
      "Iteration 1625, loss = 110802847.16538580\n",
      "Iteration 1626, loss = 110697992.20170529\n",
      "Iteration 1627, loss = 110608369.13427384\n",
      "Iteration 1628, loss = 110490181.10578807\n",
      "Iteration 1629, loss = 110394300.97933662\n",
      "Iteration 1630, loss = 110260085.19717684\n",
      "Iteration 1631, loss = 110154835.61640686\n",
      "Iteration 1632, loss = 110048738.30062306\n",
      "Iteration 1633, loss = 109939001.69404808\n",
      "Iteration 1634, loss = 109855324.49784887\n",
      "Iteration 1635, loss = 109735740.33301511\n",
      "Iteration 1636, loss = 109633967.12613820\n",
      "Iteration 1637, loss = 109525517.40005881\n",
      "Iteration 1638, loss = 109413954.39127564\n",
      "Iteration 1639, loss = 109327370.67628618\n",
      "Iteration 1640, loss = 109213995.19736999\n",
      "Iteration 1641, loss = 109092476.07678525\n",
      "Iteration 1642, loss = 108987943.41750056\n",
      "Iteration 1643, loss = 108889921.77269840\n",
      "Iteration 1644, loss = 108774555.08004725\n",
      "Iteration 1645, loss = 108700087.93428257\n",
      "Iteration 1646, loss = 108581957.59988593\n",
      "Iteration 1647, loss = 108468105.82726991\n",
      "Iteration 1648, loss = 108381029.37048875\n",
      "Iteration 1649, loss = 108274144.06950858\n",
      "Iteration 1650, loss = 108175691.03920335\n",
      "Iteration 1651, loss = 108051585.87172702\n",
      "Iteration 1652, loss = 107996575.17056237\n",
      "Iteration 1653, loss = 107865830.02958408\n",
      "Iteration 1654, loss = 107773571.05387753\n",
      "Iteration 1655, loss = 107661852.60856858\n",
      "Iteration 1656, loss = 107591887.97648405\n",
      "Iteration 1657, loss = 107480676.28224386\n",
      "Iteration 1658, loss = 107402532.35449813\n",
      "Iteration 1659, loss = 107261526.40101236\n",
      "Iteration 1660, loss = 107199057.51501544\n",
      "Iteration 1661, loss = 107080263.07608767\n",
      "Iteration 1662, loss = 106994585.80670561\n",
      "Iteration 1663, loss = 106897231.51817849\n",
      "Iteration 1664, loss = 106790269.31537278\n",
      "Iteration 1665, loss = 106719370.61919202\n",
      "Iteration 1666, loss = 106626369.96475156\n",
      "Iteration 1667, loss = 106531485.24426271\n",
      "Iteration 1668, loss = 106435596.18873087\n",
      "Iteration 1669, loss = 106353123.51371515\n",
      "Iteration 1670, loss = 106238662.30432186\n",
      "Iteration 1671, loss = 106136709.17773159\n",
      "Iteration 1672, loss = 106051272.30469792\n",
      "Iteration 1673, loss = 105978708.27537230\n",
      "Iteration 1674, loss = 105876315.81252405\n",
      "Iteration 1675, loss = 105805356.93268324\n",
      "Iteration 1676, loss = 105714606.20148829\n",
      "Iteration 1677, loss = 105613340.59139134\n",
      "Iteration 1678, loss = 105517762.40267269\n",
      "Iteration 1679, loss = 105426902.18214215\n",
      "Iteration 1680, loss = 105325396.88595189\n",
      "Iteration 1681, loss = 105243796.10079171\n",
      "Iteration 1682, loss = 105165847.48868667\n",
      "Iteration 1683, loss = 105055988.77876700\n",
      "Iteration 1684, loss = 104970010.57866877\n",
      "Iteration 1685, loss = 104917401.53449787\n",
      "Iteration 1686, loss = 104792372.78978613\n",
      "Iteration 1687, loss = 104724843.31390321\n",
      "Iteration 1688, loss = 104618318.74131393\n",
      "Iteration 1689, loss = 104580261.54613176\n",
      "Iteration 1690, loss = 104444406.85227029\n",
      "Iteration 1691, loss = 104360990.68509911\n",
      "Iteration 1692, loss = 104274703.98772025\n",
      "Iteration 1693, loss = 104184656.46408297\n",
      "Iteration 1694, loss = 104104263.99968825\n",
      "Iteration 1695, loss = 104027292.59247504\n",
      "Iteration 1696, loss = 103948161.64938803\n",
      "Iteration 1697, loss = 103838864.24747886\n",
      "Iteration 1698, loss = 103761975.62874885\n",
      "Iteration 1699, loss = 103672811.36924843\n",
      "Iteration 1700, loss = 103598316.07117392\n",
      "Iteration 1701, loss = 103507187.85214674\n",
      "Iteration 1702, loss = 103408021.84625040\n",
      "Iteration 1703, loss = 103332058.75879265\n",
      "Iteration 1704, loss = 103275411.97656581\n",
      "Iteration 1705, loss = 103168888.50447974\n",
      "Iteration 1706, loss = 103097924.02567233\n",
      "Iteration 1707, loss = 103061247.38965631\n",
      "Iteration 1708, loss = 102924085.95190252\n",
      "Iteration 1709, loss = 102872324.07099223\n",
      "Iteration 1710, loss = 102795587.77737644\n",
      "Iteration 1711, loss = 102706199.68991368\n",
      "Iteration 1712, loss = 102618052.95166242\n",
      "Iteration 1713, loss = 102565738.10027373\n",
      "Iteration 1714, loss = 102483732.73790422\n",
      "Iteration 1715, loss = 102408198.79463175\n",
      "Iteration 1716, loss = 102318334.53513952\n",
      "Iteration 1717, loss = 102262984.56113115\n",
      "Iteration 1718, loss = 102166063.38667640\n",
      "Iteration 1719, loss = 102116104.66533023\n",
      "Iteration 1720, loss = 102019591.91055898\n",
      "Iteration 1721, loss = 101945121.55386651\n",
      "Iteration 1722, loss = 101868239.39269409\n",
      "Iteration 1723, loss = 101795119.23697738\n",
      "Iteration 1724, loss = 101730325.52208152\n",
      "Iteration 1725, loss = 101639050.12483804\n",
      "Iteration 1726, loss = 101560369.72477765\n",
      "Iteration 1727, loss = 101474752.14888477\n",
      "Iteration 1728, loss = 101422181.99989432\n",
      "Iteration 1729, loss = 101355061.52088930\n",
      "Iteration 1730, loss = 101271385.30715851\n",
      "Iteration 1731, loss = 101195228.73267287\n",
      "Iteration 1732, loss = 101123752.19125809\n",
      "Iteration 1733, loss = 101030036.31237829\n",
      "Iteration 1734, loss = 101002685.32767203\n",
      "Iteration 1735, loss = 100904679.23851211\n",
      "Iteration 1736, loss = 100846520.24268578\n",
      "Iteration 1737, loss = 100776100.80419584\n",
      "Iteration 1738, loss = 100681466.51563494\n",
      "Iteration 1739, loss = 100603134.67152739\n",
      "Iteration 1740, loss = 100565154.83811255\n",
      "Iteration 1741, loss = 100489008.54585129\n",
      "Iteration 1742, loss = 100396205.90660818\n",
      "Iteration 1743, loss = 100359997.03646995\n",
      "Iteration 1744, loss = 100276665.42011541\n",
      "Iteration 1745, loss = 100197805.59208880\n",
      "Iteration 1746, loss = 100136735.82345298\n",
      "Iteration 1747, loss = 100077574.75091574\n",
      "Iteration 1748, loss = 100020709.47353959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1749, loss = 99932185.43275736\n",
      "Iteration 1750, loss = 99875139.96328667\n",
      "Iteration 1751, loss = 99795100.77648681\n",
      "Iteration 1752, loss = 99718937.52766690\n",
      "Iteration 1753, loss = 99685291.96272926\n",
      "Iteration 1754, loss = 99600890.39716814\n",
      "Iteration 1755, loss = 99554360.24192542\n",
      "Iteration 1756, loss = 99461183.74538864\n",
      "Iteration 1757, loss = 99398720.75982386\n",
      "Iteration 1758, loss = 99325224.42676367\n",
      "Iteration 1759, loss = 99260971.74953158\n",
      "Iteration 1760, loss = 99180099.53464518\n",
      "Iteration 1761, loss = 99132372.19519536\n",
      "Iteration 1762, loss = 99049143.10225219\n",
      "Iteration 1763, loss = 99003120.89351632\n",
      "Iteration 1764, loss = 98935117.79795583\n",
      "Iteration 1765, loss = 98853335.79197988\n",
      "Iteration 1766, loss = 98791660.54787932\n",
      "Iteration 1767, loss = 98755811.13383608\n",
      "Iteration 1768, loss = 98695049.33021288\n",
      "Iteration 1769, loss = 98607292.91531383\n",
      "Iteration 1770, loss = 98548954.04946516\n",
      "Iteration 1771, loss = 98467090.10522029\n",
      "Iteration 1772, loss = 98416019.83034430\n",
      "Iteration 1773, loss = 98340422.63678753\n",
      "Iteration 1774, loss = 98276395.86240527\n",
      "Iteration 1775, loss = 98219461.60035536\n",
      "Iteration 1776, loss = 98171335.82044306\n",
      "Iteration 1777, loss = 98099936.05833453\n",
      "Iteration 1778, loss = 98038284.39312169\n",
      "Iteration 1779, loss = 97986675.11451648\n",
      "Iteration 1780, loss = 97915264.90800852\n",
      "Iteration 1781, loss = 97868388.82000294\n",
      "Iteration 1782, loss = 97806846.74832839\n",
      "Iteration 1783, loss = 97741263.14885731\n",
      "Iteration 1784, loss = 97679187.44358017\n",
      "Iteration 1785, loss = 97610640.81740680\n",
      "Iteration 1786, loss = 97570380.34479378\n",
      "Iteration 1787, loss = 97476738.80899090\n",
      "Iteration 1788, loss = 97445168.24369924\n",
      "Iteration 1789, loss = 97372897.95810166\n",
      "Iteration 1790, loss = 97311659.35833189\n",
      "Iteration 1791, loss = 97260018.98007765\n",
      "Iteration 1792, loss = 97222336.43776794\n",
      "Iteration 1793, loss = 97130835.62186721\n",
      "Iteration 1794, loss = 97071654.63208075\n",
      "Iteration 1795, loss = 97004704.84710574\n",
      "Iteration 1796, loss = 96952485.63459335\n",
      "Iteration 1797, loss = 96916729.00116678\n",
      "Iteration 1798, loss = 96837666.62661117\n",
      "Iteration 1799, loss = 96773044.18817735\n",
      "Iteration 1800, loss = 96727556.99248745\n",
      "Iteration 1801, loss = 96650051.28369558\n",
      "Iteration 1802, loss = 96640393.14822419\n",
      "Iteration 1803, loss = 96550801.23549363\n",
      "Iteration 1804, loss = 96522997.83061478\n",
      "Iteration 1805, loss = 96444138.26728755\n",
      "Iteration 1806, loss = 96397115.72709092\n",
      "Iteration 1807, loss = 96323797.18470687\n",
      "Iteration 1808, loss = 96270999.54441260\n",
      "Iteration 1809, loss = 96238953.06245126\n",
      "Iteration 1810, loss = 96171044.97527236\n",
      "Iteration 1811, loss = 96101340.32087138\n",
      "Iteration 1812, loss = 96052457.17435767\n",
      "Iteration 1813, loss = 95989674.43875991\n",
      "Iteration 1814, loss = 95943132.79553360\n",
      "Iteration 1815, loss = 95890612.82705045\n",
      "Iteration 1816, loss = 95820851.26299930\n",
      "Iteration 1817, loss = 95804240.47384468\n",
      "Iteration 1818, loss = 95709915.21018876\n",
      "Iteration 1819, loss = 95658210.34930937\n",
      "Iteration 1820, loss = 95619973.98477903\n",
      "Iteration 1821, loss = 95554900.40752098\n",
      "Iteration 1822, loss = 95505191.53329349\n",
      "Iteration 1823, loss = 95464446.07568280\n",
      "Iteration 1824, loss = 95404433.39870788\n",
      "Iteration 1825, loss = 95335981.27481192\n",
      "Iteration 1826, loss = 95290807.21202521\n",
      "Iteration 1827, loss = 95250009.91374549\n",
      "Iteration 1828, loss = 95175634.13318338\n",
      "Iteration 1829, loss = 95130668.51922530\n",
      "Iteration 1830, loss = 95068243.83870515\n",
      "Iteration 1831, loss = 95026649.83523390\n",
      "Iteration 1832, loss = 94992152.26579563\n",
      "Iteration 1833, loss = 94911102.46712041\n",
      "Iteration 1834, loss = 94849557.05190533\n",
      "Iteration 1835, loss = 94797318.60501236\n",
      "Iteration 1836, loss = 94761551.30392812\n",
      "Iteration 1837, loss = 94697799.70186955\n",
      "Iteration 1838, loss = 94699107.99517757\n",
      "Iteration 1839, loss = 94600847.64270437\n",
      "Iteration 1840, loss = 94563990.82441740\n",
      "Iteration 1841, loss = 94498731.54896718\n",
      "Iteration 1842, loss = 94445361.91125132\n",
      "Iteration 1843, loss = 94409388.18819062\n",
      "Iteration 1844, loss = 94342425.21832074\n",
      "Iteration 1845, loss = 94295119.21970227\n",
      "Iteration 1846, loss = 94240733.84425505\n",
      "Iteration 1847, loss = 94185725.82107219\n",
      "Iteration 1848, loss = 94164660.72841749\n",
      "Iteration 1849, loss = 94109411.98506834\n",
      "Iteration 1850, loss = 94042038.57177685\n",
      "Iteration 1851, loss = 94003979.05898078\n",
      "Iteration 1852, loss = 93948507.08427265\n",
      "Iteration 1853, loss = 93906990.33571646\n",
      "Iteration 1854, loss = 93885996.69600457\n",
      "Iteration 1855, loss = 93794949.63955349\n",
      "Iteration 1856, loss = 93774698.87296030\n",
      "Iteration 1857, loss = 93713800.26613654\n",
      "Iteration 1858, loss = 93645600.70369376\n",
      "Iteration 1859, loss = 93629851.39606264\n",
      "Iteration 1860, loss = 93554457.38377436\n",
      "Iteration 1861, loss = 93509024.54024439\n",
      "Iteration 1862, loss = 93477936.95534182\n",
      "Iteration 1863, loss = 93449862.72429959\n",
      "Iteration 1864, loss = 93372436.86084792\n",
      "Iteration 1865, loss = 93362167.91981135\n",
      "Iteration 1866, loss = 93300758.87320976\n",
      "Iteration 1867, loss = 93252061.19305630\n",
      "Iteration 1868, loss = 93173720.52261616\n",
      "Iteration 1869, loss = 93150741.66304980\n",
      "Iteration 1870, loss = 93097977.15517172\n",
      "Iteration 1871, loss = 93029894.58580576\n",
      "Iteration 1872, loss = 93033500.55154262\n",
      "Iteration 1873, loss = 92946651.17057344\n",
      "Iteration 1874, loss = 92906119.47416411\n",
      "Iteration 1875, loss = 92884825.62568988\n",
      "Iteration 1876, loss = 92827171.15133379\n",
      "Iteration 1877, loss = 92795457.21912481\n",
      "Iteration 1878, loss = 92748800.67579623\n",
      "Iteration 1879, loss = 92695633.09131241\n",
      "Iteration 1880, loss = 92711563.84834552\n",
      "Iteration 1881, loss = 92623802.11250885\n",
      "Iteration 1882, loss = 92571499.19882226\n",
      "Iteration 1883, loss = 92535776.55988590\n",
      "Iteration 1884, loss = 92504408.16192141\n",
      "Iteration 1885, loss = 92430403.54139209\n",
      "Iteration 1886, loss = 92395527.59964539\n",
      "Iteration 1887, loss = 92424584.17797813\n",
      "Iteration 1888, loss = 92297239.52217887\n",
      "Iteration 1889, loss = 92269843.81933677\n",
      "Iteration 1890, loss = 92217903.64720726\n",
      "Iteration 1891, loss = 92234814.33144851\n",
      "Iteration 1892, loss = 92154593.39536507\n",
      "Iteration 1893, loss = 92094029.76164231\n",
      "Iteration 1894, loss = 92057287.56313080\n",
      "Iteration 1895, loss = 92065949.79538462\n",
      "Iteration 1896, loss = 91991679.48858303\n",
      "Iteration 1897, loss = 91956384.79741074\n",
      "Iteration 1898, loss = 91908898.91383840\n",
      "Iteration 1899, loss = 91897077.66002774\n",
      "Iteration 1900, loss = 91843924.21764471\n",
      "Iteration 1901, loss = 91782694.79544523\n",
      "Iteration 1902, loss = 91739833.34466459\n",
      "Iteration 1903, loss = 91716382.44990547\n",
      "Iteration 1904, loss = 91663294.70880587\n",
      "Iteration 1905, loss = 91609515.00183287\n",
      "Iteration 1906, loss = 91606457.33595391\n",
      "Iteration 1907, loss = 91539298.97810224\n",
      "Iteration 1908, loss = 91515122.18025443\n",
      "Iteration 1909, loss = 91465545.18020613\n",
      "Iteration 1910, loss = 91425010.51226878\n",
      "Iteration 1911, loss = 91391575.88531896\n",
      "Iteration 1912, loss = 91352964.11764255\n",
      "Iteration 1913, loss = 91317516.94376694\n",
      "Iteration 1914, loss = 91275038.25658549\n",
      "Iteration 1915, loss = 91246260.30101663\n",
      "Iteration 1916, loss = 91215116.89921947\n",
      "Iteration 1917, loss = 91333136.44837654\n",
      "Iteration 1918, loss = 91104758.84563437\n",
      "Iteration 1919, loss = 91090532.87444884\n",
      "Iteration 1920, loss = 91066715.52704287\n",
      "Iteration 1921, loss = 91008415.21257773\n",
      "Iteration 1922, loss = 90976372.72076288\n",
      "Iteration 1923, loss = 90940464.52200995\n",
      "Iteration 1924, loss = 90916178.96319377\n",
      "Iteration 1925, loss = 90884899.73528108\n",
      "Iteration 1926, loss = 90861983.10654917\n",
      "Iteration 1927, loss = 90814446.18173207\n",
      "Iteration 1928, loss = 90771516.63272728\n",
      "Iteration 1929, loss = 90756576.53417338\n",
      "Iteration 1930, loss = 90686690.46936882\n",
      "Iteration 1931, loss = 90652405.47063115\n",
      "Iteration 1932, loss = 90610601.58473456\n",
      "Iteration 1933, loss = 90573661.18798518\n",
      "Iteration 1934, loss = 90550185.16906835\n",
      "Iteration 1935, loss = 90523601.43584311\n",
      "Iteration 1936, loss = 90497190.33811665\n",
      "Iteration 1937, loss = 90450578.58389069\n",
      "Iteration 1938, loss = 90410230.50084265\n",
      "Iteration 1939, loss = 90357753.50329353\n",
      "Iteration 1940, loss = 90328335.76990342\n",
      "Iteration 1941, loss = 90307967.79369844\n",
      "Iteration 1942, loss = 90247549.94134767\n",
      "Iteration 1943, loss = 90240954.29124577\n",
      "Iteration 1944, loss = 90194645.78340137\n",
      "Iteration 1945, loss = 90139530.04120117\n",
      "Iteration 1946, loss = 90125208.36975046\n",
      "Iteration 1947, loss = 90101030.70854007\n",
      "Iteration 1948, loss = 90058312.81361346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1949, loss = 90001721.91263303\n",
      "Iteration 1950, loss = 89954621.18368225\n",
      "Iteration 1951, loss = 89931881.90448259\n",
      "Iteration 1952, loss = 89906992.72718063\n",
      "Iteration 1953, loss = 89852338.17267892\n",
      "Iteration 1954, loss = 89823175.90916343\n",
      "Iteration 1955, loss = 89817142.57164735\n",
      "Iteration 1956, loss = 89759439.39703360\n",
      "Iteration 1957, loss = 89736865.96471362\n",
      "Iteration 1958, loss = 89695243.40561748\n",
      "Iteration 1959, loss = 89642801.80206154\n",
      "Iteration 1960, loss = 89610661.70454414\n",
      "Iteration 1961, loss = 89585666.19129658\n",
      "Iteration 1962, loss = 89557197.00042188\n",
      "Iteration 1963, loss = 89493720.63648827\n",
      "Iteration 1964, loss = 89492071.20268038\n",
      "Iteration 1965, loss = 89442545.18886112\n",
      "Iteration 1966, loss = 89414816.70546964\n",
      "Iteration 1967, loss = 89367261.86670929\n",
      "Iteration 1968, loss = 89351780.26152286\n",
      "Iteration 1969, loss = 89314557.80701920\n",
      "Iteration 1970, loss = 89278336.20268409\n",
      "Iteration 1971, loss = 89235210.99317405\n",
      "Iteration 1972, loss = 89202746.00918399\n",
      "Iteration 1973, loss = 89170486.88497214\n",
      "Iteration 1974, loss = 89138818.77477673\n",
      "Iteration 1975, loss = 89109630.85163905\n",
      "Iteration 1976, loss = 89112553.60724021\n",
      "Iteration 1977, loss = 89041749.86203080\n",
      "Iteration 1978, loss = 88999659.77800587\n",
      "Iteration 1979, loss = 88988427.00556514\n",
      "Iteration 1980, loss = 88924414.95297009\n",
      "Iteration 1981, loss = 88925289.82409044\n",
      "Iteration 1982, loss = 88867976.66078429\n",
      "Iteration 1983, loss = 88846753.93412790\n",
      "Iteration 1984, loss = 88796628.00203936\n",
      "Iteration 1985, loss = 88786306.34805405\n",
      "Iteration 1986, loss = 88727210.83328052\n",
      "Iteration 1987, loss = 88715702.55132094\n",
      "Iteration 1988, loss = 88671834.54960315\n",
      "Iteration 1989, loss = 88657478.11943224\n",
      "Iteration 1990, loss = 88597324.30016810\n",
      "Iteration 1991, loss = 88556473.58968909\n",
      "Iteration 1992, loss = 88508487.92436157\n",
      "Iteration 1993, loss = 88522278.04907252\n",
      "Iteration 1994, loss = 88470551.26062825\n",
      "Iteration 1995, loss = 88445323.06667010\n",
      "Iteration 1996, loss = 88392568.07401218\n",
      "Iteration 1997, loss = 88375139.71473528\n",
      "Iteration 1998, loss = 88355088.94129519\n",
      "Iteration 1999, loss = 88296935.46879606\n",
      "Iteration 2000, loss = 88257837.63674562\n",
      "Iteration 1, loss = 2772572404.03217077\n",
      "Iteration 2, loss = 2769659579.23070574\n",
      "Iteration 3, loss = 2764273593.08699989\n",
      "Iteration 4, loss = 2754715107.39237022\n",
      "Iteration 5, loss = 2742623544.27444601\n",
      "Iteration 6, loss = 2728160801.05303860\n",
      "Iteration 7, loss = 2711386228.52060556\n",
      "Iteration 8, loss = 2692445570.35096979\n",
      "Iteration 9, loss = 2671557484.30509996\n",
      "Iteration 10, loss = 2648695262.22696447\n",
      "Iteration 11, loss = 2624116610.84046078\n",
      "Iteration 12, loss = 2597871266.21366072\n",
      "Iteration 13, loss = 2570048884.64182949\n",
      "Iteration 14, loss = 2540734923.78128672\n",
      "Iteration 15, loss = 2510272373.30582428\n",
      "Iteration 16, loss = 2478539900.62914324\n",
      "Iteration 17, loss = 2445724652.98177481\n",
      "Iteration 18, loss = 2411866485.53550959\n",
      "Iteration 19, loss = 2377168287.72302437\n",
      "Iteration 20, loss = 2341719219.72498369\n",
      "Iteration 21, loss = 2305475411.02490616\n",
      "Iteration 22, loss = 2268662466.62501097\n",
      "Iteration 23, loss = 2231212902.01240873\n",
      "Iteration 24, loss = 2193377691.64667273\n",
      "Iteration 25, loss = 2155103026.27688789\n",
      "Iteration 26, loss = 2116372644.33126378\n",
      "Iteration 27, loss = 2077640729.77711463\n",
      "Iteration 28, loss = 2038753780.58295417\n",
      "Iteration 29, loss = 1999344159.28242469\n",
      "Iteration 30, loss = 1959964300.90029120\n",
      "Iteration 31, loss = 1921178861.13620448\n",
      "Iteration 32, loss = 1882500781.15890574\n",
      "Iteration 33, loss = 1843731402.83634472\n",
      "Iteration 34, loss = 1805289434.31117868\n",
      "Iteration 35, loss = 1767232577.37084293\n",
      "Iteration 36, loss = 1729466018.24825740\n",
      "Iteration 37, loss = 1691807168.07168579\n",
      "Iteration 38, loss = 1654810021.07476711\n",
      "Iteration 39, loss = 1618269706.37192798\n",
      "Iteration 40, loss = 1581977253.39913750\n",
      "Iteration 41, loss = 1546781967.80463719\n",
      "Iteration 42, loss = 1511893977.12135625\n",
      "Iteration 43, loss = 1477922835.67042017\n",
      "Iteration 44, loss = 1444741952.76903534\n",
      "Iteration 45, loss = 1412221449.46020031\n",
      "Iteration 46, loss = 1380583435.27452040\n",
      "Iteration 47, loss = 1349515603.03135657\n",
      "Iteration 48, loss = 1319549271.57953978\n",
      "Iteration 49, loss = 1290642523.77378964\n",
      "Iteration 50, loss = 1262646657.41678452\n",
      "Iteration 51, loss = 1235478954.36139011\n",
      "Iteration 52, loss = 1209228488.64403272\n",
      "Iteration 53, loss = 1184119963.65709162\n",
      "Iteration 54, loss = 1160017245.32931089\n",
      "Iteration 55, loss = 1137020474.46831894\n",
      "Iteration 56, loss = 1115197539.96272087\n",
      "Iteration 57, loss = 1094515825.64934754\n",
      "Iteration 58, loss = 1074963388.32181549\n",
      "Iteration 59, loss = 1056347652.41521537\n",
      "Iteration 60, loss = 1038957816.89286804\n",
      "Iteration 61, loss = 1022593072.91181791\n",
      "Iteration 62, loss = 1007459322.29575109\n",
      "Iteration 63, loss = 993135930.92356050\n",
      "Iteration 64, loss = 980028937.43506753\n",
      "Iteration 65, loss = 967977336.99059975\n",
      "Iteration 66, loss = 956893284.77899837\n",
      "Iteration 67, loss = 946707275.58306479\n",
      "Iteration 68, loss = 937656204.35543680\n",
      "Iteration 69, loss = 929500566.33376777\n",
      "Iteration 70, loss = 922185559.30570567\n",
      "Iteration 71, loss = 915775882.30905807\n",
      "Iteration 72, loss = 909981259.38555586\n",
      "Iteration 73, loss = 904892947.06065619\n",
      "Iteration 74, loss = 900667496.49341547\n",
      "Iteration 75, loss = 896753469.69530272\n",
      "Iteration 76, loss = 893540186.58802247\n",
      "Iteration 77, loss = 890806052.20085633\n",
      "Iteration 78, loss = 888501493.19270396\n",
      "Iteration 79, loss = 886569418.22227514\n",
      "Iteration 80, loss = 884916945.65758693\n",
      "Iteration 81, loss = 883577048.87421572\n",
      "Iteration 82, loss = 882408233.95042586\n",
      "Iteration 83, loss = 881487674.78581524\n",
      "Iteration 84, loss = 880695723.64684153\n",
      "Iteration 85, loss = 880025207.25674987\n",
      "Iteration 86, loss = 879405160.66948450\n",
      "Iteration 87, loss = 878912855.16678321\n",
      "Iteration 88, loss = 878482745.14968133\n",
      "Iteration 89, loss = 878078395.83074629\n",
      "Iteration 90, loss = 877705613.70731831\n",
      "Iteration 91, loss = 877351607.13450444\n",
      "Iteration 92, loss = 876957400.84950292\n",
      "Iteration 93, loss = 876574627.77907598\n",
      "Iteration 94, loss = 876244672.36869633\n",
      "Iteration 95, loss = 875878885.51683331\n",
      "Iteration 96, loss = 875532902.30936444\n",
      "Iteration 97, loss = 875163157.46559417\n",
      "Iteration 98, loss = 874811225.35775566\n",
      "Iteration 99, loss = 874460318.73763657\n",
      "Iteration 100, loss = 874106685.81460071\n",
      "Iteration 101, loss = 873734014.82721329\n",
      "Iteration 102, loss = 873359253.82855010\n",
      "Iteration 103, loss = 873012500.40876603\n",
      "Iteration 104, loss = 872644436.56966794\n",
      "Iteration 105, loss = 872277898.54651356\n",
      "Iteration 106, loss = 871870445.43691409\n",
      "Iteration 107, loss = 871507799.68450975\n",
      "Iteration 108, loss = 871130498.97951424\n",
      "Iteration 109, loss = 870764047.94963562\n",
      "Iteration 110, loss = 870372473.85272586\n",
      "Iteration 111, loss = 869988937.31871653\n",
      "Iteration 112, loss = 869623683.20320678\n",
      "Iteration 113, loss = 869242187.01213562\n",
      "Iteration 114, loss = 868825273.54884160\n",
      "Iteration 115, loss = 868481755.56914675\n",
      "Iteration 116, loss = 868071086.57938647\n",
      "Iteration 117, loss = 867685699.04384768\n",
      "Iteration 118, loss = 867283724.98142993\n",
      "Iteration 119, loss = 866901715.84872723\n",
      "Iteration 120, loss = 866509085.61418784\n",
      "Iteration 121, loss = 866114935.67986143\n",
      "Iteration 122, loss = 865734943.56035423\n",
      "Iteration 123, loss = 865347678.60242271\n",
      "Iteration 124, loss = 864975686.59436715\n",
      "Iteration 125, loss = 864575094.36962736\n",
      "Iteration 126, loss = 864203764.23576128\n",
      "Iteration 127, loss = 863800084.01521444\n",
      "Iteration 128, loss = 863449904.93994451\n",
      "Iteration 129, loss = 863027409.88365233\n",
      "Iteration 130, loss = 862645872.16152227\n",
      "Iteration 131, loss = 862249553.40910518\n",
      "Iteration 132, loss = 861849696.05368292\n",
      "Iteration 133, loss = 861456344.83774698\n",
      "Iteration 134, loss = 861073409.50977457\n",
      "Iteration 135, loss = 860677541.22900367\n",
      "Iteration 136, loss = 860285913.49987221\n",
      "Iteration 137, loss = 859896728.02431071\n",
      "Iteration 138, loss = 859517881.08622944\n",
      "Iteration 139, loss = 859128209.30541623\n",
      "Iteration 140, loss = 858737740.53813910\n",
      "Iteration 141, loss = 858339438.48195350\n",
      "Iteration 142, loss = 857950235.76569772\n",
      "Iteration 143, loss = 857556953.15829873\n",
      "Iteration 144, loss = 857154673.29631400\n",
      "Iteration 145, loss = 856767500.04560041\n",
      "Iteration 146, loss = 856388014.74956059\n",
      "Iteration 147, loss = 855990741.10292649\n",
      "Iteration 148, loss = 855605089.20862019\n",
      "Iteration 149, loss = 855221764.59579229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 150, loss = 854842518.27240002\n",
      "Iteration 151, loss = 854429739.14703941\n",
      "Iteration 152, loss = 854033932.66151059\n",
      "Iteration 153, loss = 853649931.59022093\n",
      "Iteration 154, loss = 853251632.43590045\n",
      "Iteration 155, loss = 852869987.32037282\n",
      "Iteration 156, loss = 852481601.90165126\n",
      "Iteration 157, loss = 852084571.60670412\n",
      "Iteration 158, loss = 851700926.62111497\n",
      "Iteration 159, loss = 851315005.73827446\n",
      "Iteration 160, loss = 850899889.01817954\n",
      "Iteration 161, loss = 850502128.38841927\n",
      "Iteration 162, loss = 850115074.66272295\n",
      "Iteration 163, loss = 849712697.89579225\n",
      "Iteration 164, loss = 849326400.00703120\n",
      "Iteration 165, loss = 848934565.52901566\n",
      "Iteration 166, loss = 848525163.23449206\n",
      "Iteration 167, loss = 848142305.36298776\n",
      "Iteration 168, loss = 847742612.84173548\n",
      "Iteration 169, loss = 847331540.76018786\n",
      "Iteration 170, loss = 846932949.59411430\n",
      "Iteration 171, loss = 846537637.68116820\n",
      "Iteration 172, loss = 846129103.73206139\n",
      "Iteration 173, loss = 845759375.84755111\n",
      "Iteration 174, loss = 845366940.12422597\n",
      "Iteration 175, loss = 844958469.73538029\n",
      "Iteration 176, loss = 844567134.50769675\n",
      "Iteration 177, loss = 844163633.45617461\n",
      "Iteration 178, loss = 843765362.40971673\n",
      "Iteration 179, loss = 843379173.78818929\n",
      "Iteration 180, loss = 842994081.55110800\n",
      "Iteration 181, loss = 842579753.50809658\n",
      "Iteration 182, loss = 842199442.29079807\n",
      "Iteration 183, loss = 841799195.85091329\n",
      "Iteration 184, loss = 841387144.19698930\n",
      "Iteration 185, loss = 841001168.54318523\n",
      "Iteration 186, loss = 840591350.73901391\n",
      "Iteration 187, loss = 840189551.87476766\n",
      "Iteration 188, loss = 839804376.71341288\n",
      "Iteration 189, loss = 839396323.56004643\n",
      "Iteration 190, loss = 838991143.00642610\n",
      "Iteration 191, loss = 838579228.49476552\n",
      "Iteration 192, loss = 838180585.68109000\n",
      "Iteration 193, loss = 837768595.64090300\n",
      "Iteration 194, loss = 837370325.02582812\n",
      "Iteration 195, loss = 836978981.22354698\n",
      "Iteration 196, loss = 836578621.60476589\n",
      "Iteration 197, loss = 836157056.61782873\n",
      "Iteration 198, loss = 835759701.98139572\n",
      "Iteration 199, loss = 835371674.97988355\n",
      "Iteration 200, loss = 834967699.13413215\n",
      "Iteration 201, loss = 834555348.60123801\n",
      "Iteration 202, loss = 834162079.37888408\n",
      "Iteration 203, loss = 833772528.90733349\n",
      "Iteration 204, loss = 833344025.20024872\n",
      "Iteration 205, loss = 832946444.08901691\n",
      "Iteration 206, loss = 832570280.28409016\n",
      "Iteration 207, loss = 832151522.99319923\n",
      "Iteration 208, loss = 831731081.49875069\n",
      "Iteration 209, loss = 831313062.37189889\n",
      "Iteration 210, loss = 830911180.87903988\n",
      "Iteration 211, loss = 830502128.75503707\n",
      "Iteration 212, loss = 830105144.74681354\n",
      "Iteration 213, loss = 829692752.84158516\n",
      "Iteration 214, loss = 829299852.08733785\n",
      "Iteration 215, loss = 828915560.40760207\n",
      "Iteration 216, loss = 828537462.23557448\n",
      "Iteration 217, loss = 828151651.81589806\n",
      "Iteration 218, loss = 827741469.85920262\n",
      "Iteration 219, loss = 827316556.71699095\n",
      "Iteration 220, loss = 826926445.11928415\n",
      "Iteration 221, loss = 826529087.50275803\n",
      "Iteration 222, loss = 826134841.55902159\n",
      "Iteration 223, loss = 825705696.32719290\n",
      "Iteration 224, loss = 825302569.08172297\n",
      "Iteration 225, loss = 824914518.83254731\n",
      "Iteration 226, loss = 824504826.64798021\n",
      "Iteration 227, loss = 824114129.78047526\n",
      "Iteration 228, loss = 823687001.22654414\n",
      "Iteration 229, loss = 823283319.86256218\n",
      "Iteration 230, loss = 822874863.41669977\n",
      "Iteration 231, loss = 822466629.75209963\n",
      "Iteration 232, loss = 822064077.08385336\n",
      "Iteration 233, loss = 821652289.54479194\n",
      "Iteration 234, loss = 821241506.16099226\n",
      "Iteration 235, loss = 820851852.31394482\n",
      "Iteration 236, loss = 820438395.80460823\n",
      "Iteration 237, loss = 820046071.26612246\n",
      "Iteration 238, loss = 819630147.74583220\n",
      "Iteration 239, loss = 819212029.01639390\n",
      "Iteration 240, loss = 818794766.87013257\n",
      "Iteration 241, loss = 818370317.80135167\n",
      "Iteration 242, loss = 817964516.52974534\n",
      "Iteration 243, loss = 817574092.36766922\n",
      "Iteration 244, loss = 817127666.51996469\n",
      "Iteration 245, loss = 816711258.38283360\n",
      "Iteration 246, loss = 816291828.59102929\n",
      "Iteration 247, loss = 815862243.19320917\n",
      "Iteration 248, loss = 815450256.90304077\n",
      "Iteration 249, loss = 815032643.58050454\n",
      "Iteration 250, loss = 814590877.67301285\n",
      "Iteration 251, loss = 814184846.91485119\n",
      "Iteration 252, loss = 813767674.77113366\n",
      "Iteration 253, loss = 813328973.47575831\n",
      "Iteration 254, loss = 812940213.50686288\n",
      "Iteration 255, loss = 812509354.99282098\n",
      "Iteration 256, loss = 812057226.75125396\n",
      "Iteration 257, loss = 811619319.59601951\n",
      "Iteration 258, loss = 811193312.76031268\n",
      "Iteration 259, loss = 810773641.52748334\n",
      "Iteration 260, loss = 810331170.02971077\n",
      "Iteration 261, loss = 809912972.73649418\n",
      "Iteration 262, loss = 809463852.57287967\n",
      "Iteration 263, loss = 809047515.60472190\n",
      "Iteration 264, loss = 808587172.02895224\n",
      "Iteration 265, loss = 808150654.78804386\n",
      "Iteration 266, loss = 807717680.21867979\n",
      "Iteration 267, loss = 807273753.42730236\n",
      "Iteration 268, loss = 806843794.09795761\n",
      "Iteration 269, loss = 806400524.24605680\n",
      "Iteration 270, loss = 805973732.52203465\n",
      "Iteration 271, loss = 805525963.84976375\n",
      "Iteration 272, loss = 805073963.04193246\n",
      "Iteration 273, loss = 804644604.60090685\n",
      "Iteration 274, loss = 804181829.73920774\n",
      "Iteration 275, loss = 803734745.33487642\n",
      "Iteration 276, loss = 803296873.29577494\n",
      "Iteration 277, loss = 802862803.87179279\n",
      "Iteration 278, loss = 802402884.56038892\n",
      "Iteration 279, loss = 801954583.30534697\n",
      "Iteration 280, loss = 801500278.12783837\n",
      "Iteration 281, loss = 801045787.58874989\n",
      "Iteration 282, loss = 800605292.23251784\n",
      "Iteration 283, loss = 800163260.59975028\n",
      "Iteration 284, loss = 799702357.46198404\n",
      "Iteration 285, loss = 799269742.16809368\n",
      "Iteration 286, loss = 798838887.44289792\n",
      "Iteration 287, loss = 798370796.92893004\n",
      "Iteration 288, loss = 797940044.81900346\n",
      "Iteration 289, loss = 797480071.89585114\n",
      "Iteration 290, loss = 797032680.31076145\n",
      "Iteration 291, loss = 796602893.04877925\n",
      "Iteration 292, loss = 796144225.23854578\n",
      "Iteration 293, loss = 795710738.93339598\n",
      "Iteration 294, loss = 795281566.17366159\n",
      "Iteration 295, loss = 794833490.30795479\n",
      "Iteration 296, loss = 794381419.24623942\n",
      "Iteration 297, loss = 793959614.15060174\n",
      "Iteration 298, loss = 793511068.59411943\n",
      "Iteration 299, loss = 793048176.51062095\n",
      "Iteration 300, loss = 792583333.07945704\n",
      "Iteration 301, loss = 792163107.44809735\n",
      "Iteration 302, loss = 791678954.72872150\n",
      "Iteration 303, loss = 791214893.04863846\n",
      "Iteration 304, loss = 790760269.24206042\n",
      "Iteration 305, loss = 790301704.25812757\n",
      "Iteration 306, loss = 789831775.83278763\n",
      "Iteration 307, loss = 789353177.97151673\n",
      "Iteration 308, loss = 788897221.35417664\n",
      "Iteration 309, loss = 788431090.72747803\n",
      "Iteration 310, loss = 787967733.59415674\n",
      "Iteration 311, loss = 787488155.25967908\n",
      "Iteration 312, loss = 787007683.34190416\n",
      "Iteration 313, loss = 786542342.56391907\n",
      "Iteration 314, loss = 786084633.05861688\n",
      "Iteration 315, loss = 785616287.99705219\n",
      "Iteration 316, loss = 785134950.28186345\n",
      "Iteration 317, loss = 784631810.04733372\n",
      "Iteration 318, loss = 784155070.84635592\n",
      "Iteration 319, loss = 783714337.99167538\n",
      "Iteration 320, loss = 783189062.51853228\n",
      "Iteration 321, loss = 782688109.15621424\n",
      "Iteration 322, loss = 782208154.40283239\n",
      "Iteration 323, loss = 781722056.58578765\n",
      "Iteration 324, loss = 781234658.23282945\n",
      "Iteration 325, loss = 780760684.09899712\n",
      "Iteration 326, loss = 780254845.19710994\n",
      "Iteration 327, loss = 779768065.39595103\n",
      "Iteration 328, loss = 779284898.29542124\n",
      "Iteration 329, loss = 778811001.73921800\n",
      "Iteration 330, loss = 778285921.31135321\n",
      "Iteration 331, loss = 777816579.12089252\n",
      "Iteration 332, loss = 777308549.81570196\n",
      "Iteration 333, loss = 776800599.39796698\n",
      "Iteration 334, loss = 776299639.82442904\n",
      "Iteration 335, loss = 775793195.83496308\n",
      "Iteration 336, loss = 775310216.89824378\n",
      "Iteration 337, loss = 774789298.83859289\n",
      "Iteration 338, loss = 774282825.69041288\n",
      "Iteration 339, loss = 773777172.86091435\n",
      "Iteration 340, loss = 773272711.83454525\n",
      "Iteration 341, loss = 772782822.39915049\n",
      "Iteration 342, loss = 772266558.18965924\n",
      "Iteration 343, loss = 771742225.71732354\n",
      "Iteration 344, loss = 771248690.18340647\n",
      "Iteration 345, loss = 770720210.42632794\n",
      "Iteration 346, loss = 770206012.24033785\n",
      "Iteration 347, loss = 769696112.33576012\n",
      "Iteration 348, loss = 769178889.97002804\n",
      "Iteration 349, loss = 768679505.93238342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 350, loss = 768143819.02819204\n",
      "Iteration 351, loss = 767662568.78852069\n",
      "Iteration 352, loss = 767125635.36647725\n",
      "Iteration 353, loss = 766604499.38274443\n",
      "Iteration 354, loss = 766093092.81252337\n",
      "Iteration 355, loss = 765552967.40137780\n",
      "Iteration 356, loss = 765026972.59763241\n",
      "Iteration 357, loss = 764498779.42515266\n",
      "Iteration 358, loss = 764005592.24615514\n",
      "Iteration 359, loss = 763485689.62925041\n",
      "Iteration 360, loss = 762948880.47731614\n",
      "Iteration 361, loss = 762411837.13976097\n",
      "Iteration 362, loss = 761872760.13152289\n",
      "Iteration 363, loss = 761358603.10693812\n",
      "Iteration 364, loss = 760820883.45517874\n",
      "Iteration 365, loss = 760293497.76919258\n",
      "Iteration 366, loss = 759759375.08746302\n",
      "Iteration 367, loss = 759234633.76100099\n",
      "Iteration 368, loss = 758700208.66385329\n",
      "Iteration 369, loss = 758170419.56352282\n",
      "Iteration 370, loss = 757628372.91980183\n",
      "Iteration 371, loss = 757101473.90595484\n",
      "Iteration 372, loss = 756562657.66850793\n",
      "Iteration 373, loss = 756053254.52071941\n",
      "Iteration 374, loss = 755497291.02950084\n",
      "Iteration 375, loss = 754952301.20803738\n",
      "Iteration 376, loss = 754419293.11479723\n",
      "Iteration 377, loss = 753858560.94508421\n",
      "Iteration 378, loss = 753302109.82933044\n",
      "Iteration 379, loss = 752757945.17505610\n",
      "Iteration 380, loss = 752196590.38576388\n",
      "Iteration 381, loss = 751632991.79594469\n",
      "Iteration 382, loss = 751088876.17584133\n",
      "Iteration 383, loss = 750511181.53136921\n",
      "Iteration 384, loss = 749968869.31757903\n",
      "Iteration 385, loss = 749383932.07743752\n",
      "Iteration 386, loss = 748834066.95580173\n",
      "Iteration 387, loss = 748279474.78768790\n",
      "Iteration 388, loss = 747714791.69183195\n",
      "Iteration 389, loss = 747141173.32201934\n",
      "Iteration 390, loss = 746599906.31069100\n",
      "Iteration 391, loss = 746018210.48963904\n",
      "Iteration 392, loss = 745440436.26014793\n",
      "Iteration 393, loss = 744890480.85694444\n",
      "Iteration 394, loss = 744296221.01321554\n",
      "Iteration 395, loss = 743728110.38763964\n",
      "Iteration 396, loss = 743138313.69804835\n",
      "Iteration 397, loss = 742559258.03006089\n",
      "Iteration 398, loss = 741990408.94062817\n",
      "Iteration 399, loss = 741423112.69479990\n",
      "Iteration 400, loss = 740840488.51137936\n",
      "Iteration 401, loss = 740253363.51293564\n",
      "Iteration 402, loss = 739687386.44087160\n",
      "Iteration 403, loss = 739117654.76259971\n",
      "Iteration 404, loss = 738535489.48009431\n",
      "Iteration 405, loss = 737931007.83630335\n",
      "Iteration 406, loss = 737359046.64909768\n",
      "Iteration 407, loss = 736774147.01025856\n",
      "Iteration 408, loss = 736210125.82304215\n",
      "Iteration 409, loss = 735633315.78608263\n",
      "Iteration 410, loss = 735031830.36963356\n",
      "Iteration 411, loss = 734432350.91951001\n",
      "Iteration 412, loss = 733882530.61219394\n",
      "Iteration 413, loss = 733263239.68479240\n",
      "Iteration 414, loss = 732654977.64790571\n",
      "Iteration 415, loss = 732062675.26867223\n",
      "Iteration 416, loss = 731460809.66754127\n",
      "Iteration 417, loss = 730843998.95349073\n",
      "Iteration 418, loss = 730237834.56831849\n",
      "Iteration 419, loss = 729654646.30924952\n",
      "Iteration 420, loss = 729040952.30497396\n",
      "Iteration 421, loss = 728446834.23657358\n",
      "Iteration 422, loss = 727824458.66267467\n",
      "Iteration 423, loss = 727210185.43903983\n",
      "Iteration 424, loss = 726569513.80453944\n",
      "Iteration 425, loss = 725961259.55130041\n",
      "Iteration 426, loss = 725331569.34488702\n",
      "Iteration 427, loss = 724716456.52712417\n",
      "Iteration 428, loss = 724092943.98342967\n",
      "Iteration 429, loss = 723458958.77387452\n",
      "Iteration 430, loss = 722841137.02232337\n",
      "Iteration 431, loss = 722222019.58122921\n",
      "Iteration 432, loss = 721549469.03599548\n",
      "Iteration 433, loss = 720926410.55457282\n",
      "Iteration 434, loss = 720273332.82133961\n",
      "Iteration 435, loss = 719641083.27502120\n",
      "Iteration 436, loss = 718990339.09612179\n",
      "Iteration 437, loss = 718344744.88859880\n",
      "Iteration 438, loss = 717688833.24893284\n",
      "Iteration 439, loss = 717023116.20407093\n",
      "Iteration 440, loss = 716389178.51001513\n",
      "Iteration 441, loss = 715731245.20232689\n",
      "Iteration 442, loss = 715089414.87290132\n",
      "Iteration 443, loss = 714427386.87215257\n",
      "Iteration 444, loss = 713762154.11269557\n",
      "Iteration 445, loss = 713106841.46375275\n",
      "Iteration 446, loss = 712452094.36244380\n",
      "Iteration 447, loss = 711797629.58012879\n",
      "Iteration 448, loss = 711161240.01181471\n",
      "Iteration 449, loss = 710474188.20150423\n",
      "Iteration 450, loss = 709811707.90865612\n",
      "Iteration 451, loss = 709143850.76067412\n",
      "Iteration 452, loss = 708501154.11898744\n",
      "Iteration 453, loss = 707827778.40907395\n",
      "Iteration 454, loss = 707191509.33987725\n",
      "Iteration 455, loss = 706520383.15197563\n",
      "Iteration 456, loss = 705861450.37271953\n",
      "Iteration 457, loss = 705189668.72118497\n",
      "Iteration 458, loss = 704541382.15760171\n",
      "Iteration 459, loss = 703872446.33209848\n",
      "Iteration 460, loss = 703191964.66288114\n",
      "Iteration 461, loss = 702526026.22245276\n",
      "Iteration 462, loss = 701835404.86261261\n",
      "Iteration 463, loss = 701164070.14782429\n",
      "Iteration 464, loss = 700491511.55418122\n",
      "Iteration 465, loss = 699808159.19038498\n",
      "Iteration 466, loss = 699132411.30001414\n",
      "Iteration 467, loss = 698445768.16161406\n",
      "Iteration 468, loss = 697762091.88367474\n",
      "Iteration 469, loss = 697076032.93909013\n",
      "Iteration 470, loss = 696383387.08393741\n",
      "Iteration 471, loss = 695703808.69751894\n",
      "Iteration 472, loss = 694996651.36245513\n",
      "Iteration 473, loss = 694299023.62382352\n",
      "Iteration 474, loss = 693599202.28676701\n",
      "Iteration 475, loss = 692886664.37841117\n",
      "Iteration 476, loss = 692192968.44015241\n",
      "Iteration 477, loss = 691510518.21090996\n",
      "Iteration 478, loss = 690796606.20250380\n",
      "Iteration 479, loss = 690094623.15237892\n",
      "Iteration 480, loss = 689402874.26683903\n",
      "Iteration 481, loss = 688692910.34689701\n",
      "Iteration 482, loss = 687994557.27690613\n",
      "Iteration 483, loss = 687292663.05181479\n",
      "Iteration 484, loss = 686604629.23992610\n",
      "Iteration 485, loss = 685894067.22931015\n",
      "Iteration 486, loss = 685186044.55278707\n",
      "Iteration 487, loss = 684479089.65931690\n",
      "Iteration 488, loss = 683809713.39004481\n",
      "Iteration 489, loss = 683074083.45478761\n",
      "Iteration 490, loss = 682352925.13326919\n",
      "Iteration 491, loss = 681624565.74293971\n",
      "Iteration 492, loss = 680918565.24432075\n",
      "Iteration 493, loss = 680206404.58318484\n",
      "Iteration 494, loss = 679473288.07144308\n",
      "Iteration 495, loss = 678747844.26208937\n",
      "Iteration 496, loss = 678023582.92992508\n",
      "Iteration 497, loss = 677268736.92885602\n",
      "Iteration 498, loss = 676518279.53167856\n",
      "Iteration 499, loss = 675802555.62659466\n",
      "Iteration 500, loss = 675076957.32787609\n",
      "Iteration 501, loss = 674353484.63145053\n",
      "Iteration 502, loss = 673617251.80322599\n",
      "Iteration 503, loss = 672883929.55292714\n",
      "Iteration 504, loss = 672115892.85206425\n",
      "Iteration 505, loss = 671400942.22535658\n",
      "Iteration 506, loss = 670645480.37605357\n",
      "Iteration 507, loss = 669904609.31866086\n",
      "Iteration 508, loss = 669137287.12935615\n",
      "Iteration 509, loss = 668377235.60985458\n",
      "Iteration 510, loss = 667615253.23882675\n",
      "Iteration 511, loss = 666870613.02347553\n",
      "Iteration 512, loss = 666091626.80354774\n",
      "Iteration 513, loss = 665352826.96888888\n",
      "Iteration 514, loss = 664570210.58326685\n",
      "Iteration 515, loss = 663816874.34290671\n",
      "Iteration 516, loss = 663092257.05182290\n",
      "Iteration 517, loss = 662347321.99818313\n",
      "Iteration 518, loss = 661565704.87797546\n",
      "Iteration 519, loss = 660804936.21022999\n",
      "Iteration 520, loss = 660082701.40121853\n",
      "Iteration 521, loss = 659295973.82205868\n",
      "Iteration 522, loss = 658559423.63575041\n",
      "Iteration 523, loss = 657818549.18614376\n",
      "Iteration 524, loss = 657027402.24520719\n",
      "Iteration 525, loss = 656287855.09213936\n",
      "Iteration 526, loss = 655504831.20540285\n",
      "Iteration 527, loss = 654734488.59758472\n",
      "Iteration 528, loss = 654008308.05010545\n",
      "Iteration 529, loss = 653226933.74144816\n",
      "Iteration 530, loss = 652447925.62357736\n",
      "Iteration 531, loss = 651669543.34848368\n",
      "Iteration 532, loss = 650923467.55780959\n",
      "Iteration 533, loss = 650159341.57468927\n",
      "Iteration 534, loss = 649355251.34038699\n",
      "Iteration 535, loss = 648581109.45958841\n",
      "Iteration 536, loss = 647812726.59638464\n",
      "Iteration 537, loss = 647051458.83143425\n",
      "Iteration 538, loss = 646268363.64785802\n",
      "Iteration 539, loss = 645489456.57542908\n",
      "Iteration 540, loss = 644693402.78460157\n",
      "Iteration 541, loss = 643902576.35996187\n",
      "Iteration 542, loss = 643116238.83781278\n",
      "Iteration 543, loss = 642323296.14182675\n",
      "Iteration 544, loss = 641545280.93092561\n",
      "Iteration 545, loss = 640740980.15867496\n",
      "Iteration 546, loss = 639948217.86460984\n",
      "Iteration 547, loss = 639149059.10080206\n",
      "Iteration 548, loss = 638353286.66987979\n",
      "Iteration 549, loss = 637610551.12158334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 550, loss = 636826778.29025221\n",
      "Iteration 551, loss = 636032502.20162618\n",
      "Iteration 552, loss = 635266099.67547584\n",
      "Iteration 553, loss = 634512152.80936134\n",
      "Iteration 554, loss = 633708171.67261279\n",
      "Iteration 555, loss = 632940008.23376846\n",
      "Iteration 556, loss = 632154613.91319048\n",
      "Iteration 557, loss = 631358111.55267334\n",
      "Iteration 558, loss = 630580221.12697709\n",
      "Iteration 559, loss = 629796708.87045777\n",
      "Iteration 560, loss = 628998708.93798780\n",
      "Iteration 561, loss = 628217068.26179016\n",
      "Iteration 562, loss = 627413933.46976829\n",
      "Iteration 563, loss = 626630250.17027223\n",
      "Iteration 564, loss = 625802951.65071416\n",
      "Iteration 565, loss = 625017880.63473010\n",
      "Iteration 566, loss = 624185881.03411984\n",
      "Iteration 567, loss = 623381822.53577018\n",
      "Iteration 568, loss = 622582632.67066944\n",
      "Iteration 569, loss = 621779409.90981936\n",
      "Iteration 570, loss = 620985603.74780750\n",
      "Iteration 571, loss = 620167791.52740550\n",
      "Iteration 572, loss = 619372848.98949301\n",
      "Iteration 573, loss = 618553914.47625470\n",
      "Iteration 574, loss = 617748493.35077536\n",
      "Iteration 575, loss = 616929195.21172976\n",
      "Iteration 576, loss = 616102350.03421009\n",
      "Iteration 577, loss = 615339191.77086413\n",
      "Iteration 578, loss = 614487053.78329921\n",
      "Iteration 579, loss = 613683188.86606216\n",
      "Iteration 580, loss = 612869280.98620129\n",
      "Iteration 581, loss = 612078671.51521850\n",
      "Iteration 582, loss = 611307324.75547469\n",
      "Iteration 583, loss = 610484132.72370923\n",
      "Iteration 584, loss = 609696571.84438515\n",
      "Iteration 585, loss = 608906819.93925011\n",
      "Iteration 586, loss = 608115102.15776730\n",
      "Iteration 587, loss = 607344603.10445035\n",
      "Iteration 588, loss = 606537683.77488899\n",
      "Iteration 589, loss = 605729625.47481751\n",
      "Iteration 590, loss = 604936255.97099268\n",
      "Iteration 591, loss = 604129651.79372680\n",
      "Iteration 592, loss = 603323123.55021048\n",
      "Iteration 593, loss = 602514301.07134044\n",
      "Iteration 594, loss = 601722113.54855919\n",
      "Iteration 595, loss = 600921854.82909703\n",
      "Iteration 596, loss = 600120652.37243509\n",
      "Iteration 597, loss = 599320870.73478472\n",
      "Iteration 598, loss = 598490690.89868164\n",
      "Iteration 599, loss = 597697792.41267705\n",
      "Iteration 600, loss = 596874715.31700408\n",
      "Iteration 601, loss = 596086931.60353851\n",
      "Iteration 602, loss = 595265105.58823419\n",
      "Iteration 603, loss = 594457557.34561813\n",
      "Iteration 604, loss = 593623881.85649037\n",
      "Iteration 605, loss = 592832749.28736973\n",
      "Iteration 606, loss = 592002232.24963725\n",
      "Iteration 607, loss = 591203469.91113770\n",
      "Iteration 608, loss = 590372843.76433647\n",
      "Iteration 609, loss = 589556263.96057045\n",
      "Iteration 610, loss = 588738985.80627215\n",
      "Iteration 611, loss = 587913285.36988139\n",
      "Iteration 612, loss = 587096154.66408432\n",
      "Iteration 613, loss = 586263056.38330793\n",
      "Iteration 614, loss = 585454936.50147092\n",
      "Iteration 615, loss = 584651760.78831720\n",
      "Iteration 616, loss = 583824694.34866214\n",
      "Iteration 617, loss = 582995787.75402749\n",
      "Iteration 618, loss = 582156302.35847938\n",
      "Iteration 619, loss = 581337613.96703458\n",
      "Iteration 620, loss = 580520929.03881645\n",
      "Iteration 621, loss = 579673259.46913242\n",
      "Iteration 622, loss = 578871877.33433640\n",
      "Iteration 623, loss = 578027116.90949571\n",
      "Iteration 624, loss = 577231414.20032346\n",
      "Iteration 625, loss = 576356831.60701191\n",
      "Iteration 626, loss = 575537361.01197720\n",
      "Iteration 627, loss = 574704648.84024179\n",
      "Iteration 628, loss = 573898681.89667463\n",
      "Iteration 629, loss = 573047410.02499127\n",
      "Iteration 630, loss = 572260134.29908848\n",
      "Iteration 631, loss = 571436223.01008201\n",
      "Iteration 632, loss = 570606143.04820812\n",
      "Iteration 633, loss = 569780214.54124856\n",
      "Iteration 634, loss = 568965119.32552898\n",
      "Iteration 635, loss = 568154356.59023607\n",
      "Iteration 636, loss = 567318148.86465085\n",
      "Iteration 637, loss = 566496583.00699580\n",
      "Iteration 638, loss = 565680198.75592268\n",
      "Iteration 639, loss = 564852479.90339553\n",
      "Iteration 640, loss = 564068680.45280409\n",
      "Iteration 641, loss = 563229792.39309573\n",
      "Iteration 642, loss = 562416110.95163751\n",
      "Iteration 643, loss = 561631394.84036517\n",
      "Iteration 644, loss = 560797946.83608770\n",
      "Iteration 645, loss = 559999145.96513069\n",
      "Iteration 646, loss = 559216764.49604070\n",
      "Iteration 647, loss = 558399213.31399202\n",
      "Iteration 648, loss = 557605811.01494348\n",
      "Iteration 649, loss = 556807938.56930971\n",
      "Iteration 650, loss = 556024374.98356879\n",
      "Iteration 651, loss = 555193382.22132385\n",
      "Iteration 652, loss = 554402651.78257573\n",
      "Iteration 653, loss = 553615787.81062114\n",
      "Iteration 654, loss = 552813342.09996414\n",
      "Iteration 655, loss = 552027055.68673790\n",
      "Iteration 656, loss = 551243035.20698631\n",
      "Iteration 657, loss = 550453673.71273577\n",
      "Iteration 658, loss = 549670775.31179380\n",
      "Iteration 659, loss = 548872998.02351475\n",
      "Iteration 660, loss = 548112758.59333813\n",
      "Iteration 661, loss = 547291201.46496570\n",
      "Iteration 662, loss = 546507095.67944169\n",
      "Iteration 663, loss = 545732852.50478745\n",
      "Iteration 664, loss = 544966941.22928298\n",
      "Iteration 665, loss = 544159734.51381803\n",
      "Iteration 666, loss = 543390202.75990939\n",
      "Iteration 667, loss = 542609927.82413042\n",
      "Iteration 668, loss = 541839931.74762094\n",
      "Iteration 669, loss = 541062621.36811686\n",
      "Iteration 670, loss = 540289868.05430174\n",
      "Iteration 671, loss = 539505104.55362558\n",
      "Iteration 672, loss = 538730723.35459673\n",
      "Iteration 673, loss = 537977021.96378314\n",
      "Iteration 674, loss = 537169075.00129867\n",
      "Iteration 675, loss = 536398220.04287958\n",
      "Iteration 676, loss = 535621071.14404333\n",
      "Iteration 677, loss = 534840126.12379682\n",
      "Iteration 678, loss = 534068730.23452216\n",
      "Iteration 679, loss = 533287757.44738317\n",
      "Iteration 680, loss = 532508953.30416030\n",
      "Iteration 681, loss = 531728273.04962367\n",
      "Iteration 682, loss = 530951953.53653651\n",
      "Iteration 683, loss = 530158838.01115972\n",
      "Iteration 684, loss = 529418517.93789643\n",
      "Iteration 685, loss = 528621832.31796104\n",
      "Iteration 686, loss = 527856586.50755298\n",
      "Iteration 687, loss = 527097173.15126216\n",
      "Iteration 688, loss = 526322741.82276899\n",
      "Iteration 689, loss = 525529907.57495177\n",
      "Iteration 690, loss = 524776556.56719935\n",
      "Iteration 691, loss = 523994645.86666554\n",
      "Iteration 692, loss = 523230403.13288110\n",
      "Iteration 693, loss = 522484430.64979345\n",
      "Iteration 694, loss = 521728097.68541694\n",
      "Iteration 695, loss = 520960469.11083549\n",
      "Iteration 696, loss = 520202919.74141741\n",
      "Iteration 697, loss = 519460259.43940914\n",
      "Iteration 698, loss = 518714516.94521832\n",
      "Iteration 699, loss = 517939417.26847464\n",
      "Iteration 700, loss = 517191029.54010159\n",
      "Iteration 701, loss = 516436472.08258301\n",
      "Iteration 702, loss = 515694559.08727288\n",
      "Iteration 703, loss = 514962105.93709898\n",
      "Iteration 704, loss = 514185171.25527012\n",
      "Iteration 705, loss = 513432741.99982816\n",
      "Iteration 706, loss = 512698164.19155884\n",
      "Iteration 707, loss = 511982429.98958135\n",
      "Iteration 708, loss = 511225172.45867562\n",
      "Iteration 709, loss = 510502162.49332070\n",
      "Iteration 710, loss = 509749472.71110237\n",
      "Iteration 711, loss = 509030295.26069039\n",
      "Iteration 712, loss = 508313575.22325999\n",
      "Iteration 713, loss = 507582696.93787265\n",
      "Iteration 714, loss = 506850076.59611398\n",
      "Iteration 715, loss = 506128399.45679206\n",
      "Iteration 716, loss = 505394774.99430150\n",
      "Iteration 717, loss = 504645788.53831029\n",
      "Iteration 718, loss = 503944787.79081923\n",
      "Iteration 719, loss = 503207789.78674477\n",
      "Iteration 720, loss = 502491815.84892488\n",
      "Iteration 721, loss = 501766702.62046355\n",
      "Iteration 722, loss = 501040581.07944947\n",
      "Iteration 723, loss = 500320786.54651630\n",
      "Iteration 724, loss = 499608781.83821046\n",
      "Iteration 725, loss = 498872342.44426888\n",
      "Iteration 726, loss = 498155353.26627690\n",
      "Iteration 727, loss = 497411683.75811034\n",
      "Iteration 728, loss = 496688114.63104624\n",
      "Iteration 729, loss = 495977973.11311471\n",
      "Iteration 730, loss = 495245618.73594886\n",
      "Iteration 731, loss = 494529243.11243320\n",
      "Iteration 732, loss = 493792602.14748371\n",
      "Iteration 733, loss = 493082744.01046783\n",
      "Iteration 734, loss = 492331902.12297237\n",
      "Iteration 735, loss = 491644922.45512170\n",
      "Iteration 736, loss = 490915050.99194384\n",
      "Iteration 737, loss = 490223520.55479705\n",
      "Iteration 738, loss = 489501897.09431392\n",
      "Iteration 739, loss = 488810283.69191647\n",
      "Iteration 740, loss = 488107294.50800484\n",
      "Iteration 741, loss = 487409270.89036995\n",
      "Iteration 742, loss = 486678382.83627725\n",
      "Iteration 743, loss = 485984064.34997278\n",
      "Iteration 744, loss = 485306548.51166934\n",
      "Iteration 745, loss = 484618022.03168762\n",
      "Iteration 746, loss = 483905234.97294843\n",
      "Iteration 747, loss = 483225594.77487433\n",
      "Iteration 748, loss = 482488008.61046922\n",
      "Iteration 749, loss = 481784966.86605769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 750, loss = 481095817.62936479\n",
      "Iteration 751, loss = 480383395.77931648\n",
      "Iteration 752, loss = 479698446.30082476\n",
      "Iteration 753, loss = 478967793.62602305\n",
      "Iteration 754, loss = 478314286.03741330\n",
      "Iteration 755, loss = 477611845.72925067\n",
      "Iteration 756, loss = 476932418.02486062\n",
      "Iteration 757, loss = 476234240.11406726\n",
      "Iteration 758, loss = 475587805.24623126\n",
      "Iteration 759, loss = 474879086.87859052\n",
      "Iteration 760, loss = 474215786.36097252\n",
      "Iteration 761, loss = 473559124.30959380\n",
      "Iteration 762, loss = 472838301.86165231\n",
      "Iteration 763, loss = 472191148.70094228\n",
      "Iteration 764, loss = 471479908.96181440\n",
      "Iteration 765, loss = 470820123.09823328\n",
      "Iteration 766, loss = 470136408.64537758\n",
      "Iteration 767, loss = 469459759.83286536\n",
      "Iteration 768, loss = 468774930.14392734\n",
      "Iteration 769, loss = 468115556.98496801\n",
      "Iteration 770, loss = 467425252.04141796\n",
      "Iteration 771, loss = 466735233.71116400\n",
      "Iteration 772, loss = 466074339.71893167\n",
      "Iteration 773, loss = 465350905.52576292\n",
      "Iteration 774, loss = 464705198.21895111\n",
      "Iteration 775, loss = 464032312.96129531\n",
      "Iteration 776, loss = 463367647.32846200\n",
      "Iteration 777, loss = 462693807.17009687\n",
      "Iteration 778, loss = 462033741.60038531\n",
      "Iteration 779, loss = 461364529.74832845\n",
      "Iteration 780, loss = 460658818.20737094\n",
      "Iteration 781, loss = 460000788.60684603\n",
      "Iteration 782, loss = 459345258.71240985\n",
      "Iteration 783, loss = 458696065.23058385\n",
      "Iteration 784, loss = 458011533.77619332\n",
      "Iteration 785, loss = 457329002.21772093\n",
      "Iteration 786, loss = 456700293.70867091\n",
      "Iteration 787, loss = 456020307.62956733\n",
      "Iteration 788, loss = 455363363.62757349\n",
      "Iteration 789, loss = 454712791.58492476\n",
      "Iteration 790, loss = 454041263.56692380\n",
      "Iteration 791, loss = 453413159.65329212\n",
      "Iteration 792, loss = 452761491.09244460\n",
      "Iteration 793, loss = 452080774.21867812\n",
      "Iteration 794, loss = 451424285.80525601\n",
      "Iteration 795, loss = 450770189.16465443\n",
      "Iteration 796, loss = 450144214.79448152\n",
      "Iteration 797, loss = 449442131.79360193\n",
      "Iteration 798, loss = 448790608.26771259\n",
      "Iteration 799, loss = 448118589.48893166\n",
      "Iteration 800, loss = 447489840.18853676\n",
      "Iteration 801, loss = 446824355.33355206\n",
      "Iteration 802, loss = 446167337.96620911\n",
      "Iteration 803, loss = 445494864.73696548\n",
      "Iteration 804, loss = 444851183.81809378\n",
      "Iteration 805, loss = 444214892.98289156\n",
      "Iteration 806, loss = 443547206.46540183\n",
      "Iteration 807, loss = 442912272.38747108\n",
      "Iteration 808, loss = 442266096.78252530\n",
      "Iteration 809, loss = 441601175.62661469\n",
      "Iteration 810, loss = 440936786.64452308\n",
      "Iteration 811, loss = 440281825.88056368\n",
      "Iteration 812, loss = 439637065.08072191\n",
      "Iteration 813, loss = 439004213.23120224\n",
      "Iteration 814, loss = 438365072.03581589\n",
      "Iteration 815, loss = 437702158.34467196\n",
      "Iteration 816, loss = 437057254.57178128\n",
      "Iteration 817, loss = 436419539.10185933\n",
      "Iteration 818, loss = 435793243.95227844\n",
      "Iteration 819, loss = 435132624.46887594\n",
      "Iteration 820, loss = 434502075.45232719\n",
      "Iteration 821, loss = 433866863.15470052\n",
      "Iteration 822, loss = 433204385.34395987\n",
      "Iteration 823, loss = 432593495.34140438\n",
      "Iteration 824, loss = 431937399.67740017\n",
      "Iteration 825, loss = 431299227.96020758\n",
      "Iteration 826, loss = 430671536.78238279\n",
      "Iteration 827, loss = 430030685.03174716\n",
      "Iteration 828, loss = 429402248.42197818\n",
      "Iteration 829, loss = 428784841.91198075\n",
      "Iteration 830, loss = 428145690.79739952\n",
      "Iteration 831, loss = 427480068.29812896\n",
      "Iteration 832, loss = 426857777.86281234\n",
      "Iteration 833, loss = 426227078.62613797\n",
      "Iteration 834, loss = 425588025.83292568\n",
      "Iteration 835, loss = 424951658.60414696\n",
      "Iteration 836, loss = 424324819.03167820\n",
      "Iteration 837, loss = 423675640.52778327\n",
      "Iteration 838, loss = 423048191.60072613\n",
      "Iteration 839, loss = 422420853.59187144\n",
      "Iteration 840, loss = 421790106.06493592\n",
      "Iteration 841, loss = 421146689.52419931\n",
      "Iteration 842, loss = 420504578.28338510\n",
      "Iteration 843, loss = 419928944.05313838\n",
      "Iteration 844, loss = 419267012.42546809\n",
      "Iteration 845, loss = 418605380.75784022\n",
      "Iteration 846, loss = 417973599.68151498\n",
      "Iteration 847, loss = 417368925.10203987\n",
      "Iteration 848, loss = 416729168.51333129\n",
      "Iteration 849, loss = 416101594.58917379\n",
      "Iteration 850, loss = 415487243.34036958\n",
      "Iteration 851, loss = 414838179.92806482\n",
      "Iteration 852, loss = 414223089.18992805\n",
      "Iteration 853, loss = 413586184.26571023\n",
      "Iteration 854, loss = 412957290.90724725\n",
      "Iteration 855, loss = 412322510.01284385\n",
      "Iteration 856, loss = 411706644.94601017\n",
      "Iteration 857, loss = 411128626.12946111\n",
      "Iteration 858, loss = 410465219.17017931\n",
      "Iteration 859, loss = 409849871.91702694\n",
      "Iteration 860, loss = 409231239.66847110\n",
      "Iteration 861, loss = 408597984.91703832\n",
      "Iteration 862, loss = 408012543.71563369\n",
      "Iteration 863, loss = 407367015.97061843\n",
      "Iteration 864, loss = 406740850.37925839\n",
      "Iteration 865, loss = 406149819.60093850\n",
      "Iteration 866, loss = 405502760.71719152\n",
      "Iteration 867, loss = 404893308.87287349\n",
      "Iteration 868, loss = 404251705.51126456\n",
      "Iteration 869, loss = 403639903.81349117\n",
      "Iteration 870, loss = 403057062.59886062\n",
      "Iteration 871, loss = 402435083.76476640\n",
      "Iteration 872, loss = 401812967.47337717\n",
      "Iteration 873, loss = 401222913.15332931\n",
      "Iteration 874, loss = 400564574.51687515\n",
      "Iteration 875, loss = 399983459.34164971\n",
      "Iteration 876, loss = 399354975.86199230\n",
      "Iteration 877, loss = 398746309.21396768\n",
      "Iteration 878, loss = 398118682.53924966\n",
      "Iteration 879, loss = 397555521.88889599\n",
      "Iteration 880, loss = 396917667.91122913\n",
      "Iteration 881, loss = 396323322.02912658\n",
      "Iteration 882, loss = 395716564.35572529\n",
      "Iteration 883, loss = 395169405.71966314\n",
      "Iteration 884, loss = 394499860.32730496\n",
      "Iteration 885, loss = 393930077.45015687\n",
      "Iteration 886, loss = 393351452.06839913\n",
      "Iteration 887, loss = 392694137.31231785\n",
      "Iteration 888, loss = 392119072.35380834\n",
      "Iteration 889, loss = 391519239.25103563\n",
      "Iteration 890, loss = 390926899.76629502\n",
      "Iteration 891, loss = 390339419.73871177\n",
      "Iteration 892, loss = 389702992.72548288\n",
      "Iteration 893, loss = 389113954.56507784\n",
      "Iteration 894, loss = 388506138.59923548\n",
      "Iteration 895, loss = 387907655.51754421\n",
      "Iteration 896, loss = 387326139.33319831\n",
      "Iteration 897, loss = 386727130.73392969\n",
      "Iteration 898, loss = 386115260.73261249\n",
      "Iteration 899, loss = 385538144.71777010\n",
      "Iteration 900, loss = 384899652.45487893\n",
      "Iteration 901, loss = 384302043.68779469\n",
      "Iteration 902, loss = 383703755.46433437\n",
      "Iteration 903, loss = 383109416.79705667\n",
      "Iteration 904, loss = 382563875.04934484\n",
      "Iteration 905, loss = 381950817.32255983\n",
      "Iteration 906, loss = 381333305.88524330\n",
      "Iteration 907, loss = 380784406.42537224\n",
      "Iteration 908, loss = 380213662.11472708\n",
      "Iteration 909, loss = 379615447.54971504\n",
      "Iteration 910, loss = 379013783.69568253\n",
      "Iteration 911, loss = 378515910.07548898\n",
      "Iteration 912, loss = 377855607.05217189\n",
      "Iteration 913, loss = 377316248.08252794\n",
      "Iteration 914, loss = 376733112.51846468\n",
      "Iteration 915, loss = 376181501.67982739\n",
      "Iteration 916, loss = 375559910.75306004\n",
      "Iteration 917, loss = 375016336.38731217\n",
      "Iteration 918, loss = 374432667.89961421\n",
      "Iteration 919, loss = 373826833.89028603\n",
      "Iteration 920, loss = 373234790.17463714\n",
      "Iteration 921, loss = 372657657.76197588\n",
      "Iteration 922, loss = 372074430.02439129\n",
      "Iteration 923, loss = 371487422.14572930\n",
      "Iteration 924, loss = 370887513.62573314\n",
      "Iteration 925, loss = 370308337.99409986\n",
      "Iteration 926, loss = 369752342.11814177\n",
      "Iteration 927, loss = 369192010.04101831\n",
      "Iteration 928, loss = 368580028.94507331\n",
      "Iteration 929, loss = 367998102.09783983\n",
      "Iteration 930, loss = 367424288.34768581\n",
      "Iteration 931, loss = 366825848.43670964\n",
      "Iteration 932, loss = 366262919.37516320\n",
      "Iteration 933, loss = 365674836.11751169\n",
      "Iteration 934, loss = 365093900.94829172\n",
      "Iteration 935, loss = 364510938.54891407\n",
      "Iteration 936, loss = 363976145.86563182\n",
      "Iteration 937, loss = 363379732.63204712\n",
      "Iteration 938, loss = 362771465.76637548\n",
      "Iteration 939, loss = 362195746.99239767\n",
      "Iteration 940, loss = 361612651.00715429\n",
      "Iteration 941, loss = 361043599.20435256\n",
      "Iteration 942, loss = 360469683.37765425\n",
      "Iteration 943, loss = 359925635.58815014\n",
      "Iteration 944, loss = 359341830.78194654\n",
      "Iteration 945, loss = 358785788.03617227\n",
      "Iteration 946, loss = 358182109.28405964\n",
      "Iteration 947, loss = 357615233.28511882\n",
      "Iteration 948, loss = 357017394.35126603\n",
      "Iteration 949, loss = 356446453.49026036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 950, loss = 355900417.92520648\n",
      "Iteration 951, loss = 355330864.29993838\n",
      "Iteration 952, loss = 354766814.52995706\n",
      "Iteration 953, loss = 354174403.33904666\n",
      "Iteration 954, loss = 353584670.57590944\n",
      "Iteration 955, loss = 353066418.54141587\n",
      "Iteration 956, loss = 352485845.17622799\n",
      "Iteration 957, loss = 351883662.32371300\n",
      "Iteration 958, loss = 351363751.20637929\n",
      "Iteration 959, loss = 350768251.64532405\n",
      "Iteration 960, loss = 350230829.27775615\n",
      "Iteration 961, loss = 349664309.45365542\n",
      "Iteration 962, loss = 349111256.65779966\n",
      "Iteration 963, loss = 348533543.55233794\n",
      "Iteration 964, loss = 347970874.03454524\n",
      "Iteration 965, loss = 347433050.90622807\n",
      "Iteration 966, loss = 346854301.79972506\n",
      "Iteration 967, loss = 346272869.67963570\n",
      "Iteration 968, loss = 345728859.88508201\n",
      "Iteration 969, loss = 345156745.58058810\n",
      "Iteration 970, loss = 344595508.87058961\n",
      "Iteration 971, loss = 344020987.26031178\n",
      "Iteration 972, loss = 343461496.20278966\n",
      "Iteration 973, loss = 342903208.02561665\n",
      "Iteration 974, loss = 342350460.90304828\n",
      "Iteration 975, loss = 341767247.70196247\n",
      "Iteration 976, loss = 341229703.18945307\n",
      "Iteration 977, loss = 340632856.65977430\n",
      "Iteration 978, loss = 340075321.52616048\n",
      "Iteration 979, loss = 339505611.43776608\n",
      "Iteration 980, loss = 338952975.06186813\n",
      "Iteration 981, loss = 338359359.19152248\n",
      "Iteration 982, loss = 337786295.77256644\n",
      "Iteration 983, loss = 337239805.36038470\n",
      "Iteration 984, loss = 336704848.74617070\n",
      "Iteration 985, loss = 336099002.20567685\n",
      "Iteration 986, loss = 335541573.19572079\n",
      "Iteration 987, loss = 334976498.24128324\n",
      "Iteration 988, loss = 334432497.11842757\n",
      "Iteration 989, loss = 333835044.08741635\n",
      "Iteration 990, loss = 333266071.11373365\n",
      "Iteration 991, loss = 332719279.18378139\n",
      "Iteration 992, loss = 332123174.05232185\n",
      "Iteration 993, loss = 331519896.57493544\n",
      "Iteration 994, loss = 330953661.36416674\n",
      "Iteration 995, loss = 330374414.36499894\n",
      "Iteration 996, loss = 329769993.31514925\n",
      "Iteration 997, loss = 329164443.67513180\n",
      "Iteration 998, loss = 328556767.71627504\n",
      "Iteration 999, loss = 327973828.42650491\n",
      "Iteration 1000, loss = 327381731.70831043\n",
      "Iteration 1001, loss = 326797401.09750843\n",
      "Iteration 1002, loss = 326217475.80394167\n",
      "Iteration 1003, loss = 325589449.88545907\n",
      "Iteration 1004, loss = 324983580.66478974\n",
      "Iteration 1005, loss = 324416402.33582604\n",
      "Iteration 1006, loss = 323800814.71469533\n",
      "Iteration 1007, loss = 323185831.66822606\n",
      "Iteration 1008, loss = 322548182.24325275\n",
      "Iteration 1009, loss = 321927546.93838966\n",
      "Iteration 1010, loss = 321287667.30372864\n",
      "Iteration 1011, loss = 320625245.61337996\n",
      "Iteration 1012, loss = 319979184.96950734\n",
      "Iteration 1013, loss = 319332383.23565829\n",
      "Iteration 1014, loss = 318654475.03942484\n",
      "Iteration 1015, loss = 317991466.38894224\n",
      "Iteration 1016, loss = 317351319.30601853\n",
      "Iteration 1017, loss = 316747264.16511112\n",
      "Iteration 1018, loss = 316025565.91825485\n",
      "Iteration 1019, loss = 315432610.95434445\n",
      "Iteration 1020, loss = 314767490.00371671\n",
      "Iteration 1021, loss = 314147259.89401430\n",
      "Iteration 1022, loss = 313473454.42861164\n",
      "Iteration 1023, loss = 312791292.52651614\n",
      "Iteration 1024, loss = 312116441.79522419\n",
      "Iteration 1025, loss = 311395824.44383168\n",
      "Iteration 1026, loss = 310697348.76941127\n",
      "Iteration 1027, loss = 310004598.75015289\n",
      "Iteration 1028, loss = 309334424.01592022\n",
      "Iteration 1029, loss = 308690232.55671734\n",
      "Iteration 1030, loss = 308047131.01616985\n",
      "Iteration 1031, loss = 307427304.72688377\n",
      "Iteration 1032, loss = 306819746.46496582\n",
      "Iteration 1033, loss = 306215784.30393267\n",
      "Iteration 1034, loss = 305600398.38027507\n",
      "Iteration 1035, loss = 305013453.65745014\n",
      "Iteration 1036, loss = 304398505.00305045\n",
      "Iteration 1037, loss = 303832000.99633485\n",
      "Iteration 1038, loss = 303221959.99424785\n",
      "Iteration 1039, loss = 302633423.15634698\n",
      "Iteration 1040, loss = 302053453.33452505\n",
      "Iteration 1041, loss = 301494986.17406958\n",
      "Iteration 1042, loss = 300897897.19484752\n",
      "Iteration 1043, loss = 300305514.68671346\n",
      "Iteration 1044, loss = 299754383.00969225\n",
      "Iteration 1045, loss = 299186881.41833591\n",
      "Iteration 1046, loss = 298595878.27507985\n",
      "Iteration 1047, loss = 298014798.61187696\n",
      "Iteration 1048, loss = 297440363.26314116\n",
      "Iteration 1049, loss = 296869746.47552472\n",
      "Iteration 1050, loss = 296274469.27682924\n",
      "Iteration 1051, loss = 295723619.89052588\n",
      "Iteration 1052, loss = 295144073.70363146\n",
      "Iteration 1053, loss = 294619706.15923226\n",
      "Iteration 1054, loss = 293981844.51608592\n",
      "Iteration 1055, loss = 293425384.44747072\n",
      "Iteration 1056, loss = 292914407.42872512\n",
      "Iteration 1057, loss = 292279123.59096342\n",
      "Iteration 1058, loss = 291694432.99447727\n",
      "Iteration 1059, loss = 291155499.38337553\n",
      "Iteration 1060, loss = 290579045.10193300\n",
      "Iteration 1061, loss = 290011821.06239891\n",
      "Iteration 1062, loss = 289436571.07381153\n",
      "Iteration 1063, loss = 288853065.56034350\n",
      "Iteration 1064, loss = 288307301.43113053\n",
      "Iteration 1065, loss = 287750606.43384689\n",
      "Iteration 1066, loss = 287155483.91428721\n",
      "Iteration 1067, loss = 286610080.04626375\n",
      "Iteration 1068, loss = 286033080.15360284\n",
      "Iteration 1069, loss = 285483300.41988415\n",
      "Iteration 1070, loss = 284938116.17257738\n",
      "Iteration 1071, loss = 284383628.63021976\n",
      "Iteration 1072, loss = 283839823.27930892\n",
      "Iteration 1073, loss = 283266808.19679224\n",
      "Iteration 1074, loss = 282717342.60457325\n",
      "Iteration 1075, loss = 282160730.41859210\n",
      "Iteration 1076, loss = 281654288.98111284\n",
      "Iteration 1077, loss = 281069399.33159524\n",
      "Iteration 1078, loss = 280520741.94645220\n",
      "Iteration 1079, loss = 279983260.28413349\n",
      "Iteration 1080, loss = 279415201.60252649\n",
      "Iteration 1081, loss = 278894529.19089520\n",
      "Iteration 1082, loss = 278320563.67511261\n",
      "Iteration 1083, loss = 277772066.35540336\n",
      "Iteration 1084, loss = 277199666.11292022\n",
      "Iteration 1085, loss = 276700597.50704497\n",
      "Iteration 1086, loss = 276068006.70378625\n",
      "Iteration 1087, loss = 275501070.22817338\n",
      "Iteration 1088, loss = 274959709.00857586\n",
      "Iteration 1089, loss = 274379035.80008835\n",
      "Iteration 1090, loss = 273814262.56940234\n",
      "Iteration 1091, loss = 273270513.32180226\n",
      "Iteration 1092, loss = 272698539.94055760\n",
      "Iteration 1093, loss = 272109964.74013317\n",
      "Iteration 1094, loss = 271529881.55331808\n",
      "Iteration 1095, loss = 270928485.63240016\n",
      "Iteration 1096, loss = 270354751.84523636\n",
      "Iteration 1097, loss = 269774960.98527968\n",
      "Iteration 1098, loss = 269175287.18069547\n",
      "Iteration 1099, loss = 268610097.30708408\n",
      "Iteration 1100, loss = 268004146.02125788\n",
      "Iteration 1101, loss = 267449947.48513803\n",
      "Iteration 1102, loss = 266854967.82656136\n",
      "Iteration 1103, loss = 266314685.61815292\n",
      "Iteration 1104, loss = 265719478.86437663\n",
      "Iteration 1105, loss = 265127917.24395257\n",
      "Iteration 1106, loss = 264550680.93418315\n",
      "Iteration 1107, loss = 263997080.37478137\n",
      "Iteration 1108, loss = 263423919.40798771\n",
      "Iteration 1109, loss = 262860679.30400160\n",
      "Iteration 1110, loss = 262293293.54240546\n",
      "Iteration 1111, loss = 261731767.90266082\n",
      "Iteration 1112, loss = 261176109.10258159\n",
      "Iteration 1113, loss = 260618901.86164904\n",
      "Iteration 1114, loss = 260036417.81378841\n",
      "Iteration 1115, loss = 259477354.66468468\n",
      "Iteration 1116, loss = 258871632.85871732\n",
      "Iteration 1117, loss = 258263511.39070055\n",
      "Iteration 1118, loss = 257667306.83751124\n",
      "Iteration 1119, loss = 257088234.71207705\n",
      "Iteration 1120, loss = 256497312.41307744\n",
      "Iteration 1121, loss = 255954181.96553445\n",
      "Iteration 1122, loss = 255390600.48999560\n",
      "Iteration 1123, loss = 254845584.36496624\n",
      "Iteration 1124, loss = 254299783.44141707\n",
      "Iteration 1125, loss = 253774316.92820746\n",
      "Iteration 1126, loss = 253214571.53016979\n",
      "Iteration 1127, loss = 252682512.44525421\n",
      "Iteration 1128, loss = 252145610.49545819\n",
      "Iteration 1129, loss = 251656281.66700089\n",
      "Iteration 1130, loss = 251131991.26352835\n",
      "Iteration 1131, loss = 250620408.06076002\n",
      "Iteration 1132, loss = 250121402.62278718\n",
      "Iteration 1133, loss = 249638041.83544368\n",
      "Iteration 1134, loss = 249136757.24244457\n",
      "Iteration 1135, loss = 248636500.05326730\n",
      "Iteration 1136, loss = 248163925.91592237\n",
      "Iteration 1137, loss = 247623415.59960619\n",
      "Iteration 1138, loss = 247125798.74356452\n",
      "Iteration 1139, loss = 246636735.85718963\n",
      "Iteration 1140, loss = 246157967.53550017\n",
      "Iteration 1141, loss = 245642295.24715567\n",
      "Iteration 1142, loss = 245142737.92383787\n",
      "Iteration 1143, loss = 244666794.31716257\n",
      "Iteration 1144, loss = 244185987.73076147\n",
      "Iteration 1145, loss = 243731497.08338588\n",
      "Iteration 1146, loss = 243243067.25127089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1147, loss = 242748173.35261637\n",
      "Iteration 1148, loss = 242260783.62493476\n",
      "Iteration 1149, loss = 241784718.34515965\n",
      "Iteration 1150, loss = 241318578.71933800\n",
      "Iteration 1151, loss = 240844940.78607833\n",
      "Iteration 1152, loss = 240332476.19877118\n",
      "Iteration 1153, loss = 239893424.37238699\n",
      "Iteration 1154, loss = 239377341.19548008\n",
      "Iteration 1155, loss = 238897300.47614387\n",
      "Iteration 1156, loss = 238411356.35515666\n",
      "Iteration 1157, loss = 237940042.31342468\n",
      "Iteration 1158, loss = 237489661.77427861\n",
      "Iteration 1159, loss = 236979780.12426475\n",
      "Iteration 1160, loss = 236502109.31222847\n",
      "Iteration 1161, loss = 236047925.71894783\n",
      "Iteration 1162, loss = 235593348.21141300\n",
      "Iteration 1163, loss = 235075150.07266915\n",
      "Iteration 1164, loss = 234624765.33019471\n",
      "Iteration 1165, loss = 234126173.43859735\n",
      "Iteration 1166, loss = 233623723.55843833\n",
      "Iteration 1167, loss = 233183558.29417449\n",
      "Iteration 1168, loss = 232713191.09387711\n",
      "Iteration 1169, loss = 232216222.02924868\n",
      "Iteration 1170, loss = 231871115.49610978\n",
      "Iteration 1171, loss = 231282081.89946347\n",
      "Iteration 1172, loss = 230827330.18423164\n",
      "Iteration 1173, loss = 230372094.22423226\n",
      "Iteration 1174, loss = 229939780.69790086\n",
      "Iteration 1175, loss = 229491859.72100136\n",
      "Iteration 1176, loss = 229005913.50338155\n",
      "Iteration 1177, loss = 228574686.68206894\n",
      "Iteration 1178, loss = 228116252.50959095\n",
      "Iteration 1179, loss = 227661012.17654884\n",
      "Iteration 1180, loss = 227175719.16239163\n",
      "Iteration 1181, loss = 226732305.56631908\n",
      "Iteration 1182, loss = 226263722.09137559\n",
      "Iteration 1183, loss = 225797709.62868673\n",
      "Iteration 1184, loss = 225339166.34699640\n",
      "Iteration 1185, loss = 224880508.82051152\n",
      "Iteration 1186, loss = 224433702.63305041\n",
      "Iteration 1187, loss = 223990749.53333989\n",
      "Iteration 1188, loss = 223525409.40609428\n",
      "Iteration 1189, loss = 223063424.99427137\n",
      "Iteration 1190, loss = 222645670.25996619\n",
      "Iteration 1191, loss = 222151640.59178162\n",
      "Iteration 1192, loss = 221708587.74502230\n",
      "Iteration 1193, loss = 221285343.16074160\n",
      "Iteration 1194, loss = 220828776.76056111\n",
      "Iteration 1195, loss = 220372230.37635386\n",
      "Iteration 1196, loss = 219916761.78962889\n",
      "Iteration 1197, loss = 219477864.00655085\n",
      "Iteration 1198, loss = 219024017.37494200\n",
      "Iteration 1199, loss = 218611706.48115322\n",
      "Iteration 1200, loss = 218141132.26160866\n",
      "Iteration 1201, loss = 217724082.97573856\n",
      "Iteration 1202, loss = 217325973.27369225\n",
      "Iteration 1203, loss = 216860219.39562246\n",
      "Iteration 1204, loss = 216418128.93168059\n",
      "Iteration 1205, loss = 215988306.62057051\n",
      "Iteration 1206, loss = 215538998.93829378\n",
      "Iteration 1207, loss = 215141204.81877291\n",
      "Iteration 1208, loss = 214678455.69457066\n",
      "Iteration 1209, loss = 214342085.30057541\n",
      "Iteration 1210, loss = 213829596.58535951\n",
      "Iteration 1211, loss = 213416220.60122469\n",
      "Iteration 1212, loss = 213006148.88245335\n",
      "Iteration 1213, loss = 212581925.58216348\n",
      "Iteration 1214, loss = 212153152.18182775\n",
      "Iteration 1215, loss = 211762259.15710217\n",
      "Iteration 1216, loss = 211358529.00843185\n",
      "Iteration 1217, loss = 210936335.95159578\n",
      "Iteration 1218, loss = 210485635.08309865\n",
      "Iteration 1219, loss = 210079069.09631374\n",
      "Iteration 1220, loss = 209686377.13537845\n",
      "Iteration 1221, loss = 209264241.49237707\n",
      "Iteration 1222, loss = 208847449.71516997\n",
      "Iteration 1223, loss = 208432229.16393444\n",
      "Iteration 1224, loss = 208036543.14869469\n",
      "Iteration 1225, loss = 207650140.12433445\n",
      "Iteration 1226, loss = 207233744.14168769\n",
      "Iteration 1227, loss = 206825534.56015468\n",
      "Iteration 1228, loss = 206405344.23372614\n",
      "Iteration 1229, loss = 206025556.68915009\n",
      "Iteration 1230, loss = 205607674.62209311\n",
      "Iteration 1231, loss = 205203051.31189519\n",
      "Iteration 1232, loss = 204826930.81156391\n",
      "Iteration 1233, loss = 204392914.81821883\n",
      "Iteration 1234, loss = 204005140.68013367\n",
      "Iteration 1235, loss = 203622543.59712332\n",
      "Iteration 1236, loss = 203224758.47862539\n",
      "Iteration 1237, loss = 202802794.34343001\n",
      "Iteration 1238, loss = 202396963.96801412\n",
      "Iteration 1239, loss = 202044243.25307274\n",
      "Iteration 1240, loss = 201613997.44939974\n",
      "Iteration 1241, loss = 201191487.66290054\n",
      "Iteration 1242, loss = 200803260.04094392\n",
      "Iteration 1243, loss = 200425317.34955847\n",
      "Iteration 1244, loss = 199996022.86115763\n",
      "Iteration 1245, loss = 199583914.79109275\n",
      "Iteration 1246, loss = 199210562.43988714\n",
      "Iteration 1247, loss = 198789260.29114830\n",
      "Iteration 1248, loss = 198396332.40464371\n",
      "Iteration 1249, loss = 197996768.28110895\n",
      "Iteration 1250, loss = 197602225.82916814\n",
      "Iteration 1251, loss = 197259253.21056223\n",
      "Iteration 1252, loss = 196829649.69516784\n",
      "Iteration 1253, loss = 196465538.55903164\n",
      "Iteration 1254, loss = 196062486.50393981\n",
      "Iteration 1255, loss = 195694760.42602313\n",
      "Iteration 1256, loss = 195315748.61499739\n",
      "Iteration 1257, loss = 194912423.76761457\n",
      "Iteration 1258, loss = 194558191.21305880\n",
      "Iteration 1259, loss = 194170465.23318490\n",
      "Iteration 1260, loss = 193816994.66733879\n",
      "Iteration 1261, loss = 193446356.33174688\n",
      "Iteration 1262, loss = 193049246.03673241\n",
      "Iteration 1263, loss = 192681220.68695572\n",
      "Iteration 1264, loss = 192283070.03635734\n",
      "Iteration 1265, loss = 191917601.89147070\n",
      "Iteration 1266, loss = 191553217.91721025\n",
      "Iteration 1267, loss = 191166089.81229457\n",
      "Iteration 1268, loss = 190778810.47858530\n",
      "Iteration 1269, loss = 190425238.03593940\n",
      "Iteration 1270, loss = 190049395.07558766\n",
      "Iteration 1271, loss = 189702132.84934598\n",
      "Iteration 1272, loss = 189312399.74559942\n",
      "Iteration 1273, loss = 188937285.99493226\n",
      "Iteration 1274, loss = 188584416.55277941\n",
      "Iteration 1275, loss = 188215585.40363759\n",
      "Iteration 1276, loss = 187838253.33690783\n",
      "Iteration 1277, loss = 187463659.11478347\n",
      "Iteration 1278, loss = 187112082.66519248\n",
      "Iteration 1279, loss = 186739353.58670628\n",
      "Iteration 1280, loss = 186402957.12688988\n",
      "Iteration 1281, loss = 186030135.07333770\n",
      "Iteration 1282, loss = 185643359.31551746\n",
      "Iteration 1283, loss = 185313978.12931219\n",
      "Iteration 1284, loss = 184972780.64112821\n",
      "Iteration 1285, loss = 184584124.56038040\n",
      "Iteration 1286, loss = 184207712.75869855\n",
      "Iteration 1287, loss = 183851251.52950409\n",
      "Iteration 1288, loss = 183491302.28551659\n",
      "Iteration 1289, loss = 183175724.66400594\n",
      "Iteration 1290, loss = 182804873.16669348\n",
      "Iteration 1291, loss = 182464436.65391523\n",
      "Iteration 1292, loss = 182094580.31054401\n",
      "Iteration 1293, loss = 181748148.80629736\n",
      "Iteration 1294, loss = 181379049.92409274\n",
      "Iteration 1295, loss = 181028271.14377916\n",
      "Iteration 1296, loss = 180672054.93348053\n",
      "Iteration 1297, loss = 180327228.43840262\n",
      "Iteration 1298, loss = 179973688.11340004\n",
      "Iteration 1299, loss = 179662589.71301085\n",
      "Iteration 1300, loss = 179269620.59630838\n",
      "Iteration 1301, loss = 178925879.64083862\n",
      "Iteration 1302, loss = 178578225.87179363\n",
      "Iteration 1303, loss = 178249926.31520450\n",
      "Iteration 1304, loss = 177899228.06336993\n",
      "Iteration 1305, loss = 177558282.64854378\n",
      "Iteration 1306, loss = 177243878.72993839\n",
      "Iteration 1307, loss = 176920936.57844535\n",
      "Iteration 1308, loss = 176563534.03195256\n",
      "Iteration 1309, loss = 176251426.55965820\n",
      "Iteration 1310, loss = 175907255.18951616\n",
      "Iteration 1311, loss = 175572384.84395036\n",
      "Iteration 1312, loss = 175243066.67219031\n",
      "Iteration 1313, loss = 174894035.52459908\n",
      "Iteration 1314, loss = 174578542.47665691\n",
      "Iteration 1315, loss = 174253216.57506213\n",
      "Iteration 1316, loss = 173920891.15342027\n",
      "Iteration 1317, loss = 173614966.32571566\n",
      "Iteration 1318, loss = 173266879.04726002\n",
      "Iteration 1319, loss = 172954036.13483530\n",
      "Iteration 1320, loss = 172613543.92527291\n",
      "Iteration 1321, loss = 172298789.64169759\n",
      "Iteration 1322, loss = 171974001.33415449\n",
      "Iteration 1323, loss = 171652464.73862436\n",
      "Iteration 1324, loss = 171324085.01744077\n",
      "Iteration 1325, loss = 171023467.42759740\n",
      "Iteration 1326, loss = 170736308.67962730\n",
      "Iteration 1327, loss = 170364463.26752266\n",
      "Iteration 1328, loss = 170076186.88436639\n",
      "Iteration 1329, loss = 169759762.69429985\n",
      "Iteration 1330, loss = 169410621.06578389\n",
      "Iteration 1331, loss = 169099816.99621406\n",
      "Iteration 1332, loss = 168807923.97218049\n",
      "Iteration 1333, loss = 168485532.44812360\n",
      "Iteration 1334, loss = 168173208.05563858\n",
      "Iteration 1335, loss = 167857018.98389158\n",
      "Iteration 1336, loss = 167550044.34581754\n",
      "Iteration 1337, loss = 167241685.42943454\n",
      "Iteration 1338, loss = 166924008.15871447\n",
      "Iteration 1339, loss = 166633963.05248109\n",
      "Iteration 1340, loss = 166372764.78225681\n",
      "Iteration 1341, loss = 166012804.33695713\n",
      "Iteration 1342, loss = 165703950.57249826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1343, loss = 165423399.93765789\n",
      "Iteration 1344, loss = 165080932.01264367\n",
      "Iteration 1345, loss = 164818665.20235515\n",
      "Iteration 1346, loss = 164518760.63074702\n",
      "Iteration 1347, loss = 164242635.29218873\n",
      "Iteration 1348, loss = 163919000.99347210\n",
      "Iteration 1349, loss = 163643592.18808895\n",
      "Iteration 1350, loss = 163326126.88657284\n",
      "Iteration 1351, loss = 163098882.84399128\n",
      "Iteration 1352, loss = 162742637.17856333\n",
      "Iteration 1353, loss = 162475607.69480076\n",
      "Iteration 1354, loss = 162191115.09024552\n",
      "Iteration 1355, loss = 161889833.14670852\n",
      "Iteration 1356, loss = 161617073.35390911\n",
      "Iteration 1357, loss = 161332952.57994860\n",
      "Iteration 1358, loss = 161063158.26120967\n",
      "Iteration 1359, loss = 160798442.37772998\n",
      "Iteration 1360, loss = 160513871.35316676\n",
      "Iteration 1361, loss = 160229145.39022863\n",
      "Iteration 1362, loss = 159973010.79717374\n",
      "Iteration 1363, loss = 159668526.59627530\n",
      "Iteration 1364, loss = 159420322.30677018\n",
      "Iteration 1365, loss = 159134307.20622343\n",
      "Iteration 1366, loss = 158873194.53608358\n",
      "Iteration 1367, loss = 158579689.80613154\n",
      "Iteration 1368, loss = 158308691.39894849\n",
      "Iteration 1369, loss = 158062004.41238645\n",
      "Iteration 1370, loss = 157775978.59587631\n",
      "Iteration 1371, loss = 157490157.04479069\n",
      "Iteration 1372, loss = 157262984.07678321\n",
      "Iteration 1373, loss = 156989917.07016489\n",
      "Iteration 1374, loss = 156706023.65637848\n",
      "Iteration 1375, loss = 156459003.97684535\n",
      "Iteration 1376, loss = 156202563.34945336\n",
      "Iteration 1377, loss = 155920739.70691419\n",
      "Iteration 1378, loss = 155647640.88457468\n",
      "Iteration 1379, loss = 155413467.16467521\n",
      "Iteration 1380, loss = 155126640.31088260\n",
      "Iteration 1381, loss = 154869595.56347725\n",
      "Iteration 1382, loss = 154627097.89614087\n",
      "Iteration 1383, loss = 154341504.14433280\n",
      "Iteration 1384, loss = 154073347.82163382\n",
      "Iteration 1385, loss = 153808624.09051287\n",
      "Iteration 1386, loss = 153564588.42335811\n",
      "Iteration 1387, loss = 153304482.71793902\n",
      "Iteration 1388, loss = 153086007.89822063\n",
      "Iteration 1389, loss = 152789670.57344151\n",
      "Iteration 1390, loss = 152564308.34208006\n",
      "Iteration 1391, loss = 152290274.47054285\n",
      "Iteration 1392, loss = 152049439.77069294\n",
      "Iteration 1393, loss = 151787326.39015895\n",
      "Iteration 1394, loss = 151531180.14436138\n",
      "Iteration 1395, loss = 151296550.04661968\n",
      "Iteration 1396, loss = 151026454.66994792\n",
      "Iteration 1397, loss = 150782612.32866037\n",
      "Iteration 1398, loss = 150546522.35057238\n",
      "Iteration 1399, loss = 150283774.69978389\n",
      "Iteration 1400, loss = 150040836.88814718\n",
      "Iteration 1401, loss = 149840533.07816610\n",
      "Iteration 1402, loss = 149538196.15998718\n",
      "Iteration 1403, loss = 149312300.20957914\n",
      "Iteration 1404, loss = 149075417.53282335\n",
      "Iteration 1405, loss = 148817319.75809732\n",
      "Iteration 1406, loss = 148577493.24521899\n",
      "Iteration 1407, loss = 148330789.85592431\n",
      "Iteration 1408, loss = 148100173.51895127\n",
      "Iteration 1409, loss = 147882077.78531089\n",
      "Iteration 1410, loss = 147632971.27099338\n",
      "Iteration 1411, loss = 147405123.81091443\n",
      "Iteration 1412, loss = 147153715.44671118\n",
      "Iteration 1413, loss = 146922450.83937714\n",
      "Iteration 1414, loss = 146720031.85398608\n",
      "Iteration 1415, loss = 146487652.89628446\n",
      "Iteration 1416, loss = 146233158.10154805\n",
      "Iteration 1417, loss = 146021476.57763717\n",
      "Iteration 1418, loss = 145765077.63786951\n",
      "Iteration 1419, loss = 145577425.33762622\n",
      "Iteration 1420, loss = 145318663.30041483\n",
      "Iteration 1421, loss = 145093181.78690296\n",
      "Iteration 1422, loss = 144899492.11345154\n",
      "Iteration 1423, loss = 144680295.74892798\n",
      "Iteration 1424, loss = 144451173.18969840\n",
      "Iteration 1425, loss = 144211542.15059122\n",
      "Iteration 1426, loss = 143971357.36555445\n",
      "Iteration 1427, loss = 143746503.41690129\n",
      "Iteration 1428, loss = 143543204.93247011\n",
      "Iteration 1429, loss = 143314258.83800203\n",
      "Iteration 1430, loss = 143120022.66049516\n",
      "Iteration 1431, loss = 142880253.00939643\n",
      "Iteration 1432, loss = 142671648.20099783\n",
      "Iteration 1433, loss = 142481288.23745909\n",
      "Iteration 1434, loss = 142219040.64505789\n",
      "Iteration 1435, loss = 142009809.52298224\n",
      "Iteration 1436, loss = 141795149.37703863\n",
      "Iteration 1437, loss = 141567255.96854943\n",
      "Iteration 1438, loss = 141357776.19074178\n",
      "Iteration 1439, loss = 141164928.76187056\n",
      "Iteration 1440, loss = 140928049.93194726\n",
      "Iteration 1441, loss = 140734800.37026584\n",
      "Iteration 1442, loss = 140553993.02804872\n",
      "Iteration 1443, loss = 140316344.80838960\n",
      "Iteration 1444, loss = 140143915.44306612\n",
      "Iteration 1445, loss = 139885624.79952353\n",
      "Iteration 1446, loss = 139682885.13820583\n",
      "Iteration 1447, loss = 139459542.14592925\n",
      "Iteration 1448, loss = 139263284.97267887\n",
      "Iteration 1449, loss = 139078119.31054866\n",
      "Iteration 1450, loss = 138845539.17963237\n",
      "Iteration 1451, loss = 138640545.74128848\n",
      "Iteration 1452, loss = 138444821.32435340\n",
      "Iteration 1453, loss = 138232481.99447781\n",
      "Iteration 1454, loss = 138019400.16167563\n",
      "Iteration 1455, loss = 137829237.14278260\n",
      "Iteration 1456, loss = 137599004.62309867\n",
      "Iteration 1457, loss = 137438449.63822928\n",
      "Iteration 1458, loss = 137218061.30073985\n",
      "Iteration 1459, loss = 137031427.60752994\n",
      "Iteration 1460, loss = 136808303.87211493\n",
      "Iteration 1461, loss = 136649142.31303659\n",
      "Iteration 1462, loss = 136437670.98833823\n",
      "Iteration 1463, loss = 136241005.22593105\n",
      "Iteration 1464, loss = 136056018.12643021\n",
      "Iteration 1465, loss = 135819454.27928266\n",
      "Iteration 1466, loss = 135644276.57469624\n",
      "Iteration 1467, loss = 135470417.52239588\n",
      "Iteration 1468, loss = 135268463.93505436\n",
      "Iteration 1469, loss = 135062804.26541522\n",
      "Iteration 1470, loss = 134859064.35144389\n",
      "Iteration 1471, loss = 134690004.13310218\n",
      "Iteration 1472, loss = 134498493.88806266\n",
      "Iteration 1473, loss = 134298421.63108805\n",
      "Iteration 1474, loss = 134097273.79875611\n",
      "Iteration 1475, loss = 133921559.23195873\n",
      "Iteration 1476, loss = 133740246.57053563\n",
      "Iteration 1477, loss = 133542342.69917037\n",
      "Iteration 1478, loss = 133389489.22599562\n",
      "Iteration 1479, loss = 133160633.43665428\n",
      "Iteration 1480, loss = 132967231.52372485\n",
      "Iteration 1481, loss = 132795203.76395215\n",
      "Iteration 1482, loss = 132592678.62177466\n",
      "Iteration 1483, loss = 132435446.14410380\n",
      "Iteration 1484, loss = 132248401.29155985\n",
      "Iteration 1485, loss = 132056195.65081771\n",
      "Iteration 1486, loss = 131892643.53256348\n",
      "Iteration 1487, loss = 131704641.60913116\n",
      "Iteration 1488, loss = 131522374.56202233\n",
      "Iteration 1489, loss = 131336199.21514040\n",
      "Iteration 1490, loss = 131148030.47374900\n",
      "Iteration 1491, loss = 130972773.23072214\n",
      "Iteration 1492, loss = 130824655.02173230\n",
      "Iteration 1493, loss = 130637610.41523211\n",
      "Iteration 1494, loss = 130450187.89091961\n",
      "Iteration 1495, loss = 130297965.53627668\n",
      "Iteration 1496, loss = 130105902.46903193\n",
      "Iteration 1497, loss = 129944949.34539632\n",
      "Iteration 1498, loss = 129737223.21968772\n",
      "Iteration 1499, loss = 129574597.15472098\n",
      "Iteration 1500, loss = 129419835.60531767\n",
      "Iteration 1501, loss = 129254749.66263890\n",
      "Iteration 1502, loss = 129057328.58999607\n",
      "Iteration 1503, loss = 128882193.70079139\n",
      "Iteration 1504, loss = 128709392.90444602\n",
      "Iteration 1505, loss = 128530384.46704929\n",
      "Iteration 1506, loss = 128368414.34519793\n",
      "Iteration 1507, loss = 128222195.50760756\n",
      "Iteration 1508, loss = 128023837.48517558\n",
      "Iteration 1509, loss = 127867426.76134861\n",
      "Iteration 1510, loss = 127696021.58705129\n",
      "Iteration 1511, loss = 127517831.07511859\n",
      "Iteration 1512, loss = 127431845.00146648\n",
      "Iteration 1513, loss = 127199969.77895586\n",
      "Iteration 1514, loss = 127007653.54765894\n",
      "Iteration 1515, loss = 126887079.45701516\n",
      "Iteration 1516, loss = 126684710.51509467\n",
      "Iteration 1517, loss = 126528221.39011592\n",
      "Iteration 1518, loss = 126366923.56808418\n",
      "Iteration 1519, loss = 126202498.79628561\n",
      "Iteration 1520, loss = 126048421.50122842\n",
      "Iteration 1521, loss = 125929093.83271739\n",
      "Iteration 1522, loss = 125715074.56579266\n",
      "Iteration 1523, loss = 125589447.85367787\n",
      "Iteration 1524, loss = 125414253.84951869\n",
      "Iteration 1525, loss = 125230358.41500017\n",
      "Iteration 1526, loss = 125073798.08213519\n",
      "Iteration 1527, loss = 124917864.79119250\n",
      "Iteration 1528, loss = 124768099.33865875\n",
      "Iteration 1529, loss = 124624766.46040536\n",
      "Iteration 1530, loss = 124470111.20622474\n",
      "Iteration 1531, loss = 124301898.39980002\n",
      "Iteration 1532, loss = 124129931.09903711\n",
      "Iteration 1533, loss = 123982925.51361515\n",
      "Iteration 1534, loss = 123857939.66127343\n",
      "Iteration 1535, loss = 123700922.88438751\n",
      "Iteration 1536, loss = 123558157.82329068\n",
      "Iteration 1537, loss = 123391459.40919764\n",
      "Iteration 1538, loss = 123266588.12382868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1539, loss = 123107846.95929796\n",
      "Iteration 1540, loss = 122967393.45041180\n",
      "Iteration 1541, loss = 122792981.37669221\n",
      "Iteration 1542, loss = 122639348.34226555\n",
      "Iteration 1543, loss = 122519754.19890484\n",
      "Iteration 1544, loss = 122362905.99306859\n",
      "Iteration 1545, loss = 122197343.55781373\n",
      "Iteration 1546, loss = 122050090.16549088\n",
      "Iteration 1547, loss = 121909167.83667663\n",
      "Iteration 1548, loss = 121746496.94851263\n",
      "Iteration 1549, loss = 121634802.33411004\n",
      "Iteration 1550, loss = 121459461.49246322\n",
      "Iteration 1551, loss = 121307677.93471310\n",
      "Iteration 1552, loss = 121165283.01384446\n",
      "Iteration 1553, loss = 121026120.38608734\n",
      "Iteration 1554, loss = 120876129.75522359\n",
      "Iteration 1555, loss = 120736968.34181969\n",
      "Iteration 1556, loss = 120573084.24031553\n",
      "Iteration 1557, loss = 120441386.48002872\n",
      "Iteration 1558, loss = 120451750.17500409\n",
      "Iteration 1559, loss = 120176803.10412170\n",
      "Iteration 1560, loss = 120029940.29450488\n",
      "Iteration 1561, loss = 119878425.64825201\n",
      "Iteration 1562, loss = 119735072.62867209\n",
      "Iteration 1563, loss = 119592379.46029460\n",
      "Iteration 1564, loss = 119469743.74921916\n",
      "Iteration 1565, loss = 119327736.92431323\n",
      "Iteration 1566, loss = 119162854.36804524\n",
      "Iteration 1567, loss = 119038328.51916505\n",
      "Iteration 1568, loss = 118897150.53260690\n",
      "Iteration 1569, loss = 118759469.30597679\n",
      "Iteration 1570, loss = 118630861.59862643\n",
      "Iteration 1571, loss = 118478572.75130439\n",
      "Iteration 1572, loss = 118347991.14071156\n",
      "Iteration 1573, loss = 118187236.32408065\n",
      "Iteration 1574, loss = 118070653.31424446\n",
      "Iteration 1575, loss = 117946668.49006687\n",
      "Iteration 1576, loss = 117812819.01331922\n",
      "Iteration 1577, loss = 117682934.55428994\n",
      "Iteration 1578, loss = 117528116.12962289\n",
      "Iteration 1579, loss = 117381932.94799620\n",
      "Iteration 1580, loss = 117280076.16827974\n",
      "Iteration 1581, loss = 117132880.70376463\n",
      "Iteration 1582, loss = 117000141.96861772\n",
      "Iteration 1583, loss = 116837608.23010419\n",
      "Iteration 1584, loss = 116706433.65630300\n",
      "Iteration 1585, loss = 116582735.25224353\n",
      "Iteration 1586, loss = 116439228.67762657\n",
      "Iteration 1587, loss = 116309954.33570173\n",
      "Iteration 1588, loss = 116188613.17820035\n",
      "Iteration 1589, loss = 116090720.73648311\n",
      "Iteration 1590, loss = 115927829.20096485\n",
      "Iteration 1591, loss = 115803173.71521640\n",
      "Iteration 1592, loss = 115655584.34721799\n",
      "Iteration 1593, loss = 115527732.61691394\n",
      "Iteration 1594, loss = 115392996.85029213\n",
      "Iteration 1595, loss = 115273951.64027214\n",
      "Iteration 1596, loss = 115131647.61686590\n",
      "Iteration 1597, loss = 115016084.25401884\n",
      "Iteration 1598, loss = 114889864.46472760\n",
      "Iteration 1599, loss = 114766360.62543976\n",
      "Iteration 1600, loss = 114644625.44195749\n",
      "Iteration 1601, loss = 114518721.78168739\n",
      "Iteration 1602, loss = 114377025.79365905\n",
      "Iteration 1603, loss = 114278474.74128407\n",
      "Iteration 1604, loss = 114169683.60751797\n",
      "Iteration 1605, loss = 114026758.21792862\n",
      "Iteration 1606, loss = 113916028.38188936\n",
      "Iteration 1607, loss = 113779475.98807718\n",
      "Iteration 1608, loss = 113638605.97266728\n",
      "Iteration 1609, loss = 113533662.31205539\n",
      "Iteration 1610, loss = 113419688.74387887\n",
      "Iteration 1611, loss = 113333541.15977846\n",
      "Iteration 1612, loss = 113178602.52304241\n",
      "Iteration 1613, loss = 113042007.92002103\n",
      "Iteration 1614, loss = 112990914.21606697\n",
      "Iteration 1615, loss = 112836163.54124890\n",
      "Iteration 1616, loss = 112691916.57371770\n",
      "Iteration 1617, loss = 112589359.94005567\n",
      "Iteration 1618, loss = 112492153.63141300\n",
      "Iteration 1619, loss = 112355318.34591627\n",
      "Iteration 1620, loss = 112235684.60921595\n",
      "Iteration 1621, loss = 112101734.03210090\n",
      "Iteration 1622, loss = 112016302.30494434\n",
      "Iteration 1623, loss = 111905504.23279434\n",
      "Iteration 1624, loss = 111746960.18461502\n",
      "Iteration 1625, loss = 111667409.30601436\n",
      "Iteration 1626, loss = 111534821.00882232\n",
      "Iteration 1627, loss = 111422128.75261894\n",
      "Iteration 1628, loss = 111304984.50207515\n",
      "Iteration 1629, loss = 111199238.87282778\n",
      "Iteration 1630, loss = 111122175.21587399\n",
      "Iteration 1631, loss = 110956513.17138077\n",
      "Iteration 1632, loss = 110858977.08311744\n",
      "Iteration 1633, loss = 110761666.87811726\n",
      "Iteration 1634, loss = 110685454.25246470\n",
      "Iteration 1635, loss = 110554859.69731630\n",
      "Iteration 1636, loss = 110419524.28788479\n",
      "Iteration 1637, loss = 110318478.00428306\n",
      "Iteration 1638, loss = 110204062.02442127\n",
      "Iteration 1639, loss = 110093096.67720672\n",
      "Iteration 1640, loss = 110006337.98282556\n",
      "Iteration 1641, loss = 109885253.64249745\n",
      "Iteration 1642, loss = 109781346.09892496\n",
      "Iteration 1643, loss = 109688485.04410827\n",
      "Iteration 1644, loss = 109574424.73902033\n",
      "Iteration 1645, loss = 109474734.79950503\n",
      "Iteration 1646, loss = 109368267.00389801\n",
      "Iteration 1647, loss = 109266714.87301435\n",
      "Iteration 1648, loss = 109155190.95083770\n",
      "Iteration 1649, loss = 109051032.16487321\n",
      "Iteration 1650, loss = 108925667.17962463\n",
      "Iteration 1651, loss = 108822112.28570898\n",
      "Iteration 1652, loss = 108734302.00146315\n",
      "Iteration 1653, loss = 108636381.72209917\n",
      "Iteration 1654, loss = 108533909.22874810\n",
      "Iteration 1655, loss = 108411749.38607161\n",
      "Iteration 1656, loss = 108365123.59163788\n",
      "Iteration 1657, loss = 108276606.21475153\n",
      "Iteration 1658, loss = 108136500.36096150\n",
      "Iteration 1659, loss = 108011222.92703207\n",
      "Iteration 1660, loss = 107919762.73055871\n",
      "Iteration 1661, loss = 107819858.84223494\n",
      "Iteration 1662, loss = 107715211.52677602\n",
      "Iteration 1663, loss = 107617826.03552744\n",
      "Iteration 1664, loss = 107518816.87156796\n",
      "Iteration 1665, loss = 107423230.54249409\n",
      "Iteration 1666, loss = 107317008.22704060\n",
      "Iteration 1667, loss = 107232978.15892375\n",
      "Iteration 1668, loss = 107147655.75585933\n",
      "Iteration 1669, loss = 107031991.94050768\n",
      "Iteration 1670, loss = 106919386.17522125\n",
      "Iteration 1671, loss = 106854346.45304759\n",
      "Iteration 1672, loss = 106741911.37462346\n",
      "Iteration 1673, loss = 106653795.05090857\n",
      "Iteration 1674, loss = 106571772.93981645\n",
      "Iteration 1675, loss = 106454870.73335123\n",
      "Iteration 1676, loss = 106366707.31967138\n",
      "Iteration 1677, loss = 106278674.02519032\n",
      "Iteration 1678, loss = 106164706.08343385\n",
      "Iteration 1679, loss = 106073027.10127209\n",
      "Iteration 1680, loss = 105983171.07634206\n",
      "Iteration 1681, loss = 105879086.96566772\n",
      "Iteration 1682, loss = 105797240.79110537\n",
      "Iteration 1683, loss = 105716556.40477592\n",
      "Iteration 1684, loss = 105601105.13982268\n",
      "Iteration 1685, loss = 105551152.28307624\n",
      "Iteration 1686, loss = 105418427.23531045\n",
      "Iteration 1687, loss = 105347524.62705822\n",
      "Iteration 1688, loss = 105237511.25380248\n",
      "Iteration 1689, loss = 105158864.66066934\n",
      "Iteration 1690, loss = 105059203.93416658\n",
      "Iteration 1691, loss = 104967650.76935424\n",
      "Iteration 1692, loss = 104884436.84739521\n",
      "Iteration 1693, loss = 104790308.79520203\n",
      "Iteration 1694, loss = 104691381.51819363\n",
      "Iteration 1695, loss = 104610055.74692492\n",
      "Iteration 1696, loss = 104513417.01110984\n",
      "Iteration 1697, loss = 104424260.87479421\n",
      "Iteration 1698, loss = 104343203.93396235\n",
      "Iteration 1699, loss = 104234182.05022120\n",
      "Iteration 1700, loss = 104159364.54242685\n",
      "Iteration 1701, loss = 104066320.11605406\n",
      "Iteration 1702, loss = 103984871.01762848\n",
      "Iteration 1703, loss = 103905967.12967016\n",
      "Iteration 1704, loss = 103818646.07307909\n",
      "Iteration 1705, loss = 103730151.26783313\n",
      "Iteration 1706, loss = 103639206.89073133\n",
      "Iteration 1707, loss = 103612425.07295068\n",
      "Iteration 1708, loss = 103465185.86659090\n",
      "Iteration 1709, loss = 103391932.87323478\n",
      "Iteration 1710, loss = 103343741.11345203\n",
      "Iteration 1711, loss = 103234891.91957548\n",
      "Iteration 1712, loss = 103160743.81894423\n",
      "Iteration 1713, loss = 103073473.54549943\n",
      "Iteration 1714, loss = 102981684.42684612\n",
      "Iteration 1715, loss = 102920043.99295469\n",
      "Iteration 1716, loss = 102834198.70237638\n",
      "Iteration 1717, loss = 102758038.24931243\n",
      "Iteration 1718, loss = 102667928.44492207\n",
      "Iteration 1719, loss = 102585337.58042565\n",
      "Iteration 1720, loss = 102517667.38329102\n",
      "Iteration 1721, loss = 102453311.42604832\n",
      "Iteration 1722, loss = 102355388.01641324\n",
      "Iteration 1723, loss = 102287481.83915672\n",
      "Iteration 1724, loss = 102188520.74866766\n",
      "Iteration 1725, loss = 102112224.97630052\n",
      "Iteration 1726, loss = 102028610.21963476\n",
      "Iteration 1727, loss = 101951426.61420183\n",
      "Iteration 1728, loss = 101885357.70741291\n",
      "Iteration 1729, loss = 101816874.66625994\n",
      "Iteration 1730, loss = 101708218.65943429\n",
      "Iteration 1731, loss = 101622768.95307823\n",
      "Iteration 1732, loss = 101564581.56710581\n",
      "Iteration 1733, loss = 101469671.51890960\n",
      "Iteration 1734, loss = 101465451.04724582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1735, loss = 101325695.73217836\n",
      "Iteration 1736, loss = 101272452.74962071\n",
      "Iteration 1737, loss = 101192027.98758709\n",
      "Iteration 1738, loss = 101124455.56854992\n",
      "Iteration 1739, loss = 101009069.14888911\n",
      "Iteration 1740, loss = 100991546.82868275\n",
      "Iteration 1741, loss = 100893798.49149853\n",
      "Iteration 1742, loss = 100796667.40850952\n",
      "Iteration 1743, loss = 100752667.75255898\n",
      "Iteration 1744, loss = 100674053.52778332\n",
      "Iteration 1745, loss = 100587453.33745545\n",
      "Iteration 1746, loss = 100525022.17973194\n",
      "Iteration 1747, loss = 100455681.30503064\n",
      "Iteration 1748, loss = 100374121.15383916\n",
      "Iteration 1749, loss = 100309642.59456922\n",
      "Iteration 1750, loss = 100251910.44734532\n",
      "Iteration 1751, loss = 100162666.86215504\n",
      "Iteration 1752, loss = 100081609.51699714\n",
      "Iteration 1753, loss = 100039882.84779596\n",
      "Iteration 1754, loss = 99959714.08476359\n",
      "Iteration 1755, loss = 99904616.93407628\n",
      "Iteration 1756, loss = 99838974.46862175\n",
      "Iteration 1757, loss = 99728069.80873388\n",
      "Iteration 1758, loss = 99665209.21811762\n",
      "Iteration 1759, loss = 99601434.64026700\n",
      "Iteration 1760, loss = 99522972.88433307\n",
      "Iteration 1761, loss = 99464977.13404682\n",
      "Iteration 1762, loss = 99386480.02691497\n",
      "Iteration 1763, loss = 99349225.20375341\n",
      "Iteration 1764, loss = 99265542.83989047\n",
      "Iteration 1765, loss = 99179344.46000712\n",
      "Iteration 1766, loss = 99110773.08039840\n",
      "Iteration 1767, loss = 99071641.09432122\n",
      "Iteration 1768, loss = 99001082.89567073\n",
      "Iteration 1769, loss = 98927062.42040750\n",
      "Iteration 1770, loss = 98863871.83276214\n",
      "Iteration 1771, loss = 98768561.38246824\n",
      "Iteration 1772, loss = 98760273.52435775\n",
      "Iteration 1773, loss = 98637440.92974880\n",
      "Iteration 1774, loss = 98564621.78070277\n",
      "Iteration 1775, loss = 98512698.61798152\n",
      "Iteration 1776, loss = 98492507.26635702\n",
      "Iteration 1777, loss = 98396442.68456480\n",
      "Iteration 1778, loss = 98328638.60028383\n",
      "Iteration 1779, loss = 98252499.11819896\n",
      "Iteration 1780, loss = 98226867.69270332\n",
      "Iteration 1781, loss = 98153743.14288273\n",
      "Iteration 1782, loss = 98074516.79620969\n",
      "Iteration 1783, loss = 97995059.95682034\n",
      "Iteration 1784, loss = 97952556.53929840\n",
      "Iteration 1785, loss = 97879647.76582247\n",
      "Iteration 1786, loss = 97832170.05582315\n",
      "Iteration 1787, loss = 97730461.75925951\n",
      "Iteration 1788, loss = 97711558.79059571\n",
      "Iteration 1789, loss = 97632011.65661427\n",
      "Iteration 1790, loss = 97556358.21698044\n",
      "Iteration 1791, loss = 97490448.81242341\n",
      "Iteration 1792, loss = 97455471.91627032\n",
      "Iteration 1793, loss = 97365711.38195185\n",
      "Iteration 1794, loss = 97323190.54552019\n",
      "Iteration 1795, loss = 97280484.22094178\n",
      "Iteration 1796, loss = 97185402.52694547\n",
      "Iteration 1797, loss = 97141215.29702859\n",
      "Iteration 1798, loss = 97063498.66360389\n",
      "Iteration 1799, loss = 97020963.53493075\n",
      "Iteration 1800, loss = 96950730.17464983\n",
      "Iteration 1801, loss = 96869859.62158507\n",
      "Iteration 1802, loss = 96887663.62358081\n",
      "Iteration 1803, loss = 96794680.80871391\n",
      "Iteration 1804, loss = 96721620.89127487\n",
      "Iteration 1805, loss = 96663969.11505680\n",
      "Iteration 1806, loss = 96606166.64440367\n",
      "Iteration 1807, loss = 96560171.61349560\n",
      "Iteration 1808, loss = 96494867.49453424\n",
      "Iteration 1809, loss = 96421466.52699126\n",
      "Iteration 1810, loss = 96363012.25232936\n",
      "Iteration 1811, loss = 96319282.64821514\n",
      "Iteration 1812, loss = 96277440.72579326\n",
      "Iteration 1813, loss = 96209215.24878779\n",
      "Iteration 1814, loss = 96138190.89498667\n",
      "Iteration 1815, loss = 96098556.75233242\n",
      "Iteration 1816, loss = 96034456.74891022\n",
      "Iteration 1817, loss = 95985833.19619623\n",
      "Iteration 1818, loss = 95926416.06715214\n",
      "Iteration 1819, loss = 95863456.99374940\n",
      "Iteration 1820, loss = 95820480.55699736\n",
      "Iteration 1821, loss = 95761046.91423063\n",
      "Iteration 1822, loss = 95689152.79478186\n",
      "Iteration 1823, loss = 95673004.84915352\n",
      "Iteration 1824, loss = 95590573.68354878\n",
      "Iteration 1825, loss = 95521370.78644231\n",
      "Iteration 1826, loss = 95487736.93575118\n",
      "Iteration 1827, loss = 95421206.87058300\n",
      "Iteration 1828, loss = 95365088.78937766\n",
      "Iteration 1829, loss = 95310528.71182993\n",
      "Iteration 1830, loss = 95250336.92941375\n",
      "Iteration 1831, loss = 95190403.14034609\n",
      "Iteration 1832, loss = 95154789.42611109\n",
      "Iteration 1833, loss = 95082612.14783683\n",
      "Iteration 1834, loss = 95015345.77595749\n",
      "Iteration 1835, loss = 94963784.85718408\n",
      "Iteration 1836, loss = 94926112.25658457\n",
      "Iteration 1837, loss = 94860686.54164796\n",
      "Iteration 1838, loss = 94845175.91987273\n",
      "Iteration 1839, loss = 94744704.45504279\n",
      "Iteration 1840, loss = 94711551.29950266\n",
      "Iteration 1841, loss = 94650351.27637276\n",
      "Iteration 1842, loss = 94595551.35224034\n",
      "Iteration 1843, loss = 94558480.52127005\n",
      "Iteration 1844, loss = 94507408.68269460\n",
      "Iteration 1845, loss = 94431805.12405892\n",
      "Iteration 1846, loss = 94387477.05488822\n",
      "Iteration 1847, loss = 94342914.40088391\n",
      "Iteration 1848, loss = 94309138.97456323\n",
      "Iteration 1849, loss = 94258170.68945172\n",
      "Iteration 1850, loss = 94188152.84851059\n",
      "Iteration 1851, loss = 94140519.21702263\n",
      "Iteration 1852, loss = 94082913.54491764\n",
      "Iteration 1853, loss = 94027062.26845422\n",
      "Iteration 1854, loss = 94001380.62591715\n",
      "Iteration 1855, loss = 93919909.24384394\n",
      "Iteration 1856, loss = 93878969.61795408\n",
      "Iteration 1857, loss = 93814440.80195254\n",
      "Iteration 1858, loss = 93758756.06369159\n",
      "Iteration 1859, loss = 93712392.02066082\n",
      "Iteration 1860, loss = 93669669.27500623\n",
      "Iteration 1861, loss = 93623381.82538800\n",
      "Iteration 1862, loss = 93561252.52075037\n",
      "Iteration 1863, loss = 93541710.66112249\n",
      "Iteration 1864, loss = 93464737.31790380\n",
      "Iteration 1865, loss = 93445091.66072994\n",
      "Iteration 1866, loss = 93369496.79327849\n",
      "Iteration 1867, loss = 93315808.07505490\n",
      "Iteration 1868, loss = 93276427.13300410\n",
      "Iteration 1869, loss = 93236453.94911608\n",
      "Iteration 1870, loss = 93185550.70755479\n",
      "Iteration 1871, loss = 93106345.66794977\n",
      "Iteration 1872, loss = 93107274.09098160\n",
      "Iteration 1873, loss = 93023730.48074272\n",
      "Iteration 1874, loss = 92969361.34928532\n",
      "Iteration 1875, loss = 92968442.62274797\n",
      "Iteration 1876, loss = 92892639.84978500\n",
      "Iteration 1877, loss = 92854958.86994636\n",
      "Iteration 1878, loss = 92801704.24889815\n",
      "Iteration 1879, loss = 92739632.57230768\n",
      "Iteration 1880, loss = 92720773.32691619\n",
      "Iteration 1881, loss = 92674519.74173786\n",
      "Iteration 1882, loss = 92606283.46379705\n",
      "Iteration 1883, loss = 92566377.30696695\n",
      "Iteration 1884, loss = 92530850.57108355\n",
      "Iteration 1885, loss = 92512932.21454583\n",
      "Iteration 1886, loss = 92421616.29255232\n",
      "Iteration 1887, loss = 92415599.55481532\n",
      "Iteration 1888, loss = 92338422.23133783\n",
      "Iteration 1889, loss = 92300621.98468505\n",
      "Iteration 1890, loss = 92264988.34366257\n",
      "Iteration 1891, loss = 92201839.18367971\n",
      "Iteration 1892, loss = 92214534.37448466\n",
      "Iteration 1893, loss = 92109625.73206538\n",
      "Iteration 1894, loss = 92080626.89427364\n",
      "Iteration 1895, loss = 92061743.14640903\n",
      "Iteration 1896, loss = 91990362.85556242\n",
      "Iteration 1897, loss = 91958927.44893709\n",
      "Iteration 1898, loss = 91907610.99353619\n",
      "Iteration 1899, loss = 91921867.22735837\n",
      "Iteration 1900, loss = 91839883.39706168\n",
      "Iteration 1901, loss = 91795685.70723096\n",
      "Iteration 1902, loss = 91768144.08293143\n",
      "Iteration 1903, loss = 91723265.04479270\n",
      "Iteration 1904, loss = 91677998.04645915\n",
      "Iteration 1905, loss = 91615971.96679471\n",
      "Iteration 1906, loss = 91604248.52129042\n",
      "Iteration 1907, loss = 91564222.45330922\n",
      "Iteration 1908, loss = 91512257.87998161\n",
      "Iteration 1909, loss = 91468878.56258662\n",
      "Iteration 1910, loss = 91424106.16565722\n",
      "Iteration 1911, loss = 91376071.71953015\n",
      "Iteration 1912, loss = 91344575.21167806\n",
      "Iteration 1913, loss = 91343384.78666840\n",
      "Iteration 1914, loss = 91260055.38650122\n",
      "Iteration 1915, loss = 91229418.51180574\n",
      "Iteration 1916, loss = 91179780.99592432\n",
      "Iteration 1917, loss = 91333849.20945394\n",
      "Iteration 1918, loss = 91082473.61925450\n",
      "Iteration 1919, loss = 91066752.15085649\n",
      "Iteration 1920, loss = 91036557.62130138\n",
      "Iteration 1921, loss = 90993247.80305785\n",
      "Iteration 1922, loss = 90942192.30297785\n",
      "Iteration 1923, loss = 90891420.00627171\n",
      "Iteration 1924, loss = 90869535.63862257\n",
      "Iteration 1925, loss = 90847377.33647704\n",
      "Iteration 1926, loss = 90805514.79335496\n",
      "Iteration 1927, loss = 90769107.32250077\n",
      "Iteration 1928, loss = 90717382.80411664\n",
      "Iteration 1929, loss = 90694455.01379095\n",
      "Iteration 1930, loss = 90638605.48706025\n",
      "Iteration 1931, loss = 90604194.41614029\n",
      "Iteration 1932, loss = 90555606.27273628\n",
      "Iteration 1933, loss = 90517489.59435077\n",
      "Iteration 1934, loss = 90478408.45114817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1935, loss = 90474911.95855092\n",
      "Iteration 1936, loss = 90414611.06531715\n",
      "Iteration 1937, loss = 90378210.95239778\n",
      "Iteration 1938, loss = 90340878.06238483\n",
      "Iteration 1939, loss = 90291563.77817318\n",
      "Iteration 1940, loss = 90252613.94402178\n",
      "Iteration 1941, loss = 90207185.54338881\n",
      "Iteration 1942, loss = 90153093.81375287\n",
      "Iteration 1943, loss = 90156093.92364205\n",
      "Iteration 1944, loss = 90101754.49463832\n",
      "Iteration 1945, loss = 90048518.53716531\n",
      "Iteration 1946, loss = 90028510.18884547\n",
      "Iteration 1947, loss = 89998094.35528420\n",
      "Iteration 1948, loss = 89949275.38861305\n",
      "Iteration 1949, loss = 89920829.79763402\n",
      "Iteration 1950, loss = 89849059.42634571\n",
      "Iteration 1951, loss = 89832521.14070660\n",
      "Iteration 1952, loss = 89806097.06500737\n",
      "Iteration 1953, loss = 89752932.37403132\n",
      "Iteration 1954, loss = 89707222.94689853\n",
      "Iteration 1955, loss = 89692166.35576189\n",
      "Iteration 1956, loss = 89640427.35625696\n",
      "Iteration 1957, loss = 89607488.14380473\n",
      "Iteration 1958, loss = 89566741.97105274\n",
      "Iteration 1959, loss = 89530164.10475157\n",
      "Iteration 1960, loss = 89490612.04946738\n",
      "Iteration 1961, loss = 89487246.93025784\n",
      "Iteration 1962, loss = 89434818.13476314\n",
      "Iteration 1963, loss = 89371640.57263672\n",
      "Iteration 1964, loss = 89361233.02821901\n",
      "Iteration 1965, loss = 89346378.56257024\n",
      "Iteration 1966, loss = 89272056.21507488\n",
      "Iteration 1967, loss = 89234742.19710447\n",
      "Iteration 1968, loss = 89219448.24734889\n",
      "Iteration 1969, loss = 89158911.19816375\n",
      "Iteration 1970, loss = 89142003.00685515\n",
      "Iteration 1971, loss = 89101753.35169616\n",
      "Iteration 1972, loss = 89065447.87151259\n",
      "Iteration 1973, loss = 89044481.13273530\n",
      "Iteration 1974, loss = 88973051.85882840\n",
      "Iteration 1975, loss = 88944960.08358854\n",
      "Iteration 1976, loss = 88944145.56484765\n",
      "Iteration 1977, loss = 88878920.68712847\n",
      "Iteration 1978, loss = 88841735.10723688\n",
      "Iteration 1979, loss = 88819467.83921638\n",
      "Iteration 1980, loss = 88758570.52616760\n",
      "Iteration 1981, loss = 88744689.21788117\n",
      "Iteration 1982, loss = 88695568.04640426\n",
      "Iteration 1983, loss = 88690016.64766552\n",
      "Iteration 1984, loss = 88602662.01876180\n",
      "Iteration 1985, loss = 88593534.68907666\n",
      "Iteration 1986, loss = 88551220.73065712\n",
      "Iteration 1987, loss = 88521887.13584325\n",
      "Iteration 1988, loss = 88472145.09254873\n",
      "Iteration 1989, loss = 88462296.64395735\n",
      "Iteration 1990, loss = 88402981.03357932\n",
      "Iteration 1991, loss = 88380170.15209696\n",
      "Iteration 1992, loss = 88323720.77766205\n",
      "Iteration 1993, loss = 88330133.28935561\n",
      "Iteration 1994, loss = 88266087.65179023\n",
      "Iteration 1995, loss = 88230342.91639121\n",
      "Iteration 1996, loss = 88182929.67787234\n",
      "Iteration 1997, loss = 88172118.28289539\n",
      "Iteration 1998, loss = 88164203.49400267\n",
      "Iteration 1999, loss = 88095646.55428836\n",
      "Iteration 2000, loss = 88050124.49898773\n",
      "Iteration 1, loss = 2757686040.63122368\n",
      "Iteration 2, loss = 2754683134.13493299\n",
      "Iteration 3, loss = 2748720793.96323824\n",
      "Iteration 4, loss = 2738936484.56913471\n",
      "Iteration 5, loss = 2726930850.78311682\n",
      "Iteration 6, loss = 2712548813.10728168\n",
      "Iteration 7, loss = 2695844329.56518555\n",
      "Iteration 8, loss = 2676975139.23891687\n",
      "Iteration 9, loss = 2656103896.19147635\n",
      "Iteration 10, loss = 2633274066.39623737\n",
      "Iteration 11, loss = 2608644975.46482563\n",
      "Iteration 12, loss = 2582395933.33049011\n",
      "Iteration 13, loss = 2554644845.86843729\n",
      "Iteration 14, loss = 2525506021.67667055\n",
      "Iteration 15, loss = 2495068575.60214472\n",
      "Iteration 16, loss = 2463360846.40850830\n",
      "Iteration 17, loss = 2430631908.93595982\n",
      "Iteration 18, loss = 2396798672.54443502\n",
      "Iteration 19, loss = 2362110612.83459473\n",
      "Iteration 20, loss = 2326728927.45307970\n",
      "Iteration 21, loss = 2290531312.33088970\n",
      "Iteration 22, loss = 2253716576.19199848\n",
      "Iteration 23, loss = 2216077898.45735168\n",
      "Iteration 24, loss = 2178074754.00229454\n",
      "Iteration 25, loss = 2139844001.29839659\n",
      "Iteration 26, loss = 2101065378.17389035\n",
      "Iteration 27, loss = 2062346131.32894945\n",
      "Iteration 28, loss = 2023415612.24232268\n",
      "Iteration 29, loss = 1984164301.90500569\n",
      "Iteration 30, loss = 1944761282.64493728\n",
      "Iteration 31, loss = 1905948326.04121852\n",
      "Iteration 32, loss = 1867264757.19956517\n",
      "Iteration 33, loss = 1828480018.73943901\n",
      "Iteration 34, loss = 1789955105.61836600\n",
      "Iteration 35, loss = 1751800499.81109166\n",
      "Iteration 36, loss = 1714005623.06945014\n",
      "Iteration 37, loss = 1676507658.89712000\n",
      "Iteration 38, loss = 1639512767.32579756\n",
      "Iteration 39, loss = 1602945220.65357995\n",
      "Iteration 40, loss = 1566427228.39282680\n",
      "Iteration 41, loss = 1531236919.92549062\n",
      "Iteration 42, loss = 1496359787.91445160\n",
      "Iteration 43, loss = 1462368053.95594573\n",
      "Iteration 44, loss = 1429165400.67286086\n",
      "Iteration 45, loss = 1396597787.35632443\n",
      "Iteration 46, loss = 1364745226.70133638\n",
      "Iteration 47, loss = 1333963359.09164190\n",
      "Iteration 48, loss = 1303948437.77511692\n",
      "Iteration 49, loss = 1274805419.71489716\n",
      "Iteration 50, loss = 1246641523.54515648\n",
      "Iteration 51, loss = 1219539103.07961035\n",
      "Iteration 52, loss = 1193107620.98633337\n",
      "Iteration 53, loss = 1167929990.69797111\n",
      "Iteration 54, loss = 1143648589.40049863\n",
      "Iteration 55, loss = 1120612447.27752733\n",
      "Iteration 56, loss = 1098958604.00661087\n",
      "Iteration 57, loss = 1078254536.83001184\n",
      "Iteration 58, loss = 1058596477.45836663\n",
      "Iteration 59, loss = 1039911767.59424293\n",
      "Iteration 60, loss = 1022447050.86622071\n",
      "Iteration 61, loss = 1005968238.82692134\n",
      "Iteration 62, loss = 990757093.33000278\n",
      "Iteration 63, loss = 976392244.63121951\n",
      "Iteration 64, loss = 963228606.41355276\n",
      "Iteration 65, loss = 950968252.38774633\n",
      "Iteration 66, loss = 939810611.37064421\n",
      "Iteration 67, loss = 929585154.84302640\n",
      "Iteration 68, loss = 920474513.72211874\n",
      "Iteration 69, loss = 912255922.78251445\n",
      "Iteration 70, loss = 904932711.35522592\n",
      "Iteration 71, loss = 898079897.67641664\n",
      "Iteration 72, loss = 892132915.87714875\n",
      "Iteration 73, loss = 887121731.45816970\n",
      "Iteration 74, loss = 882856202.44865620\n",
      "Iteration 75, loss = 879097221.86745381\n",
      "Iteration 76, loss = 875877354.03218472\n",
      "Iteration 77, loss = 873066676.98086679\n",
      "Iteration 78, loss = 870765485.65579879\n",
      "Iteration 79, loss = 868856762.85637176\n",
      "Iteration 80, loss = 867266266.03098369\n",
      "Iteration 81, loss = 865872242.71482289\n",
      "Iteration 82, loss = 864702920.59209025\n",
      "Iteration 83, loss = 863781013.62606466\n",
      "Iteration 84, loss = 862973697.42456305\n",
      "Iteration 85, loss = 862326374.52522790\n",
      "Iteration 86, loss = 861718805.54480410\n",
      "Iteration 87, loss = 861231883.67809403\n",
      "Iteration 88, loss = 860808304.94233584\n",
      "Iteration 89, loss = 860423961.42534673\n",
      "Iteration 90, loss = 860060796.90624309\n",
      "Iteration 91, loss = 859716947.69174159\n",
      "Iteration 92, loss = 859347294.84375608\n",
      "Iteration 93, loss = 858997502.55796349\n",
      "Iteration 94, loss = 858677590.98071742\n",
      "Iteration 95, loss = 858343741.07735765\n",
      "Iteration 96, loss = 858002222.50348532\n",
      "Iteration 97, loss = 857647304.98821473\n",
      "Iteration 98, loss = 857297071.89744377\n",
      "Iteration 99, loss = 856966844.28602135\n",
      "Iteration 100, loss = 856635124.00588107\n",
      "Iteration 101, loss = 856282192.65676951\n",
      "Iteration 102, loss = 855927339.62624681\n",
      "Iteration 103, loss = 855586496.95126367\n",
      "Iteration 104, loss = 855232130.55499530\n",
      "Iteration 105, loss = 854876215.08539212\n",
      "Iteration 106, loss = 854516024.64303017\n",
      "Iteration 107, loss = 854172948.90175521\n",
      "Iteration 108, loss = 853800701.66407752\n",
      "Iteration 109, loss = 853438464.56634843\n",
      "Iteration 110, loss = 853085429.15317035\n",
      "Iteration 111, loss = 852723149.54953194\n",
      "Iteration 112, loss = 852352576.61928713\n",
      "Iteration 113, loss = 851992036.86796319\n",
      "Iteration 114, loss = 851611845.93218148\n",
      "Iteration 115, loss = 851266213.29253411\n",
      "Iteration 116, loss = 850896336.74079406\n",
      "Iteration 117, loss = 850524503.99775672\n",
      "Iteration 118, loss = 850144815.86003566\n",
      "Iteration 119, loss = 849776848.66449547\n",
      "Iteration 120, loss = 849401201.32688344\n",
      "Iteration 121, loss = 849031515.27733457\n",
      "Iteration 122, loss = 848670452.77018678\n",
      "Iteration 123, loss = 848307443.73497486\n",
      "Iteration 124, loss = 847939116.92315042\n",
      "Iteration 125, loss = 847560365.18431437\n",
      "Iteration 126, loss = 847201856.02023292\n",
      "Iteration 127, loss = 846826221.59451532\n",
      "Iteration 128, loss = 846480147.10223138\n",
      "Iteration 129, loss = 846097088.70006120\n",
      "Iteration 130, loss = 845746425.26588500\n",
      "Iteration 131, loss = 845359424.26558912\n",
      "Iteration 132, loss = 844991000.25120199\n",
      "Iteration 133, loss = 844610141.85161150\n",
      "Iteration 134, loss = 844232730.16750443\n",
      "Iteration 135, loss = 843858102.07413304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 136, loss = 843479737.71781945\n",
      "Iteration 137, loss = 843132756.76368988\n",
      "Iteration 138, loss = 842755233.12637877\n",
      "Iteration 139, loss = 842369338.54262292\n",
      "Iteration 140, loss = 842017955.44272137\n",
      "Iteration 141, loss = 841640629.82747126\n",
      "Iteration 142, loss = 841261195.32476270\n",
      "Iteration 143, loss = 840885355.97538400\n",
      "Iteration 144, loss = 840483773.21430385\n",
      "Iteration 145, loss = 840150411.58661246\n",
      "Iteration 146, loss = 839787182.65445888\n",
      "Iteration 147, loss = 839406266.91664016\n",
      "Iteration 148, loss = 839026379.95060444\n",
      "Iteration 149, loss = 838656357.22273445\n",
      "Iteration 150, loss = 838299933.42415643\n",
      "Iteration 151, loss = 837924296.37711167\n",
      "Iteration 152, loss = 837529489.12792063\n",
      "Iteration 153, loss = 837177899.04386127\n",
      "Iteration 154, loss = 836790988.35571623\n",
      "Iteration 155, loss = 836426360.37138951\n",
      "Iteration 156, loss = 836068246.92234647\n",
      "Iteration 157, loss = 835680912.38674557\n",
      "Iteration 158, loss = 835303114.67800605\n",
      "Iteration 159, loss = 834958551.05730283\n",
      "Iteration 160, loss = 834561099.36799741\n",
      "Iteration 161, loss = 834194050.89107883\n",
      "Iteration 162, loss = 833821172.83744347\n",
      "Iteration 163, loss = 833425243.16470277\n",
      "Iteration 164, loss = 833082634.38981318\n",
      "Iteration 165, loss = 832702924.61227679\n",
      "Iteration 166, loss = 832298733.68929362\n",
      "Iteration 167, loss = 831933976.43062449\n",
      "Iteration 168, loss = 831545561.39552987\n",
      "Iteration 169, loss = 831165400.62976408\n",
      "Iteration 170, loss = 830799998.20075679\n",
      "Iteration 171, loss = 830427680.12424481\n",
      "Iteration 172, loss = 830031399.99259484\n",
      "Iteration 173, loss = 829658926.87750673\n",
      "Iteration 174, loss = 829302505.43940425\n",
      "Iteration 175, loss = 828924949.39647174\n",
      "Iteration 176, loss = 828556821.32925284\n",
      "Iteration 177, loss = 828170817.80665374\n",
      "Iteration 178, loss = 827802932.99050236\n",
      "Iteration 179, loss = 827387986.75902307\n",
      "Iteration 180, loss = 826997358.84030509\n",
      "Iteration 181, loss = 826581903.60632610\n",
      "Iteration 182, loss = 826190138.41430843\n",
      "Iteration 183, loss = 825798933.96520090\n",
      "Iteration 184, loss = 825352808.81012940\n",
      "Iteration 185, loss = 824937949.81129861\n",
      "Iteration 186, loss = 824521503.44929540\n",
      "Iteration 187, loss = 824093412.22029281\n",
      "Iteration 188, loss = 823685923.63901687\n",
      "Iteration 189, loss = 823245214.71746993\n",
      "Iteration 190, loss = 822832978.76582193\n",
      "Iteration 191, loss = 822390205.69566154\n",
      "Iteration 192, loss = 821959724.16732180\n",
      "Iteration 193, loss = 821531197.22526717\n",
      "Iteration 194, loss = 821113676.50521255\n",
      "Iteration 195, loss = 820681570.37585223\n",
      "Iteration 196, loss = 820244113.88284492\n",
      "Iteration 197, loss = 819795579.56317306\n",
      "Iteration 198, loss = 819365686.20891523\n",
      "Iteration 199, loss = 818934939.24737155\n",
      "Iteration 200, loss = 818503143.35782683\n",
      "Iteration 201, loss = 818052921.85826790\n",
      "Iteration 202, loss = 817613107.58907676\n",
      "Iteration 203, loss = 817185462.08670807\n",
      "Iteration 204, loss = 816720047.39726472\n",
      "Iteration 205, loss = 816279040.51963532\n",
      "Iteration 206, loss = 815859678.96093214\n",
      "Iteration 207, loss = 815389209.53594172\n",
      "Iteration 208, loss = 814921786.92854142\n",
      "Iteration 209, loss = 814473307.62444913\n",
      "Iteration 210, loss = 814015770.49192643\n",
      "Iteration 211, loss = 813559147.31297314\n",
      "Iteration 212, loss = 813095022.76724362\n",
      "Iteration 213, loss = 812635236.55752516\n",
      "Iteration 214, loss = 812173648.27117145\n",
      "Iteration 215, loss = 811711920.49929583\n",
      "Iteration 216, loss = 811263235.99788153\n",
      "Iteration 217, loss = 810821254.10816002\n",
      "Iteration 218, loss = 810340095.06680226\n",
      "Iteration 219, loss = 809865433.04998529\n",
      "Iteration 220, loss = 809394695.23327506\n",
      "Iteration 221, loss = 808937375.85702264\n",
      "Iteration 222, loss = 808475413.85721302\n",
      "Iteration 223, loss = 807992884.81511343\n",
      "Iteration 224, loss = 807522207.63613415\n",
      "Iteration 225, loss = 807064041.65008175\n",
      "Iteration 226, loss = 806597179.69972658\n",
      "Iteration 227, loss = 806127956.97126770\n",
      "Iteration 228, loss = 805639313.98202336\n",
      "Iteration 229, loss = 805171144.78030264\n",
      "Iteration 230, loss = 804689467.33794451\n",
      "Iteration 231, loss = 804234875.25639117\n",
      "Iteration 232, loss = 803781890.74884796\n",
      "Iteration 233, loss = 803278718.20715415\n",
      "Iteration 234, loss = 802805695.89206374\n",
      "Iteration 235, loss = 802329680.69517267\n",
      "Iteration 236, loss = 801853495.00535905\n",
      "Iteration 237, loss = 801378630.77441525\n",
      "Iteration 238, loss = 800885800.50622237\n",
      "Iteration 239, loss = 800404539.11484647\n",
      "Iteration 240, loss = 799927020.35127819\n",
      "Iteration 241, loss = 799423998.78766739\n",
      "Iteration 242, loss = 798936885.75230539\n",
      "Iteration 243, loss = 798461162.91360390\n",
      "Iteration 244, loss = 797950692.74010849\n",
      "Iteration 245, loss = 797462643.12535048\n",
      "Iteration 246, loss = 796976334.95432246\n",
      "Iteration 247, loss = 796479373.89316821\n",
      "Iteration 248, loss = 795981193.77123320\n",
      "Iteration 249, loss = 795474567.73909557\n",
      "Iteration 250, loss = 794986156.19436789\n",
      "Iteration 251, loss = 794495598.84447873\n",
      "Iteration 252, loss = 794003366.57613409\n",
      "Iteration 253, loss = 793498283.28988910\n",
      "Iteration 254, loss = 793026190.66299224\n",
      "Iteration 255, loss = 792512798.65835226\n",
      "Iteration 256, loss = 792005101.70897388\n",
      "Iteration 257, loss = 791501184.72644365\n",
      "Iteration 258, loss = 790978832.16313899\n",
      "Iteration 259, loss = 790477906.73006964\n",
      "Iteration 260, loss = 789960393.09934425\n",
      "Iteration 261, loss = 789445941.48408139\n",
      "Iteration 262, loss = 788934250.54618478\n",
      "Iteration 263, loss = 788431797.63099194\n",
      "Iteration 264, loss = 787882963.84089589\n",
      "Iteration 265, loss = 787366720.12941730\n",
      "Iteration 266, loss = 786849486.55176950\n",
      "Iteration 267, loss = 786313850.02130842\n",
      "Iteration 268, loss = 785775908.76712751\n",
      "Iteration 269, loss = 785257276.87634647\n",
      "Iteration 270, loss = 784716313.59095883\n",
      "Iteration 271, loss = 784183780.01063645\n",
      "Iteration 272, loss = 783649963.97944546\n",
      "Iteration 273, loss = 783132981.54105794\n",
      "Iteration 274, loss = 782568762.18320680\n",
      "Iteration 275, loss = 782033287.13338995\n",
      "Iteration 276, loss = 781489819.66435826\n",
      "Iteration 277, loss = 780963964.26666474\n",
      "Iteration 278, loss = 780413323.70812118\n",
      "Iteration 279, loss = 779859718.08702981\n",
      "Iteration 280, loss = 779317699.60909641\n",
      "Iteration 281, loss = 778762955.06627953\n",
      "Iteration 282, loss = 778219773.67484331\n",
      "Iteration 283, loss = 777664764.10240912\n",
      "Iteration 284, loss = 777109614.56813240\n",
      "Iteration 285, loss = 776562867.42839634\n",
      "Iteration 286, loss = 776024494.85706365\n",
      "Iteration 287, loss = 775460501.89792645\n",
      "Iteration 288, loss = 774929751.38700819\n",
      "Iteration 289, loss = 774351124.84442627\n",
      "Iteration 290, loss = 773801207.36046207\n",
      "Iteration 291, loss = 773284689.36009574\n",
      "Iteration 292, loss = 772706592.19253051\n",
      "Iteration 293, loss = 772148236.07780349\n",
      "Iteration 294, loss = 771617050.80957711\n",
      "Iteration 295, loss = 771066006.50241137\n",
      "Iteration 296, loss = 770517529.45248163\n",
      "Iteration 297, loss = 769983556.28317738\n",
      "Iteration 298, loss = 769419525.04353011\n",
      "Iteration 299, loss = 768853545.25996828\n",
      "Iteration 300, loss = 768287032.69472766\n",
      "Iteration 301, loss = 767753322.30897284\n",
      "Iteration 302, loss = 767153614.73277259\n",
      "Iteration 303, loss = 766599276.28613067\n",
      "Iteration 304, loss = 766041555.33317769\n",
      "Iteration 305, loss = 765464034.38552225\n",
      "Iteration 306, loss = 764883676.82369864\n",
      "Iteration 307, loss = 764303806.11782444\n",
      "Iteration 308, loss = 763765422.24529135\n",
      "Iteration 309, loss = 763169104.55669391\n",
      "Iteration 310, loss = 762591922.87681568\n",
      "Iteration 311, loss = 762025065.98939776\n",
      "Iteration 312, loss = 761437230.67160463\n",
      "Iteration 313, loss = 760853598.15858126\n",
      "Iteration 314, loss = 760295448.16823363\n",
      "Iteration 315, loss = 759696925.32177699\n",
      "Iteration 316, loss = 759121520.98056757\n",
      "Iteration 317, loss = 758519244.66127563\n",
      "Iteration 318, loss = 757941241.23345673\n",
      "Iteration 319, loss = 757353242.53975749\n",
      "Iteration 320, loss = 756760884.53609359\n",
      "Iteration 321, loss = 756142581.15221405\n",
      "Iteration 322, loss = 755552103.42544568\n",
      "Iteration 323, loss = 754955347.21387970\n",
      "Iteration 324, loss = 754387599.22587192\n",
      "Iteration 325, loss = 753789795.21408570\n",
      "Iteration 326, loss = 753193400.05173087\n",
      "Iteration 327, loss = 752588127.37343073\n",
      "Iteration 328, loss = 751986931.47502804\n",
      "Iteration 329, loss = 751401362.32440221\n",
      "Iteration 330, loss = 750788390.49830759\n",
      "Iteration 331, loss = 750193223.58926237\n",
      "Iteration 332, loss = 749584281.35138011\n",
      "Iteration 333, loss = 748983061.92982829\n",
      "Iteration 334, loss = 748373024.72159839\n",
      "Iteration 335, loss = 747776034.76174581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 336, loss = 747164707.04470050\n",
      "Iteration 337, loss = 746551077.68817925\n",
      "Iteration 338, loss = 745968630.36340928\n",
      "Iteration 339, loss = 745331620.71318626\n",
      "Iteration 340, loss = 744706034.59031463\n",
      "Iteration 341, loss = 744143533.52793443\n",
      "Iteration 342, loss = 743496050.81176019\n",
      "Iteration 343, loss = 742877394.92459738\n",
      "Iteration 344, loss = 742254710.11985111\n",
      "Iteration 345, loss = 741650547.48531473\n",
      "Iteration 346, loss = 741017278.82332659\n",
      "Iteration 347, loss = 740395507.19704258\n",
      "Iteration 348, loss = 739784074.50847447\n",
      "Iteration 349, loss = 739163908.96476293\n",
      "Iteration 350, loss = 738515250.50151181\n",
      "Iteration 351, loss = 737936390.33423042\n",
      "Iteration 352, loss = 737302291.62600601\n",
      "Iteration 353, loss = 736661308.24646068\n",
      "Iteration 354, loss = 736015319.66301405\n",
      "Iteration 355, loss = 735377157.80165780\n",
      "Iteration 356, loss = 734743466.94373226\n",
      "Iteration 357, loss = 734110702.93099713\n",
      "Iteration 358, loss = 733487558.97735465\n",
      "Iteration 359, loss = 732848947.51803541\n",
      "Iteration 360, loss = 732214526.96442628\n",
      "Iteration 361, loss = 731555491.74765813\n",
      "Iteration 362, loss = 730903374.23141551\n",
      "Iteration 363, loss = 730286782.28889585\n",
      "Iteration 364, loss = 729629725.64047158\n",
      "Iteration 365, loss = 728988341.75031769\n",
      "Iteration 366, loss = 728350621.75112796\n",
      "Iteration 367, loss = 727722059.65884113\n",
      "Iteration 368, loss = 727071362.04676175\n",
      "Iteration 369, loss = 726429663.74397624\n",
      "Iteration 370, loss = 725776427.35143447\n",
      "Iteration 371, loss = 725125671.50604248\n",
      "Iteration 372, loss = 724469942.38975275\n",
      "Iteration 373, loss = 723852836.51026750\n",
      "Iteration 374, loss = 723185222.10352683\n",
      "Iteration 375, loss = 722506741.49095821\n",
      "Iteration 376, loss = 721853259.90095735\n",
      "Iteration 377, loss = 721194980.23138273\n",
      "Iteration 378, loss = 720528274.77250230\n",
      "Iteration 379, loss = 719883046.63485968\n",
      "Iteration 380, loss = 719189364.64636075\n",
      "Iteration 381, loss = 718536602.45603395\n",
      "Iteration 382, loss = 717860039.77434182\n",
      "Iteration 383, loss = 717188094.17857778\n",
      "Iteration 384, loss = 716544088.27101719\n",
      "Iteration 385, loss = 715836297.56157756\n",
      "Iteration 386, loss = 715195518.15974212\n",
      "Iteration 387, loss = 714502410.89573610\n",
      "Iteration 388, loss = 713846205.76052713\n",
      "Iteration 389, loss = 713176945.68118918\n",
      "Iteration 390, loss = 712520877.39929998\n",
      "Iteration 391, loss = 711843089.68516564\n",
      "Iteration 392, loss = 711171969.08723342\n",
      "Iteration 393, loss = 710506913.52125597\n",
      "Iteration 394, loss = 709841886.07369101\n",
      "Iteration 395, loss = 709171571.80107331\n",
      "Iteration 396, loss = 708471280.92162752\n",
      "Iteration 397, loss = 707794156.82824242\n",
      "Iteration 398, loss = 707110172.26772130\n",
      "Iteration 399, loss = 706433402.82769954\n",
      "Iteration 400, loss = 705743888.04286027\n",
      "Iteration 401, loss = 705043396.23083258\n",
      "Iteration 402, loss = 704373959.18839037\n",
      "Iteration 403, loss = 703694573.47893107\n",
      "Iteration 404, loss = 703026212.22682929\n",
      "Iteration 405, loss = 702309036.91120386\n",
      "Iteration 406, loss = 701622087.96127462\n",
      "Iteration 407, loss = 700944290.84317124\n",
      "Iteration 408, loss = 700270131.55742741\n",
      "Iteration 409, loss = 699584227.25401962\n",
      "Iteration 410, loss = 698898322.70308268\n",
      "Iteration 411, loss = 698181665.06796718\n",
      "Iteration 412, loss = 697497657.42399013\n",
      "Iteration 413, loss = 696807979.95430279\n",
      "Iteration 414, loss = 696112365.88704813\n",
      "Iteration 415, loss = 695401496.85103261\n",
      "Iteration 416, loss = 694692899.97095716\n",
      "Iteration 417, loss = 693971173.45953107\n",
      "Iteration 418, loss = 693262481.52048218\n",
      "Iteration 419, loss = 692560572.05274296\n",
      "Iteration 420, loss = 691868030.35965216\n",
      "Iteration 421, loss = 691146356.99932623\n",
      "Iteration 422, loss = 690416072.29832017\n",
      "Iteration 423, loss = 689692928.09956539\n",
      "Iteration 424, loss = 688976536.91113913\n",
      "Iteration 425, loss = 688248243.33867288\n",
      "Iteration 426, loss = 687529620.09831011\n",
      "Iteration 427, loss = 686798566.82743227\n",
      "Iteration 428, loss = 686088439.79887474\n",
      "Iteration 429, loss = 685348368.82805407\n",
      "Iteration 430, loss = 684653390.10488319\n",
      "Iteration 431, loss = 683922557.47438884\n",
      "Iteration 432, loss = 683174425.82690132\n",
      "Iteration 433, loss = 682451695.75142205\n",
      "Iteration 434, loss = 681725264.62621772\n",
      "Iteration 435, loss = 680991671.87013006\n",
      "Iteration 436, loss = 680275991.06095815\n",
      "Iteration 437, loss = 679528280.17445970\n",
      "Iteration 438, loss = 678805170.44636321\n",
      "Iteration 439, loss = 678058326.25764585\n",
      "Iteration 440, loss = 677359521.32816899\n",
      "Iteration 441, loss = 676611557.77424824\n",
      "Iteration 442, loss = 675864629.47278047\n",
      "Iteration 443, loss = 675145961.17023516\n",
      "Iteration 444, loss = 674398511.00879705\n",
      "Iteration 445, loss = 673666504.61952364\n",
      "Iteration 446, loss = 672934143.61651826\n",
      "Iteration 447, loss = 672198937.03642261\n",
      "Iteration 448, loss = 671504871.37080431\n",
      "Iteration 449, loss = 670737897.47712505\n",
      "Iteration 450, loss = 669986811.84421313\n",
      "Iteration 451, loss = 669248507.42686093\n",
      "Iteration 452, loss = 668514222.65078449\n",
      "Iteration 453, loss = 667776615.95884371\n",
      "Iteration 454, loss = 667060114.14321339\n",
      "Iteration 455, loss = 666340901.57553315\n",
      "Iteration 456, loss = 665577704.67449880\n",
      "Iteration 457, loss = 664848458.33886528\n",
      "Iteration 458, loss = 664151727.27405703\n",
      "Iteration 459, loss = 663372439.36308026\n",
      "Iteration 460, loss = 662636525.09811056\n",
      "Iteration 461, loss = 661916221.76860559\n",
      "Iteration 462, loss = 661164421.74888635\n",
      "Iteration 463, loss = 660412974.70252943\n",
      "Iteration 464, loss = 659692400.94526052\n",
      "Iteration 465, loss = 658967840.87102449\n",
      "Iteration 466, loss = 658214228.74436104\n",
      "Iteration 467, loss = 657487431.31858826\n",
      "Iteration 468, loss = 656732927.70113945\n",
      "Iteration 469, loss = 655975935.80215180\n",
      "Iteration 470, loss = 655233736.52810800\n",
      "Iteration 471, loss = 654506292.62519288\n",
      "Iteration 472, loss = 653755314.84520829\n",
      "Iteration 473, loss = 653019944.80642092\n",
      "Iteration 474, loss = 652251648.76622641\n",
      "Iteration 475, loss = 651518207.43767667\n",
      "Iteration 476, loss = 650753554.64723027\n",
      "Iteration 477, loss = 650018640.33534086\n",
      "Iteration 478, loss = 649252350.48834038\n",
      "Iteration 479, loss = 648511151.07740581\n",
      "Iteration 480, loss = 647719176.87444925\n",
      "Iteration 481, loss = 646960151.42380929\n",
      "Iteration 482, loss = 646187953.29049134\n",
      "Iteration 483, loss = 645428615.61229670\n",
      "Iteration 484, loss = 644683186.86604607\n",
      "Iteration 485, loss = 643917371.41703343\n",
      "Iteration 486, loss = 643172630.75033057\n",
      "Iteration 487, loss = 642406711.07420707\n",
      "Iteration 488, loss = 641675516.57648468\n",
      "Iteration 489, loss = 640886075.15459061\n",
      "Iteration 490, loss = 640127903.89458191\n",
      "Iteration 491, loss = 639369384.98052239\n",
      "Iteration 492, loss = 638598449.44394326\n",
      "Iteration 493, loss = 637864092.71434927\n",
      "Iteration 494, loss = 637080123.03084767\n",
      "Iteration 495, loss = 636331177.96144664\n",
      "Iteration 496, loss = 635540589.71882355\n",
      "Iteration 497, loss = 634758776.60676587\n",
      "Iteration 498, loss = 633986228.38504624\n",
      "Iteration 499, loss = 633242003.22204220\n",
      "Iteration 500, loss = 632475444.68521750\n",
      "Iteration 501, loss = 631725317.44955325\n",
      "Iteration 502, loss = 630958859.18962967\n",
      "Iteration 503, loss = 630194352.69303882\n",
      "Iteration 504, loss = 629404079.95293260\n",
      "Iteration 505, loss = 628684326.74226439\n",
      "Iteration 506, loss = 627875476.28901052\n",
      "Iteration 507, loss = 627117345.45082831\n",
      "Iteration 508, loss = 626338327.03235066\n",
      "Iteration 509, loss = 625558554.41085911\n",
      "Iteration 510, loss = 624786769.10899293\n",
      "Iteration 511, loss = 624020902.08622372\n",
      "Iteration 512, loss = 623215662.05783546\n",
      "Iteration 513, loss = 622459201.60113239\n",
      "Iteration 514, loss = 621655851.94442391\n",
      "Iteration 515, loss = 620867720.17891765\n",
      "Iteration 516, loss = 620130626.13673902\n",
      "Iteration 517, loss = 619350667.25181341\n",
      "Iteration 518, loss = 618588471.60949504\n",
      "Iteration 519, loss = 617813128.19293094\n",
      "Iteration 520, loss = 617062981.28883934\n",
      "Iteration 521, loss = 616253871.51760793\n",
      "Iteration 522, loss = 615502838.43088615\n",
      "Iteration 523, loss = 614742946.14919245\n",
      "Iteration 524, loss = 613956913.82131445\n",
      "Iteration 525, loss = 613214811.24214518\n",
      "Iteration 526, loss = 612436623.32631946\n",
      "Iteration 527, loss = 611667498.23122668\n",
      "Iteration 528, loss = 610933406.80752456\n",
      "Iteration 529, loss = 610151309.65864384\n",
      "Iteration 530, loss = 609369647.63666487\n",
      "Iteration 531, loss = 608590022.96842897\n",
      "Iteration 532, loss = 607827492.87730718\n",
      "Iteration 533, loss = 607064804.76567543\n",
      "Iteration 534, loss = 606264801.10527611\n",
      "Iteration 535, loss = 605505554.30785203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 536, loss = 604742020.66555691\n",
      "Iteration 537, loss = 603995079.43714607\n",
      "Iteration 538, loss = 603227001.19380498\n",
      "Iteration 539, loss = 602447406.25672674\n",
      "Iteration 540, loss = 601675916.15748250\n",
      "Iteration 541, loss = 600896518.66346002\n",
      "Iteration 542, loss = 600135533.02798498\n",
      "Iteration 543, loss = 599358221.59938407\n",
      "Iteration 544, loss = 598594046.41301334\n",
      "Iteration 545, loss = 597809726.30599320\n",
      "Iteration 546, loss = 597072127.62232208\n",
      "Iteration 547, loss = 596275140.61504793\n",
      "Iteration 548, loss = 595521499.67255211\n",
      "Iteration 549, loss = 594774283.43705451\n",
      "Iteration 550, loss = 594054680.29154444\n",
      "Iteration 551, loss = 593255220.83464265\n",
      "Iteration 552, loss = 592507004.60201132\n",
      "Iteration 553, loss = 591783543.80264032\n",
      "Iteration 554, loss = 591001249.65116370\n",
      "Iteration 555, loss = 590262849.31446171\n",
      "Iteration 556, loss = 589506275.46247721\n",
      "Iteration 557, loss = 588744448.64981151\n",
      "Iteration 558, loss = 587966042.95318425\n",
      "Iteration 559, loss = 587241148.78556561\n",
      "Iteration 560, loss = 586480380.10447693\n",
      "Iteration 561, loss = 585731218.69155443\n",
      "Iteration 562, loss = 584966660.00337017\n",
      "Iteration 563, loss = 584228854.36253679\n",
      "Iteration 564, loss = 583478056.80427110\n",
      "Iteration 565, loss = 582723443.59363151\n",
      "Iteration 566, loss = 581926002.27752411\n",
      "Iteration 567, loss = 581190389.63671637\n",
      "Iteration 568, loss = 580429643.05809176\n",
      "Iteration 569, loss = 579681855.60718179\n",
      "Iteration 570, loss = 578921874.02239382\n",
      "Iteration 571, loss = 578152097.15976405\n",
      "Iteration 572, loss = 577414459.92678511\n",
      "Iteration 573, loss = 576663654.78241682\n",
      "Iteration 574, loss = 575889784.42706978\n",
      "Iteration 575, loss = 575144648.65658033\n",
      "Iteration 576, loss = 574365838.61766255\n",
      "Iteration 577, loss = 573632504.44266367\n",
      "Iteration 578, loss = 572870282.67119086\n",
      "Iteration 579, loss = 572116555.83123481\n",
      "Iteration 580, loss = 571360221.13821423\n",
      "Iteration 581, loss = 570646423.71420145\n",
      "Iteration 582, loss = 569912459.30852520\n",
      "Iteration 583, loss = 569163761.42757165\n",
      "Iteration 584, loss = 568462379.74450207\n",
      "Iteration 585, loss = 567709154.60553432\n",
      "Iteration 586, loss = 566996353.72945058\n",
      "Iteration 587, loss = 566265370.17660284\n",
      "Iteration 588, loss = 565531495.75794137\n",
      "Iteration 589, loss = 564785867.13908124\n",
      "Iteration 590, loss = 564090896.80399752\n",
      "Iteration 591, loss = 563349796.67815983\n",
      "Iteration 592, loss = 562637798.23553789\n",
      "Iteration 593, loss = 561907144.68147993\n",
      "Iteration 594, loss = 561192223.44702780\n",
      "Iteration 595, loss = 560480191.50058162\n",
      "Iteration 596, loss = 559758168.40667319\n",
      "Iteration 597, loss = 559060083.11320043\n",
      "Iteration 598, loss = 558308613.34991407\n",
      "Iteration 599, loss = 557592724.60384786\n",
      "Iteration 600, loss = 556862367.15124881\n",
      "Iteration 601, loss = 556151687.93560255\n",
      "Iteration 602, loss = 555415590.39490283\n",
      "Iteration 603, loss = 554698315.89516068\n",
      "Iteration 604, loss = 553954624.04892612\n",
      "Iteration 605, loss = 553277909.55122805\n",
      "Iteration 606, loss = 552517814.44397950\n",
      "Iteration 607, loss = 551783941.12861097\n",
      "Iteration 608, loss = 551043590.91476452\n",
      "Iteration 609, loss = 550331710.34889150\n",
      "Iteration 610, loss = 549609105.09964871\n",
      "Iteration 611, loss = 548884943.54965055\n",
      "Iteration 612, loss = 548147262.13949072\n",
      "Iteration 613, loss = 547421834.25964284\n",
      "Iteration 614, loss = 546712607.51206577\n",
      "Iteration 615, loss = 545977965.53814101\n",
      "Iteration 616, loss = 545264066.43597448\n",
      "Iteration 617, loss = 544544933.84620941\n",
      "Iteration 618, loss = 543799746.01678419\n",
      "Iteration 619, loss = 543077181.72764528\n",
      "Iteration 620, loss = 542383312.34190238\n",
      "Iteration 621, loss = 541624913.05885112\n",
      "Iteration 622, loss = 540918775.70572329\n",
      "Iteration 623, loss = 540189080.57498932\n",
      "Iteration 624, loss = 539500543.20790231\n",
      "Iteration 625, loss = 538755669.14063978\n",
      "Iteration 626, loss = 538066191.64032769\n",
      "Iteration 627, loss = 537357308.07209456\n",
      "Iteration 628, loss = 536683967.73275739\n",
      "Iteration 629, loss = 535943569.43609864\n",
      "Iteration 630, loss = 535259564.04073048\n",
      "Iteration 631, loss = 534560968.37682152\n",
      "Iteration 632, loss = 533849333.24224919\n",
      "Iteration 633, loss = 533148013.89298779\n",
      "Iteration 634, loss = 532449041.15202719\n",
      "Iteration 635, loss = 531748446.91790354\n",
      "Iteration 636, loss = 531028914.07889611\n",
      "Iteration 637, loss = 530340442.68607426\n",
      "Iteration 638, loss = 529637156.24029469\n",
      "Iteration 639, loss = 528935580.29308838\n",
      "Iteration 640, loss = 528246138.28996366\n",
      "Iteration 641, loss = 527564097.63381785\n",
      "Iteration 642, loss = 526815749.33175111\n",
      "Iteration 643, loss = 526132591.58008242\n",
      "Iteration 644, loss = 525423975.72896945\n",
      "Iteration 645, loss = 524746227.29842621\n",
      "Iteration 646, loss = 524061464.62178516\n",
      "Iteration 647, loss = 523383460.75847298\n",
      "Iteration 648, loss = 522684711.14809781\n",
      "Iteration 649, loss = 522024760.90069556\n",
      "Iteration 650, loss = 521336464.39398819\n",
      "Iteration 651, loss = 520631983.25499272\n",
      "Iteration 652, loss = 519960269.08233488\n",
      "Iteration 653, loss = 519279147.57763666\n",
      "Iteration 654, loss = 518620611.51568723\n",
      "Iteration 655, loss = 517921110.02177536\n",
      "Iteration 656, loss = 517258681.73138058\n",
      "Iteration 657, loss = 516599314.17107052\n",
      "Iteration 658, loss = 515943607.95885080\n",
      "Iteration 659, loss = 515257188.61506116\n",
      "Iteration 660, loss = 514576429.86743456\n",
      "Iteration 661, loss = 513885108.31812853\n",
      "Iteration 662, loss = 513216656.07918745\n",
      "Iteration 663, loss = 512560585.00721264\n",
      "Iteration 664, loss = 511882571.49558049\n",
      "Iteration 665, loss = 511185454.10732818\n",
      "Iteration 666, loss = 510533632.32450390\n",
      "Iteration 667, loss = 509850840.03959596\n",
      "Iteration 668, loss = 509216389.05340266\n",
      "Iteration 669, loss = 508545643.31998116\n",
      "Iteration 670, loss = 507893899.83038384\n",
      "Iteration 671, loss = 507217393.83750242\n",
      "Iteration 672, loss = 506541130.52474439\n",
      "Iteration 673, loss = 505905373.92930347\n",
      "Iteration 674, loss = 505231098.04735142\n",
      "Iteration 675, loss = 504569952.94604492\n",
      "Iteration 676, loss = 503906985.81393182\n",
      "Iteration 677, loss = 503247886.58654904\n",
      "Iteration 678, loss = 502602064.97925109\n",
      "Iteration 679, loss = 501926517.22902435\n",
      "Iteration 680, loss = 501260572.78055131\n",
      "Iteration 681, loss = 500623465.18663442\n",
      "Iteration 682, loss = 499994758.53848320\n",
      "Iteration 683, loss = 499279001.86810631\n",
      "Iteration 684, loss = 498652646.70146686\n",
      "Iteration 685, loss = 497970406.28327984\n",
      "Iteration 686, loss = 497344821.53929317\n",
      "Iteration 687, loss = 496675924.38863355\n",
      "Iteration 688, loss = 496039031.62835681\n",
      "Iteration 689, loss = 495349351.04011041\n",
      "Iteration 690, loss = 494715561.29610300\n",
      "Iteration 691, loss = 494050084.39230406\n",
      "Iteration 692, loss = 493387014.50256044\n",
      "Iteration 693, loss = 492781425.06759721\n",
      "Iteration 694, loss = 492100453.82728732\n",
      "Iteration 695, loss = 491472493.90292698\n",
      "Iteration 696, loss = 490826033.17495543\n",
      "Iteration 697, loss = 490172824.70217019\n",
      "Iteration 698, loss = 489565936.64493436\n",
      "Iteration 699, loss = 488887754.88160855\n",
      "Iteration 700, loss = 488279553.81632078\n",
      "Iteration 701, loss = 487609793.64360076\n",
      "Iteration 702, loss = 486958682.51040804\n",
      "Iteration 703, loss = 486351746.88018560\n",
      "Iteration 704, loss = 485705873.88661987\n",
      "Iteration 705, loss = 485064839.85336667\n",
      "Iteration 706, loss = 484433217.56336421\n",
      "Iteration 707, loss = 483858277.88089389\n",
      "Iteration 708, loss = 483168915.17545152\n",
      "Iteration 709, loss = 482554879.02596104\n",
      "Iteration 710, loss = 481903781.33635384\n",
      "Iteration 711, loss = 481270867.56031352\n",
      "Iteration 712, loss = 480706266.79420817\n",
      "Iteration 713, loss = 480039371.87530160\n",
      "Iteration 714, loss = 479398589.95671970\n",
      "Iteration 715, loss = 478802285.85698128\n",
      "Iteration 716, loss = 478162360.73986578\n",
      "Iteration 717, loss = 477517222.63552636\n",
      "Iteration 718, loss = 476909758.87540025\n",
      "Iteration 719, loss = 476286751.32267970\n",
      "Iteration 720, loss = 475672915.98792756\n",
      "Iteration 721, loss = 475045683.12299860\n",
      "Iteration 722, loss = 474413966.06744736\n",
      "Iteration 723, loss = 473826921.70563287\n",
      "Iteration 724, loss = 473256580.11474741\n",
      "Iteration 725, loss = 472576820.23211610\n",
      "Iteration 726, loss = 471949640.14038604\n",
      "Iteration 727, loss = 471299930.34546334\n",
      "Iteration 728, loss = 470683944.83709371\n",
      "Iteration 729, loss = 470075298.04848075\n",
      "Iteration 730, loss = 469440009.89722985\n",
      "Iteration 731, loss = 468835920.98495173\n",
      "Iteration 732, loss = 468234106.65654618\n",
      "Iteration 733, loss = 467580136.62980318\n",
      "Iteration 734, loss = 466940356.61783618\n",
      "Iteration 735, loss = 466366457.44668978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 736, loss = 465713619.74984473\n",
      "Iteration 737, loss = 465124359.63500851\n",
      "Iteration 738, loss = 464509386.32888496\n",
      "Iteration 739, loss = 463943293.32324374\n",
      "Iteration 740, loss = 463316766.44854522\n",
      "Iteration 741, loss = 462713382.72966564\n",
      "Iteration 742, loss = 462106779.97827101\n",
      "Iteration 743, loss = 461496335.48264205\n",
      "Iteration 744, loss = 460940066.39098507\n",
      "Iteration 745, loss = 460347587.66697776\n",
      "Iteration 746, loss = 459721719.60252130\n",
      "Iteration 747, loss = 459165501.14973032\n",
      "Iteration 748, loss = 458534177.24251837\n",
      "Iteration 749, loss = 457952770.27349520\n",
      "Iteration 750, loss = 457342882.27333701\n",
      "Iteration 751, loss = 456742440.87814313\n",
      "Iteration 752, loss = 456170214.76850730\n",
      "Iteration 753, loss = 455556323.39471251\n",
      "Iteration 754, loss = 454974464.79115403\n",
      "Iteration 755, loss = 454365377.05217326\n",
      "Iteration 756, loss = 453752178.30734903\n",
      "Iteration 757, loss = 453159269.70414031\n",
      "Iteration 758, loss = 452602505.40865654\n",
      "Iteration 759, loss = 451967047.28639770\n",
      "Iteration 760, loss = 451436839.02639157\n",
      "Iteration 761, loss = 450821935.21425146\n",
      "Iteration 762, loss = 450206518.63962972\n",
      "Iteration 763, loss = 449615294.48479772\n",
      "Iteration 764, loss = 449016019.97052491\n",
      "Iteration 765, loss = 448450482.22664422\n",
      "Iteration 766, loss = 447826519.72304219\n",
      "Iteration 767, loss = 447262783.64783943\n",
      "Iteration 768, loss = 446652554.40616357\n",
      "Iteration 769, loss = 446072997.89242935\n",
      "Iteration 770, loss = 445486756.53303427\n",
      "Iteration 771, loss = 444871969.85063374\n",
      "Iteration 772, loss = 444349819.45461416\n",
      "Iteration 773, loss = 443688706.01469761\n",
      "Iteration 774, loss = 443112015.44295180\n",
      "Iteration 775, loss = 442530324.99689800\n",
      "Iteration 776, loss = 441955281.16429675\n",
      "Iteration 777, loss = 441347310.81494981\n",
      "Iteration 778, loss = 440786890.56936717\n",
      "Iteration 779, loss = 440192249.90457040\n",
      "Iteration 780, loss = 439565949.11881870\n",
      "Iteration 781, loss = 438990299.49703437\n",
      "Iteration 782, loss = 438428898.07084215\n",
      "Iteration 783, loss = 437834611.53013307\n",
      "Iteration 784, loss = 437269730.95282513\n",
      "Iteration 785, loss = 436644212.66539919\n",
      "Iteration 786, loss = 436079033.61949748\n",
      "Iteration 787, loss = 435520273.36261070\n",
      "Iteration 788, loss = 434911623.73734784\n",
      "Iteration 789, loss = 434341550.92112350\n",
      "Iteration 790, loss = 433737790.53814149\n",
      "Iteration 791, loss = 433202232.51772070\n",
      "Iteration 792, loss = 432586739.84043825\n",
      "Iteration 793, loss = 432011320.86003798\n",
      "Iteration 794, loss = 431413442.52018183\n",
      "Iteration 795, loss = 430831168.52467179\n",
      "Iteration 796, loss = 430265946.49684429\n",
      "Iteration 797, loss = 429652754.11462867\n",
      "Iteration 798, loss = 429075416.73291987\n",
      "Iteration 799, loss = 428483272.63369763\n",
      "Iteration 800, loss = 427917823.93316787\n",
      "Iteration 801, loss = 427334008.04058516\n",
      "Iteration 802, loss = 426754891.39550054\n",
      "Iteration 803, loss = 426146174.78954768\n",
      "Iteration 804, loss = 425590740.77355176\n",
      "Iteration 805, loss = 425037075.88454175\n",
      "Iteration 806, loss = 424432399.66189647\n",
      "Iteration 807, loss = 423878472.63091969\n",
      "Iteration 808, loss = 423319878.17094564\n",
      "Iteration 809, loss = 422740214.17472917\n",
      "Iteration 810, loss = 422159080.51066494\n",
      "Iteration 811, loss = 421598932.83482522\n",
      "Iteration 812, loss = 421022147.84889030\n",
      "Iteration 813, loss = 420472066.32106227\n",
      "Iteration 814, loss = 419922572.31339127\n",
      "Iteration 815, loss = 419353284.68514419\n",
      "Iteration 816, loss = 418778439.48593247\n",
      "Iteration 817, loss = 418241530.65371573\n",
      "Iteration 818, loss = 417687731.67640609\n",
      "Iteration 819, loss = 417135716.96567482\n",
      "Iteration 820, loss = 416559297.33296514\n",
      "Iteration 821, loss = 415973095.65999216\n",
      "Iteration 822, loss = 415417899.90412879\n",
      "Iteration 823, loss = 414889765.71975338\n",
      "Iteration 824, loss = 414314416.47111934\n",
      "Iteration 825, loss = 413743133.77081287\n",
      "Iteration 826, loss = 413171060.73923391\n",
      "Iteration 827, loss = 412612215.54871136\n",
      "Iteration 828, loss = 412042090.55668837\n",
      "Iteration 829, loss = 411494246.44556528\n",
      "Iteration 830, loss = 410930205.39828110\n",
      "Iteration 831, loss = 410353660.82402152\n",
      "Iteration 832, loss = 409795480.02656502\n",
      "Iteration 833, loss = 409231141.66582668\n",
      "Iteration 834, loss = 408652259.37662679\n",
      "Iteration 835, loss = 408103230.66484720\n",
      "Iteration 836, loss = 407516126.50181180\n",
      "Iteration 837, loss = 406965045.01294267\n",
      "Iteration 838, loss = 406379068.98071134\n",
      "Iteration 839, loss = 405819204.81387579\n",
      "Iteration 840, loss = 405257730.38947541\n",
      "Iteration 841, loss = 404700388.88932878\n",
      "Iteration 842, loss = 404143065.57421267\n",
      "Iteration 843, loss = 403578038.86703169\n",
      "Iteration 844, loss = 402993719.18233228\n",
      "Iteration 845, loss = 402419342.95312238\n",
      "Iteration 846, loss = 401886468.07317829\n",
      "Iteration 847, loss = 401329832.75886989\n",
      "Iteration 848, loss = 400759404.18069720\n",
      "Iteration 849, loss = 400221041.42144704\n",
      "Iteration 850, loss = 399662274.67915773\n",
      "Iteration 851, loss = 399110493.75326878\n",
      "Iteration 852, loss = 398546259.46214610\n",
      "Iteration 853, loss = 397977869.24812484\n",
      "Iteration 854, loss = 397413582.20294034\n",
      "Iteration 855, loss = 396867360.82833982\n",
      "Iteration 856, loss = 396307635.42454416\n",
      "Iteration 857, loss = 395795605.59079462\n",
      "Iteration 858, loss = 395213376.27276546\n",
      "Iteration 859, loss = 394656273.51739210\n",
      "Iteration 860, loss = 394107556.57231092\n",
      "Iteration 861, loss = 393525282.31094378\n",
      "Iteration 862, loss = 393014660.47366458\n",
      "Iteration 863, loss = 392429274.94595522\n",
      "Iteration 864, loss = 391870407.93745893\n",
      "Iteration 865, loss = 391335122.22676688\n",
      "Iteration 866, loss = 390777660.15379083\n",
      "Iteration 867, loss = 390248160.04052752\n",
      "Iteration 868, loss = 389651663.44430053\n",
      "Iteration 869, loss = 389110595.18936169\n",
      "Iteration 870, loss = 388589010.65120870\n",
      "Iteration 871, loss = 387987079.46854597\n",
      "Iteration 872, loss = 387456764.03527856\n",
      "Iteration 873, loss = 386888289.96180266\n",
      "Iteration 874, loss = 386321112.42283481\n",
      "Iteration 875, loss = 385785336.40549058\n",
      "Iteration 876, loss = 385212857.58533853\n",
      "Iteration 877, loss = 384667773.75641018\n",
      "Iteration 878, loss = 384108282.81067902\n",
      "Iteration 879, loss = 383593961.33928859\n",
      "Iteration 880, loss = 383003101.36845732\n",
      "Iteration 881, loss = 382451587.48290151\n",
      "Iteration 882, loss = 381897859.95929384\n",
      "Iteration 883, loss = 381425175.14163846\n",
      "Iteration 884, loss = 380792552.09974164\n",
      "Iteration 885, loss = 380276431.91622740\n",
      "Iteration 886, loss = 379721407.05845904\n",
      "Iteration 887, loss = 379156298.73713988\n",
      "Iteration 888, loss = 378632921.87571138\n",
      "Iteration 889, loss = 378070031.30079776\n",
      "Iteration 890, loss = 377526025.17005295\n",
      "Iteration 891, loss = 376993438.07932413\n",
      "Iteration 892, loss = 376432335.68864530\n",
      "Iteration 893, loss = 375965242.79715848\n",
      "Iteration 894, loss = 375374721.44137573\n",
      "Iteration 895, loss = 374844935.33586794\n",
      "Iteration 896, loss = 374325224.27569056\n",
      "Iteration 897, loss = 373772498.61290640\n",
      "Iteration 898, loss = 373233806.05862653\n",
      "Iteration 899, loss = 372733785.88535362\n",
      "Iteration 900, loss = 372158079.64191312\n",
      "Iteration 901, loss = 371621789.53529847\n",
      "Iteration 902, loss = 371098288.56430066\n",
      "Iteration 903, loss = 370564748.35192353\n",
      "Iteration 904, loss = 370085035.80766863\n",
      "Iteration 905, loss = 369534085.67459309\n",
      "Iteration 906, loss = 368986008.77844697\n",
      "Iteration 907, loss = 368464729.65832239\n",
      "Iteration 908, loss = 367940462.89166445\n",
      "Iteration 909, loss = 367423788.79602474\n",
      "Iteration 910, loss = 366885501.74579537\n",
      "Iteration 911, loss = 366469906.51750731\n",
      "Iteration 912, loss = 365844112.29329747\n",
      "Iteration 913, loss = 365347866.61379492\n",
      "Iteration 914, loss = 364828010.22348922\n",
      "Iteration 915, loss = 364311468.89165938\n",
      "Iteration 916, loss = 363784038.03461415\n",
      "Iteration 917, loss = 363293462.15789169\n",
      "Iteration 918, loss = 362747973.04999930\n",
      "Iteration 919, loss = 362227878.21425712\n",
      "Iteration 920, loss = 361701855.70362103\n",
      "Iteration 921, loss = 361177274.76003605\n",
      "Iteration 922, loss = 360661721.34525746\n",
      "Iteration 923, loss = 360124873.34903592\n",
      "Iteration 924, loss = 359595064.27491206\n",
      "Iteration 925, loss = 359082557.81519765\n",
      "Iteration 926, loss = 358581842.75973171\n",
      "Iteration 927, loss = 358046568.67728090\n",
      "Iteration 928, loss = 357498028.29533368\n",
      "Iteration 929, loss = 357005335.26735359\n",
      "Iteration 930, loss = 356466053.67096531\n",
      "Iteration 931, loss = 355923409.79481059\n",
      "Iteration 932, loss = 355416252.99937260\n",
      "Iteration 933, loss = 354893275.61939514\n",
      "Iteration 934, loss = 354354387.55826575\n",
      "Iteration 935, loss = 353824973.23911119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 936, loss = 353356233.87248796\n",
      "Iteration 937, loss = 352804778.41172981\n",
      "Iteration 938, loss = 352267342.21642601\n",
      "Iteration 939, loss = 351724265.13090038\n",
      "Iteration 940, loss = 351201302.42480272\n",
      "Iteration 941, loss = 350718763.72399563\n",
      "Iteration 942, loss = 350175835.07620835\n",
      "Iteration 943, loss = 349662021.87543017\n",
      "Iteration 944, loss = 349154804.61438936\n",
      "Iteration 945, loss = 348645153.46971273\n",
      "Iteration 946, loss = 348091918.82200688\n",
      "Iteration 947, loss = 347589146.10914153\n",
      "Iteration 948, loss = 347055562.75600892\n",
      "Iteration 949, loss = 346541523.49737376\n",
      "Iteration 950, loss = 346038857.20790857\n",
      "Iteration 951, loss = 345538108.33464724\n",
      "Iteration 952, loss = 344988709.27959096\n",
      "Iteration 953, loss = 344465744.23017627\n",
      "Iteration 954, loss = 343930349.20989734\n",
      "Iteration 955, loss = 343463476.85590523\n",
      "Iteration 956, loss = 342951219.31840020\n",
      "Iteration 957, loss = 342410236.70831752\n",
      "Iteration 958, loss = 341907371.31391227\n",
      "Iteration 959, loss = 341391841.30073076\n",
      "Iteration 960, loss = 340897525.38679886\n",
      "Iteration 961, loss = 340393421.31924218\n",
      "Iteration 962, loss = 339894972.18404520\n",
      "Iteration 963, loss = 339379275.09422207\n",
      "Iteration 964, loss = 338877788.84756029\n",
      "Iteration 965, loss = 338400936.69435608\n",
      "Iteration 966, loss = 337875946.32914734\n",
      "Iteration 967, loss = 337362635.24584198\n",
      "Iteration 968, loss = 336860600.78650385\n",
      "Iteration 969, loss = 336363269.91569245\n",
      "Iteration 970, loss = 335870749.52935916\n",
      "Iteration 971, loss = 335344191.43375528\n",
      "Iteration 972, loss = 334823441.12483132\n",
      "Iteration 973, loss = 334348856.48889118\n",
      "Iteration 974, loss = 333850075.78332889\n",
      "Iteration 975, loss = 333341691.59491700\n",
      "Iteration 976, loss = 332848897.44783211\n",
      "Iteration 977, loss = 332325131.73386967\n",
      "Iteration 978, loss = 331828456.58076400\n",
      "Iteration 979, loss = 331327695.16048175\n",
      "Iteration 980, loss = 330886199.24132633\n",
      "Iteration 981, loss = 330310256.67535502\n",
      "Iteration 982, loss = 329794264.27176988\n",
      "Iteration 983, loss = 329294990.44250375\n",
      "Iteration 984, loss = 328825467.48318309\n",
      "Iteration 985, loss = 328289834.80547965\n",
      "Iteration 986, loss = 327784885.64387435\n",
      "Iteration 987, loss = 327278369.48594487\n",
      "Iteration 988, loss = 326817757.20041323\n",
      "Iteration 989, loss = 326264427.71205282\n",
      "Iteration 990, loss = 325799009.16221541\n",
      "Iteration 991, loss = 325310351.62260753\n",
      "Iteration 992, loss = 324806453.39582807\n",
      "Iteration 993, loss = 324291460.35359865\n",
      "Iteration 994, loss = 323812347.98833561\n",
      "Iteration 995, loss = 323327475.41815704\n",
      "Iteration 996, loss = 322808475.30146331\n",
      "Iteration 997, loss = 322307819.52296865\n",
      "Iteration 998, loss = 321803880.07803088\n",
      "Iteration 999, loss = 321313820.34571034\n",
      "Iteration 1000, loss = 320830692.72605723\n",
      "Iteration 1001, loss = 320331765.43698722\n",
      "Iteration 1002, loss = 319864356.77411902\n",
      "Iteration 1003, loss = 319359022.59516162\n",
      "Iteration 1004, loss = 318840986.66919547\n",
      "Iteration 1005, loss = 318378637.32589507\n",
      "Iteration 1006, loss = 317907110.79060078\n",
      "Iteration 1007, loss = 317399408.94908470\n",
      "Iteration 1008, loss = 316898202.82462925\n",
      "Iteration 1009, loss = 316416450.28669500\n",
      "Iteration 1010, loss = 315943910.06953251\n",
      "Iteration 1011, loss = 315418280.22219712\n",
      "Iteration 1012, loss = 314953028.21115482\n",
      "Iteration 1013, loss = 314443305.35053319\n",
      "Iteration 1014, loss = 313949096.92578405\n",
      "Iteration 1015, loss = 313457484.92249125\n",
      "Iteration 1016, loss = 312967975.10742402\n",
      "Iteration 1017, loss = 312516414.40292341\n",
      "Iteration 1018, loss = 311991368.53816563\n",
      "Iteration 1019, loss = 311529475.61659998\n",
      "Iteration 1020, loss = 311028581.86417675\n",
      "Iteration 1021, loss = 310622153.89889312\n",
      "Iteration 1022, loss = 310074679.16771936\n",
      "Iteration 1023, loss = 309588646.43269187\n",
      "Iteration 1024, loss = 309093435.35014755\n",
      "Iteration 1025, loss = 308631013.77104872\n",
      "Iteration 1026, loss = 308132923.51926017\n",
      "Iteration 1027, loss = 307678460.68706012\n",
      "Iteration 1028, loss = 307170039.89548868\n",
      "Iteration 1029, loss = 306677098.13235915\n",
      "Iteration 1030, loss = 306199381.11204356\n",
      "Iteration 1031, loss = 305722707.62436354\n",
      "Iteration 1032, loss = 305234664.38752866\n",
      "Iteration 1033, loss = 304752660.84636658\n",
      "Iteration 1034, loss = 304292327.73776329\n",
      "Iteration 1035, loss = 303823495.25027001\n",
      "Iteration 1036, loss = 303325738.56174219\n",
      "Iteration 1037, loss = 302853093.35097456\n",
      "Iteration 1038, loss = 302364101.82779288\n",
      "Iteration 1039, loss = 301890495.12117046\n",
      "Iteration 1040, loss = 301439272.36541170\n",
      "Iteration 1041, loss = 300956715.95917022\n",
      "Iteration 1042, loss = 300492498.00140882\n",
      "Iteration 1043, loss = 300023336.86855811\n",
      "Iteration 1044, loss = 299571539.01195979\n",
      "Iteration 1045, loss = 299092888.72100544\n",
      "Iteration 1046, loss = 298615753.77783000\n",
      "Iteration 1047, loss = 298138309.29828900\n",
      "Iteration 1048, loss = 297886013.36653709\n",
      "Iteration 1049, loss = 297316753.76325560\n",
      "Iteration 1050, loss = 296854426.26906848\n",
      "Iteration 1051, loss = 296431997.82704014\n",
      "Iteration 1052, loss = 295984276.87158704\n",
      "Iteration 1053, loss = 295578985.07303947\n",
      "Iteration 1054, loss = 295128367.10699600\n",
      "Iteration 1055, loss = 294705077.19724417\n",
      "Iteration 1056, loss = 294269799.54592687\n",
      "Iteration 1057, loss = 293819573.92981511\n",
      "Iteration 1058, loss = 293368384.76376539\n",
      "Iteration 1059, loss = 292935222.47997993\n",
      "Iteration 1060, loss = 292473283.86425126\n",
      "Iteration 1061, loss = 292023365.11159801\n",
      "Iteration 1062, loss = 291576771.64642936\n",
      "Iteration 1063, loss = 291126435.16698188\n",
      "Iteration 1064, loss = 290707196.92492211\n",
      "Iteration 1065, loss = 290235569.07245272\n",
      "Iteration 1066, loss = 289758284.58060610\n",
      "Iteration 1067, loss = 289354131.18929410\n",
      "Iteration 1068, loss = 288858119.49297190\n",
      "Iteration 1069, loss = 288406568.35894686\n",
      "Iteration 1070, loss = 287981036.03646749\n",
      "Iteration 1071, loss = 287529668.39079368\n",
      "Iteration 1072, loss = 287071375.81723052\n",
      "Iteration 1073, loss = 286587163.53218186\n",
      "Iteration 1074, loss = 286174023.01856077\n",
      "Iteration 1075, loss = 285689551.47443748\n",
      "Iteration 1076, loss = 285266653.35001266\n",
      "Iteration 1077, loss = 284805766.29752439\n",
      "Iteration 1078, loss = 284370253.37048090\n",
      "Iteration 1079, loss = 283918518.11835217\n",
      "Iteration 1080, loss = 283475736.93049705\n",
      "Iteration 1081, loss = 283047077.84549475\n",
      "Iteration 1082, loss = 282599285.68050647\n",
      "Iteration 1083, loss = 282141595.39938605\n",
      "Iteration 1084, loss = 281702687.25484598\n",
      "Iteration 1085, loss = 281306091.18728155\n",
      "Iteration 1086, loss = 280827660.90105951\n",
      "Iteration 1087, loss = 280363051.19779390\n",
      "Iteration 1088, loss = 279927920.17987466\n",
      "Iteration 1089, loss = 279513840.45124632\n",
      "Iteration 1090, loss = 279046198.24427944\n",
      "Iteration 1091, loss = 278608727.80080026\n",
      "Iteration 1092, loss = 278205285.62872422\n",
      "Iteration 1093, loss = 277747384.05209315\n",
      "Iteration 1094, loss = 277335885.13983196\n",
      "Iteration 1095, loss = 276871094.63147491\n",
      "Iteration 1096, loss = 276444036.50765395\n",
      "Iteration 1097, loss = 276004144.52148443\n",
      "Iteration 1098, loss = 275555573.33066684\n",
      "Iteration 1099, loss = 275129930.60055459\n",
      "Iteration 1100, loss = 274694476.33052766\n",
      "Iteration 1101, loss = 274249917.18879807\n",
      "Iteration 1102, loss = 273822670.69667488\n",
      "Iteration 1103, loss = 273424681.34716958\n",
      "Iteration 1104, loss = 272998713.22290665\n",
      "Iteration 1105, loss = 272529597.77020746\n",
      "Iteration 1106, loss = 272114766.68561590\n",
      "Iteration 1107, loss = 271671913.89197814\n",
      "Iteration 1108, loss = 271251949.06889683\n",
      "Iteration 1109, loss = 270824354.79150736\n",
      "Iteration 1110, loss = 270411212.85390544\n",
      "Iteration 1111, loss = 269957610.11641508\n",
      "Iteration 1112, loss = 269532306.49519694\n",
      "Iteration 1113, loss = 269132014.52417552\n",
      "Iteration 1114, loss = 268695543.94071525\n",
      "Iteration 1115, loss = 268258160.37767202\n",
      "Iteration 1116, loss = 267827624.60570034\n",
      "Iteration 1117, loss = 267392485.15499043\n",
      "Iteration 1118, loss = 266948662.00787213\n",
      "Iteration 1119, loss = 266569475.58388487\n",
      "Iteration 1120, loss = 266090502.61498708\n",
      "Iteration 1121, loss = 265703678.52904233\n",
      "Iteration 1122, loss = 265246635.86933699\n",
      "Iteration 1123, loss = 264835537.03733534\n",
      "Iteration 1124, loss = 264384854.49725148\n",
      "Iteration 1125, loss = 263976194.27222061\n",
      "Iteration 1126, loss = 263587695.45339569\n",
      "Iteration 1127, loss = 263157535.23631114\n",
      "Iteration 1128, loss = 262718962.56918871\n",
      "Iteration 1129, loss = 262309381.16181251\n",
      "Iteration 1130, loss = 261868649.16338640\n",
      "Iteration 1131, loss = 261484555.34463775\n",
      "Iteration 1132, loss = 261056164.69951883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1133, loss = 260656414.45145690\n",
      "Iteration 1134, loss = 260245330.29927620\n",
      "Iteration 1135, loss = 259846805.02062789\n",
      "Iteration 1136, loss = 259433775.16268718\n",
      "Iteration 1137, loss = 259026277.45126891\n",
      "Iteration 1138, loss = 258606079.24243093\n",
      "Iteration 1139, loss = 258174396.36644265\n",
      "Iteration 1140, loss = 257775341.49190900\n",
      "Iteration 1141, loss = 257352978.76151758\n",
      "Iteration 1142, loss = 256981167.91727123\n",
      "Iteration 1143, loss = 256576898.08474320\n",
      "Iteration 1144, loss = 256156921.82665089\n",
      "Iteration 1145, loss = 255764155.94725302\n",
      "Iteration 1146, loss = 255361673.73207781\n",
      "Iteration 1147, loss = 254970497.96485960\n",
      "Iteration 1148, loss = 254597659.82144174\n",
      "Iteration 1149, loss = 254174239.32266662\n",
      "Iteration 1150, loss = 253787396.54626608\n",
      "Iteration 1151, loss = 253397278.50520033\n",
      "Iteration 1152, loss = 252971717.66789791\n",
      "Iteration 1153, loss = 252598631.17659515\n",
      "Iteration 1154, loss = 252214332.74940363\n",
      "Iteration 1155, loss = 251798731.33111951\n",
      "Iteration 1156, loss = 251387493.84478948\n",
      "Iteration 1157, loss = 251012764.67710307\n",
      "Iteration 1158, loss = 250592972.01138416\n",
      "Iteration 1159, loss = 250194429.60773325\n",
      "Iteration 1160, loss = 249809362.50926444\n",
      "Iteration 1161, loss = 249423080.22392854\n",
      "Iteration 1162, loss = 249048089.89174405\n",
      "Iteration 1163, loss = 248626132.18760648\n",
      "Iteration 1164, loss = 248227623.51178673\n",
      "Iteration 1165, loss = 247822372.58767298\n",
      "Iteration 1166, loss = 247388866.90029347\n",
      "Iteration 1167, loss = 247039854.02320927\n",
      "Iteration 1168, loss = 246634101.66207138\n",
      "Iteration 1169, loss = 246236150.19087002\n",
      "Iteration 1170, loss = 245876406.90588427\n",
      "Iteration 1171, loss = 245405881.57667947\n",
      "Iteration 1172, loss = 245019683.64891458\n",
      "Iteration 1173, loss = 244658140.26508874\n",
      "Iteration 1174, loss = 244269854.33623788\n",
      "Iteration 1175, loss = 243898018.67635587\n",
      "Iteration 1176, loss = 243492184.34968802\n",
      "Iteration 1177, loss = 243117994.12448868\n",
      "Iteration 1178, loss = 242746510.12476897\n",
      "Iteration 1179, loss = 242309996.60940477\n",
      "Iteration 1180, loss = 241939764.69757691\n",
      "Iteration 1181, loss = 241552669.90542102\n",
      "Iteration 1182, loss = 241135423.81601959\n",
      "Iteration 1183, loss = 240745866.10820371\n",
      "Iteration 1184, loss = 240368137.76564774\n",
      "Iteration 1185, loss = 239972263.07768553\n",
      "Iteration 1186, loss = 239597428.34699571\n",
      "Iteration 1187, loss = 239225004.22345814\n",
      "Iteration 1188, loss = 238826275.14321288\n",
      "Iteration 1189, loss = 238438541.21840793\n",
      "Iteration 1190, loss = 238072501.37888569\n",
      "Iteration 1191, loss = 237660337.35722229\n",
      "Iteration 1192, loss = 237280109.81659377\n",
      "Iteration 1193, loss = 236925728.59416121\n",
      "Iteration 1194, loss = 236527065.60178331\n",
      "Iteration 1195, loss = 236121604.81672937\n",
      "Iteration 1196, loss = 235752811.32536197\n",
      "Iteration 1197, loss = 235378126.03135443\n",
      "Iteration 1198, loss = 235003934.36474416\n",
      "Iteration 1199, loss = 234633092.12837878\n",
      "Iteration 1200, loss = 234251152.78067255\n",
      "Iteration 1201, loss = 233848740.18788117\n",
      "Iteration 1202, loss = 233490512.65464127\n",
      "Iteration 1203, loss = 233128789.94984478\n",
      "Iteration 1204, loss = 232753929.57338855\n",
      "Iteration 1205, loss = 232380932.02428979\n",
      "Iteration 1206, loss = 231979349.74995485\n",
      "Iteration 1207, loss = 231632113.70774263\n",
      "Iteration 1208, loss = 231224894.95433542\n",
      "Iteration 1209, loss = 230972569.85724908\n",
      "Iteration 1210, loss = 230509977.89621595\n",
      "Iteration 1211, loss = 230142837.94132930\n",
      "Iteration 1212, loss = 229806623.09663537\n",
      "Iteration 1213, loss = 229436824.63028067\n",
      "Iteration 1214, loss = 229069934.67165264\n",
      "Iteration 1215, loss = 228748511.01912975\n",
      "Iteration 1216, loss = 228414099.34760413\n",
      "Iteration 1217, loss = 228019915.19516668\n",
      "Iteration 1218, loss = 227659712.11863786\n",
      "Iteration 1219, loss = 227311309.74161333\n",
      "Iteration 1220, loss = 226967141.75705141\n",
      "Iteration 1221, loss = 226604695.42897490\n",
      "Iteration 1222, loss = 226258798.72369301\n",
      "Iteration 1223, loss = 225886563.63591942\n",
      "Iteration 1224, loss = 225546865.67775798\n",
      "Iteration 1225, loss = 225203945.92605972\n",
      "Iteration 1226, loss = 224842591.54529902\n",
      "Iteration 1227, loss = 224515566.22648337\n",
      "Iteration 1228, loss = 224139500.45687610\n",
      "Iteration 1229, loss = 223802670.21382284\n",
      "Iteration 1230, loss = 223447595.75002593\n",
      "Iteration 1231, loss = 223093924.25709596\n",
      "Iteration 1232, loss = 222765834.67303056\n",
      "Iteration 1233, loss = 222400346.13000280\n",
      "Iteration 1234, loss = 222050035.55217519\n",
      "Iteration 1235, loss = 221718692.96764526\n",
      "Iteration 1236, loss = 221370010.73534408\n",
      "Iteration 1237, loss = 221020429.44310218\n",
      "Iteration 1238, loss = 220684141.46952522\n",
      "Iteration 1239, loss = 220352642.59295708\n",
      "Iteration 1240, loss = 219978330.66245538\n",
      "Iteration 1241, loss = 219641256.77767432\n",
      "Iteration 1242, loss = 219270737.76985154\n",
      "Iteration 1243, loss = 218936747.17299998\n",
      "Iteration 1244, loss = 218579452.58036181\n",
      "Iteration 1245, loss = 218205385.22785029\n",
      "Iteration 1246, loss = 217885813.15013844\n",
      "Iteration 1247, loss = 217525429.48041859\n",
      "Iteration 1248, loss = 217160441.85136983\n",
      "Iteration 1249, loss = 216819011.43098000\n",
      "Iteration 1250, loss = 216472718.65631166\n",
      "Iteration 1251, loss = 216135110.05856639\n",
      "Iteration 1252, loss = 215768310.92775166\n",
      "Iteration 1253, loss = 215443478.81955197\n",
      "Iteration 1254, loss = 215072657.25036225\n",
      "Iteration 1255, loss = 214740238.86062640\n",
      "Iteration 1256, loss = 214429942.61917403\n",
      "Iteration 1257, loss = 214038939.24071556\n",
      "Iteration 1258, loss = 213724986.99801472\n",
      "Iteration 1259, loss = 213372507.70510745\n",
      "Iteration 1260, loss = 213034860.84292424\n",
      "Iteration 1261, loss = 212701505.83574191\n",
      "Iteration 1262, loss = 212404645.23015356\n",
      "Iteration 1263, loss = 211995607.71598393\n",
      "Iteration 1264, loss = 211667098.85750824\n",
      "Iteration 1265, loss = 211343573.17598751\n",
      "Iteration 1266, loss = 210981151.07607850\n",
      "Iteration 1267, loss = 210677460.00917786\n",
      "Iteration 1268, loss = 210349571.62681782\n",
      "Iteration 1269, loss = 209976686.89403972\n",
      "Iteration 1270, loss = 209656873.42537400\n",
      "Iteration 1271, loss = 209339336.41362432\n",
      "Iteration 1272, loss = 209023229.92125872\n",
      "Iteration 1273, loss = 208689972.92209908\n",
      "Iteration 1274, loss = 208349750.15908238\n",
      "Iteration 1275, loss = 208035750.07257175\n",
      "Iteration 1276, loss = 207702971.07657808\n",
      "Iteration 1277, loss = 207346495.95625451\n",
      "Iteration 1278, loss = 207019292.55922458\n",
      "Iteration 1279, loss = 206710577.27968335\n",
      "Iteration 1280, loss = 206398149.37723508\n",
      "Iteration 1281, loss = 206043032.86791131\n",
      "Iteration 1282, loss = 205717891.55885950\n",
      "Iteration 1283, loss = 205405109.66974214\n",
      "Iteration 1284, loss = 205120780.73257351\n",
      "Iteration 1285, loss = 204751637.45591170\n",
      "Iteration 1286, loss = 204433954.45970798\n",
      "Iteration 1287, loss = 204119821.85360077\n",
      "Iteration 1288, loss = 203779814.92668059\n",
      "Iteration 1289, loss = 203477776.78347632\n",
      "Iteration 1290, loss = 203172603.84553593\n",
      "Iteration 1291, loss = 202835053.19005290\n",
      "Iteration 1292, loss = 202529238.75958058\n",
      "Iteration 1293, loss = 202234197.75668836\n",
      "Iteration 1294, loss = 201874522.35705370\n",
      "Iteration 1295, loss = 201563395.25055045\n",
      "Iteration 1296, loss = 201218787.27881023\n",
      "Iteration 1297, loss = 200897883.52489704\n",
      "Iteration 1298, loss = 200580298.45878613\n",
      "Iteration 1299, loss = 200294282.95744166\n",
      "Iteration 1300, loss = 199955268.30691612\n",
      "Iteration 1301, loss = 199662722.31676167\n",
      "Iteration 1302, loss = 199343987.53365269\n",
      "Iteration 1303, loss = 199061927.86186531\n",
      "Iteration 1304, loss = 198706881.05172378\n",
      "Iteration 1305, loss = 198406425.75473794\n",
      "Iteration 1306, loss = 198116247.78817046\n",
      "Iteration 1307, loss = 197841060.58477336\n",
      "Iteration 1308, loss = 197509102.78362259\n",
      "Iteration 1309, loss = 197207216.75306597\n",
      "Iteration 1310, loss = 196916445.96264806\n",
      "Iteration 1311, loss = 196649773.32828921\n",
      "Iteration 1312, loss = 196309540.26016748\n",
      "Iteration 1313, loss = 195998247.09503064\n",
      "Iteration 1314, loss = 195701202.83467487\n",
      "Iteration 1315, loss = 195395078.85096467\n",
      "Iteration 1316, loss = 195078424.53832310\n",
      "Iteration 1317, loss = 194847175.74317944\n",
      "Iteration 1318, loss = 194500987.24856776\n",
      "Iteration 1319, loss = 194199686.08676878\n",
      "Iteration 1320, loss = 193895657.10684079\n",
      "Iteration 1321, loss = 193605306.43048301\n",
      "Iteration 1322, loss = 193290667.53015092\n",
      "Iteration 1323, loss = 192972851.66871783\n",
      "Iteration 1324, loss = 192694515.98271874\n",
      "Iteration 1325, loss = 192382717.70928001\n",
      "Iteration 1326, loss = 192119019.87214971\n",
      "Iteration 1327, loss = 191786579.24787539\n",
      "Iteration 1328, loss = 191521448.68021733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1329, loss = 191201664.23768303\n",
      "Iteration 1330, loss = 190890570.00244385\n",
      "Iteration 1331, loss = 190616785.92550671\n",
      "Iteration 1332, loss = 190328704.92440051\n",
      "Iteration 1333, loss = 190036033.71095988\n",
      "Iteration 1334, loss = 189748295.32022765\n",
      "Iteration 1335, loss = 189460877.29297137\n",
      "Iteration 1336, loss = 189190362.94867787\n",
      "Iteration 1337, loss = 188840679.86260453\n",
      "Iteration 1338, loss = 188575629.87088582\n",
      "Iteration 1339, loss = 188278662.57857746\n",
      "Iteration 1340, loss = 188058174.14498115\n",
      "Iteration 1341, loss = 187705780.71826500\n",
      "Iteration 1342, loss = 187406318.31822547\n",
      "Iteration 1343, loss = 187140587.38990736\n",
      "Iteration 1344, loss = 186853504.79549843\n",
      "Iteration 1345, loss = 186575899.44290361\n",
      "Iteration 1346, loss = 186263009.36542672\n",
      "Iteration 1347, loss = 186014530.53774542\n",
      "Iteration 1348, loss = 185701709.67866373\n",
      "Iteration 1349, loss = 185436989.51771250\n",
      "Iteration 1350, loss = 185157655.01262498\n",
      "Iteration 1351, loss = 184885342.50846684\n",
      "Iteration 1352, loss = 184593978.61749092\n",
      "Iteration 1353, loss = 184311111.66251701\n",
      "Iteration 1354, loss = 184055804.28791243\n",
      "Iteration 1355, loss = 183725503.45495248\n",
      "Iteration 1356, loss = 183512718.14327165\n",
      "Iteration 1357, loss = 183213329.11367416\n",
      "Iteration 1358, loss = 182919504.94831458\n",
      "Iteration 1359, loss = 182674570.11565697\n",
      "Iteration 1360, loss = 182432638.76576990\n",
      "Iteration 1361, loss = 182098487.70581299\n",
      "Iteration 1362, loss = 181833629.06184977\n",
      "Iteration 1363, loss = 181556569.79083410\n",
      "Iteration 1364, loss = 181274047.09838665\n",
      "Iteration 1365, loss = 181011492.58598581\n",
      "Iteration 1366, loss = 180738153.11556482\n",
      "Iteration 1367, loss = 180467359.96550822\n",
      "Iteration 1368, loss = 180186842.33595285\n",
      "Iteration 1369, loss = 179934704.61935410\n",
      "Iteration 1370, loss = 179640846.80842462\n",
      "Iteration 1371, loss = 179356397.91030100\n",
      "Iteration 1372, loss = 179137716.83897769\n",
      "Iteration 1373, loss = 178852021.59648538\n",
      "Iteration 1374, loss = 178558655.14048466\n",
      "Iteration 1375, loss = 178305747.70505837\n",
      "Iteration 1376, loss = 178042953.51492319\n",
      "Iteration 1377, loss = 177798369.66245738\n",
      "Iteration 1378, loss = 177484012.85125113\n",
      "Iteration 1379, loss = 177225273.10901809\n",
      "Iteration 1380, loss = 176964959.91788962\n",
      "Iteration 1381, loss = 176709930.52393186\n",
      "Iteration 1382, loss = 176498193.10986179\n",
      "Iteration 1383, loss = 176194744.54951659\n",
      "Iteration 1384, loss = 175885514.40616134\n",
      "Iteration 1385, loss = 175648120.02685964\n",
      "Iteration 1386, loss = 175413652.94403780\n",
      "Iteration 1387, loss = 175101035.67091805\n",
      "Iteration 1388, loss = 174874013.07980704\n",
      "Iteration 1389, loss = 174605082.59442672\n",
      "Iteration 1390, loss = 174350893.29714626\n",
      "Iteration 1391, loss = 174124702.69399470\n",
      "Iteration 1392, loss = 173855091.72147390\n",
      "Iteration 1393, loss = 173577677.34577271\n",
      "Iteration 1394, loss = 173298193.26726469\n",
      "Iteration 1395, loss = 173065247.62537837\n",
      "Iteration 1396, loss = 172826814.68250352\n",
      "Iteration 1397, loss = 172541330.31042212\n",
      "Iteration 1398, loss = 172278705.03476259\n",
      "Iteration 1399, loss = 172015723.21458486\n",
      "Iteration 1400, loss = 171770962.87902930\n",
      "Iteration 1401, loss = 171556646.64090636\n",
      "Iteration 1402, loss = 171250757.62332663\n",
      "Iteration 1403, loss = 171016062.13123983\n",
      "Iteration 1404, loss = 170755923.55365112\n",
      "Iteration 1405, loss = 170523450.95983163\n",
      "Iteration 1406, loss = 170257420.90038761\n",
      "Iteration 1407, loss = 170002662.25400317\n",
      "Iteration 1408, loss = 169767888.57233253\n",
      "Iteration 1409, loss = 169571958.55315390\n",
      "Iteration 1410, loss = 169269843.24431819\n",
      "Iteration 1411, loss = 169015961.58613205\n",
      "Iteration 1412, loss = 168781877.80541989\n",
      "Iteration 1413, loss = 168555282.55054909\n",
      "Iteration 1414, loss = 168309580.78105721\n",
      "Iteration 1415, loss = 168041218.79883775\n",
      "Iteration 1416, loss = 167796647.72024599\n",
      "Iteration 1417, loss = 167579761.01740265\n",
      "Iteration 1418, loss = 167320140.35960191\n",
      "Iteration 1419, loss = 167104897.28496325\n",
      "Iteration 1420, loss = 166844172.60449049\n",
      "Iteration 1421, loss = 166603441.65085399\n",
      "Iteration 1422, loss = 166416276.75707760\n",
      "Iteration 1423, loss = 166142477.47373369\n",
      "Iteration 1424, loss = 165879787.38324431\n",
      "Iteration 1425, loss = 165660575.49714884\n",
      "Iteration 1426, loss = 165394397.40357190\n",
      "Iteration 1427, loss = 165168590.26260450\n",
      "Iteration 1428, loss = 164976575.97980711\n",
      "Iteration 1429, loss = 164727348.04986626\n",
      "Iteration 1430, loss = 164477284.08827347\n",
      "Iteration 1431, loss = 164231726.45610693\n",
      "Iteration 1432, loss = 164031213.36939338\n",
      "Iteration 1433, loss = 163782360.81682611\n",
      "Iteration 1434, loss = 163557502.39190468\n",
      "Iteration 1435, loss = 163300551.02935466\n",
      "Iteration 1436, loss = 163094104.97469556\n",
      "Iteration 1437, loss = 162827092.02097678\n",
      "Iteration 1438, loss = 162616422.13400680\n",
      "Iteration 1439, loss = 162438954.51679969\n",
      "Iteration 1440, loss = 162164078.09972635\n",
      "Iteration 1441, loss = 161935686.56547806\n",
      "Iteration 1442, loss = 161751558.48437706\n",
      "Iteration 1443, loss = 161470455.30137768\n",
      "Iteration 1444, loss = 161267106.11182261\n",
      "Iteration 1445, loss = 161005698.10047010\n",
      "Iteration 1446, loss = 160810149.32641125\n",
      "Iteration 1447, loss = 160546674.07471213\n",
      "Iteration 1448, loss = 160335548.46291947\n",
      "Iteration 1449, loss = 160113932.83962885\n",
      "Iteration 1450, loss = 159910457.99243677\n",
      "Iteration 1451, loss = 159630531.81575522\n",
      "Iteration 1452, loss = 159440580.03829449\n",
      "Iteration 1453, loss = 159206168.89326847\n",
      "Iteration 1454, loss = 158983182.17378807\n",
      "Iteration 1455, loss = 158753682.40414476\n",
      "Iteration 1456, loss = 158547560.63660395\n",
      "Iteration 1457, loss = 158325514.81499401\n",
      "Iteration 1458, loss = 158114935.43608236\n",
      "Iteration 1459, loss = 157901076.23673457\n",
      "Iteration 1460, loss = 157660246.88111690\n",
      "Iteration 1461, loss = 157462905.82936895\n",
      "Iteration 1462, loss = 157222097.15944850\n",
      "Iteration 1463, loss = 157007855.97963658\n",
      "Iteration 1464, loss = 156809275.21279019\n",
      "Iteration 1465, loss = 156562079.18286368\n",
      "Iteration 1466, loss = 156390211.89676237\n",
      "Iteration 1467, loss = 156131734.36255762\n",
      "Iteration 1468, loss = 155918438.55589160\n",
      "Iteration 1469, loss = 155718791.67775330\n",
      "Iteration 1470, loss = 155497434.25134292\n",
      "Iteration 1471, loss = 155267531.03364843\n",
      "Iteration 1472, loss = 155053521.71716660\n",
      "Iteration 1473, loss = 154864144.46120334\n",
      "Iteration 1474, loss = 154628719.48797008\n",
      "Iteration 1475, loss = 154433607.64238575\n",
      "Iteration 1476, loss = 154188362.32896125\n",
      "Iteration 1477, loss = 154049875.44090223\n",
      "Iteration 1478, loss = 153790489.69412094\n",
      "Iteration 1479, loss = 153608908.63842604\n",
      "Iteration 1480, loss = 153384596.37181523\n",
      "Iteration 1481, loss = 153145643.24075106\n",
      "Iteration 1482, loss = 152939469.98032892\n",
      "Iteration 1483, loss = 152763274.42375213\n",
      "Iteration 1484, loss = 152521650.71317786\n",
      "Iteration 1485, loss = 152338785.60980421\n",
      "Iteration 1486, loss = 152119882.73847002\n",
      "Iteration 1487, loss = 151913640.10494316\n",
      "Iteration 1488, loss = 151708131.51019743\n",
      "Iteration 1489, loss = 151520252.86527258\n",
      "Iteration 1490, loss = 151293497.66987154\n",
      "Iteration 1491, loss = 151081966.98350984\n",
      "Iteration 1492, loss = 150883857.53553969\n",
      "Iteration 1493, loss = 150687297.94264317\n",
      "Iteration 1494, loss = 150490288.05799049\n",
      "Iteration 1495, loss = 150286692.81068310\n",
      "Iteration 1496, loss = 150081236.13847527\n",
      "Iteration 1497, loss = 149914117.53942546\n",
      "Iteration 1498, loss = 149652861.63076270\n",
      "Iteration 1499, loss = 149481827.04258254\n",
      "Iteration 1500, loss = 149277565.06681252\n",
      "Iteration 1501, loss = 149096084.11057085\n",
      "Iteration 1502, loss = 148875086.10653281\n",
      "Iteration 1503, loss = 148688188.43476379\n",
      "Iteration 1504, loss = 148484206.21873501\n",
      "Iteration 1505, loss = 148275048.13423675\n",
      "Iteration 1506, loss = 148089610.23638153\n",
      "Iteration 1507, loss = 147900331.95189881\n",
      "Iteration 1508, loss = 147693299.96709675\n",
      "Iteration 1509, loss = 147496352.18051744\n",
      "Iteration 1510, loss = 147295326.57344827\n",
      "Iteration 1511, loss = 147123075.84846422\n",
      "Iteration 1512, loss = 146933830.40840024\n",
      "Iteration 1513, loss = 146720786.02075627\n",
      "Iteration 1514, loss = 146537736.63209110\n",
      "Iteration 1515, loss = 146375335.77496901\n",
      "Iteration 1516, loss = 146145598.39733496\n",
      "Iteration 1517, loss = 145965796.27044550\n",
      "Iteration 1518, loss = 145811041.43635696\n",
      "Iteration 1519, loss = 145566085.27332354\n",
      "Iteration 1520, loss = 145381762.34975240\n",
      "Iteration 1521, loss = 145261083.52366164\n",
      "Iteration 1522, loss = 144997141.24097472\n",
      "Iteration 1523, loss = 144842524.23556042\n",
      "Iteration 1524, loss = 144646208.94886538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1525, loss = 144475251.60705048\n",
      "Iteration 1526, loss = 144278110.27789661\n",
      "Iteration 1527, loss = 144102921.03942782\n",
      "Iteration 1528, loss = 143894923.79299533\n",
      "Iteration 1529, loss = 143734220.34913483\n",
      "Iteration 1530, loss = 143565040.17820796\n",
      "Iteration 1531, loss = 143395962.18874857\n",
      "Iteration 1532, loss = 143182438.28511634\n",
      "Iteration 1533, loss = 143011394.08007678\n",
      "Iteration 1534, loss = 142823703.48638073\n",
      "Iteration 1535, loss = 142678075.03625593\n",
      "Iteration 1536, loss = 142495775.26253843\n",
      "Iteration 1537, loss = 142290848.99260825\n",
      "Iteration 1538, loss = 142144273.10648763\n",
      "Iteration 1539, loss = 141955322.85671887\n",
      "Iteration 1540, loss = 141746360.45382786\n",
      "Iteration 1541, loss = 141557276.21642056\n",
      "Iteration 1542, loss = 141418898.25186512\n",
      "Iteration 1543, loss = 141206811.76243627\n",
      "Iteration 1544, loss = 141047638.88587567\n",
      "Iteration 1545, loss = 140849075.29654881\n",
      "Iteration 1546, loss = 140670837.94020912\n",
      "Iteration 1547, loss = 140481974.51016396\n",
      "Iteration 1548, loss = 140320370.35383531\n",
      "Iteration 1549, loss = 140145871.08263299\n",
      "Iteration 1550, loss = 139975237.38142675\n",
      "Iteration 1551, loss = 139798507.22207779\n",
      "Iteration 1552, loss = 139609718.37297219\n",
      "Iteration 1553, loss = 139425672.32637650\n",
      "Iteration 1554, loss = 139239969.08433834\n",
      "Iteration 1555, loss = 139077606.03053766\n",
      "Iteration 1556, loss = 138936767.12788478\n",
      "Iteration 1557, loss = 138729261.22240391\n",
      "Iteration 1558, loss = 138569539.77267739\n",
      "Iteration 1559, loss = 138369435.44734347\n",
      "Iteration 1560, loss = 138196302.64488778\n",
      "Iteration 1561, loss = 138051264.07128116\n",
      "Iteration 1562, loss = 137882215.79993618\n",
      "Iteration 1563, loss = 137675949.32880032\n",
      "Iteration 1564, loss = 137511496.85387242\n",
      "Iteration 1565, loss = 137339433.88145599\n",
      "Iteration 1566, loss = 137154167.30375528\n",
      "Iteration 1567, loss = 137003317.08206198\n",
      "Iteration 1568, loss = 136837372.65559119\n",
      "Iteration 1569, loss = 136621983.94316378\n",
      "Iteration 1570, loss = 136466338.89723104\n",
      "Iteration 1571, loss = 136291761.90280041\n",
      "Iteration 1572, loss = 136107281.06370261\n",
      "Iteration 1573, loss = 135957913.60319346\n",
      "Iteration 1574, loss = 135776118.65351701\n",
      "Iteration 1575, loss = 135612868.39732361\n",
      "Iteration 1576, loss = 135467315.94008657\n",
      "Iteration 1577, loss = 135284020.95015594\n",
      "Iteration 1578, loss = 135124469.88137966\n",
      "Iteration 1579, loss = 134954110.81612003\n",
      "Iteration 1580, loss = 134771989.68195248\n",
      "Iteration 1581, loss = 134614308.37113187\n",
      "Iteration 1582, loss = 134431265.34841919\n",
      "Iteration 1583, loss = 134287568.92769352\n",
      "Iteration 1584, loss = 134098267.36204986\n",
      "Iteration 1585, loss = 133971443.59135474\n",
      "Iteration 1586, loss = 133782285.49880484\n",
      "Iteration 1587, loss = 133642757.18753457\n",
      "Iteration 1588, loss = 133473126.97775230\n",
      "Iteration 1589, loss = 133304175.77749313\n",
      "Iteration 1590, loss = 133150734.33691844\n",
      "Iteration 1591, loss = 133002605.96880160\n",
      "Iteration 1592, loss = 132819318.75525273\n",
      "Iteration 1593, loss = 132659730.78531078\n",
      "Iteration 1594, loss = 132487988.53630936\n",
      "Iteration 1595, loss = 132352518.39090407\n",
      "Iteration 1596, loss = 132160830.37367047\n",
      "Iteration 1597, loss = 132014212.44355059\n",
      "Iteration 1598, loss = 131861306.41851984\n",
      "Iteration 1599, loss = 131727352.92041416\n",
      "Iteration 1600, loss = 131542199.97233070\n",
      "Iteration 1601, loss = 131378160.72645348\n",
      "Iteration 1602, loss = 131216526.11752814\n",
      "Iteration 1603, loss = 131071757.40726338\n",
      "Iteration 1604, loss = 130964873.02732022\n",
      "Iteration 1605, loss = 130766486.39696068\n",
      "Iteration 1606, loss = 130632437.76411113\n",
      "Iteration 1607, loss = 130452659.55599475\n",
      "Iteration 1608, loss = 130321844.75894099\n",
      "Iteration 1609, loss = 130179197.89684844\n",
      "Iteration 1610, loss = 129994117.72826947\n",
      "Iteration 1611, loss = 129876716.56925076\n",
      "Iteration 1612, loss = 129708359.39037286\n",
      "Iteration 1613, loss = 129552521.33492142\n",
      "Iteration 1614, loss = 129411635.78664321\n",
      "Iteration 1615, loss = 129258321.20762530\n",
      "Iteration 1616, loss = 129126697.85221833\n",
      "Iteration 1617, loss = 128938941.77753393\n",
      "Iteration 1618, loss = 128816567.53229627\n",
      "Iteration 1619, loss = 128660929.34430937\n",
      "Iteration 1620, loss = 128496143.94597109\n",
      "Iteration 1621, loss = 128335593.75720474\n",
      "Iteration 1622, loss = 128262643.87069219\n",
      "Iteration 1623, loss = 128068573.54379216\n",
      "Iteration 1624, loss = 127881335.06655654\n",
      "Iteration 1625, loss = 127760774.94421901\n",
      "Iteration 1626, loss = 127614490.99423912\n",
      "Iteration 1627, loss = 127457833.21331038\n",
      "Iteration 1628, loss = 127302998.57866760\n",
      "Iteration 1629, loss = 127160806.10947506\n",
      "Iteration 1630, loss = 127071654.05271468\n",
      "Iteration 1631, loss = 126870953.93394254\n",
      "Iteration 1632, loss = 126734624.97295524\n",
      "Iteration 1633, loss = 126602604.13176124\n",
      "Iteration 1634, loss = 126451701.14340262\n",
      "Iteration 1635, loss = 126292306.15666680\n",
      "Iteration 1636, loss = 126145363.37358876\n",
      "Iteration 1637, loss = 126003356.06776442\n",
      "Iteration 1638, loss = 125859082.19772284\n",
      "Iteration 1639, loss = 125719736.13388433\n",
      "Iteration 1640, loss = 125562160.29557386\n",
      "Iteration 1641, loss = 125421229.91482709\n",
      "Iteration 1642, loss = 125320618.29582407\n",
      "Iteration 1643, loss = 125125665.24158068\n",
      "Iteration 1644, loss = 125008867.10261206\n",
      "Iteration 1645, loss = 124863340.94457681\n",
      "Iteration 1646, loss = 124747284.16919178\n",
      "Iteration 1647, loss = 124563433.41921976\n",
      "Iteration 1648, loss = 124456910.31340061\n",
      "Iteration 1649, loss = 124336550.34379934\n",
      "Iteration 1650, loss = 124151230.61464863\n",
      "Iteration 1651, loss = 123995781.53938910\n",
      "Iteration 1652, loss = 123884471.13065755\n",
      "Iteration 1653, loss = 123756466.68942049\n",
      "Iteration 1654, loss = 123580002.99489331\n",
      "Iteration 1655, loss = 123465849.09136300\n",
      "Iteration 1656, loss = 123360643.38821480\n",
      "Iteration 1657, loss = 123258751.78843407\n",
      "Iteration 1658, loss = 123064970.44155601\n",
      "Iteration 1659, loss = 122918429.71857406\n",
      "Iteration 1660, loss = 122759378.38198389\n",
      "Iteration 1661, loss = 122642950.46275920\n",
      "Iteration 1662, loss = 122493763.79464363\n",
      "Iteration 1663, loss = 122347491.14566164\n",
      "Iteration 1664, loss = 122240736.05168289\n",
      "Iteration 1665, loss = 122093708.38401560\n",
      "Iteration 1666, loss = 121966261.62575658\n",
      "Iteration 1667, loss = 121827295.99600257\n",
      "Iteration 1668, loss = 121710997.47596802\n",
      "Iteration 1669, loss = 121568323.24459924\n",
      "Iteration 1670, loss = 121427156.40488669\n",
      "Iteration 1671, loss = 121318886.10034847\n",
      "Iteration 1672, loss = 121135451.00781165\n",
      "Iteration 1673, loss = 121003877.37250224\n",
      "Iteration 1674, loss = 120880927.72338445\n",
      "Iteration 1675, loss = 120717047.39014234\n",
      "Iteration 1676, loss = 120609762.11477892\n",
      "Iteration 1677, loss = 120451868.95952803\n",
      "Iteration 1678, loss = 120357069.20671529\n",
      "Iteration 1679, loss = 120194683.82254213\n",
      "Iteration 1680, loss = 120062270.26612286\n",
      "Iteration 1681, loss = 119917469.87542580\n",
      "Iteration 1682, loss = 119797355.68523350\n",
      "Iteration 1683, loss = 119667076.60145870\n",
      "Iteration 1684, loss = 119516003.78684132\n",
      "Iteration 1685, loss = 119409153.79063424\n",
      "Iteration 1686, loss = 119254279.61275661\n",
      "Iteration 1687, loss = 119138698.27250026\n",
      "Iteration 1688, loss = 119000796.92722069\n",
      "Iteration 1689, loss = 118882001.25916214\n",
      "Iteration 1690, loss = 118746351.39610294\n",
      "Iteration 1691, loss = 118599959.47977298\n",
      "Iteration 1692, loss = 118491429.83211854\n",
      "Iteration 1693, loss = 118345035.41326815\n",
      "Iteration 1694, loss = 118201154.48066525\n",
      "Iteration 1695, loss = 118167853.70233932\n",
      "Iteration 1696, loss = 117958955.86531878\n",
      "Iteration 1697, loss = 117846250.07180242\n",
      "Iteration 1698, loss = 117711872.46265924\n",
      "Iteration 1699, loss = 117578543.15438133\n",
      "Iteration 1700, loss = 117452556.36812936\n",
      "Iteration 1701, loss = 117327597.53387178\n",
      "Iteration 1702, loss = 117216610.78926139\n",
      "Iteration 1703, loss = 117115094.39439413\n",
      "Iteration 1704, loss = 116954923.82785425\n",
      "Iteration 1705, loss = 116829288.66079697\n",
      "Iteration 1706, loss = 116699800.94871858\n",
      "Iteration 1707, loss = 116661585.57500687\n",
      "Iteration 1708, loss = 116448892.30626711\n",
      "Iteration 1709, loss = 116344838.70117852\n",
      "Iteration 1710, loss = 116247548.84528445\n",
      "Iteration 1711, loss = 116124058.33317196\n",
      "Iteration 1712, loss = 115972486.13363327\n",
      "Iteration 1713, loss = 115903388.29470833\n",
      "Iteration 1714, loss = 115732425.53576384\n",
      "Iteration 1715, loss = 115634522.71275972\n",
      "Iteration 1716, loss = 115509556.79767600\n",
      "Iteration 1717, loss = 115403692.40638949\n",
      "Iteration 1718, loss = 115261490.52101736\n",
      "Iteration 1719, loss = 115139641.00507072\n",
      "Iteration 1720, loss = 115062418.40989073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1721, loss = 115006459.19021872\n",
      "Iteration 1722, loss = 114841255.96169494\n",
      "Iteration 1723, loss = 114695147.14722139\n",
      "Iteration 1724, loss = 114559105.00706379\n",
      "Iteration 1725, loss = 114457798.09388736\n",
      "Iteration 1726, loss = 114348716.13295320\n",
      "Iteration 1727, loss = 114226695.17458317\n",
      "Iteration 1728, loss = 114107146.10998429\n",
      "Iteration 1729, loss = 114021665.47212954\n",
      "Iteration 1730, loss = 113871589.35778254\n",
      "Iteration 1731, loss = 113741512.88469847\n",
      "Iteration 1732, loss = 113648707.00734572\n",
      "Iteration 1733, loss = 113527997.35354146\n",
      "Iteration 1734, loss = 113467798.24319722\n",
      "Iteration 1735, loss = 113307701.21614581\n",
      "Iteration 1736, loss = 113199343.29118468\n",
      "Iteration 1737, loss = 113105697.78844444\n",
      "Iteration 1738, loss = 113016418.21819817\n",
      "Iteration 1739, loss = 112865858.27150291\n",
      "Iteration 1740, loss = 112780679.00721873\n",
      "Iteration 1741, loss = 112634020.93012463\n",
      "Iteration 1742, loss = 112535883.40415552\n",
      "Iteration 1743, loss = 112393055.27726898\n",
      "Iteration 1744, loss = 112340299.09974436\n",
      "Iteration 1745, loss = 112207455.06352974\n",
      "Iteration 1746, loss = 112100408.94296503\n",
      "Iteration 1747, loss = 111983124.64219899\n",
      "Iteration 1748, loss = 111872105.98231737\n",
      "Iteration 1749, loss = 111728856.33866240\n",
      "Iteration 1750, loss = 111695036.64447631\n",
      "Iteration 1751, loss = 111529608.31697455\n",
      "Iteration 1752, loss = 111422054.85105801\n",
      "Iteration 1753, loss = 111319590.38720581\n",
      "Iteration 1754, loss = 111257014.37241316\n",
      "Iteration 1755, loss = 111114759.12044258\n",
      "Iteration 1756, loss = 111028863.50930110\n",
      "Iteration 1757, loss = 110889911.24022578\n",
      "Iteration 1758, loss = 110774232.68564966\n",
      "Iteration 1759, loss = 110675141.36496639\n",
      "Iteration 1760, loss = 110567283.68092351\n",
      "Iteration 1761, loss = 110448751.76827906\n",
      "Iteration 1762, loss = 110344557.05181222\n",
      "Iteration 1763, loss = 110278801.91159610\n",
      "Iteration 1764, loss = 110144106.00072391\n",
      "Iteration 1765, loss = 110010678.11071253\n",
      "Iteration 1766, loss = 109954143.99910627\n",
      "Iteration 1767, loss = 109879988.24936187\n",
      "Iteration 1768, loss = 109729312.37406196\n",
      "Iteration 1769, loss = 109613431.80743669\n",
      "Iteration 1770, loss = 109532088.43585339\n",
      "Iteration 1771, loss = 109390410.27112360\n",
      "Iteration 1772, loss = 109296785.45151077\n",
      "Iteration 1773, loss = 109190985.32871012\n",
      "Iteration 1774, loss = 109073064.67815863\n",
      "Iteration 1775, loss = 109020307.47307138\n",
      "Iteration 1776, loss = 108923057.96266919\n",
      "Iteration 1777, loss = 108789865.36392500\n",
      "Iteration 1778, loss = 108685575.11542124\n",
      "Iteration 1779, loss = 108570539.57028002\n",
      "Iteration 1780, loss = 108513969.49373010\n",
      "Iteration 1781, loss = 108363235.53975622\n",
      "Iteration 1782, loss = 108270406.15595280\n",
      "Iteration 1783, loss = 108161260.65241377\n",
      "Iteration 1784, loss = 108091408.85699564\n",
      "Iteration 1785, loss = 107957955.50072490\n",
      "Iteration 1786, loss = 107845545.08499631\n",
      "Iteration 1787, loss = 107754549.56577057\n",
      "Iteration 1788, loss = 107671557.99020572\n",
      "Iteration 1789, loss = 107579370.48907746\n",
      "Iteration 1790, loss = 107480371.03416243\n",
      "Iteration 1791, loss = 107365325.62989405\n",
      "Iteration 1792, loss = 107277141.94402801\n",
      "Iteration 1793, loss = 107175105.42853665\n",
      "Iteration 1794, loss = 107081423.19472481\n",
      "Iteration 1795, loss = 107015524.67996009\n",
      "Iteration 1796, loss = 106871799.41055800\n",
      "Iteration 1797, loss = 106803963.73490624\n",
      "Iteration 1798, loss = 106697885.07577105\n",
      "Iteration 1799, loss = 106606281.37132969\n",
      "Iteration 1800, loss = 106484992.39347835\n",
      "Iteration 1801, loss = 106387905.69372591\n",
      "Iteration 1802, loss = 106341763.85255778\n",
      "Iteration 1803, loss = 106259140.76296325\n",
      "Iteration 1804, loss = 106144355.27059282\n",
      "Iteration 1805, loss = 106011323.59403844\n",
      "Iteration 1806, loss = 105927507.88737826\n",
      "Iteration 1807, loss = 105853979.89945924\n",
      "Iteration 1808, loss = 105740292.07114647\n",
      "Iteration 1809, loss = 105657396.71319062\n",
      "Iteration 1810, loss = 105551674.84680229\n",
      "Iteration 1811, loss = 105492275.14869072\n",
      "Iteration 1812, loss = 105387760.15517417\n",
      "Iteration 1813, loss = 105281843.48606890\n",
      "Iteration 1814, loss = 105171282.54798509\n",
      "Iteration 1815, loss = 105107011.89810272\n",
      "Iteration 1816, loss = 105033506.82491827\n",
      "Iteration 1817, loss = 104931221.47739327\n",
      "Iteration 1818, loss = 104867342.84504184\n",
      "Iteration 1819, loss = 104744770.49827139\n",
      "Iteration 1820, loss = 104644292.63223788\n",
      "Iteration 1821, loss = 104551433.35240364\n",
      "Iteration 1822, loss = 104468970.91531023\n",
      "Iteration 1823, loss = 104377351.30823702\n",
      "Iteration 1824, loss = 104300407.51337287\n",
      "Iteration 1825, loss = 104210844.29628862\n",
      "Iteration 1826, loss = 104124597.14670476\n",
      "Iteration 1827, loss = 104004756.44729896\n",
      "Iteration 1828, loss = 103936849.18488327\n",
      "Iteration 1829, loss = 103821911.14003679\n",
      "Iteration 1830, loss = 103761842.23909155\n",
      "Iteration 1831, loss = 103652694.46705994\n",
      "Iteration 1832, loss = 103588735.39131606\n",
      "Iteration 1833, loss = 103484277.89676510\n",
      "Iteration 1834, loss = 103381593.15729822\n",
      "Iteration 1835, loss = 103343983.85897955\n",
      "Iteration 1836, loss = 103245969.19887671\n",
      "Iteration 1837, loss = 103138389.47744696\n",
      "Iteration 1838, loss = 103079707.68863082\n",
      "Iteration 1839, loss = 102947388.58161470\n",
      "Iteration 1840, loss = 102886687.84645095\n",
      "Iteration 1841, loss = 102823990.02016127\n",
      "Iteration 1842, loss = 102690757.45197032\n",
      "Iteration 1843, loss = 102682243.64880012\n",
      "Iteration 1844, loss = 102573641.05846812\n",
      "Iteration 1845, loss = 102447720.00581744\n",
      "Iteration 1846, loss = 102387380.69973744\n",
      "Iteration 1847, loss = 102292721.98203906\n",
      "Iteration 1848, loss = 102204386.18162988\n",
      "Iteration 1849, loss = 102126610.91357280\n",
      "Iteration 1850, loss = 102076880.45491211\n",
      "Iteration 1851, loss = 101951764.79904111\n",
      "Iteration 1852, loss = 101902704.96970439\n",
      "Iteration 1853, loss = 101790219.49083531\n",
      "Iteration 1854, loss = 101722907.80473085\n",
      "Iteration 1855, loss = 101617421.87893750\n",
      "Iteration 1856, loss = 101529464.79010130\n",
      "Iteration 1857, loss = 101456631.14005128\n",
      "Iteration 1858, loss = 101374426.57513958\n",
      "Iteration 1859, loss = 101297038.04330459\n",
      "Iteration 1860, loss = 101204345.50133346\n",
      "Iteration 1861, loss = 101143802.94784941\n",
      "Iteration 1862, loss = 101039531.67861247\n",
      "Iteration 1863, loss = 100972949.81011507\n",
      "Iteration 1864, loss = 100864866.44212908\n",
      "Iteration 1865, loss = 100849576.71859355\n",
      "Iteration 1866, loss = 100723772.66582423\n",
      "Iteration 1867, loss = 100658579.06952658\n",
      "Iteration 1868, loss = 100557694.29158705\n",
      "Iteration 1869, loss = 100461229.58777794\n",
      "Iteration 1870, loss = 100455166.01020430\n",
      "Iteration 1871, loss = 100295012.60264069\n",
      "Iteration 1872, loss = 100264290.91754568\n",
      "Iteration 1873, loss = 100171520.46672100\n",
      "Iteration 1874, loss = 100115542.82319994\n",
      "Iteration 1875, loss = 100007668.55408181\n",
      "Iteration 1876, loss = 99939379.27693167\n",
      "Iteration 1877, loss = 99876884.96807839\n",
      "Iteration 1878, loss = 99777641.16322900\n",
      "Iteration 1879, loss = 99695753.56422989\n",
      "Iteration 1880, loss = 99624724.65033509\n",
      "Iteration 1881, loss = 99576768.37720568\n",
      "Iteration 1882, loss = 99484261.22221424\n",
      "Iteration 1883, loss = 99447235.90127881\n",
      "Iteration 1884, loss = 99332829.90300646\n",
      "Iteration 1885, loss = 99341065.20973140\n",
      "Iteration 1886, loss = 99182697.17971003\n",
      "Iteration 1887, loss = 99134995.64508475\n",
      "Iteration 1888, loss = 99039119.55889715\n",
      "Iteration 1889, loss = 98989675.20492637\n",
      "Iteration 1890, loss = 98924335.49009085\n",
      "Iteration 1891, loss = 98812796.27742240\n",
      "Iteration 1892, loss = 98790997.99763748\n",
      "Iteration 1893, loss = 98669645.38059452\n",
      "Iteration 1894, loss = 98615906.04639097\n",
      "Iteration 1895, loss = 98560778.46156900\n",
      "Iteration 1896, loss = 98484991.34727578\n",
      "Iteration 1897, loss = 98399517.97039494\n",
      "Iteration 1898, loss = 98330996.22368921\n",
      "Iteration 1899, loss = 98330832.51803727\n",
      "Iteration 1900, loss = 98211624.88631298\n",
      "Iteration 1901, loss = 98165519.08433130\n",
      "Iteration 1902, loss = 98084325.44258530\n",
      "Iteration 1903, loss = 98067858.80160373\n",
      "Iteration 1904, loss = 97947049.11374919\n",
      "Iteration 1905, loss = 97854508.41693957\n",
      "Iteration 1906, loss = 97828473.06312732\n",
      "Iteration 1907, loss = 97772397.93155719\n",
      "Iteration 1908, loss = 97676774.06790894\n",
      "Iteration 1909, loss = 97609740.67841329\n",
      "Iteration 1910, loss = 97554498.64426745\n",
      "Iteration 1911, loss = 97508505.82947478\n",
      "Iteration 1912, loss = 97395139.55236204\n",
      "Iteration 1913, loss = 97379957.50611933\n",
      "Iteration 1914, loss = 97344884.11640696\n",
      "Iteration 1915, loss = 97204067.22459416\n",
      "Iteration 1916, loss = 97146714.03172548\n",
      "Iteration 1917, loss = 97302007.04875620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1918, loss = 97012797.89593728\n",
      "Iteration 1919, loss = 96951373.82387562\n",
      "Iteration 1920, loss = 96907051.30824469\n",
      "Iteration 1921, loss = 96844777.17903255\n",
      "Iteration 1922, loss = 96767034.00457966\n",
      "Iteration 1923, loss = 96700920.74184822\n",
      "Iteration 1924, loss = 96633974.88056657\n",
      "Iteration 1925, loss = 96585496.43092613\n",
      "Iteration 1926, loss = 96567065.33661741\n",
      "Iteration 1927, loss = 96458213.39885992\n",
      "Iteration 1928, loss = 96390746.27414262\n",
      "Iteration 1929, loss = 96330308.47559886\n",
      "Iteration 1930, loss = 96264330.79297431\n",
      "Iteration 1931, loss = 96203205.62842123\n",
      "Iteration 1932, loss = 96131228.43664679\n",
      "Iteration 1933, loss = 96080543.26586288\n",
      "Iteration 1934, loss = 96033910.71453670\n",
      "Iteration 1935, loss = 95989882.86365758\n",
      "Iteration 1936, loss = 95910824.11896494\n",
      "Iteration 1937, loss = 95838542.62983388\n",
      "Iteration 1938, loss = 95816987.45297119\n",
      "Iteration 1939, loss = 95698497.30261903\n",
      "Iteration 1940, loss = 95673413.60315582\n",
      "Iteration 1941, loss = 95592697.27153161\n",
      "Iteration 1942, loss = 95485229.75570786\n",
      "Iteration 1943, loss = 95486265.23668355\n",
      "Iteration 1944, loss = 95409611.69576764\n",
      "Iteration 1945, loss = 95323689.68522532\n",
      "Iteration 1946, loss = 95266475.08636157\n",
      "Iteration 1947, loss = 95248543.64727607\n",
      "Iteration 1948, loss = 95154568.25110883\n",
      "Iteration 1949, loss = 95091299.47975223\n",
      "Iteration 1950, loss = 95027256.11918253\n",
      "Iteration 1951, loss = 95001310.87364046\n",
      "Iteration 1952, loss = 94936641.73885319\n",
      "Iteration 1953, loss = 94854604.01965737\n",
      "Iteration 1954, loss = 94784001.10855927\n",
      "Iteration 1955, loss = 94750047.78565119\n",
      "Iteration 1956, loss = 94678380.88321374\n",
      "Iteration 1957, loss = 94624953.40722091\n",
      "Iteration 1958, loss = 94555197.90975115\n",
      "Iteration 1959, loss = 94509681.34397629\n",
      "Iteration 1960, loss = 94455568.46701264\n",
      "Iteration 1961, loss = 94414310.76568574\n",
      "Iteration 1962, loss = 94327132.63563122\n",
      "Iteration 1963, loss = 94259537.06113906\n",
      "Iteration 1964, loss = 94229174.36712813\n",
      "Iteration 1965, loss = 94166618.40528961\n",
      "Iteration 1966, loss = 94111577.91668285\n",
      "Iteration 1967, loss = 94055205.61213419\n",
      "Iteration 1968, loss = 93982658.18684572\n",
      "Iteration 1969, loss = 93924712.23739655\n",
      "Iteration 1970, loss = 93878161.86309752\n",
      "Iteration 1971, loss = 93826822.34626465\n",
      "Iteration 1972, loss = 93749619.90676098\n",
      "Iteration 1973, loss = 93705110.06197780\n",
      "Iteration 1974, loss = 93619772.91803652\n",
      "Iteration 1975, loss = 93603276.73851529\n",
      "Iteration 1976, loss = 93567178.97216496\n",
      "Iteration 1977, loss = 93484386.18071479\n",
      "Iteration 1978, loss = 93406784.08431524\n",
      "Iteration 1979, loss = 93371288.25717770\n",
      "Iteration 1980, loss = 93286228.98353706\n",
      "Iteration 1981, loss = 93251463.50412464\n",
      "Iteration 1982, loss = 93191441.95878306\n",
      "Iteration 1983, loss = 93166587.33457366\n",
      "Iteration 1984, loss = 93106173.65154193\n",
      "Iteration 1985, loss = 93031489.35821417\n",
      "Iteration 1986, loss = 92998243.72604191\n",
      "Iteration 1987, loss = 92911008.39295919\n",
      "Iteration 1988, loss = 92847200.30278243\n",
      "Iteration 1989, loss = 92836151.96180293\n",
      "Iteration 1990, loss = 92754506.44142790\n",
      "Iteration 1991, loss = 92728444.09297518\n",
      "Iteration 1992, loss = 92668489.65244617\n",
      "Iteration 1993, loss = 92659536.65919724\n",
      "Iteration 1994, loss = 92529571.00239809\n",
      "Iteration 1995, loss = 92518201.98102945\n",
      "Iteration 1996, loss = 92437179.28658952\n",
      "Iteration 1997, loss = 92403365.41863927\n",
      "Iteration 1998, loss = 92353042.66906030\n",
      "Iteration 1999, loss = 92326943.47123784\n",
      "Iteration 2000, loss = 92248512.88310084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingRegressor(cv=5,\n",
       "                  estimators=[('Gradient Boost',\n",
       "                               GradientBoostingRegressor(learning_rate=0.01,\n",
       "                                                         max_depth=10,\n",
       "                                                         min_samples_split=100,\n",
       "                                                         random_state=42)),\n",
       "                              ('MLP',\n",
       "                               MLPRegressor(hidden_layer_sizes=8, max_iter=2000,\n",
       "                                            n_iter_no_change=1000,\n",
       "                                            random_state=42, tol=0.001,\n",
       "                                            verbose=True)),\n",
       "                              ('Ada Boost',\n",
       "                               AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=10,\n",
       "                                                                                      mi...\n",
       "                                               importance_type=None,\n",
       "                                               interaction_constraints=None,\n",
       "                                               learning_rate=0.1,\n",
       "                                               max_delta_step=None,\n",
       "                                               max_depth=10,\n",
       "                                               min_child_weight=None,\n",
       "                                               missing=nan,\n",
       "                                               monotone_constraints=None,\n",
       "                                               n_estimators=100, n_jobs=None,\n",
       "                                               num_parallel_tree=None,\n",
       "                                               predictor=None, random_state=42,\n",
       "                                               reg_alpha=10, reg_lambda=None,\n",
       "                                               scale_pos_weight=None,\n",
       "                                               subsample=None, tree_method=None,\n",
       "                                               validate_parameters=None,\n",
       "                                               verbosity=None))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_estimator = StackingRegressor(\n",
    "    estimators=estimators, final_estimator=final_estimator, cv=5\n",
    ")\n",
    "stacking_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c8bdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = stacking_estimator.predict(X_train)\n",
    "pred_test = stacking_estimator.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bce41b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROM</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Screen size</th>\n",
       "      <th>Dual Sim</th>\n",
       "      <th>Expandable Memory</th>\n",
       "      <th>5G</th>\n",
       "      <th>Fingerprint Sensor</th>\n",
       "      <th>Brand_Asus</th>\n",
       "      <th>Brand_BlackBerry</th>\n",
       "      <th>Brand_Google</th>\n",
       "      <th>...</th>\n",
       "      <th>Model_iPhone XR</th>\n",
       "      <th>Model_iPhone XS</th>\n",
       "      <th>Model_iPhone XS Max</th>\n",
       "      <th>Model_style</th>\n",
       "      <th>Model_style 2</th>\n",
       "      <th>Model_style2</th>\n",
       "      <th>OS_BlackBerry OS</th>\n",
       "      <th>OS_Other</th>\n",
       "      <th>OS_Symbian OS</th>\n",
       "      <th>OS_iOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22672</th>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15956</th>\n",
       "      <td>128.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27170</th>\n",
       "      <td>64.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11469</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39206</th>\n",
       "      <td>256.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14223</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12007 rows × 626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ROM  RAM  Screen size  Dual Sim  Expandable Memory  5G  \\\n",
       "9766    64.0  1.0          4.7         0                  0   0   \n",
       "22672  128.0  2.0          4.7         0                  0   0   \n",
       "2300    16.0  1.0          4.0         0                  0   0   \n",
       "15956  128.0  4.0          6.2         1                  1   0   \n",
       "27170   64.0  6.0          6.3         0                  0   0   \n",
       "...      ...  ...          ...       ...                ...  ..   \n",
       "11469   32.0  3.0          6.5         1                  1   0   \n",
       "6713    32.0  1.5          5.5         0                  1   0   \n",
       "39206  256.0  6.0          6.1         1                  0   0   \n",
       "14223   32.0  2.0          4.7         0                  0   0   \n",
       "3475    32.0  3.0          6.3         1                  1   0   \n",
       "\n",
       "       Fingerprint Sensor  Brand_Asus  Brand_BlackBerry  Brand_Google  ...  \\\n",
       "9766                    1           0                 0             0  ...   \n",
       "22672                   0           0                 0             0  ...   \n",
       "2300                    0           0                 0             0  ...   \n",
       "15956                   1           0                 0             0  ...   \n",
       "27170                   0           0                 0             0  ...   \n",
       "...                   ...         ...               ...           ...  ...   \n",
       "11469                   1           0                 0             0  ...   \n",
       "6713                    0           0                 0             0  ...   \n",
       "39206                   0           0                 0             0  ...   \n",
       "14223                   0           0                 0             0  ...   \n",
       "3475                    1           0                 0             0  ...   \n",
       "\n",
       "       Model_iPhone XR  Model_iPhone XS  Model_iPhone XS Max  Model_style  \\\n",
       "9766                 0                0                    0            0   \n",
       "22672                0                0                    0            0   \n",
       "2300                 0                0                    0            0   \n",
       "15956                0                0                    0            0   \n",
       "27170                0                0                    0            0   \n",
       "...                ...              ...                  ...          ...   \n",
       "11469                0                0                    0            0   \n",
       "6713                 0                0                    0            0   \n",
       "39206                0                0                    0            0   \n",
       "14223                0                0                    0            0   \n",
       "3475                 0                0                    0            0   \n",
       "\n",
       "       Model_style 2  Model_style2  OS_BlackBerry OS  OS_Other  OS_Symbian OS  \\\n",
       "9766               0             0                 0         0              0   \n",
       "22672              0             0                 0         0              0   \n",
       "2300               0             0                 0         0              0   \n",
       "15956              0             0                 0         0              0   \n",
       "27170              0             0                 0         0              0   \n",
       "...              ...           ...               ...       ...            ...   \n",
       "11469              0             0                 0         0              0   \n",
       "6713               0             0                 0         0              0   \n",
       "39206              0             0                 0         0              0   \n",
       "14223              0             0                 0         0              0   \n",
       "3475               0             0                 0         0              0   \n",
       "\n",
       "       OS_iOS  \n",
       "9766        1  \n",
       "22672       1  \n",
       "2300        1  \n",
       "15956       0  \n",
       "27170       0  \n",
       "...       ...  \n",
       "11469       0  \n",
       "6713        0  \n",
       "39206       1  \n",
       "14223       1  \n",
       "3475        0  \n",
       "\n",
       "[12007 rows x 626 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a5fa5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96555851434785\n",
      "0.958339506647074\n"
     ]
    }
   ],
   "source": [
    "stackingscore_train = stacking_estimator.score(X_train, y_train)\n",
    "stackingscore_test = stacking_estimator.score(X_test, y_test)\n",
    "print(stackingscore_train)\n",
    "print(stackingscore_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5295a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9687.605732325752\n",
      "10608.38958448765\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "rmse_stacking_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_stacking_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "print(rmse_stacking_train)\n",
    "print(rmse_stacking_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57b641ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>pred</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>22000</td>\n",
       "      <td>21292.880859</td>\n",
       "      <td>707.119141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22672</th>\n",
       "      <td>39000</td>\n",
       "      <td>39541.265625</td>\n",
       "      <td>-541.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>11000</td>\n",
       "      <td>10095.214844</td>\n",
       "      <td>904.785156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15956</th>\n",
       "      <td>29500</td>\n",
       "      <td>46780.242188</td>\n",
       "      <td>-17280.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27170</th>\n",
       "      <td>49000</td>\n",
       "      <td>47062.917969</td>\n",
       "      <td>1937.082031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price          pred      residual\n",
       "9766   22000  21292.880859    707.119141\n",
       "22672  39000  39541.265625   -541.265625\n",
       "2300   11000  10095.214844    904.785156\n",
       "15956  29500  46780.242188 -17280.242188\n",
       "27170  49000  47062.917969   1937.082031"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = y_test.copy()\n",
    "data[\"pred\"]=pred_test\n",
    "data[\"residual\"] = data[\"Price\"]-data[\"pred\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed18b9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(data[\"pred\"], data[\"residual\"], color=\"red\")\n",
    "plt.title(\"Predicted Price vs Residual\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Price\", fontsize=14)\n",
    "plt.ylabel(\"Residual\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a25b6f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>ROM</th>\n",
       "      <th>RAM</th>\n",
       "      <th>OS</th>\n",
       "      <th>Screen size</th>\n",
       "      <th>Dual Sim</th>\n",
       "      <th>Expandable Memory</th>\n",
       "      <th>5G</th>\n",
       "      <th>Fingerprint Sensor</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Y5 Prime</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Android</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Y5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Android</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone 4S</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>iOS</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Y5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Android</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Y5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Android</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand      Model   ROM  RAM       OS  Screen size  Dual Sim  \\\n",
       "0  Huawei   Y5 Prime  16.0  2.0  Android          5.5         1   \n",
       "1  Huawei         Y5  16.0  2.0  Android          5.7         1   \n",
       "2   Apple  iPhone 4S  16.0  0.5      iOS          3.5         0   \n",
       "3  Huawei         Y5  16.0  2.0  Android          5.7         0   \n",
       "4  Huawei         Y5  16.0  2.0  Android          5.7         1   \n",
       "\n",
       "   Expandable Memory  5G  Fingerprint Sensor  Price  \n",
       "0                  1   0                   1   5000  \n",
       "1                  1   0                   1   5000  \n",
       "2                  0   0                   0   5000  \n",
       "3                  0   0                   0   5000  \n",
       "4                  0   0                   0   5000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.get_dummies(X, columns=[\"Brand\", \"Model\", \"OS\"], drop_first=True)\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04952eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>ROM</th>\n",
       "      <th>RAM</th>\n",
       "      <th>OS</th>\n",
       "      <th>Screen size</th>\n",
       "      <th>Dual Sim</th>\n",
       "      <th>Expandable Memory</th>\n",
       "      <th>5G</th>\n",
       "      <th>Fingerprint Sensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone 11</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64</td>\n",
       "      <td>iOS</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand      Model   ROM  RAM   OS  Screen size  Dual Sim  Expandable Memory  \\\n",
       "0  Apple  iPhone 11  16.0   64  iOS          5.9         0                  0   \n",
       "\n",
       "   5G  Fingerprint Sensor  \n",
       "0   0                   0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [['Brand', \"Apple\"],['Model', \"iPhone 11\"],['ROM', 16.0],['RAM', 64],['OS',\"iOS\"],['Screen size',5.9],['Dual Sim', 0],['Expandable Memory',0],['5G',0],['Fingerprint Sensor',0]]\n",
    "new_data2 = {'Brand': [\"Apple\"],\n",
    "             'Model': [\"iPhone 11\"],\n",
    "             'ROM':[16.0],\n",
    "             'RAM':[64],\n",
    "             'OS':[\"iOS\"],\n",
    "             'Screen size':[5.9],\n",
    "             'Dual Sim':[0],\n",
    "             'Expandable Memory':[0],\n",
    "             '5G':[0],\n",
    "             'Fingerprint Sensor':[0]\n",
    "            }\n",
    "dat2 = pd.DataFrame(new_data2)\n",
    "dat = pd.DataFrame(new_data)\n",
    "dat2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66d2e65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROM</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Screen size</th>\n",
       "      <th>Dual Sim</th>\n",
       "      <th>Expandable Memory</th>\n",
       "      <th>5G</th>\n",
       "      <th>Fingerprint Sensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>64</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROM  RAM  Screen size  Dual Sim  Expandable Memory  5G  Fingerprint Sensor\n",
       "0  16.0   64          5.9         0                  0   0                   0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = pd.get_dummies(dat2, columns=[\"Brand\", \"Model\", \"OS\"], drop_first=True)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ace706d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_test2 \u001b[38;5;241m=\u001b[39m \u001b[43mstacking_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_test2)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:267\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    Predicted targets.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    266\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_estimator_\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:775\u001b[0m, in \u001b[0;36mStackingRegressor.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the predictions for X for each estimator.\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;124;03m        Prediction outputs for each estimator.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:237\u001b[0m, in \u001b[0;36m_BaseStacking._transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 237\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(est, meth)(X)\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m ]\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:238\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    237\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m est, meth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m ]\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1877\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1863\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[0;32m   1864\u001b[0m \n\u001b[0;32m   1865\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1875\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m   1876\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1877\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1880\u001b[0m     \u001b[38;5;66;03m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[0;32m   1881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
     ]
    }
   ],
   "source": [
    "pred_test2 = stacking_estimator.predict(new_data2)\n",
    "print(pred_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f4cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
